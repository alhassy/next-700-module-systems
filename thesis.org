 # -*- eval: (my/execute-startup-blocks) -*-

# C-c C-p ‚áí Produce thesis PDF
#
# HOW TO MAKE PDF: C-e C-e l l    THEN   biber thesis.bcf; time pdflatex --shell-escape thesis.tex
# OR WHEN NARROWED:     biber thesis.bcf; time pdflatex --interaction=nonstopmode --shell-escape thesis.tex
#

#
# (push '("" "titletoc" nil) org-latex-default-packages-alist)

:RequiredModificationToMargin:
#+begin_src emacs-lisp
(bind-key* "C-c C-p" (lambda () (interactive)
                       (org-latex-export-to-latex)
                       (shell-command "biber thesis.bcf; time pdflatex --shell-escape thesis.tex")))

(org-special-block-extras-defblock margin
  (marker nil
          :face '(:foreground "grey" :weight bold
          :underline "orange" :overline "orange"))
  (color "gray!80"
          counter "sidenote"
          width "0.45\\textwidth")
          ;; Width: https://tex.stackexchange.com/a/101861/69371
  :please-inline__no-extra-newlines__k-thx-bye!
  "Produce an HTML tooltip or a LaTeX margin note.

The ‚Äòmargin‚Äô block is intended for ‚Äúone-off‚Äù (mostly optional) remarks.

For notes that you want to use repeatedly, in multiple articles
or in multiple locations in the same article, consider using
‚Äòdocumentation‚Äô to declare them and ‚Äòdoc‚Äô to invoke them.

For LaTeX, place ‚Äò#+resize:‚Äô to have the remainder of a block be
resized, for now 1.3 the margin width ---requires \\usepackage{adjustbox}.

----------------------------------------------------------------------

WIDTH, COUNTER, and COLOR are LaTeX specfic.

When no label, marker, is used for a marginal note, we rely
on a COUNTER, such as ‚Äòfootnote‚Äô (default) or ‚Äòsidenote.‚Äô
Since HTML has no margin per se, we use ‚Äú‚àò‚Äù as default marker:
Users hover over it to read the marginal note.

Marginal notes have their labels, markers, in black
and the notes themselves have COLOR being grey!80.
In Emacs, margin links appear grey with an orange tinted boarder.

Regarding LaTeX, since verbatim environments do not in general work well
as arguments to other commands, such as ‚Äò\\marginpar‚Äô, we save the contents
of the special block in a ‚Äòminipage‚Äô within a LaTeX ‚Äòbox‚Äô; then we can
unfold such
a box in the margin. Hence, ‚Äòsrc‚Äô blocks can appear within ‚Äòmargin‚Äô blocks
(‚Ä¢ÃÄ·¥ó‚Ä¢ÃÅ)Ÿà

The WIDTH argument is the width of the margin; i.e., the width of the
underlying
minipage.

One could use \\maxsizebox{.25\\textwidth}{\\textheight}{ ... }
which only resizes the content if its natural size is larger than
the given ‚å©width‚å™ or ‚å©height‚å™.  We don't use this, since
maxsizebox does not natively allow linebreaks
(e.g., one would wrap contents in a tabular environment then use
‚Äò\\\\‚Äô, two backslashes, to request a line break; but this
crashes if one wants to also use verbatim environments.)

In LaTeX, it may be useful to invoke ‚Äò\\dotfill‚Äô."
  (-let [stepcounter (if marker "" (format "\\stepcounter{%s}" counter))]
    (pcase backend
      (`latex
       (setq marker (or marker (format "{\\the%s}" counter))) ;; "\\circ"
       (format "%s\\!\\!${}^{\\textnormal{%s}}$%%
               \\newsavebox{\\OrgSpecialBlockExtrasMarginBox}%%
               \\begin{lrbox}{\\OrgSpecialBlockExtrasMarginBox}
               \\begin{minipage}{%s}
               \\raggedright \\iffalse Otherwise default alignment is fully justified. \\fi
               \\footnotesize
               \\setminted{fontsize=\\footnotesize, breaklines} \\iffalse HACK! \\fi
               {\\color{black}${}^{\\textnormal{%s}}$}\n\\color{%s}\\normalfont\n %s
               \\end{minipage}
               \\end{lrbox}%%
               \\marginpar{\\usebox{\\OrgSpecialBlockExtrasMarginBox}}%%
               \\hspace{-0ex}%%
               \\global\\let\\OrgSpecialBlockExtrasMarginBox\\relax{}"
               stepcounter
               marker
               width
               marker
               color
               (if (s-contains? "#+resize:" contents)
                   (s-concat
                    (s-replace "#+resize:"
                               "#+latex:\\maxsizebox{1.3\\textwidth}{\\textheight}{\\begin{tabular}{l}\n"
                               (s-trim contents))
                    "\n\\end{tabular}}")
                 (s-trim contents))
               ))
      (_ (setq marker (or marker "¬∞"))
         (format "<abbr class=\"tooltip\" title=\"%s\">%s</abbr>&emsp13;"
                 (org-special-block-extras--poor-mans-html-org-export contents)
                 ; MA: FIXME: (org-export-string-as contents 'html:body-only-please)
                 marker)))))
#+end_src

#+RESULTS:
| :face | (:foreground grey :weight bold :underline orange :overline orange) | :export | (lambda (label description backend) (s-replace-all `((@@ . )) (org-special-block-extras--margin backend (or description label) label :ospe-link? t))) | :help-echo | (lambda (window object position) (save-excursion (goto-char position) (-let* (((&plist :path :format :raw-link :contents-begin :contents-end) (cadr (org-element-context))) (description (when (equal format 'bracket) (copy-region-as-kill contents-begin contents-end) (substring-no-properties (car kill-ring))))) (format %s |


:End:

# +latex_class_options: [notoc]
#+latex_class_options: [oneside, 10pt]
#+LATEX_CLASS: scrbook
# +EXPORT_FILE_NAME: thesis_new

# https://alhassy.github.io/next-700-module-systems/thesis.pdf
#+title: Do-it-yourself Module Systems
# subtitle: We can change things later, but can't change it if there's nothing to change!
# subtitle: The Next 700 Module Systems
# +DESCRIPTION: Thesis for Musa Al-hassy; McMaster University 2020.
# +AUTHOR: [[mailto:alhassm@mcmaster.ca][Musa Al-hassy]]
#+EMAIL: alhassy@gmail.com
#+OPTIONS: toc:nil d:nil title:nil

#+PROPERTY: header-args :tangle no :comments link
#+PROPERTY: header-args:coq :comments none

# At the end of a section, explain why the section is there,
# and what the reader should take away from it.

# MA: LaTeX pads colons, :, with spacing.
# For inline typing annotations, use ghost colon ‚Äú\:‚Äù to avoid this issue.

#+macro: lof @@latex:L\"{o}f@@@@html:LoÃàf@@
#+macro: newline @@latex: \newline@@

# Macros to add tcolorbox title's to certain lists.
# See  https://tex.stackexchange.com/questions/275853/adding-a-table-to-list-of-tables
# Also: https://tex.stackexchange.com/questions/446704/addtocontents-and-minitoc
# Also:
#+latex: \def\TABLE#1{\addcontentsline{lot}{table}{\thesection\;\; #1} #1}
#+latex: \def\FIGURE#1{\addcontentsline{lof}{figure}{\thesection\;\; #1} #1}
#+latex_header: \usepackage{caption} \captionsetup[table]{labelformat=empty}

# Use \caption*{text} to label tables with just ‚Äútext‚Äù instead of ‚ÄúTable ùìÉ: text‚Äù
#+latex: \def\sc{}

# Forbid LaTeX from making linebreaks
#+macro: mbox @@latex: \mbox{@@ $1 @@latex:}@@

#+latex_header: \long\def\ignore#1{}

# MA: Final version should not have the following incantation active.
# +OPTIONS: broken-links:auto

* Immediate dois  :ignore:

# Stale ;; good ideas for another life ---closing.
# https://github.com/alhassy/next-700-module-systems/issues/32
# https://github.com/alhassy/next-700-module-systems/issues/33
# https://github.com/alhassy/next-700-module-systems/issues/34

# Remark: Judgement rules are just constructors of an ADT.
#
# ADTs are intended to be related to grammars, of section
# \ref{sec:what_is_a_language}, so let's actually flesh-out this relationship; the
# mention of ùí≤-types gives a concrete example of how the ‚Äúdo-it-yourself‚Äù appears
# later on in Chapter 5: For the monadic bind, instead of Œ† or Œ£, one can use ùí≤
# ---the latter part of Chapter 5 does not change bind in order to demonstrate
# another technique for making ADTs from contexts.
#

#  Add quote from grothendick about 0 and abstract nonsense.

:Sequents:

The Lhs of a sequent generally acts as a book keeping mechanism. Namely,
implication introduction is awkward otherwise since one has to somehow document
the new assumption, usually via extra-lingustic labels. Interestingly, when we
merge the two, labeling assumptions and keeping track of them locally, we obtain
unique terms that denote the resulting proofs: Lambda terms!! üòØ

:End:

# Mention: Signatures as I have them do not allow for overloading.

# Lots of relevant references is a good thing. It shows you know the
# literature, and thus implicitly convinces the reader that what
# you're doing must be new.

# src_agda[:exports code]{module M (params) where f : œÑ; f = E}
# ‚âà  src_agda2[:exports code]{f : params ‚Üí œÑ; f = E}

:NEW:
We need optional defns in out packages so that their semnatics
is Cartmells theories; even though optional defns are not
used in Agda Context, they are used in the Lisp prototype.
That's why we setup our framework to get to Cartmells GATs.

Add remark about dangers of type-in-type.

Indeed, the choice of term grammar and judegmental rules
‚Äúdo not matter‚Äù; indeed, when we get to the final definition of Cartmell's GATs
we define them over a doubly paramterised family of terms and a ternary judgement relation.
We have only shown a possible judgement relation, not /the/ relation we intend to use;
indeed later on in 2.4 we mention levels for sets, and so do not have
type-in-type.

use fancy header to have sections at each page.
:END:

# some function arguments can be omitted, both to decrease code size and to improve readability.

# \hbox{X} means do not break line my word X
# eg p12 bottom!

# In Ch6 we spoke of 750% line savings; now ``over 80%''
# (original comment here: mention this in Ch4).

# CASL & Maude do things as I do on p27, maybe reference this.


:SOL_modules:
@InProceedings{DBLP:conf/slp/Chen87,
  author       = {Weidong Chen},
  title        = {A Theory of Modules Based on Second-Order Logic},
  year         = 1987,
  booktitle    = {Proceedings of the 1987 Symposium on Logic Programming, San
                  Francisco, California, USA, August 31 - September 4, 1987},
  pages        = {24-33},
  crossref     = {DBLP:conf/slp/1987},
  timestamp    = {Wed, 04 Dec 2013 14:42:59 +0100},
  biburl       = {https://dblp.org/rec/conf/slp/Chen87.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@proceedings{DBLP:conf/slp/1987,
  title     = {Proceedings of the 1987 Symposium on Logic Programming, San Francisco,
               California, USA, August 31 - September 4, 1987},
  publisher = {{IEEE-CS}},
  year      = {1987},
  isbn      = {0-8186-0799-8},
  timestamp = {Wed, 04 Dec 2013 14:42:58 +0100},
  biburl    = {https://dblp.org/rec/conf/slp/1987.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
:End:

:JC:
Back on March 6th, as documented in
https://github.com/alhassy/next-700-module-systems/issues/27 you had both a nice
Story and a nice Outline.
:End:

# 3.3 One completely different solution might be to put the figure in *Chapter
# 1* (!) with annotations attached to every arrow that links to where this is
# defined in the thesis itself. The ultimate in traceability! The¬†move to Ch1
# sounds like a great idea! :-)

:PointsOfCh2:

For reference, here are the main points:

   - (1) What is a language? (2) Signatures (3) Presentations of Signatures
   - (4) A whirlwind tour of Agda, (5) Facets of Structuring Mechanisms
   - (6) Contexts are Promising, (7) Coq modules as Generalised Signatures
   - (8) Problem of the thesis, (9) Thesis outcomes

   I've organised the points into groups, for each bullet ‚Äò-‚Äô, since I think
   they're related.

   The first group is intended to be an introduction to the background material
   to get the reader comfortable with Œ£ and Œ†.

   The next then recasts the previous within the setting of Agda,
   and tries to show interdefinability of different notions of packaging
   thereby showing that packages ‚âà contexts ‚âà modules is a promising idea.

   The third group aims to be ‚Äòrelated works‚Äô.

   The final group wraps up with a reminder on why we're even bothing talking
   about Œ£, Œ†, and Agda.

   Personally, this is how I currently see Chapter 2:
   (1, 2, 3) What are the weird symbols Œ£ and Œ†?
   (4, 5) How do we get them in a computer, where are they in our software?
   (6 ,7) Where else are these weird symbols?
   (8, 9) What's the thesis doing for/with them?

   From that, things seem to be coherent.

   I do agree that [possibly simplified] versions of (8, 9) belong in Chapter 1.
:End:

:Meaning:
You and I /might/ look at ‚Äú‚àû‚Äù and think ‚Äúinfintiy‚Äù but a person speaking Tagalog
/might/ think that is the ‚ÄúHa‚Äù syllable. The meaning is not in the symbol, but in
the reader.
:End:

* Neato petito margins :ignore:

#+latex_header: \usepackage[includemp,
#+latex_header:             paperwidth=18.90cm,
#+latex_header:             paperheight=24.58cm,
#+latex_header:             top=2.170cm,
#+latex_header:             bottom=3.510cm,
#+latex_header:             inner=2.1835cm,
#+latex_header:             outer=2.1835cm,
#+latex_header:             hmargin=15mm, vmargin=20mm,
#+latex_header:             marginparwidth=5cm,
#+latex_header:             marginparsep=0.4cm]{geometry}
#+latex_header: \usepackage{marginfix}
#+latex_header:
#+latex_header: % no margins
#+latex_header: \def\nomargins{
#+latex_header: \newgeometry{top=2.170cm,
#+latex_header:             bottom=3.510cm,
#+latex_header:             inner=2.1835cm,
#+latex_header:             outer=2.1835cm,
#+latex_header:             ignoremp}}
#+latex_header: \def\yesmargins{\restoregeometry}
# Actually, these force new pages; so let's do something else.
#+latex_header: \newenvironment{fullwidth}{\begin{minipage}{15.5cm}}{\end{minipage}}
# +latex: \begin{fullwidth}
# words
# +latex: \end{fullwidth}

# Must be at the top!
#+latex_header: \let\OGfootnote\footnote

#+latex_header:
#+latex_header: \usepackage{adjustbox}
#+latex_header: \usepackage{xcolor} % named colours
#+latex_header:
#+latex_header: % https://ctan.math.ca/tex-archive/macros/latex/contrib/snotez/snotez_en.pdf
#+latex_header: \usepackage[footnote]{snotez} % Give us the command \sidenote
#+latex_header: \setsidenotes{text-mark-format=\textsuperscript{\normalfont{#1}},
#+latex_header:               note-mark-format=#1, % e.g., ‚Äú#1:‚Äù
#+latex_header:               note-mark-sep=\enskip}
#+latex_header:
#+latex_header: \def\remark#1{\begingroup%
#+latex_header: % \renewcommand\sidenotemark{\color{white}}
#+latex_header: \sidenote[\enspace]{\color{gray!80}\hspace{-1em}\noindent #1}\endgroup}
#+latex_header:
#+latex_header:
#+latex_header: % ignore grey of \remark
#+latex_header: \def\remarkfigure#1{\remark{\color{black}\large\maxsizebox{0.6\textwidth}{\textheight}{#1}}}
#+latex_header:

# footecitet takes only ONE argument.
#+latex: \def\footcitet#1{\stepcounter{sidenote}{\let\thefootnote\thesidenote\OGfootnote{\,\fullcite{#1}}}}

# an honest to goodness footnote
#+latex: \def\FOOTNOTE#1{\stepcounter{sidenote}{\let\thefootnote\thesidenote\OGfootnote{\,#1}}}

#+latex: % For some reason, this cannot be in the header!
#+latex: \def\footnote#1{\stepcounter{sidenote}$^{\thesidenote}$\sidenote[$\,$]{\hspace{-1.2em}
#+latex:     $^{\thesidenote}$ \color{gray!80} #1}}
#+latex:

# https://tex.stackexchange.com/questions/159118/how-to-iterate-over-a-comma-separated-list
#+latex_header: \usepackage{xparse}
#+latex_header: \ExplSyntaxOn
#+latex_header:
# +latex_header: \NewDocumentCommand{\sidecite}{ m }
# +latex_header:  {
# +latex_header:   \cite{#1}\clist_map_inline:nn { #1 } {\remark{\cite{##1}\hspace{0.6em} \fullcite{##1}\\}}%\hspace{-0.9em}
# +latex_header:  }
#+latex_header:
#+latex_header: \NewDocumentCommand{\sidecite}{ m }
#+latex_header:  {{\setsidenotes{note-mark-sep=\relax}%
#+latex_header:   \cite{#1}\clist_map_inline:nn { #1 } {\sidenote[\relax]{\color{gray!80}\noindent\cite{##1}\hspace{0.6em} \fullcite{##1}}}%
#+latex_header:  }}
#+latex_header:
#+latex_header: \ExplSyntaxOff
#+latex_header:
# +latex: \def\sidecite#1{\cite{#1} \remark{\fullcite{#1}}}



# for some reason, I need this footnote before anything else will work; eg toc wont render!
 #+begin_export latex
% \footnote{\sc Draft}
 #+end_export
# MA: I just placed a footnote /before/ the toc!

 # Treat citet:X as \sidecite{X}
#+NAME: startup-code
#+begin_src emacs-lisp :exports none :results silent
(maybe-clone "https://github.com/armkeh/unicode-sty.git")

(org-link-set-parameters
  "citet"
  :follow (lambda (label) )
  :export (lambda (label description backend)
            (format (pcase backend
                      ('latex "\\sidecite{%s}")
                      (_ "I don‚Äôt know how to export that!"))
                    label)))
#+end_src
** COMMENT Documentation
- \remark
- \remarkfigure
- \sidecite

** COMMENT Examples
 #+latex: A\footnote{A}
 #+latex: B\sidenote{S}
 #+latex:
 #+latex: \vspace{1ex}
 #+latex: C AV\marginnote{C and then some }
 #+latex:
 #+latex: \setcounter{secnumdepth}{3}
 #+latex:
 hola

 The framework developed in this thesis is motivated by the following concerns
 when developing libraries in the dependently-typed language (DTL) Agda, such as
 citet:RATH,tpc,dtl_why.

 #+latex: and \fullcite{tpc}

 The framework developed in this thesis is motivated by the following concerns
 when developing libraries in the dependently-typed language (DTL) Agda, such as
 #+latex: \cite{RATH} or \sidecite{RATH, tpc}.


 but yet
 # look at sidecitet:dtl_why

 #+begin_export latex
 \remarkfigure{
 \smartdiagram[constellation diagram]{
  {Monoids}
 ,{Monoids \emph{with} carrier \texttt{C}}
 ,{\mbox{\hspace{-1.7em}Homomorphisms}, \mbox{products}, duals}
 ,{\mbox{Signature} \mbox{(Tree} \mbox{skeleton)}}
 ,{Pointed Magma} % \\ (‚ÄúExclusion‚Äù)
 ,{Terms \\ \mbox{\hspace{-0.5em}(Trees with} \mbox{variables)}}
 ,{Monoids \emph{over} a setoid}
 % ,Universal Algebra constructions
 ,{Monoids \mbox{\hspace{-0.5em}\emph{with} carrier \texttt{C}}
    \mbox{\hspace{-0.5em}\emph{and} operation} $\_{}\oplus\_{}$}}
 }
 or
 \remarkfigure{
 \smartdiagram[priority descriptive diagram]{
  {Monoids}
 ,{Monoids \emph{with} carrier \texttt{C}}
 ,{\mbox{\hspace{-1.7em}Homomorphisms}, \mbox{products}, duals}
 ,{\mbox{Signature} \mbox{(Tree} \mbox{skeleton)}}
 ,{Pointed Magma} % \\ (‚ÄúExclusion‚Äù)
 ,{Terms \\ \mbox{\hspace{-0.5em}(Trees with} \mbox{variables)}}
 ,{Monoids \emph{over} a setoid}
 % ,Universal Algebra constructions
 ,{Monoids \mbox{\hspace{-0.5em}\emph{with} carrier \texttt{C}}
    \mbox{\hspace{-0.5em}\emph{and} operation} $\_{}\oplus\_{}$}}
 }

 \vspace{2em}

 \footnote{There is no number in this footnote}


 \remark{neato!}

 The framework developed in this thesis is motivated by the following concerns
 when developing libraries in the dependently-typed language (DTL) Agda, such as
 \footnote{Monoids \mbox{\emph{with} carrier \texttt{C}} \mbox{\emph{and} operation} $\_{}\oplus\_{}$}

 #+end_export

\marginnote[0.7cm]{
  X is defined in arefsubsec{Y}, in refch{Z}.
}
* Preamble & title page                                              :ignore:

# Top level editorial comments.
#+MACRO: remark  @@latex: \fbox{\textbf{Comment: $1 }}@@

#+latex_header: \usepackage{multicol}
#+latex_header: \usepackage{glossaries}
# +latex_header: \makeglossaries
#+latex_header: \hyphenation{
#+latex_header: no-tatio-nal
#+latex_header: combi-na-tors
#+latex_header: name-spacing
#+latex_header: }

** Unicode                                                           :ignore:
# https://armkeh.github.io/unicode-sty/
# On line 27, remove: amsmath and amsthm
#+LATEX_HEADER: \usepackage{\string~"/unicode-sty/unicode"}

# +LATEX_HEADER: \usepackage{papers/UnicodeSymbols}
#+latex_header: \usepackage{newunicodechar}
#+latex_header: \newunicodechar{√ó}{\ensuremath{\times}}
#+latex_header: \newunicodechar{‚ôØ}{\ensuremath{\sharp}}
#+latex_header: \newunicodechar{‚®æ}{\ensuremath{\mathop{\fatsemi}}}
#+latex_header: \newunicodechar{‚Ä≤}{\ensuremath{'}}
#+latex_header: \newunicodechar{‚Ä≥}{\ensuremath{''}}
#+latex_header: \newunicodechar{‚Äµ}{\ensuremath{`}}

#+latex_header: \newunicodechar{ Ãá}{\ensuremath{{}^.}}


#+latex_header: \newunicodechar{‚Üª}{\ensuremath{\circlearrowright}}
#+latex_header: \newunicodechar{‚Ü∫}{\ensuremath{\circlearrowleft}}

#+latex_header: \newunicodechar{‚àé}{\ensuremath{\qed}}
#+latex_header: \newunicodechar{‚òÖ}{\ensuremath{\star}}
#+latex_header: \newunicodechar{‚Çì}{\ensuremath{{}_\times}}

#+latex_header: \newunicodechar{ ÃÄ}{`}

** Art :ignore:
#+latex_header: \usepackage{tikz}
#+latex_header: \usetikzlibrary{decorations.text,calc,arrows.meta}

# +latex: \FloatBarrier
# The FloatBarrier stops floats (figures are floats) from jumping over them. I
# will need to look into passing [tbh] options to figures from org mode further.
#+LATEX_HEADER: \usepackage{placeins}

# Now ‚Äúquoteit‚Äù blocks have their contents italicised.
#+latex_header: \newenvironment{quoteit}{\begin{quote}\itshape}{\end{quote}}

** Minted setup -- colouring code blocks                             :ignore:

#+LATEX_HEADER: \usepackage{minted}

#+LATEX_HEADER: \usepackage{tcolorbox}
#+latex: \tcbset{colback=green!10!white}
# \tcbsetforeverylayer{colframe=red!75!black}
#+latex: \newtcolorbox{myexamplebox}[1]{title=#1,
#+latex: colback=red!5!white, colframe=red!75!black, colbacktitle=yellow!50!red, coltitle=red!25!black, fonttitle=\bfseries,
#+latex: subtitle style={boxrule=0.4pt, colback=yellow!50!red!25!white}}

#+latex_header: \tcbuselibrary{breakable}
#+latex_header: \tcbuselibrary{skins}
#+latex_header_extra: \newtcolorbox{mybox}[2][]{colback=red!5!white,colframe=red!75!black,fonttitle=\bfseries,colbacktitle=red!85!black,title=#2,#1}
#+latex_header_extra: \newtcolorbox{myboxB}[2][]{colback=red!5!white,colframe=red!75!black,fonttitle=\bfseries,colbacktitle=red!85!black,enhanced,skin=enhanced jigsaw,breakable,title=#2,#1}

# Print a local, chapter based, toc within a pleasant box
#+MACRO: localtoc \begin{tcolorbox}[title=Chapter Contents, colback=red!5!white,  colframe=blue!50!red] \startcontents[level-1]  \printcontents[level-1]{}{0}{\setcounter{tocdepth}{5}} \end{tcolorbox}

#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \def\mytitle{??? Program Code ???}
#+LATEX_HEADER: \BeforeBeginEnvironment{minted}{\begin{tcolorbox}[title=\hfill \mytitle]}%
#+LATEX_HEADER: \AfterEndEnvironment{minted}{\end{tcolorbox}}%

# begin_example blocks are surrounded with blocks WITHOUT a title;
# this makes them useful to refer to them as captioned figures.
#+LATEX_HEADER: \BeforeBeginEnvironment{verbatim}{\begin{tcolorbox}}%
#+LATEX_HEADER: \AfterEndEnvironment{verbatim}{\end{tcolorbox}}%


# Before a code block, write {{{code(title-of-block)}}}
# #
#+MACRO: code     @@latex:\def\mytitle{$1}@@
# +MACRO: code      #+attr_latex: :options title=$1

# let's always break newlines, with a ‚Äò‚Ü™‚Äô indicated new lines.
#+LaTeX: \setminted[haskell]{fontsize=\footnotesize, breaklines}
#+LaTeX: \setminted[agda]{fontsize=\footnotesize, breaklines}
#+LaTeX: \setminted[agda2]{fontsize=\footnotesize, breaklines}
#+LaTeX: \setminted[common-lisp]{fontsize=\footnotesize, breaklines}
# https://tex.stackexchange.com/questions/406862/different-fontsize-for-minted-and-mintinline
#
#+latex: \makeatletter
#+latex: \newcommand{\currentfontsize}{\fontsize{\f@size}{\f@baselineskip}\selectfont}
#+latex: \makeatother
#+latex:
#+latex: \setmintedinline{fontsize=\currentfontsize}

# LaTeX doesn't allow \def's in a \def; but a \def may occur in a \ [re]newcommand.
# +LATEX_HEADER: \BeforeBeginEnvironment{listing}{ \let\oldcaption\caption \renewcommand{\caption}[1]{ \def\mytitle{#1} } }%
# +LATEX_HEADER: \AfterEndEnvironment{listing}{ \let\caption\oldcaption }%
# #
# This doesn't work since org inserts \caption !after! the minted block, which
# needs the \mytitle.



# Nope.
# +LATEX_HEADER: \BeforeBeginEnvironment{tablular}{\begin{tcolorbox}}%
# +LATEX_HEADER: \AfterEndEnvironment{tabular}{\end{tcolorbox}}%

** LaTeX setup                                                       :ignore:

# Hijacking \date to add addtional text to the frontmatter of a ‚Äòreport‚Äô.
#
#
# DATE: \today\vfill \centerline{---Supervisors---} {{{newline}}} [[mailto:carette@mcmaster.ca][Jacques Carette]] and [[mailto:kahl@cas.mcmaster.ca][Wolfram Kahl]]

# +LATEX_HEADER: \usepackage[hmargin=25mm,vmargin=25mm]{geometry}
# +LaTeX_HEADER: \setlength{\parskip}{1em}

# +latex_class_options: [12pt]
# +LATEX_CLASS: report-noparts
# +LATEX_CLASS: kaobook
# Defined below.
#
# Double spacing:
# LaTeX: \setlength{\parskip}{3em}\renewcommand{\baselinestretch}{2.0}
#
#+LATEX_HEADER: \setlength{\parskip}{1em}

#+LATEX_HEADER: \usepackage{xcolor} % named colours
# +LATEX_HEADER: \usepackage[dvipsnames]{xcolor} % named colours
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \definecolor{darkred}{rgb}{0.3, 0.0, 0.0}
#+LATEX_HEADER: \definecolor{darkgreen}{rgb}{0.0, 0.3, 0.1}
#+LATEX_HEADER: \definecolor{darkblue}{rgb}{0.0, 0.1, 0.3}
#+LATEX_HEADER: \definecolor{darkorange}{rgb}{1.0, 0.55, 0.0}
#+LATEX_HEADER: \definecolor{sienna}{rgb}{0.53, 0.18, 0.09}
#+LATEX_HEADER_EXTRA: \hypersetup{colorlinks,linkcolor=darkblue,citecolor=darkblue,urlcolor=darkgreen}
#+LATEX_HEADER_EXTRA: \urlstyle{same}
#+NAME: symbols for itemisation environment
#+BEGIN_EXPORT latex
\def\labelitemi{$\diamond$}
\def\labelitemii{$\circ$}
\def\labelitemiii{$\star$}

% Level 0                 Level 0
% + Level 1               ‚ãÑ Level 1
%   - Level 2       --->      ‚àò Level 2
%     * Level 3                   ‚ãÜ Level 3
%
#+END_EXPORT

# Having small-font code blocks.
# LATEX_HEADER: \RequirePackage{fancyvrb}
# LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}

** \sc and old friends :ignore:

# https://www.tug.org/pipermail/tex-live/2016-July/038985.html
# [tex-live] Class scrartcl Error: undefined old font command '\it' and '\rm'
#
#+latex_header: \makeatletter
#+latex_header: \DeclareOldFontCommand{\rm}{\normalfont\rmfamily}{\mathrm}
#+latex_header: \DeclareOldFontCommand{\sf}{\normalfont\sffamily}{\mathsf}
#+latex_header: \DeclareOldFontCommand{\tt}{\normalfont\ttfamily}{\mathtt}
#+latex_header: \DeclareOldFontCommand{\bf}{\normalfont\bfseries}{\mathbf}
#+latex_header: \DeclareOldFontCommand{\it}{\normalfont\itshape}{\mathit}
#+latex_header: \DeclareOldFontCommand{\sl}{\normalfont\slshape}{\@nomath\sl}
#+latex_header: \DeclareOldFontCommand{\sc}{\normalfont\scshape}{\@nomath\sc}
#+latex_header: \makeatother
#+latex_header:

** ~reports-noparts~ LaTeX Class                                   :noexport:

A custom version of the reports class which makes the outermost headings
chapters, rather than parts.
#+NAME: startup-code
#+BEGIN_SRC emacs-lisp :results none
(setq org-latex-caption-above nil)

;; https://orgmode.org/org.html#Table-of-Contents
;; #+TOC: headlines 1 local
(push '("" "titletoc" nil) org-latex-default-packages-alist)

(add-to-list 'org-src-lang-modes '("agda" . haskell))
(add-to-list 'org-src-lang-modes '("agda2" . haskell))

(add-to-list
  'org-latex-classes
    '("report-noparts"
      "\\documentclass{report}"
      ("\\chapter{%s}" . "\\chapter*{%s}")
      ("\\section{%s}" . "\\section*{%s}")
      ("\\subsection{%s}" . "\\subsection*{%s}")
      ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
      ("\\paragraph{%s}" . "\\paragraph*{%s}")
      ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+END_SRC
#+NAME: startup-code
#+BEGIN_SRC emacs-lisp :results none
(add-to-list
  'org-latex-classes
    '("scrbook"
      "\\documentclass{scrbook}"
      ("\\chapter{%s}" . "\\chapter*{%s}")
      ("\\section{%s}" . "\\section*{%s}")
      ("\\subsection{%s}" . "\\subsection*{%s}")
      ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
      ("\\paragraph{%s}" . "\\paragraph*{%s}")
      ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+END_SRC

** COMMENT Fancy chapter headings                                            :ignore:
#+latex_header: \usepackage[Bjornstrup]{fncychap}
#+latex:  % Options: Sonny, Lenny, Glenn, Conny, Rejne, Bjarne, Bjornstrup
#+latex:  % defaults:
#+latex:  %\ChNameVar{\Large\sf}
#+latex:  %\ChNumVar{\Huge}
#+latex:  %\ChTitleVar{\Large\sf}

#+begin_export latex
% Change colour of fncychap
% https://tex.stackexchange.com/questions/36902/questions-about-bjornstrup
% https://tex.stackexchange.com/questions/89922/how-do-you-change-the-font-when-using-fncychap

\colorlet{partbgcolor}{gray!30}% shaded background color for parts
\colorlet{partnumcolor}{gray}% color for numbers in parts
\colorlet{chapbgcolor}{gray!30}% shaded background color for chapters
\colorlet{chapnumcolor}{gray}% color for numbers in chapters

\newcommand*\partformat{%
  \fontsize{76}{80}\usefont{T1}{pzc}{m}{n}\selectfont%
  \hfill\textcolor{partnumcolor}{\thepart}}

\makeatletter
\renewcommand*{\@part}{}
\def\@part[#1]#2{%
  \ifnum \c@secnumdepth >-2\relax
    \refstepcounter{part}%
    \@maybeautodot\thepart%
    \addparttocentry{\thepart}{#1}%
  \else
    \addparttocentry{}{#1}%
  \fi
  \begingroup
    \setparsizes{\z@}{\z@}{\z@\@plus 1fil}\par@updaterelative
    \raggedpart
    \interlinepenalty \@M
    \normalfont\sectfont\nobreak
    \setlength\fboxsep{0pt}
    \colorbox{partbgcolor}{\rule{0pt}{40pt}%
    \makebox[\linewidth]{%
    \begin{minipage}{\dimexpr\linewidth+20pt\relax}
      \ifnum \c@secnumdepth >-2\relax
        \vskip-25pt
        \size@partnumber{\partformat}%
      \fi      %
      \vskip\baselineskip
      \hspace*{\dimexpr\myhi+10pt\relax}%
      \parbox{\dimexpr\linewidth-2\myhi-20pt\relax}{\raggedleft\LARGE#2\strut}%
      \hspace*{\myhi}\par\medskip%
    \end{minipage}%
      }%
    }%
    \partmark{#1}\par
  \endgroup
  \@endpart
}

\renewcommand\DOCH{%
  \settowidth{\py}{\CNoV\thechapter}
  \addtolength{\py}{-10pt}
  \fboxsep=0pt%
  \colorbox{chapbgcolor}{\rule{0pt}{40pt}\parbox[b]{\textwidth}{\hfill}}%
  \kern-\py\raise20pt%
  \hbox{\color{chapnumcolor}\CNoV\thechapter}\\%
}

\renewcommand\DOTI[1]{%
  \nointerlineskip\raggedright%
  \fboxsep=\myhi%
  \vskip-1ex%
  \colorbox{chapbgcolor}{\parbox[t]{\mylen}{\CTV\FmTi{#1}}}\par\nobreak%
  \vskip 40pt%
}

\renewcommand\DOTIS[1]{%
  \fboxsep=0pt
  \colorbox{chapbgcolor}{\rule{0pt}{40pt}\parbox[b]{\textwidth}{\hfill}}\\%
  \nointerlineskip\raggedright%
  \fboxsep=\myhi%
  \colorbox{chapbgcolor}{\parbox[t]{\mylen}{\CTV\FmTi{#1}}}\par\nobreak%
  \vskip 40pt%
 }
\makeatother


% http://latexcolor.com/
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{deepskyblue}{rgb}{0.0, 0.75, 1.0}
        \definecolor{deeppink}{rgb}{1.0, 0.08, 0.58}
\colorlet{partbgcolor}{red}% shaded background color for parts
\colorlet{partnumcolor}{red}% color for numbers in parts
\colorlet{chapbgcolor}{deepskyblue}% shaded background color for chaps
\colorlet{chapnumcolor}{red}% color for numbers in chaps

#+end_export

** more ltx headers :ignore:

#+latex_header:  \usepackage{mathpartir, proof}
#+latex_header_extra: \newunicodechar{√ó}{\ensuremath{\times}}
#+latex_header_extra: \newunicodechar{‚ãÜ}{\ensuremath{\star}}
#+latex_header_extra: \newunicodechar{‚àê}{\ensuremath{\coprod}}
#+latex_header_extra: \newunicodechar{‚àé}{\ensuremath{\qedsymbol}}
#+latex_header: \usepackage{smartdiagram}
#+LATEX_HEADER: \usepackage{placeins}
# +latex: \FloatBarrier
# The FloatBarrier stops floats (figures are floats) from jumping over them. I
# will need to look into passing [tbh] options to figures from org mode further.

** COMMENT Removing the red box that appears in "minted" when using unicode :ignore:
# Src: https://tex.stackexchange.com/questions/343494/minted-red-box-around-greek-characters
#
#+LATEX_HEADER_EXTRA: \makeatletter
#+LATEX_HEADER_EXTRA: \AtBeginEnvironment{minted}{\dontdofcolorbox}
#+LATEX_HEADER_EXTRA: \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
#+LATEX_HEADER_EXTRA: \makeatother

** Personal title page                                               :ignore:

#+latex: \nomargins
#+begin_center org

#+begin_export latex
\thispagestyle{empty}

{\color{white}{.}}

\vspace{5em}

% {\Huge The Next 700 Module Systems}
{\Huge Do-it-yourself Module Systems}

\vspace{1ex}

{\Large Extending Dependently-Typed Languages to Implement
\\ Module System Features In The Core Language}

\vspace{2em}

Department of Computing and Software

McMaster University

\vspace{2em}
\href{mailto:alhassy@gmail.com}{Musa Al-hassy}

\vspace{2em}
\today
#+end_export

\vfill

{{{code({\sc PhD Thesis \hspace{15em} \color{gray}{.} })}}}
#+begin_src haskell
-- Supervisors                                                       -- Emails
Jacques Carette                                                      carette@mcmaster.ca
Wolfram Kahl                                                         kahl@cas.mcmaster.ca
#+end_src
#+end_center

:Hide:
#+begin_edcomm org
:ed: WK
Please resolve references before you ship PDF...
#+end_edcomm
:End:

# LaTeX: \centerline{\sc Draft}* Abstract and toc                                                   :ignore:
   :PROPERTIES:
   :CUSTOM_ID: abstract
   :END:

 # Use:  x vs.{{{null}}} ys
 # This informs LaTeX not to put the normal space necessary after a period.
 #
 #+MACRO: null  @@latex:\null{}@@

:HideAbstract_and_toc:
#+begin_abstract

 Structuring-mechanisms, such as Java's ~package~ and Haskell's ~module~, are often
 afterthought secondary citizens whose primary purpose is to act as namespace
 delimiters, while relatively more effort is given to their abstraction
 encapsulation counterparts, e.g., Java's classes and Haskell's typeclasses. A
 /dependently-typed language/ (DTL) is a typed language where we can write /types/
 that depend on /terms/; thereby blurring conventional distinctions between a
 variety of concepts. In contrast, languages with non-dependent type systems
 tend to distinguish /external vs.{{{null}}} internal/ structuring-mechanisms
 ---as in Java's ~package~ for namespacing vs.{{{null}}} ~class~ for abstraction
 encapsulation--- with more dedicated attention and power for the internal case
 ---as it is expressible within the type theory.

 #+latex: \vspace{1ex}

 To our knowledge, relatively few languages ---such as OCaml, Maude, and the B
 Method--- allow for the manipulation of external structuring-mechanisms as they
 do for internal ones. Sufficiently expressive type systems, such as those of
 dependently typed languages, allow for the internalisation of many concepts
 thereby conflating a number of traditional programming notions. Since DTLs
 permit types that depend on terms, the types may require non-trivial term
 calculation in order to be determined. Languages without such expressive type
 systems necessitate certain constraints on its constructs according to their
 intended usage. It is not clear whether such constraints have been brought to
 more expressive languages out of necessity or out of convention. Hence we
 propose a systematic exploration of the structuring-mechanism design space for
 dependently typed languages to understand /what are the module systems for DTLs?/

 #+latex: \vspace{1ex}

 First-class structuring-mechanisms have values and types of their own which
 need to be subject to manipulation by the user, so it is reasonable to consider
 manipulation combinators for them from the beginning. Such combinators would
 correspond to the many generic operations that one naturally wants to perform
 on structuring-mechanisms ---e.g., combining them, hiding components, renaming
 components--- some of which, in the external case, are impossible to perform in
 any DTL without resorting to third-party tools for pre-processing. Our aim is
 to provide a sound footing for systems of structuring-mechanisms so that
 structuring-mechanisms become another common feature in dependently typed
 languages. An important contribution of this work is an Agda implementation of
 our module combinators ---which we hope to be accepted into a future release of
 the Agda standard library.

 If anything, our aim is practical ---to save developers from ad hoc copy-paste
 preprocessing hacks.
 #+begin_center org
 #+begin_small
 ---Source: https://github.com/alhassy/next-700-module-systems---
 #+end_small
 #+end_center
 #+end_abstract

#+latex: \newpage
#+latex: \thispagestyle{empty}
#+latex: \tableofcontents
# +TOC: headlines 4
# Change the titles from ‚ÄúList of ùí≥‚Äù to something else.
# +latex: \renewcommand{\listfigurename}{List of ???}
# +latex: \renewcommand{\listtablename}{Tables}
# +latex: \listoffigures
#+latex: \listoftables

#+begin_edcomm
:ed: Editor Remark

Re-read everything and make sure if anything is ‚Äòpartly borrowed‚Äô from another
source then it is properly cited!

‚ÄúIf you knowingly ‚Äúborrowed‚Äù even one clause, let alone one sentence, then you
have committed plagiarism. Think of it this way: Plagiarism is another word for
theft. That‚Äôs exactly what it is. Were you to open a bag of bread in a grocery
store and eat one piece of bread, leaving the remainder of the bag on the shelf,
you would have knowingly stolen that one piece of bread. The fact that you
didn‚Äôt take the rest of the bread with you doesn‚Äôt negate the theft of that one
piece. That one sentence you noted is like that one piece of bread. It‚Äôs
stolen. It wasn‚Äôt yours. You didn‚Äôt own it. You took it from someone
else. Someone had to write that sentence in order for it to exist. By cutting
and pasting it into your ‚Äúoriginal‚Äù work, you committed theft. So, yes,
plagiarism even comes down to one sentence.‚Äù ---Ninth Ward Goethe
#+end_edcomm
:End:

#+latex: \newpage

** Abstract                                                  :ignore:

#+begin_center
*Abstract*
#+end_center

   In programming languages, record types give a
   universe of discourse (via so-called Œ£-types);
   parameterised record types fix parts of that universe
   ahead of time (via Œ†-types),
   and algebraic datatypes give us first-class syntax (via ùí≤-types),
   which can then be used to program, e.g., evaluators and optimisers.
   A frequently-encountered issue in library design for statically-typed languages
   is that, for example, the algebraic datatype
   implementing the first-class view of the language induced by a record
   declaration cannot be defined by simple reference to the record type
   declaration, nor to any common ``source''.
   This leads to unwelcome repetition, and to maintenance burdens.
   Similarly, the ``unbundling problem'' concerns similar
   repetition that arises for variants of record types
   where some fields are turned into parameters.

   The goal of this thesis is to show how,
   in dependently-typed languages (DTLs),
   algebraic datatypes and parameterised record types
   can be obtained from a single pragmatic declaration /within/ the
   dependently-typed language itself, without using a separate ``module language''.
   Besides this
   practical shared declaration interface, which is extensible in the language,
   we also find that common data structures correspond to simple theories.

   #    Put simply, the topic of the thesis is summarised as follows:
   Put simply, the thesis is about making tedious /and/ inexpressible patterns of
   programming in DTLs (dependently typed languages) become mechanical /and/
   expressible.  The situations described above occur frequently when working in a
   dependently-typed language, and it is reasonable enough to have the computer
   handle them.

   We develop a notion of /contexts/ that serve as common source
   for definitions of algebraic datatype and of parameterised record types,
   and demonstrate a ``language'' of ``package operations'' that
   enables us to avoid the above-mentioned replication
   that pervades current library developments.

   One the one hand, we demonstrate an implementation of that language
   as integrated editor functionality --- this makes it possible
   to directly emulate the different solutions that are employed
   in current library developments, and refactor these
   into a shape that uses single declaration of contexts,
   thus avoiding the usual repetition that is otherwise required for
   provision of record types at different levels of parameterisation
   and of algebraic datatypes.

   On the other hand, we will demonstrate that the power of dependently-typed
   languages is sufficient to implement such package operations in a
   statically-typed manner /within/ the language;
   using this approach will require adapting to the accordingly-changed library
   interfaces.

   Although our development uses the dependently-typed programming language
   Agda throughout,
   we emphasise that the /idea/ is sufficiently generic to be implemented in other
   DTLs.


 #+latex: \ignore{
   In fact, we can have the computer do so
   not just via string manipulation but instead using the DTL itself.

   0. There are specific things we do as people to get things
      done. (Chapter \ref{sec:examples_from_the_wild})
   1. These specific things are tedious and mostly mechanical.
   2. Agda cannot let us accomplish these goals directly. (Chapter
      \ref{sec:packages_and_their_parts})
   3. However, Agda allows a *pragmatic* approach to do so by rolling-out our own
      approach to modules: src_haskell[:exports code]{Context}. (Chapter \ref{sec:contexts})
   4. It's pragmatic since it's an Agda library /using/ monadic
      src_haskell[:exports code]{do}-notation and using Agda's type checking as
      well as all of its features, such as termination and well-definedness
      checking.  The cost of such a library is that it is not as smooth as a
      built-in grouping mechanism.
   5. Finally, the /idea/ is sufficiently generic to be implemented in other DTLs;
      so the solution to (2) generalises to any DTL sufficient for implementing
      src_haskell[:exports code]{Context} ---the stronger the DTL, the more of
      src_haskell[:exports code]{Context}'s combinators can be implemented, the
      more module combinators one has in hand. This idea is fleshed out
      abstractly in Chapter \ref{sec:Pi-Sigma-W}, and also in Chapter
      \ref{sec:contexts} by providing the key insightful syntactic
      transformations on a DTL's grammar.

As an application, it is useful to have large libraries with diverse redundancy
---so users can solve problems in any way they like--- but they are hard to
build (Chapter \ref{sec:examples_from_the_wild}); in particular, it is costly to
keep structure in-sync.  We look at one particular problem: Structure
unbundling; i.e., exposing hidden fields as if they were parameters and
conversely packing away parameters as if they were fields.  Along the way, we
end up looking at other useful operations on packages that are useful for
library building (Chapter \ref{sec:PF}).
#+latex: }

#+latex: \yesmargins
** A middle-path with margins :ignore:

#+latex: \setcounter{footnote}{0}% \stepcounter{sidenote}

#+begin_center
*A middle-path with margins*
#+end_center

Imagine having to stop reading mid-sentence, go to the bottom of the page, read
a footnote, then stumble around till you get back to where you were
@@latex:reading\footnote{No more such oppression! \newline Consequently, we
reset sidenote counters at the start of each chapter.}.@@ Even worse is when one
seeks a cryptic abbreviation and must decode it a world-away, in the references
at the end of the document.

I would like you to be able to read this work /smoothly, with minimal
interruptions/. As such, inspired by Graham, Knuth and Patashnik's ``Concrete
Mathematics'' citet:DBLP:books/aw/GKP1994 among others, we have opted to include
‚Äúmathematical graffiti‚Äù in the margins.  In particular, the margins side notes
may have /informal and opinionated/
@@latex:remarks\footnote{\color{gray!80}Professional academic writing to the
left; here in the right we take a relaxed tone.}.@@ We're trying to avoid being
too dry, and aim at being somewhat light-hearted.

Dijkstra citet:EWD:EWD1300 might construe the graffiti as /mathematical
politeness/ that could potentially save the reader a minute.  Even though a
characteristic of academic writing is its terseness,
we don't want to baffle or puzzle our readers, and so we use the
informality of the graffiti to say what we mean bluntly, /but/ it may be less
accurate or not as formally justifiable as the text proper.

#+latex: \vspace{2em}
#+begin_quoteit
Some consider the puzzles that are created by their omissions as spicy
challenges, without which their texts would be boring; others shun clarity lest
their worth is considered trivial.  [...] Some authors believe that, in order to
keep the reader awake, one has to tickle him with surprises. [...] essential for
earning the respect of their readership.  ---Edsger Dijkstra \cite{EWD:EWD1300}
#+end_quoteit
#+latex: \vspace{2em}
# Intentionally a \cite and not a citet:, since I don't want to show the full bib
# to the side.

#+latex: \begin{fullwidth}\fbox{ \parbox{\textwidth}{
When there are no side remarks to be made, or a code snippet would be better
viewed with greater width, we will unabashedly switch to using the full width of
the page ---temporarily, on the fly, and without ceremony.
#+latex: \vspace{0.5em}\hrule\vspace{0.5em}
In particular, in numerous places, we want to show the /exact/ code generated from
our prototype ---rather than an after-the-fact prettification, which would
undermine the ‚Äòutility‚Äô of the tool.
#+latex: }}\end{fullwidth} \vfill

A superficial cost of utilising margin space is that the overall page count may
be @@latex:‚Äòover-exaggerated‚Äô\footnote{\color{gray!80}Which doesn't matter,
since you're likely reading this online!}.@@ Nonetheless, I have found long
empty columns of margin space /yearning/ to be filled with explanatory remarks,
references, or somewhat helpful diagrams.  Paraphrasing Hofstadter
citet:hofstadter_gdel_1979, the little pearls in the margins were so connected in
my own mind with the ideas that I was writing about that for me to deprive my
readers of the connection that I myself felt so strongly would be nothing less
than perverse.

#  \maketitle
# +latex: \renewcommand\contentsname{Brief Table of Contents}
#+latex: \setcounter{tocdepth}{2}
# +latex: \begin{small}\tableofcontents\end{small}
#+latex: \nomargins\tableofcontents\yesmargins
# +latex: \renewcommand\contentsname{Detailed Table of Contents}


# http://ctan.mirror.globo.tech/macros/latex/contrib/shorttoc/shorttoc.pdf
# +latex_header: \usepackage{shorttoc}
# +latex: \shorttoc{Condensed Table of Contents}{1}
# +TOC: headlines 2
# +TOC: tables

** Remove red boxes :ignore:
#+latex_header: % From https://tex.stackexchange.com/questions/343494/minted-red-box-around-greek-characters
#+latex_header: \usepackage{etoolbox,xpatch}
#+latex_header:
#+latex_header: \makeatletter
#+latex_header: \AtBeginEnvironment{minted}{\dontdofcolorbox}
#+latex_header: \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
#+latex_header: \xpatchcmd{\inputminted}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
#+latex_header: \xpatchcmd{\mintinline}{\minted@fvset}{\minted@fvset\dontdofcolorbox}{}{}
#+latex_header: \makeatother

**  my-info                                             :noweb_setup:ignore:

#+latex_header: \newunicodechar{ÃÄ}{\ensuremath{\!\!\!^`}}
#+latex_header: \newunicodechar{ÃÅ}{\ensuremath{\!\!\!^`}}
#+latex_header: \newunicodechar{·¥ó}{\ensuremath{\;\smile}}
#+latex_header: \newunicodechar{Ÿà}{\ensuremath{\fatsemi}}

# Use <<my-info>> to get the source text copied elsewhere.
# Use <<my-info()>> to get the result of this program inserted elsewhere.
# Use ‚Äú-- <<my-info()>>‚Äù to have each line prepended with ‚Äú-- ‚Äù and treated as a comment.
# Wherever you use noweb syntax, ensure you have ‚Äú:noweb yes‚Äù declared.
#+name: my-info
#+begin_src emacs-lisp :exports none
(format
 "\nThe Next 700 Module Systems (‚Ä¢ÃÄ·¥ó‚Ä¢ÃÅ)Ÿà Musa Al-hassy ‚ü®%s‚ü©
\nThis file was mechanically generated from a literate program.
Namely, my PhD thesis on ‚Äòdo-it-yourself module systems for Agda‚Äô.
\nhttps://alhassy.github.io/next-700-module-systems/thesis.pdf
\nThere are ‚Äú[[backward][references]]‚Äù to the corresponding expository text.
\nAgda version %s; Standard library version 1.2"
 (format-time-string "%Y-%m-%d %A %H:%M:%S") agda2-version)
#+end_src
** fancy header setup                                               :ignore:

# Useful: https://www.overleaf.com/learn/latex/headers_and_footers#Reference_guide
#+latex_header: \usepackage{fancyhdr}
#+latex_header: \pagestyle{fancy}
#+latex_header: \fancyhf{} % clears the header and footer, otherwise the elements of the default "plain" page style will appear.
#+latex_header: \fancyhead[L]{\rightmark}
#+latex_header: \fancyhead[R]{\thepage}
# +latex_header: \renewcommand{\headrulewidth}{0pt}
#+latex_header: \fancyfoot[CE,CO]{\leftmark}
#+latex_header: \fancyfoot[LE,RO]{} % \thepage
#+latex_header: \renewcommand{\headrulewidth}{2pt}
#+latex_header: \renewcommand{\footrulewidth}{1pt}

* Introduction


#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

#+latex_header: \usepackage{smartdiagram}

#+latex_header: \usepackage{graphicx,wrapfig}
# The ‚Äú,‚Äù is not a seperator but a terminator in smartdiagrams: It must appear
# at the end of a line; not the next line.
#+latex_header: \usepackage{adjustbox}
# https://stackoverflow.com/questions/3352054/latex-automatically-scale-down-an-area-so-that-it-will-be-inside-a-page-if-it

#+latex_header: \usepackage{my-tikz-cats}

#+latex: \def\Type{\mathsf{Type}}

** Intro :ignore:

#+latex: \begin{fullwidth}
The construction of programming libraries is managed by decomposing ideas into
self-contained units that are frequently called ‚Äòmodules‚Äô,
and that we will call ‚Äòpackages‚Äô.
Relationships between packages are then formalised as transformations that reorganise
representations
of data.  Depending on the /expressivity/ of a language, packages may serve to
avoid having different ideas share the same name ---which is usually their /only/
use--- but they may additionally serve as silos of source definitions from which
interfaces and types may be /extracted/.
The following drawing exemplifies this idea for monoids
(which model a notion of composition):
From a single definition of `Monoids',
we would like to be able to obtain
definition for all the other concepts
via appropriate /derivation/ mechanisms.


# #+begin_margin :width "0.45\\textwidth"
# Deriving related /types/ from /the/ definition of monoids:
# #+resize:
#+begin_export latex
\vspace{-0.8em}\begin{center}
\label{dia:monoids}
\color{black}%\Large
\maxsizebox{0.72\columnwidth}{0.72\columnwidth}{
\smartdiagram[constellation diagram]{
 {Monoids}
,{Monoids \mbox{\hspace{-2.3ex}\emph{parameterised}} \mbox{\hspace{-1ex}\emph{by} carrier \texttt{C}}}
,{Pointed Magma} % \\ (‚ÄúExclusion‚Äù)
,{Monoid terms \\ \mbox{\hspace{-2ex}(Trees with} \mbox{\hspace{-1ex}variables)}}
,{\strut\\ \mbox{\hspace{-1.5em}Homomorphisms}, \mbox{products,} duals}
,{\mbox{Signature} \mbox{(Tree} \mbox{skeleton)}}
,{\strut\\[-1.2ex] \mbox{Monoids} \mbox{\hspace{-2ex}\emph{parameterised}} \mbox{\emph{by} a setoid}}
% ,Universal Algebra constructions
,{\strut\\[-1.2ex] Monoids \mbox{\hspace{-4ex}\emph{parameterised by}}
   \mbox{\hspace{-3ex} carrier \texttt{C} \emph{and} }
   \mbox{\hspace{-2ex} operation $\oplus$}}}
}%maxsizebox
\end{center}\vspace{-1.5em}
#+end_export
# #+end_margin

#+latex: \end{fullwidth}

@@latex: \noindent@@
In general,
such derived constructions are /out of reach/ from /within/ a language and have to
be extracted /by hand/ by users who have the time and training to do so.
Unfortunately, this is the standard approach; however, it is error-prone and
disguises mechanical /library methods/ (that are written /once/ and proven correct)
as /design patterns/ (which need to be carefully implemented for /each/ use and
argued to be correct).  The goal of this thesis is to show that sufficiently
expressive languages make packages an interesting /and/ central programming
concept by extending their common use as silos of data with the ability for
/users/ to /mechanically/ derive related ideas (programming constructs) as well as
the relationships citet:purposes_of_proof,realms between them.

:DELETE:
#+caption: Deriving related /types/ from /the/ definition of monoids
#+begin_export latex
\Large \maxsizebox{1.3\textwidth}{\textheight}{
\label{fig:monoid-derivatives}
\smartdiagram[constellation diagram]{
 {\footnotesize Monoids}
,{\footnotesize Monoids \emph{with} carrier \texttt{C}}
,{\footnotesize Homomorphisms, products, duals}
,{\footnotesize Signature (Tree skeletons)}
,{\footnotesize Pointed Magma} % \\ (‚ÄúExclusion‚Äù)
,{\footnotesize Terms \\ (Trees with variables)}
,{\footnotesize Monoids \emph{over} a setoid}
% ,Universal Algebra constructions
,{\scriptsize Monoids \emph{with} carrier \texttt{C} and operation $\_{}\oplus\_{}$}
}}
#+end_export
:END:

#+latex: \iffalse
When developing libraries, such as citet:RATH, in the dependently-typed language
(DTL) Agda, one is forced to mitigate a number of hurdles. We turn to these
hurdles in the following subsections ---some of which are also discussed clearly
in citet:tpc. The remainder of this chapter is organised as follows: Sections 1.1
to 1.4 present the motivating problems that arise when working in a DTL;
these will be discussed in greater detail in Chapter 3.
Section 1.5 briefly discusses our
desire to have our resulting system be /usable/, and Section 1.6
concludes with an overview of the thesis.
#+latex: \fi

When developing libraries, such as citet:RATH, in the dependently-typed language
(DTL) Agda, one is forced to mitigate a number of hurdles. We turn to these
hurdles (some of which are also discussed clearly in citet:tpc)
in Sections 1.1 to 1.4, where we provide a first, brief presentation
of  the motivating problems that arise when working in a DTL;
these will be discussed in greater detail in Chapter 3
after we cover the necessary background in Chapter 2.
Since a proper explanation of the contributions of this thesis
requires the detailed explanations in Chapter 3 of the motivations,
which in turn build on the background knowledge expanded in Chapter 2,
we delay the presentation of our contributions until Chapter 4.

For the remainder of this chapter,
Section 1.5 briefly discusses our
desire to have our resulting system be /usable/, Section 1.6
contains an overview of the whole thesis,
and Section 1.7 explains the relationship to previous publications.

# #+latex: \clearpage
** Practical Concern ‚ôØ1: Renaming and Remembering Relationships

#+latex: \vspace{-.7em}
There is excessive repetition in the simplest of tasks when working with
packages.  For example, to /uniformly/ decorate the names in an Agda package with
subscripts ~‚ÇÄ, ‚ÇÅ, ‚ÇÇ~ (similar to the /decorations/ of the Z-notation) requires the
package's contents be listed twice.  It would be more economical to /apply/ a
renaming function to a package.  More generally, we frequently want to perform a
renaming to view an idea in a more natural, concrete, setting; the following
drawing indicates some candidates for the basic concept of /magma/ (a carrier set
with a single binary operation):

#+resize:
#+begin_export latex
\vspace{-1.2em}
\color{black}%\Large
\begin{tikzpicture}
\setlength{\unit}{2.8cm}
\def\arrowthickness{thick}
\def\nodethickness{thick}
\def\textoffset{0cm}
\def\arrowtype{<->}

\mknode{Num}{x = 1, y = 1, candidate color, text = \texttt{Numeric \\  \_{}+\_{}}}
\mknode{Set}{x = 3, y = 1, candidate color, text = \texttt{Sets \\  $\_{}\cup\_{}$}}
\mknode{Lis}{x = 2, y = 0, candidate color, text = \texttt{Lists \\ \_{}++\_{} \\[-0.2ex] {\footnotesize (Catenation)} }}
\mknode{Pro}{x = 2, y = 2, candidate color,
  text =  \texttt{Programs \\ \_{};\_{} \\[-0.2ex] {\footnotesize (Sequencing)} }}
\mknode{Mag}{x = 2, y = 1, given color, text = \fbox{Magma} \\[0.8ex] \texttt{Carrier \\ op}}


\mkline{left = Mag}{right = Num, required color, label = ???, location = above}
\mkline{right = Mag}{left = Set, required color, label = ???, location = below}

\mkline[bend left]{left = Lis}{bot = Num, label = ???, sloped, location = below,   required color}
\mkline[bend right]{right = Lis}{bot = Set, label = ???, sloped, location = below, required color}

\mkline[bend left]{top = Num}{left = Pro, required color, label = ???, sloped, location = above}
\mkline[bend right]{top = Set}{right = Pro, required color, label = ???, sloped, location = above}
\mkline{bot = Pro}{top = Mag, label = ???, location = right,  required color}
\mkline{bot = Mag}{top = Lis, label = ???, location = left,  required color}
\end{tikzpicture}
#+end_export

In this picture, given the starting point in the center,
we would like to be able to derive the surrounding candidate constructions,
together with implementations of the (red) relationships between them.
However,
shallow renaming mechanisms /lose the relationships/ to the original parent
package and so ‚Äòdo nothing‚Äô coercions
#+begin_margin :width "0.45\\textwidth"
src_agda[:exports code]{coe : Numeric ‚Üí Magma} \newline
@@latex:\mbox{\strut\kern0.8em@@ src_agda[:exports code]{coe record {Numeric = N; _+_ = op}} @@latex:}@@
@@latex:\mbox{\strut\kern1.5em@@ src_agda[:exports code]{¬†= record {Carrier = N; op = op}} @@latex:}@@
#+end_margin
have to be written by hand.
Concrete examples of how several large Agda projects work around these renaming-related issues
will be discussed in Section @@latex:\ref{sec:examples:renaming}@@.
(The need to ‚Äòremember relationships‚Äô
is shared by the other concerns discussed in this section.)

** Practical Concern ‚ôØ2: Unbundling
In general, in a DTL, /packages behave like functions/ in that they may have a
subset of their contents designated as /parameters exposed at the type-level/
which users can /instantiate/. The shift between the two forms is known as *the
unbundling problem*
citet:packaging_mathematical_structures.

For example, if ~Group~ and ~Monoid~ are defined in the usual way,
with the carrier being `bundled up' as a constituent,
then theorem statements about `a group and a monoid on the same carrier'
require a setup involving an `after-the-fact constraint':

#+latex: \strut\hfill\begin{minipage}{0.65\columnwidth}
~‚àÄ (G : Group) (M : Monoid)~
#+latex: \\\strut\kern1em
 {{{mbox(~‚Üí  Group.Carrier G ‚â°  Monoid.Carrier M~)}}}
#+latex: \\\strut\kern1em
 ~‚Üí  ‚ãØ~
#+latex: \end{minipage}\hfill\strut

If /unbundled/ definitions ~GroupOn~ and ~MonoidOn~ are available,
this can be expressed more clearly in the following way:

#+latex: \medskip\centerline{
~‚àÄ (C : Set) (G : GroupOn ¬†C) (M : MonoidOn C)¬†‚Üí  ‚ãØ~.
#+latex: }

The unbundling problem is essentially
how to obtain ~GroupOn~ from ~Group~ without repeating
almost all of the ~Group~ definition.

Unfortunately,
library developers generally provide only a few /variations/ on /a/ package;
such as
having no parameters or having only /functional symbols/ as parameters.
Whereas functions can /bundle-up/ or /unbundle/ their parameters
using currying and uncurrying, only the latter is generally supported and, even
then, not in an elegant fashion.  Rather than provide /several variations/ on a
package, it would be more economical to provide one singular fully-bundled
package and have an operator that allows users to /declaratively/, ‚Äúon the fly‚Äù,
expose package constituents as parameters.

*** COMMENT Let us try to clarify this subtlety.

# WK: These details may at this point be more confusing than helpful.

At its core, the unbundling problem is well-known as ‚Äò(un)currying‚Äô: The
restructuring of record consuming functions as ‚Äòparameterised families of
functions‚Äô. Uncurrying can be phrased as follows.
#+begin_margin :width "0.45\\textwidth"
The symbol ‚Äò‚âÖ‚Äô means ‚Äúisomorphic with‚Äù and it means ‚Äúessentially
interchangeable‚Äù.  More formally, it signals that there is a non-lossy protocol
between two types.  It is most generally defined in the setting of category
theory: $A ‚âÖ B$ \emph{precisely} when there are two transformations $f : A ‚Üí B$
and $g : B ‚Üí A$ that ‚Äòundo one another‚Äô in that $f ‚àò g = \mathsf{Id} = g ‚àò f$.
#+end_margin

#+begin_export  latex
\begin{tcolorbox}[colframe=red!75!black]
\vspace{-2em}
\begin{align*}
   A &: \Type
\\ B &: \Type
\\ C &: \Type
\end{align*}

\vspace{-1.5em}
\centerline{\rule{30em}{1pt}}
\vspace{-1em}
\[ A √ó B ‚Üí C \quad‚âÖ\quad A ‚Üí (B ‚Üí C) \]
\end{tcolorbox}
#+end_export

The right side brings a number of /practical conveniences/ in the form of
simplified concrete syntax ---e.g., reduced parentheses for function
arguments--- and in terms of auxiliary combinators to ‚Äòfix‚Äô an /A/-value ahead of
time ---i.e., ‚Äòpartial function application‚Äô. The /unbundling problem/
#+begin_margin :width "0.45\\textwidth"
Variations of this problem appear in various forms in computing; e.g., as
/quantifier (un)nesting/ in predicate logic or /lambda lifting/ in programming
language theory.
#+end_margin
replaces simple product and function types with their /dependent/ generalisations.
#+begin_margin :width "0.45\\textwidth"
Notice that /before/ $A, B, C$ were /independent/ types; whereas /here/ we have that
$Y$ depends on $I$ and $X$, and $X$ depends on $I$.

\vspace{1em} When we write $X : I ‚Üí \Type$ we are declaring that $X$ is a /family
of types indexed by the type $I$/.  Dependent types and type-formers such as
record-formation ‚ÄòŒ£‚Äô and parameterisation ‚ÄòŒ†‚Äô are motivated in Chapter
\ref{sec:packages_and_their_parts}.
#+end_margin
#+begin_export  latex
\begin{tcolorbox}[colframe=red!75!black]
\vspace{-2em}
\begin{align*}
   I &: \Type
\\ X &: I ‚Üí \Type
\\ Y &: (Œ£ \, i : I ‚Ä¢ X\, i) ‚Üí \Type
\end{align*}

\vspace{-1.5em}
\centerline{\rule{30em}{1pt}}

\vspace{-1em}
\[ Œ† \, p ‚à∂ (Œ£ \, i ‚à∂ I ‚Ä¢ X\, i) ‚Ä¢ Y\, p \quad‚âÖ\quad Œ† \, i ‚à∂ I ‚Ä¢ Œ† \, x ‚à∂ X\, i ‚Ä¢ Y\, (i, x) \]
\end{tcolorbox}
#+end_export

As with currying, the right side here is preferable at times since it
immediately
#+begin_margin :width "0.45\\textwidth"
Unbundled forms: Obtain the dashed arrow explicitly.
#+resize:
#+begin_export latex
\color{black}\Large
  \begin{tikzpicture}
  \filldraw[color=red!60, fill=red!5, very thick](-5.25,-2) ellipse (1cm and 1cm);
  \node at (-5.25, -1.2) {\tiny Given };
  \node at (-5.25, -1.4) {\tiny Structure};

  \filldraw[color=green!60, fill=green!5, very thick](-5.25,-2.2) ellipse (0.75cm and 0.5cm);
  \node at (-5.25, -2.0) {\tiny Chosen};
  \node at (-5.25, -2.2) {\tiny Sub-structure};

  \filldraw[color=teal!60, fill=teal!5, very thick](-0.25,-2) ellipse (1cm and 1cm);
  \node at (-.25, -2) {\tiny New Concept};

  \draw[ultra thick, dashed, ->] (-4.25, -2) to (-1.25,-2);
\end{tikzpicture}
#+end_export
#+end_margin
lets one ‚Äòfix‚Äô ---i.e., select--- a value $i‚ÇÄ : I$ to obtain the specialised
type \[ Œ† x ‚à∂ X\, i‚ÇÄ ‚Ä¢ Y\, (i‚ÇÄ, x) \enskip .\] In contrast to the right, the
left side can only be contorted
#+begin_margin :width "0.45\\textwidth"
Bundled forms: Two solid arrows to get one dashed arrow:

(In these diagrams, the arrows are used to denote a dependency
relationship.)

#+resize:
#+begin_export latex
\color{black}\Large
  \begin{tikzpicture}
  \filldraw[color=red!60, fill=red!5, very thick](-5.25,-2) ellipse (1cm and 1cm);
  \node at (-5.25, -1.9) {\tiny Ambient };
  \node at (-5.25, -2.1) {\tiny Structure};

  \filldraw[color=teal!60, fill=teal!5, very thick](-0.25,-2) ellipse (1cm and 1cm);
  \node at (-.25, -2) {\tiny New Concept};

  \filldraw[color=green!60, fill=green!5, very thick](-5.25,2) ellipse (1cm and 1cm);
  \node at (-5.25, 2.1) {\tiny Referenced};
  \node at (-5.25, 1.9) {\tiny Sub-structure};

  \draw[ultra thick, dashed, ->] (-4.25, -2) to (-1.25,-2);
  \draw[ultra thick, ->] (-4.3, 1.7) to (-0.8,-1.2);
  \draw[ultra thick, ->] (-5.25, 1) to (-5.25,-1);
\end{tikzpicture}
#+end_export
#+end_margin
to simulate the idea of fixing a field, $i_1 : I$, ahead of time; e.g.: \[ Œ† p ‚à∂
(Œ£ i ‚à∂ I ‚Ä¢ X\, i) ‚Ä¢ Z\, p \quad\text{ where }\quad Z\, p \;=\; \bigg(Y\, p √ó
(\mathsf{fst}\, p \,‚â°\, i_1)\bigg) \] The verbosity of this formulation is what
we wish to mitigate.

The dependent nature of DTLs means that this problem is not solely about
functions ---and so, we cannot simply insist on formulations similar to the
right side; i.e., omitting the record former ‚ÄòŒ£‚Äô.  Since types can /depend on the
values/ of other types, this now becomes a problem about types as well. In
particular, we may view the parameterised type family $Z$ as being a new concept
that is formed around a chosen substructure $i‚ÇÄ : X$ ---which must be referenced
from ‚Äòoutside‚Äô using the ambient structure $Y$; as shown in the informal
3-node diagram to the right.  It would be far more practical to treat the
structure we actually care about as if it were a ‚Äòtop level item‚Äô rather than
‚Äòsomething to be hunted down‚Äô; as shown in the 2-node diagram to the right.

# These situation is captured nicely by informal diagrams[fn:44]
# of Figures ref:fig:bundled and ref:fig:unbundled; concrete instances of these
# diagrams are presented later on, as Figures ref:fig:unbundled-distributivity and
# ref:fig:bundled-distributivity.

# \noindent Concrete instances of these diagrams are presented later on, as
# Figures ref:fig:unbundled-distributivity and ref:fig:bundled-distributivity.


*** It is interesting to note                      :ignore:
# +latex: \par
It is interesting to note that the unbundling problem appears in a number of
guises within the setting of programming language design.  For instance, it can
be seen in numerous popular languages, including Haskell and JavaScript, in the
form
#+begin_margin :width "0.45\\textwidth"
   Define
   src_haskell[:exports code]{f : X √ó Y ‚Üí Z} \newline by projecting fields as needed \newline
   src_haskell[:exports code]{f p = ‚ãØ fst p ‚ãØ snd p ‚ãØ }
   \newline or by exposing the fields directly \newline
   src_haskell[:exports code]{f (x, y) = ‚ãØ x ‚ãØ y ‚ãØ }.
   \newline But to ‚Äòcurry‚Äô is another matter: \newline
   {{{mbox( src_haskell[:exports code]{f' = Œª x ‚Ä¢ Œª y ‚Ä¢ ‚ãØ x ‚ãØ y ‚ãØ }. )}}}
#+end_margin
of /pattern matching/, or /de-structuring/; wherein *explicit* treatment of record
arguments as /packaging mechanisms,/ *silently* disappears in the /presentation/ of
function definitions. Then, /implicit currying/ is the feature that allows the
presentation to accommodate arguments /sequentially/ (‚Äúone at a time‚Äù) rather than
‚Äúall at once‚Äù.
# The move from function-formation ‚ÄòŒª‚Äô to type-formation ‚ÄòŒ†‚Äô results in essentially the
# so-called /quantifier nesting/ rules of predicate logic citet:DBLP:books/sp/GriesS93.

Further in-depth discussion of unbundling issues
is presented in Section @@latex:\ref{sec:examples:readability}@@.

** Theoretical Concern ‚ôØ1: Exceptionality

Dependently-typed languages blur the distinction between expressions and types,
treating them as the same thing: /Terms/.
This collapses a number of seemingly different language
constructs into the same thing.
Unfortunately, in most
#+begin_margin :width "0.45\\textwidth"
There are rare exceptions. E.g., some members of the non-DTL ML
language family allow first-class modules.
#+end_margin
programming languages,
packages are treated as /exceptional/
values that differ from /usual/ values ---such as functions and numbers--- in that
the former are ‚Äòsecond-class citizens‚Äô which only serve to collect the latter
‚Äòfirst-class citizens‚Äô.  This forces users to learn two families of
‚Äòsub-languages‚Äô ---one for each citizen class.  There is essentially no
/theoretical/ reason why packages do not deserve first-class citizenship, and so
receive the same treatment as other /unexceptional/ values.
Another advantage of giving packages equal treatment is that
we are inexorably led to wonder what *computable algebraic structure* they have
and how they relate to other constructs in a language; e.g., packages are
essentially record-valued functions.

Perhaps the most famous instance of the promotion
#+begin_margin :width "0.45\\textwidth"
/With abstractions comes ease of understanding and manipulation./
#+resize:
#+begin_export latex
\color{black}
\smartdiagram[priority descriptive diagram]{System (collection) of relationships, Matrices, Linear Transformations}
#+end_export
#+end_margin
of a second-class concept to first-class status comes from linear algebra, and
subsequently, the theory of vector spaces.  When there are a number of
relationships involving a number of unknowns, the relationships could be
‚Äòmassaged algebraically‚Äô to produce simper constraints on the unknowns, possibly
providing ‚Äòsolutions‚Äô to the system of relationships directly.  The shift from
/systems of equations/ that serve to collect relationships, to /matrices/
(expressing equations [[margin:][The matrix equation $A \cdot x = B$ captures the system of
equations with coefficients from $A$, unknowns from $x$, and $B$ are the ‚Äòtarget
coefficients‚Äô.]] $\!$) gave way to the treatment of such systems as algebraic
entities unto themselves: They can be treated with nearly the same interface as
that of integers, say, that of rings.
#+begin_margin :width "0.45\\textwidth"
   An interesting aside is that a /collection/ mechanism gave rise to the abstract
   /matrix/ concept, which is then seen as a reification of the even more abstract
   notion of linear transformation between vector spaces ---which are in turn,
   packages parameterised over fields (and, in practice, over bases).
#+end_margin
As such, ‚Äòcomponent-wise addition of equations in system $A$ with system $B$‚Äô
becomes more tractable as $A + B$ and satisfies the many familiar properties
of numeric addition.  Even more generally, for any theory of ‚Äòindividuals‚Äô
one can consider the associated matrix theory ---e.g., if $M$ is a monoid,
then the matrices whose elements are drawn from $M$ /inherit/ the monoidal
structure--- and so give a construction of /system of equations/ on that
theory.  To investigate the algebraic nature of packaging mechanisms is
another aim of this thesis.

   #+latex: \nomargins

** Theoretical Concern ‚ôØ2: Syntax

   #+latex: \vspace{-1em}
   /Packages/, as we call them, serve to group together sequences of declarations.
   If any declarations are opaque, not fully defined, they become, what we call,
   /parameters/ of the package ---which may then be identified as a /record type/
   with the opaque declarations called /fields/.  However, when a declaration is
   /intentionally opaque/ not because it is missing an implementation, but rather
   it acts as a value construction itself, then one uses /algebraic data types/, or
   ‚Äòtermtypes‚Äô. Such types share the general structure of a package, as shown in
   the code block below, so it would be interesting to illuminate the exact
   difference between the concepts ---/if any/. In practice, one forms a record
   type to model an interface, instances of which are actual implementations,
   and one forms an /associated/ termtype to /describe computations/ over that record
   type, thereby making possible a syntactic treatment of the interface,
   via which, for example, textual substitution, simplification and optimisations, and evaluators
   can be implemented.

   #+latex: \vspace{-0.7em}
   #+latex_header: \newunicodechar{‚çÆ}{;}
   #+latex: \begin{tcolorbox}[title = Closely-related definitions, colback=red!5!white, colframe=red!75!black]

   #+latex: \vspace{-0.5em}
#+begin_parallel
{{{code(Theory of monoids)}}}
#+begin_src agda
record Monoid : Set‚ÇÅ where
  C : Set
  -- function symbols
  ‚çÆ_ : C ‚Üí C ‚Üí C
  Id : C
  -- axioms
  lid : ‚àÄ x ‚Üí  Id ‚çÆ x  ‚â°  x
  rid : ‚àÄ x ‚Üí  x ‚çÆ Id  ‚â°  x
  assoc : ‚àÄ x y z
          ‚Üí   (x ‚çÆ y) ‚çÆ z
             ‚â° x ‚çÆ (y ‚çÆ z)
#+end_src

Monoid operations versus expressions:
| ~_‚®æ_~ | ‚âà | ~Branch~ |
| ~Id~  | ‚âà | ~Nil~    |
#+columnbreak:

{{{code(Terms over ‚Äòvariables‚Äô \texttt{C})}}}
#+begin_src agda
data Term (C : Set) : Set where
  -- injection
  embed : C ‚Üí Term C
  -- function symbols
  _‚çÆ_  : Term C ‚Üí Term C ‚Üí Term C
  Id : Term C
#+end_src

{{{code(Binary trees with leaf labels drawn from \texttt{C})}}}
#+begin_src agda
data Tree (C : Set) : Set where
  Leaf   : C ‚Üí Tree C
  Branch : Tree C
                ‚Üí Tree C ‚Üí Tree C
  Nil    : Tree C
#+end_src

#+end_parallel

 #+latex: \end{tcolorbox}

 #+latex: \vspace{-0.8em}
 #+latex: \noindent
   For example, @@ignore:as shown in the first diagram of the thesis,@@
   the record type of monoids models composition,
   whereas the @@ignore:(tremendously useful)@@
   termtype of binary trees acts as a description language for monoids.  These
   can be rendered in Agda as shown above.  The */problem of maintenance/* now
   arises: Whenever the record type is altered, one must mechanically update the
   associated termtype.  It would be more economical to extract /both/ record
   types and termtypes from a single package declaration.

   #+latex: \vspace{-0.3em}{\footnotesize \begin{tcolorbox}[title = ‚ÄúTermtype‚Äù terminology, colback=yellow!5!white, colframe=red!75!black]
   We will refer to algebraic data types as /termtypes/, rather than /term type/ or
   /term-type/.

   The reason for doing so is that in Chapter \ref{sec:packages_and_their_parts}
   we will discuss /terms/ and /types/, and come to see them as indistinguishable
   ---for the most part. As such, the phrase /term type/ could be read ambiguously
   as ‚Äúthe type of terms‚Äù or as ‚Äúthe term denoting a type‚Äù. For these reasons,
   we have chosen ‚Äútermtype‚Äù. Moreover, in Chapter \ref{sec:contexts}, we will
   form a macro that consumes a particular kind of package and yields a
   termtype: The name of the macro is ~termtype~.
   #+latex: \end{tcolorbox}}
** yesmargins :ignore:
  #+latex: \yesmargins
** Guiding Principle: Practical Usability

In this thesis, we aim to mitigate the above concerns with a focus on
*practicality*.  @@ignore:[[margin:][If you can't use it, it's essentially useless!]]@@
A theoretical
framework may address the concerns, but it would be incapable of accommodating
/real-world use-cases/ when it cannot be applied to real-world code. For instance,
one may speak of ‚Äòamalgamating packages‚Äô, which can always ‚Äúbe made disjoint‚Äù,
but in practice the union of two packages would likely result in name clashes
---which could be avoided in a number of ways; i.e., selected, automatic,
protocols--- but the /user-defined names/ are important and so a result that is
‚Äúunique up to isomorphism‚Äù is not practical. As such, we will implement a
framework to show that the above concerns can be addressed in a way that
*actually works*.
@@latex: \ignore{A concrete example is demonstrated later on, on page
 \pageref{fig:pushout-example}.}@@

** Thesis Overview

# +latex: \hyphenpenalty10000
# +latex: \exhyphenpenalty10000

# +latex: \FloatBarrier

The remainder of the thesis is organised as follows.
#+begin_margin :width "0.45\\textwidth"
‚ÄúThesis outline‚Äù:

#+latex: \kern1ex
#+resize:
#+begin_export  latex
\color{black}\Large
\smartdiagram[flow diagram:vertical]{
  Real-world use cases
 ,IDE Prototype
 ,DTL Library}
#+end_export
#+end_margin


# 2. \ref{sec:packages_and_their_parts}
# 3. \ref{sec:examples_from_the_wild}
# 4.
# 5.
# 6. \ref{sec:PF}
# 7. \ref{sec:contexts}
# 8. \ref{sec:conclusion}

#+latex: \noindent\textsc{%
*Chapter \ref{sec:packages_and_their_parts}* consists of preliminaries, to make
the thesis self-contained.
#+latex:   }

An introduction to grammars and elementary type theory,
along with a motivation of the dependent type formers of Œ†- and Œ£-types.

 #+latex: \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]
Chapter \ref{sec:packages_and_their_parts}
is intentionally written in ``blog style'',
and  goes out of its way to explain basic ideas using analogies and
   ‚Äòreal-life (non-computing) examples‚Äô.
 #+latex: \end{tcolorbox}

# Chapter \ref{sec:packages_and_their_parts}
Section \ref{sec:what_is_DTL}
contains a brief overview of dependently-typed programming with Agda,
with a focus on packaging constructs: Namespacing with src_agda[:exports
code]{module}, record types with src_agda[:exports code]{record}, and as
contexts with Œ£-padding.

#+latex: \noindent\textsc{%
*Chapter \ref{sec:examples_from_the_wild}* consists of real world examples of
  problems encountered with the existing package system of Agda.
#+latex: }

  Along the way, we identify a set of /DTL design patterns/ that users repeatedly
  implement. An indicator of the *practicality* of our resulting framework is the
  ability to actually implement such patterns as library methods.

#+latex: \noindent\textsc{%
*Chapter \ref{sec:research_problem_statement}* discusses the technical contributions
of the thesis.
#+latex: }

  Building on the preliminaries reviewed thus far,
  we now present a survey of package systems in DTLs,
  and in that context outline the contributions of this
  thesis. The contributions listed will then act as a guide for the remainder of
  the thesis.

#+latex: \noindent\textsc{%
*Chapter \ref{sec:Pi-Sigma-W}* provides an Œ†-Œ£-ùí≤ view of structuring mechanisms
as well as a discussion of related work.
#+latex: }

 The interdefinability of various packaging constructs is demonstrated.
 Afterwards is a quick review of other DTLs that shows that the idea of a
 unified notion of package is promising ---Agda is only the language we have
 chosen for presentation,
 but the ideas transfer to other DTLs. Finally, we sketch out our approach,
 abstractly, to actually using contexts to obtaining different semantics ---such
 as parameterised records and termtypes.

#+latex: \noindent\textsc{%
*Chapter \ref{sec:PF}* discusses a prototype that addresses /nearly/ all of our
concerns.
#+latex: }

We implemented a prototype package manipulation framework as an editor extension
of Emacs, the main development environment for Agda.@@latex:\kern0.25em%@@
#+begin_margin :width "0.45\\textwidth"
Generating Agda Code
#+resize:
\color{black}\Large
\smartdiagram[flow diagram:horizontal]{\!\!\! Typechecked Agda  ,Emacs Lisp}
#+end_margin
Therefore, package manipulations are written in Lisp rather than
in the target language, Agda.  However, the ability to rapidly, textually,
manipulate a package makes the prototype an extremely useful tool to test ideas
and implementations of package combinators.  In particular, the aforementioned
example of forming unions of packages is implemented in such a way that the
amount of input required ---such as /along/ what interface should a given pair of
packages be /glued/ and /how/ name clashes should be handled--- can be ‚Äòinferred‚Äô
(when not provided) by making use of Lisp's support for keyword
arguments. Moreover, the union operation is a /user-defined/ combinator: It is a
/possible/ implementation by a user of the prototype, built upon the prototype's
‚Äúpackage meta-primitives‚Äù.

# \noindent
# Unfortunately, the prototype
# #+begin_margin :width "0.45\\textwidth"
# Generating Agda Code
# #+resize:
# \color{black}\Large
# \smartdiagram[flow diagram:horizontal]{\!\!\! Typechecked Agda  ,Emacs Lisp}
# #+end_margin
# introduces a new sublanguage for users to learn.  Packages are /nearly/
# first-class citizens: Their manipulation must be specified in Lisp rather than
# in the host language, Agda.  However, the ability to rapidly, textually,
# manipulate a package makes the prototype an extremely useful tool to test ideas
# and implementations of package combinators.  In particular, the aforementioned
# example of forming unions of packages is implemented in such a way that the
# amount of input required ---such as /along/ what interface should a given pair of
# packages be /glued/ and /how/ name clashes should be handled--- can be ‚Äòinferred‚Äô
# (when not provided) by making use of Lisp's support for keyword
# arguments. Moreover, the union operation is a /user-defined/ combinator: It is a
# /possible/ implementation by a user of the prototype, built upon the prototype's
# ‚Äúpackage meta-primitives‚Äù.

#+latex: \noindent\textsc{%
*Chapter \ref{sec:contexts}* takes the lessons learned from the prototype to show
  that /DTLs can have a unified package system within the host language/.
#+latex: }

  The prototype is given semantics as Agda types and functions by forming a
  *practical* library within Agda that achieves the core features of the prototype.
  The switch to a DTL is nontrivial due to the type system; e.g., fresh names
  cannot be arbitrarily introduced nor can syntactic shuffling happen without a
  bit of overhead. The resulting library is both usable and practical, but lacks
  the immense power of the prototype due to the limitations of the existing
  implementation of Agda's metaprogramming facility.
  As an application, we demonstrate how ubiquitous data structures in computing
  arise /mechanically/ as termtypes of simple ‚Äòmathematical theories‚Äô ---i.e.,
  packages.

  The full working code may be found in Appendix \ref{sec:code}.

#+latex:  \noindent\textsc{%
*Chapter \ref{sec:conclusion}* concludes with a discussion about the results
presented in the thesis.
#+latex: }

The underlying motivation for the research is the conviction that packages play
#+begin_margin :width "0.45\\textwidth"
How most people use packages:
#+resize:
#+latex: \color{black} \smartdiagram[sequence diagram]{\mbox{Parameterised} \\ \!\!\!Namespacing}
#+end_margin
/the/ crucial
#+begin_margin :width "0.45\\textwidth"
Alternative usage paths:
#+resize:
#+latex: \color{black}\Large \smartdiagram[sequence diagram]{\mbox{Definition} Silo \mbox{\hspace{-4ex}(Namespacing)}, Record Types, \mbox{Algebraic} Data Types}
#+end_margin
role for forming compound computations, subsuming /both/ record types
and termtypes.


#+latex:  \noindent\textsc{%
*Appendix \ref{sec:code}* is just the code for the src_haskell[:exports
   code]{Context} library.
#+latex: }

The design of this code
is discussed at length in Chapter \ref{sec:contexts}.
More precisely,
Chapter \ref{sec:contexts} is a /literate program/
using the approach of Stanisic and Legrand
citet:DBLP:conf/europar/StanisicL14,
and Appendix \ref{sec:code}
has been /tangled/ from the source of Chapter \ref{sec:contexts}.


** Relationship with Previous Publications

The research towards this thesis has so far led to one publication,
citet:DBLP:conf/gpce/Al-hassyCK19,
where the main author was the author of this thesis,
and the paper reports on an early version of the
prototype presented in Chapter 6,
developed by the author of this thesis alone.


*** COMMENT Accessibility  :ignore:

 #+latex: \vspace{-.0em}\begin{fullwidth}\begin{tcolorbox}[title = How accessible is this thesis?, colback=red!5!white, colframe=red!75!black]
 + Chapter 1 is presented from a high-level overview and tries to be accessible
   to a computer scientist exposed to fundamental functional programming.

 + Chapter \ref{sec:packages_and_their_parts} tries to be *accessible to the
   layman*. It goes out of its way to explain basic ideas using analogies and
   ‚Äòreal-life (non-computing) examples‚Äô.  /The effort placed therein is so that/
   /‚Äòalmost anyone‚Äô can pick up this thesis and have ‚Äòan idea‚Äô of the problems it
   targets./

 + Chapter \ref{sec:examples_from_the_wild} may be tough reading for readers not
   familiar with category theory or who have not actually written any Agda code.
   However, I'd like to reassure the reader that no knowledge of category theory
   is actually required since we are discussing the *shape* of the code and not
   its contents. Moreover, the necessary Agda is covered in the previous
   chapter.

 + Chapter \ref{sec:research_problem_statement} can only be appreciated in the
   context of the previous chapters ---even more so for readers not intimately
   familiar with any DTL.

 + Chapter \ref{sec:Pi-Sigma-W} starts of gently requiring only basic
   familiarity with Agda (Chapter \ref{sec:packages_and_their_parts}).  However,
   the second half of the chapter is rather terse, but is admittedly light
   reading for the expert who is comfortable with phrases such as ‚Äúterm algebras
   are just initial objects, which always exist for the /F/-algebras of polynomial
   functors $F$‚Äù.

 + Chapter \ref{sec:PF} may be less daunting than its predecessor, as it has
   line-by-line explanations of code fragments as well as accompanying diagrams.

 + Chapter \ref{sec:contexts} tries to leave it to the reader on ‚Äúhow to read
   the chapter‚Äù.  The exposition of core ideas is presented in a box consisting
   of the main insight (operation definition) along with its realisation using
   Agda's metaprogramming mechanism. As such, readers could read the high level
   idea or the implementation ---which, unlike Chapter 4, we have included so as
   to demonstrate that we are speaking of ideas whose implementations are not
   ‚Äòso difficult‚Äô that they apply to other DTLs besides Agda.

 + Chapter \ref{sec:conclusion}, the final chapter, is a high-level overview of
   what has been accomplished and what we can look forward to achieving in the
   future.  It may be slightly less accessible than Chapter 1.

 + Appendix \ref{sec:code} is just the code for the src_haskell[:exports
   code]{Context} library. The required Agda background of Chapter
   \ref{sec:packages_and_their_parts} suffices; moreover, the design of the code
   is discussed at length in Chapter \ref{sec:contexts}.  More precisely,
   Chapter \ref{sec:contexts} is a /literate program/
   using the approach of Stanisic and Legrand
   \footcitet{DBLP:conf/europar/StanisicL14},
   and Appendix \ref{sec:code}
   has been /tangled/ from the source of Chapter \ref{sec:contexts}.

 #+latex: \end{tcolorbox} \end{fullwidth}

* nomargins                                                          :ignore:
#+latex: \nomargins\clearpage
* Packages and Their Parts

<<sec:packages_and_their_parts>>
# +latex: \label{sec:packages_and_their_parts}

#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

#+latex: \def\src{\mathtt{src}\,}
#+latex: \def\tgt{\mathtt{tgt}\,}
#+latex: \def\List{\mathtt{List}\,}
#+latex: \def\package{\mathtt{package}\,}
#+latex: \def\Type{\mathtt{Type}}
#+latex: \def\src{\mathtt{src}\,}
#+latex: \def\tgt{\mathtt{tgt}\,}
#+latex: \def\type{\mathtt{type}\,}
#+latex: \def\Type{\mathtt{Type}}

** Intro :ignore:

# +begin_parallel

#+latex: \vspace{-2ex}
#+latex: \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]
\parskip0.6ex
Chapter \ref{sec:packages_and_their_parts}
is intentionally written in ``blog style''.

It starts with an introduction to grammars and elementary type theory,
along with a motivation of the dependent type formers Œ† and Œ£ types,
going out of its way to explain basic ideas using analogies and
   ‚Äòreal-life (non-computing) examples‚Äô.

This chapter ends with a brief overview of dependently-typed programming with
Agda in Section \ref{sec:what_is_DTL},
with a focus on packaging constructs: Namespacing with src_agda[:exports
code]{module}, record types with src_agda[:exports code]{record}, and as
contexts with Œ£-padding.
 #+latex: \end{tcolorbox}


#+begin_export  latex
\begin{wrapfigure}{r}{5.7cm}
% \caption{Languages}
% \label{fig:languages}
\kern-3ex
\maxsizebox{8cm}{7.5cm}{
\smartdiagram[descriptive diagram]{
  {Syntax    , {Written text; a sequence of symbols}},
{Well-formed , {Adherence to a particular organisation; e.g., grammatically correct}},
{Types       , {Classifications of sentence parts}},
{Semantics   , { An idea, or thing, ‚Äúpossible in some world‚Äù}},
{Package     , {A language consisting of a vocabulary and sentences}},
{Combinator  , {A translation of ideas in one language (package) into another}},
}%
}%
%\FloatBarrier%
\end{wrapfigure}
#+end_export
The purpose of language is to communicate ideas that ‚Äòlive‚Äô in our minds
---conversely,
language also [[https://en.wikipedia.org/wiki/Linguistic_relativity][influences]] the kinds of thoughts we may have.@@latex:\kern0.25em%@@
#+latex:\FOOTNOTE{
*Linguistics.* The idea that /language limits the kinds of thoughts one can
have/ is known as the [[https://en.wikipedia.org/wiki/Linguistic_relativity][Sapir-Whorf Hypothesis]]
\cite{DBLP:conf/cogsci/TsengCRX16,DBLP:conf/cogsci/CibelliXAGR16,DBLP:journals/csl/MehlerPD11,DBLP:conf/ijcnn/Perlovsky09}
and it has largely been discredited in-preference to the weaker idea that
language /influences/ the kinds of thoughts one can have.  For instance, in
Arabic the singular word /akaltuha/ tersely captures an idea, a sentence, that
would require three words in English ---namely, /I ate it/.  For a computing
example, in Prolog one may write a constraint solver ---say to find a solution
to a Suodku puzzle--- which would require tenfold the number of lines in, say,
Python since the former is intended to work with constraint problems.  As such,
thoughts can be had in different language, but some languages may allow thoughts
to be more easily expressed.
#+latex: }
In particular, written text captures ideas independently of the person who
initially thought of them.  To understand the idea /behind/ a written sentence,
people agree on /how/ sentences may be organised and /what/ content they denote from
their parts.  For example, in English, a sentence is considered ‚Äòwell-formed‚Äô if
it is in the order subject-verb-object ---such as /‚ÄúJim ate the apple‚Äù/--- and it
is considered ‚Äòmeaningful‚Äô if the subject and object are noun phrases that
/denote things in a world that could exist/ and the verb is a /possible action/ by
the subject on the object. For instance, in the previous example, there /could/ be
a person named /Jim/ who /could/ eat an apple, and so the sentence is meaningful.
In contrast,
 the phrase /‚Äúthe colourless green apple
kissed Jim‚Äù/ is well-formed /but not/ meaningful: The indicated action /could
happen/, say, /in a world/ of sentient apples; however, the subject ---/the
colourless green apple/--- /cannot possibly exist/ since a thing cannot be both
lacking colour but also having colour at the same time.@@latex:\kern0.25em%@@
#+latex:\FOOTNOTE{
*Green Apples.* In our cursory glance of linguistic examples we spoke of /green
apples/ with the implicit understanding that /green/ is an adjective that qualifies
its subject, rather than /green apples/ being taken as an atomic name of a /species/
of apples that may not necessarily be green.  That is, when we speak of /P x/ we
mean an individual entity /x/ that has the property /P/. This somewhat natural
convention is superficially problematic in mathematics; so much so that it is
dubbed [[https://ncatlab.org/nlab/show/red+herring+principle][/the red-herring principle/]].  Indeed, in mathematical practice,
adjectives are often used to qualify their subjects in what seems like a
contradictory fashion.  For example, /a semigroup is a non-unitial monoid/ is a
terse summary of the, possibly unfamiliar, notion of semigroup using, the
possibly more familiar, notion of monoid.  However, a monoid, by definition, has
a unit and so the phrase /non-until monoid/ is technically meaningless; instead,
it denotes the notion of a monoid with all references to a unit dropped,
ignored. Interestingly, this use of adjectives to ‚Äúdropping details‚Äù is a common
combinator for producing new packages from old, as we will come to see.
#+latex: }
Moreover, /depending on
who you ask/, the action of the previous example ---/the [...] apple kissed
Jim/---, may be ludicrous /on the basis/ that kissing is ‚Äòclassified‚Äô as a verb
whose subject, in the ‚Äòreal‚Äô world, has the ability to kiss.  As such,
‚Äòmeaningfulness‚Äô is not necessarily fixed, but may vary. Likewise, as there is
no one universal language spoken by all people, written text is also not fixed
but varies; e.g., a translation tool may convert an idea /captured in/ Arabic to a
related idea /captured in/ French.  It is with these observations that we will
discuss the concepts required to have a formal theory of packages, as summarised
in the figure above.
# Figure \ref{fig:languages}.

:OG:
# +latex: \begin{tcolorbox}
#+latex: \label{tbl:languages}
#+caption: Necessary concepts on the left and their informal explanations on the right
|---------------------------+---------------------------------------------------------------|
| Syntax                    | Written text; a sequence of symbols                           |
| Well-formed               | Adherence to a particular organisation                        |
| Types                     | Classifications of the relationships between words            |
| Semantics, Interpretation | An idea, or thing, ‚Äúpossible in some world‚Äù                   |
|---------------------------+---------------------------------------------------------------|
| Package, Theory, Context  | A language consisting of a vocabulary and sentences           |
| Package Combinator        | A translation of ideas in one language (package) into another |
|---------------------------+---------------------------------------------------------------|
# +latex: \end{tcolorbox}
:end:

#+latex: \begin{myboxB}{Game-Play Analogy}
# The contents of Figure \ref{fig:languages} may be intimidating to the
# The contents of the above figure may be intimidating to the uninitiated; so we
The contents of the above figure are a bit abstract; so we reach for a /concrete/
game-play based analogy that may make the concepts more accessible.

#+latex: \tcblower

Programming, as is the case with all of mathematics, is the manipulation of
symbols according to specific /rules/.  Moreover, like a game, when one plays
---i.e., shuffles symbols around--- one may interpret the game pieces and the
actions to /denote/ some meaning, such as reflecting aspects of the players or of
reality.  Many play because it is fun to do so ---i.e., the game has /intrinsic/,
/built-in/, value---; there are only pieces (mathematical symbols or /terms/) and
rules to be followed, and nothing more.  Complex games may involve a number of
pieces (terms) which are classified by the /types/ of roles they serve, and the
rules of play allow us to make observations or /judgements/ about them; such as,
‚Äúin the stage Œì of the game, game piece $x$ serves the role œÑ‚Äù and this is
denoted $Œì ‚ä¢ x : œÑ$ mathematically.  Games which allow such observations are
called /type theories/ in mathematics.  When games are played, they may override
concepts in reality; e.g., in Chess, the phrase /Knight's move/ refers to a
particular set of possible plays and has nothing to do with knights in the
real-world. As such, one calls the collection of specific game words, and what
they mean, within a game (/type theory/) the /object-language/ and uses the phrase
/meta-language/ to refer to the ambient language of the real-world.  As it
happens, some games have localised interactions between players where the rules
may be changed temporarily and so we have /games within games/, then the
object-language of the main game becomes the meta-language of the inner
game. The objects of the game and their interaction rules, are its /lexicon/ and
/grammar/, together forming its /syntax/; and what the game means is its /semantics/.
To say that a game piece (term) denotes (/extensionally/) some idea ùë∞, we need to
be able to /express/ that idea which may only be possible in the meta-language;
e.g., pieces in a mini-game within a game may themselves denote pieces within
the primary game ---more concretely, a game may require a roll of a die whose
numbers /denote/, or /refer to/, players in the main game which are not expressible
in the mini-game.  A /model/ of a game (type theory) is an interpretation of the
game's pieces in way that the rules are true under the interpretation.
#+latex: \end{myboxB}

:SyntaxAdjSemantics:
#+begin_center
*Syntax is a particular representation of a semantics*!
#+end_center
:End:

To see an example of packages, consider the following real-world examples of
dynamical systems.  First, suppose you have a machine whose actions you cannot
see, but you have a control panel before you that shows a starting screen,
~start~, and the panel has one button, ~next~, that forces the machine to act which
updates the screen. Moreover, there is a screen capture called ~thrice~ /which
happens/ to be the result of pressing ~next~ three times after starting the
machine. Second, suppose you are an artist mixing colours together.
#+begin_parallel
{{{code(Machine)}}}
#+begin_src haskell
State  : Type
start  : State
next   : State ‚Üí State
thrice : State
thrice = next (next (next start))
#+end_src
#+columnbreak:
{{{code(Colours)}}}
#+begin_src haskell
Colour : Type
red    : Colour
green  : Colour
blue   : Colour
mix    : Colour √ó Colour ‚Üí Colour
purple : Colour
purple = mix red blue
dark   : Colour ‚Üí Colour
dark c = mix c blue
#+end_src
#+end_parallel

#+begin_center
(The bold emphasis, on certain key words, below is /intended/ as an informal
*definition* of ideas to be fleshed out later in the chapter.)
#+end_center

Each of these is a
#+latex: \textbf{package}\FOOTNOTE{
*Interfaces.* By the end of the thesis, we hope the reader will see that there is
/essentially no theoretical distinction/ between: Packages, modules, classes,
interfaces, records, and contexts.  As such, we are /intentionally/ using them as
if they were synonymous ---which contradicts popular usages.  Briefly, a package
with one parameter src_emacs-lisp[:exports code]{p}, and declarations
src_emacs-lisp[:exports code]{ds} that may use the parameter, is essentially a
function src_emacs-lisp[:exports code]{Œª p ‚Üí ds'} that takes in a value for the
parameter src_emacs-lisp[:exports code]{p} and returns the package's
declarations src_emacs-lisp[:exports code]{ds} in the shape of a record of
declarations src_emacs-lisp[:exports code]{ds'}; finally, the main distinction
between src_emacs-lisp[:exports code]{p} and src_emacs-lisp[:exports code]{ds}
is that the declarations consist of a type declaration with associated
definitions whereas src_emacs-lisp[:exports code]{p} is only a type declaration
lacking a definition, and so we treat packages as contexts ‚Äú
src_haskell[:exports code]{p; ds} ‚Äù and refer to non-definitional declarations
as /parameters/.  Traditionally, a ‚Äòparameter‚Äô refers to a part of the discussion
that is allowed to vary and we are locally overriding the meaning of the word.
Dear reader, whenever you read an article, the phrase ‚Äúthe author‚Äù changes it
meaning, and so you have already encountered local overrides ---even more so,
when authors declare their conventions at the start of their papers; e.g., /for
brevity, ‚Äòring‚Äô means a commutative ring with one/.
#+latex: }:
A sequence of ‚Äòdeclarations‚Äô of operations; wherein
elements may be ‚Äòparameters‚Äô in the declarations of others.  A *declaration* is a
‚Äúname ‚à∂ classification‚Äù pair of words, /optionally/ with another ‚Äúname =
definition‚Äù pair of words that shows how the new word /name/ can be obtained from
the vocabulary already declared thus far. For example, in these packages
(languages) =thrice= and =purple= are aliases for expressions (sentences)
constructed from other words.  A *parameter* ---also known as a
*field*--- is a declaration that is not an alias; i.e., it has no associated
=-pair. Parameters are essentially the building blocks of a language; they
cannot be expressed in terms of other words.  A non-parameter is essentially
/fully defined, implemented,/ as an alias of a mixture of earlier words; whereas
parameters are ‚Äòopaque‚Äô ---/not yet implemented/.  In particular, in the colours
example above, =dark= /defines/ a function that uses the /symbolic name/ ~mix~ in its
definition. There is an important subtlety between ~mix~ and ~dark~: The latter,
~dark~, is an /actual function/ that is fully determined when an /implementation/ of
the /symbolic name/ ~mix~ is provided. The (parameter) name ~mix~ is said to be a
/function symbol/ rather than a function: It is the /name/ of a function,
but it lacks any implementation and is thus not actually a function.
A /function symbol/ is to a function, like a name is to a person:
Your name does not fully determine who you are as a person.

** Section Goals                                                     :ignore:

# +latex: \subsection*{Subsection Goals}
# This section aims to present a mathematical formalisation of packages.  For
# brevity, we only consider parameters in the first few sections then accommodate
# non-parameters after a working definition is established.  As discussed in the
# introduction, there are a number of ‚Äòsub-languages‚Äô one must be familiar with in
# any setting ---e.g., function symbols and types (classifications) and their
# respective operations--- and so a prime goal of our discussions will be to
# /reduce/ the number of distinctions so that we have a /uniform/ approach to
# different aspects of a language.

#+latex: \newline \vspace{-1em}


This chapter is organised as follows.  Section \ref{sec:what_is_a_language}
sketches out the English sentences example from above ---on colours---
introducing the notation used for declaring grammars of languages, along with
typing contexts.  Section \ref{sec:signatures} then extrapolates the key
insights using the idea of signatures.  In section
\ref{sec:packages_and_their_parts:sigma_pi}, the desire to present packages
(signatures) /practically/ in a uniform notation ---to /reduce/ the number of
distinctions--- leads to types that /vary/ according to other types, thereby
motivating Œ†-types; then the (un)bundling problem is used to motivate the
introduction of Œ£-type.  Finally, the chapter concludes, in section
\ref{sec:what_is_DTL}, with a terse review of the Agda language as a tool
supporting the ideas of the previous subsections. In particular, the ideas
presented earlier in the chapter (Œ†, Œ£, grammars) gain life in Agda as
src_agda[:exports code]{record}s, namespacing src_agda[:exports code]{module}s,
and algebraic src_agda[:exports code]{data}types (respectively).


# +latex: \begin{fullwidth}
{{{localtoc}}}
# +latex: \end{fullwidth}
# +latex: \clearpage % Does not help with the two wrong footnote numbers above

** yesmargins                                                       :ignore:
#+latex: \yesmargins
** What is a language?

<<sec:what_is_a_language>>
# +latex: \label{sec:what_is_a_language}


#+latex: \tcbset{colback=green!10!white}

In this section @@latex:\iffalse@@
#+begin_margin :width "0.45\\textwidth"
The plan for this section is loosely summarised by the following diagram:
#+begin_export latex
%\begin{center}
\maxsizebox{\textwidth}{\textheight}{%
\usetikzlibrary{shapes.geometric} % required in the preamble
\smartdiagramset{module shape=circle,
font=\scriptsize,
module minimum width=1cm,
module minimum height=1cm,
text width=1cm,
circular distance=2cm,
circular final arrow disabled=true,
}%
\smartdiagram[circular diagram:clockwise]{English \mbox{Example}, \!\!\!\mbox{Arithmetic} \mbox{Example}, Rules, \!\!\mbox{Contexts}}}
%\end{center}
#+end_export
#+end_margin
@@latex:\fi%@@
we introduce two languages in preparation for the terminology
and ideas of the next section. The first language, /Madlips/, will only be
discussed briefly and is mentioned due to its inherit
accessibility, @@latex:\iffalse@@
#+begin_margin :width "0.45\\textwidth"
Also accessible is Winterhalter's [[https://github.com/TheoWinterhalter/phd-thesis/releases/download/v1.2.1/TheoWinterhalter-PhD-v1.2.1.pdf][Formalisation and Meta-Theory of Type Theory]]
\cite{types:Winterhalter_2020}; a delightful read with a similar ‚Äòmarginful‚Äô
approach; its presentation language is Coq instead of Agda. See also
\cite{types:with_computational_assumptions}.
#+end_margin
\kern-0.4em%
@@latex:\fi%@@
thereby avoiding unnecessary domain specific clutter and making definitions
clearer.

# The languages are presented gently in increasing
# degrees of abstraction.

*Madlips*:
#+begin_margin :width "0.45\\textwidth"
This is a collection of English sentences that may result from the /lips/ of a
person who is /mad/. Example phrases include =He Ate The Apple, He Ate Jim,= and
=Apple Kissed The Jim= ---whereas the first is reasonable, the second is
worrisome, and the final phrase is confusing.
#+end_margin
Simple English sentences have the form subject-verb-object such as /‚ÄúJim ate the
apple‚Äù/. To /mindlessly/ produce such sentences, one must produce a subject,
then a verb, then an object ---all from given lists of possibilities. A
convenient notation to describe a language is its /grammar/
citet:DBLP:journals/iandc/Chomsky59b,DBLP:journals/iandc/Chomsky59a presented in
/Backus-Naur Form/
citet:DBLP:journals/cj/ChaplinCH73,DBLP:conf/aplas/GuoyongDF02,DBLP:journals/bmcbi/LarosBDT11,DBLP:journals/cacm/Knuth64a
as shown below.

# +latex: \FloatBarrier
# The FloatBarrier stops floats (figures are floats) from jumping over them. I
# will need to look into passing [tbh] options to figures from org mode further.
# The FloatBarrier apparently is not the culprit for the two wrong footnote
# numbers above.

{{{code(Madlips Grammar)}}}
# +caption: Madlips Grammar
# +begin_figure org
#+latex: \begin{figure}[h!]
#+latex: \label{fig:madlips-grammar}
#+begin_center
#+begin_src haskell
Subject  ‚à∑= Jim | He | Apple
Verb     ‚à∑= Ate | Kissed
Object   ‚à∑= The Subject | Subject
Sentence ‚à∑= Subject Verb Object
#+end_src
#+end_center
# +end_figure
#+latex: \end{figure}
The notation ~œÑ ‚à∑= c‚ÇÄ | c‚ÇÅ | ‚Ä¶ | c‚Çô~ defines the name œÑ as an alias for the
collection of words ---also called /strings/ or /constructors/--- ~c‚ÇÄ~ or ~c‚ÇÅ~ or ‚Ä¶ or
~c‚Çô~; that is the bar ‚Äò|‚Äô is read ‚Äòor‚Äô. The name œÑ is also known as a /syntactic
category/.  For example, in the Madlips grammar, =Subject= is the name of the
collection of words /Jim, He,/ and /Apple/.  A constructor may be followed by words
of another collection, which are called /the arguments of the constructor/.  For
example, the =Object= collection has a ~The~ constructor which must be followed by a
word of the =Subject= collection; e.g, =The Apple= is a valid /value/ of the =Object=
collection, whereas =The= is just an incomplete construction of =Object= words.  The
last clause of =Object= is just =Subject=: An invisible (unwritten) constructor that
takes a value of =Subject= as its argument; e.g., ~He~ and all other values of
=Subject= are also values of the =Object= collection. Similarly, the =Sentence=
collection consists of one invisible (unwritten) constructor that takes 3
arguments ---a subject, a verb, and an object. Below is an example /derivation/ of
a /sentence/ in the /language generated by this grammar/; at each ‚Äò‚Üí‚Äô step, one of
the collection names is replaced by one of its constructors until there are no
more possible replacements ---justifications are shown to the right.
{{{code(Example Derivation)}}}
#+begin_src haskell
   Sentence
‚Üí Subject Verb Object         -- Definition of ‚ÄòSentence‚Äô
‚Üí Jim     Verb Object         -- Choose a ‚ÄòSubject‚Äô value
‚Üí Jim     Ate  Object         -- Choose a ‚ÄòVerb‚Äô value
‚Üí Jim     Ate  The Subject    -- Construct an ‚ÄòObject‚Äô value
‚Üí Jim     Ate  The Apple      -- Choose a ‚ÄòSubject‚Äô value
#+end_src
Similarly, one may form =He Kissed Jim= as well as the @@latex:\newline@@ meaningless
#+begin_margin :width "0.45\\textwidth"
We are treating sequences of symbols /extensionally/ as mere representations,
denotations, of unique ideas.  For instance, in a context where ~He~ refers to
~Jim~, we may as well say ~He Ate The Apple~ is /the same as/ ~Jim Ate The Apple~.
However, the previous two Madlips sentences are /intrinsically/, by their very
syntactic nature, /distinct/. Some operations are only possible when we treat
sentences in one mode or the other; e.g., sentence decomposition is syntactic.
#+end_margin
sentence =Apple Kissed He=.
- The first is vague, the pronoun ‚ÄòHe‚Äô does not designate a known person but
  instead ‚Äústands in‚Äù for a /variable/, yet unknown, person. As such, the first
  sentence can be assigned a meaning once we have a /context/ of which pronouns
  refer to which people.
- The second just doesn't make sense. Sometimes nonsensical sentences can be
  avoided by restructuring the grammar, say, by introducing auxiliary syntactic
  categories. A more general solution is to introduce /judgement rules/ that
  characterise the subset of sentences that are sensible.

#+latex: \noindent
We will return to the notions of /context/ and /judgement/ after the next example language.

*Freshmen*:
Introductory computing classes are generally interested in arithmetic
that involves both numeric and truth values ---also known as /Boolean values/. We can capture some of their ideas with the following
grammar.
{{{code(Freshmen Grammar)}}}
#+begin_src haskell
Term ‚à∑= Zero | Succ Term | Term + Term   -- Numeric portion
      | True | False | Term ‚âà Term       -- Boolean portion
#+end_src
Unlike the previous grammar, instead of =+ Term Term= to declare a constructor ‚Äò+‚Äô
that takes two =Term= values, we write the operation ~_+_~ as an \emph{infix} operation
in the middle, since that is a common convention for such an
operation. Likewise, =Term ‚âà Term= specifies a constructor ~_‚âà_~ that takes two term
values.

(With this, we are following the general convention
to use underscores ‚Äú_‚Äù to denote the /position/ of arguments to
constructions that do not appear first in a term. For example, one writes
=if_then_else_= to indicate that we have a construction that takes /three/
arguments, as indicated by the number of underscores; whence in a term such as
=if ùìç then ùìé else ùìè= it is understood that we have the construction =if_then_else_=
applied to the arguments ùìç, ùìé, and ùìè.)

** nomargins                                                        :ignore:
#+latex: \nomargins

Example terms include the numbers ~Zero, Succ Zero,~ and ~Succ Succ Zero~ ---which
denote 0, 1 (the successor of zero), and 2 (the successor of the successor of
zero). The sensible Boolean terms ~True ‚âà False~ and ~True~ are also possible
---regardless of /how true/ they may be.  However, the nonsensical terms ~True +
False~ and ~Zero ‚âà True~ are also possible. As mentioned earlier, judgement rules
can be used to characterise the sensible terms: The relationship ‚Äúterm /t/ is an
element of kind œÑ‚Äù, written ~t ‚à∂ œÑ~ is defined by (1) introducing a new syntactic
category (called ‚Äútypes‚Äù) to ‚Äòtag‚Äô terms with the kind of elements they denote,
and (2) declaring the conditions under which the relationship is true.
{{{code(Types for Freshmen)}}}
#+begin_src haskell
Type ‚à∑= Number | Boolean
#+end_src
#+begin_export latex
\begin{tcolorbox}[colframe=red!75!black, title= Judgement Rules]
\begin{mathpar}
       \inferrule{¬†}{\mathtt{Zero} : \mathtt{Number}}
  \and \inferrule{t : \mathtt{Number}}{\mathtt{Succ}\, t : \mathtt{Number}}
  \and \inferrule{s : \mathtt{Number} \quad t : \mathtt{Number}}%
        {s\, + \,t : \mathtt{Number}}
  \and \inferrule{¬†}{\mathtt{True} : \mathtt{Boolean}}
  \and \inferrule{¬†}{\mathtt{False} : \mathtt{Boolean}}
  \and \inferrule{s : \mathtt{Number} \quad t : \mathtt{Number}}%
        {s\, ‚âà \,t : \mathtt{Boolean}}
  \and \inferrule{s : \mathtt{Boolean} \quad t : \mathtt{Boolean}}%
        {s\, ‚âà \,t : \mathtt{Boolean}}
\end{mathpar}
\end{tcolorbox}
#+end_export
A rule ‚Äú ${premises \over conclusion}$ ‚Äù means ‚Äúif the top parts are all true,
then the bottom part is also true‚Äù ---for instance, in elementary school, one
may have seen ‚Äú $\text{{\footnotesize +}}\frac{\substack{11 \\ \;\;1}}{12}$ ‚Äù
for arithmetic---; some rules have no premises and so their conclusions are
unconditionally true.  That these are /judgement rules/ means that a particular
instance of the relationship ~t ‚à∂ œÑ~ is true if and only if it is the conclusion
of ‚Äòrepeatedly stacking‚Äô these rules on each other.  For example, below we have
a /derivation tree/ that allows us to conclude the sentence ~Zero ‚âà Succ Zero~ is a
Boolean term ---regardless of /how true/ the equality may be. Such trees are both
read and written from the /bottom to the top/, where each horizontal line is an
invocation of one of the judgement rules from above, until there are no more
possible rules to apply.
#+latex: \def\Zero{\mathtt{Zero}}
#+latex: \def\Number{\mathtt{Number}}
#+latex: \def\Boolean{\mathtt{Boolean}}
#+begin_export latex
\begin{mathpar}
\inferrule{ \inferrule{¬†}{\mathtt{Zero} : \mathtt{Number}}
          \qquad \inferrule{\inferrule{¬†}{\mathtt{Zero} : \mathtt{Number}}}
                      {\mathtt{Succ\, Zero} : \mathtt{Number}}}
          {\mathtt{Zero}\, ‚âà \,\left(\mathtt{Succ\, Zero}\right) : \mathtt{Boolean}}
\end{mathpar}
#+end_export

This solves the problem of nonsensical terms; for example, ~True + Zero~ /cannot be
assigned/ a type since the judgement rule involving =_+_= requires both its
arguments to be numbers. As such, /consideration is moved from raw terms, to
typeable terms./ The types can be interpreted as /well-definedness constraints/ on
the constructions of terms.  Alternatively, types can be considered as /abstract
interpreters/ in that, say, we may not know the exact /value/ of ~s + t~ but we know
that it is a ~Number~ /provided/ both ~s~ and ~t~ are numbers; whereas we know nothing
about ~Zero + False~.

#+latex: \begin{tcolorbox}[colframe=red!75!black]
| Concept | Intended Interpretation                                |
|---------+--------------------------------------------------------|
| type    | a collection of things                                 |
| term    | a particular one of those things                       |
| $x : œÑ$ | the declaration that $x$ is indeed within collection œÑ |
#+latex: \end{tcolorbox}

There is one remaining ingredient we have yet to transfer over from the Madlips
setting: Pronouns, or /variables/, which ‚Äústand in‚Äù for ‚Äúyet unknown‚Äù values of a
particular type. Since a variable, say, ~ùìç~, is a stand-in value, a term such as
~ùìç + Zero~ has the ~Number~ type /provided/ the variable ùìç is known, in a /context/, to
be of type ~Number~ as well. As such, in the presence of variables, the typing
relation ~_:_~ must be extended to, say, ~_‚ä¢_‚à∂_~ so that we have /typed terms in a
context/.  \[ Œì ‚ä¢ t : œÑ \qquad‚â°\qquad \text{‚Äú\emph{In the context Œì, term $t$
has type œÑ}‚Äù} \] A /context/, denoted Œì, is simply a list of associations: In
Madlips, a context associates pronouns with the names of people they refer to;
in Freshmen, a context associates variables with their types. For example, $Œì :
\mathtt{Variable} ‚Üí \mathtt{Type}; Œì(x) = \mathtt{Number}$ associates the =Number=
type to every variable. In general, a context only needs to mention the pronouns
(variables) used in a sentence (term) for the sentence (term) to be understood,
and so it may be /presented/ as a set of pairs $Œì = \{(x‚ÇÅ, œÑ‚ÇÅ), ‚Ä¶, (x‚Çô, œÑ‚Çô)\}$
/with/ the understanding that $Œì(x·µ¢) = œÑ·µ¢$.  However, since we want to /treat/ each
association $(x·µ¢, œÑ·µ¢)$ as saying ‚Äú$x·µ¢$ has type $œÑ·µ¢$‚Äù, it is common to present
the /tuples/ in the form $x·µ¢ : œÑ·µ¢$ ---that is, the colon ‚Äò:‚Äô is /overloaded/ for
denoting tuples in contexts and for denoting typing relationships.

{{{code(Extending Freshmen with Variables)}}}
#+begin_src haskell
Term     ‚à∑= ‚ãØ | Variable
Variable ‚à∑= ùìç | ùìé | ùìè
#+end_src

We have one new rule to type variables, which makes use of the underlying
context.
#+latex: \begin{tcolorbox}[colframe=red!75!black]
#+begin_export latex
\begin{mathpar}
       \inferrule{Œì(x) = œÑ}{Œì ‚ä¢ x : œÑ}
\end{mathpar}
#+end_export
#+latex: \end{tcolorbox}
All previous rules must now additionally keep track of the context; e.g.,
the =_+_= rule becomes:
#+begin_export latex
\begin{mathpar}
  \inferrule{Œì ‚ä¢ s : \mathtt{Number} \quad Œì ‚ä¢ t : \mathtt{Number}}%
             {Œì ‚ä¢ s\, + \,t : \mathtt{Number}}
\end{mathpar}
#+end_export
We may now derive ~ùìç ‚à∂ Number ‚ä¢ ùìç + Zero ‚à∂ Number~ but cannot complete the
senseless phrase ~ùìç ‚à∂ Boolean ‚ä¢ ùìç + Zero ‚à∂ ???~.  /That is, the same terms may
be typeable in some contexts but not in others./

Before we move on, it is interesting to note that contexts can themselves be
presented with a grammar ---as shown below, where constructors ‚Äò,‚Äô and ‚Äò:‚Äô each
take two arguments and are written infix; i.e., instead of the usual ~, arg‚ÇÅ arg‚ÇÅ~
we write ~arg‚ÇÅ , arg‚ÇÇ~. Contexts are /well-formed/ when variables are associated at
most one type; i.e., when contexts /represent/ ‚Äòpartial functions‚Äô.
{{{code(Grammar for Contexts)}}}
#+begin_src haskell
Context     ‚à∑= ‚àÖ | Association, Context
Association ‚à∑= Variable : Type
#+end_src

Finally, it is interesting to observe that the addition of variables results in
an interesting correspondence: /Terms in context are functions of their
variables./ More precisely, if there is a method ~‚ü¶_‚üß~ that /interprets/ type names ~œÑ~
as actual sets ~‚ü¶œÑ‚üß~ and terms ~t ‚à∂ œÑ~ as /values/ of those sets ~‚ü¶t‚üß ‚à∂ ‚ü¶œÑ‚üß~, then a
*term* in context ~x‚ÇÅ ‚à∂ œÑ‚ÇÅ, ‚Ä¶, x‚Çô ‚à∂ œÑ‚Çô ‚ä¢ t ‚à∂ œÑ~ corresponds to the *function* $f :
‚ü¶œÑ‚ÇÅ‚üß √ó ‚ãØ √ó ‚ü¶œÑ‚Çô‚üß ‚Üí ‚ü¶œÑ‚üß; f(x‚ÇÅ, ‚Ä¶, x‚Çô) = ‚ü¶t‚üß$.  /That is, terms in context model
parameterisation without speaking of sets and functions./ (Conversely, /functions/
$A ‚Üí B$ ‚Äúare‚Äù /elements/ of $B$ /in a context/ $A$.)  As mentioned in the
introduction, we want to treat packages as the central structure for compound
computations. To this aim, we have the
#+latex: approximate\FOOTNOTE{
Briefly, given a parameterised package in Agda (section \ref{sec:agda_tour})
src_agda[:exports code]{module M (x : ‚Ñï) where y : ‚Ñï; y = 3 + x} we may form the
term in context $x : ‚Ñï \;‚ä¢\; y : ‚Ñï = 3 + x$ (section \ref{sec:GTT}) and
there is a clear converse construction.  Next, if we place a ‚ÄòŒª‚Äô in front of
that context, we get a function, and so parameterised packages are functions.
#+latex: }
slogan: /*Parameterised packages are terms in context.*/

** yesmargins                                                       :ignore:
#+latex: \yesmargins
** Signatures

#+latex: \label{sec:signatures}
#+latex: \tcbset{colback=green!10!white}

The languages of the previous section can be organised into /signatures/, which
define interfaces in computing since they consist of the /names/ of the types of
data as well as the /names/ of operations on the types ---there are only symbolic
names, not implementations. The purpose of this section is to organise the ideas
presented in the previous section ---shown again in the figure below--- in a
refinement-style so that the resulting formal definition permits the
presentation of packages given in section \ref{sec:what_is_a_language} above.

# +latex_header_extra: \usetikzlibrary{decorations.pathmorphing} % required in the preamble
#+begin_export latex
\begin{center}
\maxsizebox{.9\textwidth}{\textheight}{
\smartdiagram[flow diagram:horizontal]{Signatures\\ (Packages), Types, Terms, Type Variables, \!\!\!\mbox{Presentations}}}
\end{center}
#+end_export

#+latex: \noindent
The arrows ‚Äú ~ùí≥ ‚ü∂ ùí¥~ ‚Äù in the above diagram may be read as /‚Äúùí≥ gives rise to an
issue involving ùí¥‚Äù/. The purpose of this figure is to sketch out the intended
transitions from signatures, to types, and, eventually, to presentations;
then to an improved definition of /(generalised) signatures/ which may be used
as the formal definition of a /package/.

*** Typed terms in arbitrary signatures

A *signature*
#+begin_margin :width "0.45\\textwidth"
A signature is also known as a /vocabulary/.

#+latex: \vspace{1ex}
/Unary signatures/ are those with only one source sort for each function symbol
---i.e., the length of $\src f$ is always 1--- and so are just graphs.  Hence,
/signatures generalise graphical sketches/.

#+latex: \vspace{1ex}
The slogan *Signatures ‚âà Graphs* is captured by the following
correspondence, (re)interpretation of signature components:
+ Sorts ‚âà ‚Äúdots on a page‚Äù; Vertices
+ Function symbols ‚âà ‚Äúlines between the dots‚Äù; Edges

# +name: tbl:sigs-are-graphs
# +begin_figure org
# +latex: \label{tbl:sigs-are-graphs}
# | Signatures       | ‚âà | Graphs                                     |
# |------------------+---+--------------------------------------------|
# | Sorts            |   | ‚Äúdots on a page‚Äù, Nodes, Vertices          |
# | Function symbols |   | ‚Äúlines between the dots‚Äù, Edges, Tentacles |
# +end_figure
# +latex: \end{tcolorbox}
#+end_margin
citet:JacobsCLTT,LogicHandbookVol5 is a tuple /(ùíÆ, ‚Ñ±, src, tgt)/ consisting of
+ a
  #+latex: set\ignore{\footnote{
  In programming language communities \cite{10.5555/114891}, a signature is also
  known as /a programming language/ ---since our (non-generalised) signatures do
  not admit function types, they are not equivalent to $Œª^{√ó,‚Üí}$, /a pure lambda/
  /calculus, with function and product types, and basic datatypes ùíÆ and primitive
  operations ‚Ñ±/.  Moreover, sorts are also known as /base types/, /type symbols/, or
  /type constants/ ---in constrast to ‚Äòtype constructors‚Äô, which are type-yielding
  functions.
  #+latex: }}
  ùíÆ of /sorts/ ---the names of types---,
+ a set ‚Ñ± of /(function) symbols/,@@latex:\footnote{ Sometimes signatures are
  presented with dedicated sets of ‚Äòfunction symbols‚Äô and ‚Äòpredicate, relation,
  symbols‚Äô. The chosen presentation avoids such a route since we want to use
  Agda, which does not distinguish between the two.  Indeed, for us, \emph{there
  are no predicate symbols nor function symbols, only symbols} and \emph{there
  are no proof terms, only terms}.  We may \emph{simulate} predicate symbols by
  declaring that a sort, say, ‚Äòùîπ‚Äô in ùíÆ models the Booleans, the truth-values
  ---then, for instance, a ‚Äòproof term‚Äô is a term of type ùîπ.  }@@ and
+ two
  #+latex:  mappings\ignore{\footnote{
  Computing generally requires more sorts in comparison to traditional algebras
  in classical mathematics and so giving a signature's symbols with numbers for
  their arities is not as helpful as giving each symbol a list of its source
  sorts ---whose length then determines its arity.  For a traditional
  mathematical flavour, consult [[https://www.math.uwaterloo.ca/~snburris/htdocs/UALG/univ-algebra.pdf][/A Course in Universal Algebra/]]
  \cite{DBLP:books/daglib/0067494}.
  #+latex: }}
  $\src : ‚Ñ± ‚Üí \List ùíÆ$ and $\tgt : ‚Ñ± ‚Üí ùíÆ$ that associate a
  list[fn:20] of /source sorts/ and a /target sort/ with a given function symbol.

*Typing* the symbols of a signature as follows@@latex: \iffalse@@
#+begin_margin :width "0.45\\textwidth"
The wedge symbol ‚Äò‚àß‚Äô is read ‚Äúand‚Äù; e.g., $p ‚àß q$ is read /‚Äústatements $p$ and
$q$ are both true‚Äù/.  The symbol ‚Äò‚â°‚Äô is read ‚Äúequivales‚Äù, ‚Äúexactly when‚Äù, or ‚Äúif
and only if‚Äù; e.g., $p ‚â° q$ is read /‚Äúp holds exactly when q holds‚Äù/.
#+end_margin
@@latex: \fi{}@@
lets us treat signatures
as general forms of ‚Äòtype theories‚Äô since we may speak of ‚Äòtyped terms‚Äô.
\[
f : s‚ÇÅ √ó ‚ãØ √ó s‚Çô ‚Üí t \qquad‚â°\quad \src f = [s‚ÇÅ, ‚Ä¶, s‚Çô] \;‚àß\; \tgt f = t
\]
@@latex: \clearpage@@
Moreover, we regain the /typing judgements/ of the previous section by introducing
a grammar for /terms/.
Given a set ùí± of *variables*, we may define *terms*
#+begin_margin :width "0.45\\textwidth"
These are also known as /expressions/ and /(abstract syntax) trees/
---\cite{10.5555/114891}: The leaves of which are labelled with variables (from
ùí±) or constants (symbols $f$ with $\src f = []$), and the internal nodes are
labelled with function symbols (from ‚Ñ±) of positive arity, with outdegree equal
to the arity of the label. Hence, *abstract syntax is characterised algebraically
using signatures*; moreover, every context-free grammar gives a canonical
signatures ---with non-terminals as sorts and constructors as function
symbols--- but the converse is not true since signatures may have infinitely
many sorts or symbols, and they have no designated ‚Äòstart state‚Äô.
#+end_margin
with the following grammar.
{{{code(Grammar for Arbitrary Terms)}}}
#+begin_src haskell
Term ‚à∑= x             -- A variable; an element of ùí±
       | f t‚ÇÅ t‚ÇÇ ‚Ä¶ t‚Çô -- A function symbol f of ‚Ñ± taking
                      --    n sorts where each t·µ¢ is a Term
#+end_src

#+begin_box Signature Typing
#+begin_export latex
\label{fig:signature-typing}
\begin{mathpar}
       \inferrule{Œì(x) = œÑ}{Œì ‚ä¢ x : œÑ}
  \and \inferrule{Œì \,‚ä¢\, t‚ÇÅ : œÑ‚Çô \quad ‚Ä¶ \quad Œì \,‚ä¢\, t‚Çô : œÑ‚Çô \qquad \mathtt{f} : œÑ‚ÇÅ √ó ‚ãØ √ó œÑ‚Çô ‚Üí œÑ}
       {Œì \,‚ä¢\, \mathtt{f}\, t‚ÇÅ\, t‚ÇÇ\, ‚Ä¶\, t‚Çô : \mathtt{œÑ}}
\end{mathpar}
#+end_export
#+end_box

As discussed in the previous section, variables are /not/ necessary and if they
are /not/ permitted, we omit the first clause of =Term= and only use the second
typing rule ---we also drop the contexts since there would be no variables for
which variable-type associations must be remembered. Without variables, the
resulting terms are called /ground terms/. Since terms are defined recursively,
inductively, the set of ground terms is non-empty precisely when at least one
function symbol ~c~ needs no arguments, in which case we say ~c~ is a /constant
symbol/ and
#+begin_margin :width "0.45\\textwidth"
The second typing rule now becomes an axiom rather than inference rule:
For any /constant/ $c$ of type œÑ:
#+begin_tree
+ Constant Type :: \;‚ä¢\; c : œÑ
  -
#+end_tree
The typing context is empty since the type of a constant is fixed, and therefore
independent of the context in which it appears.
#+end_margin
make the following abbreviation:
\[
c : œÑ \qquad ‚â° \qquad \src c = [] \;‚àß\; \tgt c = œÑ
\]
Alternatively, the abbreviation ~œÑ‚ÇÅ √ó ‚ãØ √ó œÑ‚Çô ‚Üí œÑ~ is written as just =œÑ=
/when/ /n = 0/.

*** Signature Presentation, Briefly

How do we actually *present* a signature?
#+begin_margin :width "0.45\\textwidth"
How do we /write down/ the required parts of a signature?  It is reasonable
---‚Äòbrute force‚Äô--- to begin by presenting the required components of a
signature as /listings/: The values of sets are listed out, and the value of
function $f$ at input $x$ ---/f(x)/--- is shown in a table at the intersection of
the row labelled $f$ and the column labelled $x$.  Are there better approaches?
#+end_margin

For instance, recall the Freshmen language, we can present an /approximation/
#+begin_margin :width "0.45\\textwidth"
This is an approximation since we have constrained the equality construction,
=_‚âà_=, to take /only/ numeric arguments; whereas the original Freshmen allowed both
numbers and Booleans as arguments to equality /provided/ the arguments have the
/same type/. We shall return to this issue later when discussing /type variables/.
#+end_margin
of it as a signature by providing the necessary components ùíÆ, ‚Ñ±, $\src$, and
$\tgt$ as follows ---where, for brevity, we write ‚Ñ¨ and ùí© instead of =Boolean= and =Number=.
| =ùíÆ = {Number, Boolean}= |
| =‚Ñ± = {Zero, Succ, Plus, True, False, Equal}= |
# and src, tgt:
#+latex: \vspace{-2em}
  |   /op/   | =Zero= | =Succ= | =True= | =False= |  =_+_=   |  =_‚âà_=   |
  |  <c>   | <c>  | <c>  | <c>  |  <c>  |  <c>   |  <c>   |
  |--------+------+------+------+-------+--------+--------|
  | $\src$ |  ~[]~  | =[ùí©]=  |  ~[]~  |  ~[]~   | =[ùí©, ùí©]= | =[ùí©, ùí©]= |
  | $\tgt$ |  =ùí©=   |  =ùí©=   |  ~‚Ñ¨~   |   ~‚Ñ¨~   |   =ùí©=    |   =‚Ñ¨=    |

#+latex: \vspace{-1.5em}
# #+begin_footnotesize
# ( For each choice of /op/ in the first line, =src op= is defined by the
# corresponding column of the second line; likewise for =tgt op=. )
# #+end_footnotesize
#

This is however rather /clumsy/ and not that clear: We may collapse the =src, tgt=
definitions into the =_:_‚Üí_= relation defined above; i.e., replacing /two/
definition declarations ~src Zero = [] ‚àß tgt Zero = Number~ by /one/ definition
declaration
#+begin_margin :width "0.45\\textwidth"
After all, the previous section sets up typed terms
in any signature. That is, *replace ~src, tgt~ in preference to ~_‚à∂_‚Üí_~.*
#+end_margin
~Zero ‚à∂ Number~.  However, such a change would still leave function symbol names
repeated twice: Once in the definition of ~‚Ñ±~ and once in the definition of ~_‚à∂_‚Üí_~;
the latter mentions all the names of ‚Ñ± and so ‚Ñ± may be /inferred/ from the typing
relationships.  We are now left with two kinds of declarations: The sorts ùíÆ and
the typing declarations.  However, the set ùíÆ only serves to declare its elements
as sort symbols; if we use a new relationship, say ~_‚à∂ Type~ defined by ~œÑ ‚à∂ Type ‚â°
œÑ ‚àà ùíÆ~, then the sort symbols can also be introduced by seemingly similar ‚Äòtyping
declarations‚Äô. With this approach, Freshmen can be introduced more naturally
#+begin_margin :width "0.45\\textwidth"
It is important to note that there are three relations here with ‚Äò‚à∂‚Äô in their
name ---~_‚à∂Type~, ~_‚à∂_‚Üí_~, and ~_‚à∂_~ for constant-typing.  These are summarised
explicitly at the start of the next section.
#+end_margin
as follows.

{{{code(Freshmen as a Generalised Signature)}}}
#+begin_src haskell
Number  : Type
Boolean : Type

Zero : Number
Succ : Number ‚Üí Number
_+_  : Number √ó Number ‚Üí Number

True  : Boolean
False : Boolean
_‚âà_   : Number √ó Number ‚Üí Boolean
#+end_src

Notice, we started with two sets and two functions, i.e., signatures, but the
above is a sequence of name-type associations.  Recall, that the symbol Œì has
consistently been used to denote such things.  That is, these /‚Äògeneralised‚Äô
signatures are contexts./ We may thus define *packages* to be contexts where later
declared names may be typed by earlier names; i.e., the types of later items may
refer to the names of earlier declared items.

*** COMMENT package_
More precisely, with the relation ~package_~ defined
below, we can characterise packages as the contexts whose earlier elements allow
their later elements to be typeable.  For example, the context =S ‚à∂ Type; x ‚à∂ S=
can be proven to be package whereas the context =S ‚à∂ Type; x ‚à∂ Q= cannot ---it has
the ‚Äòglobal name‚Äô /Q/.

#+latex: \begin{tcolorbox}[colframe=red!75!black, title=Rules for determining when a signature is a package]
#+begin_export latex
A package is a context where later names' types may refer to earlier names.

\vspace{1ex}
Given a set $Name$ for variable names and context Œì, let $FName_Œì$ denote
the values of $Name$ that do not occur as names in context Œì
---these are the ‚Äúfresh names for context Œì‚Äù.

\begin{mathpar}
  \inferrule{¬†}{\package ‚àÖ}
  \and \inferrule{\package Œì \qquad œÑ ‚àà FName_Œì}{\package(Œì, œÑ : \mathtt{Type})}
  \and \inferrule{ \package Œì  \qquad f ‚àà FName_Œì \qquad  Œì ‚ä¢ œÑ·µ¢ : \mathtt{Type} \;\;\text{for each œÑ·µ¢}
    }{\package(Œì, f : œÑ‚ÇÅ √ó ‚ãØ √ó œÑ‚Çô ‚Üí œÑ‚Çô‚Çä‚ÇÅ)}
\end{mathpar}

By using $FName_Œì$, names are declared at most once in a context.
#+end_export
#+latex: \end{tcolorbox}

Below is an example derivation demonstrating that the context ~ùí© ‚à∂ Type, ‚Ñ¨ ‚à∂
Type, z ‚à∂ ùí©, s ‚à∂ ùí© ‚Üí ùí©~ (an initial segment of Freshmen) is actually a package by
taking $Name = \{ùí©, ‚Ñ¨, s, z\}$.
#+begin_export latex
\begin{tiny}
\begin{mathpar}
  \inferrule{
    \inferrule{¬†}{‚àÖ, ùí© : \Type, ‚Ñ¨ : \Type, z : ùí© ‚ä¢ ùí© : \Type}
    \and\inferrule{¬†}{s ‚àà FName}
    \and\inferrule{
    \inferrule{¬†}{‚àÖ, ùí© : \Type, ‚Ñ¨ : \Type ‚ä¢ ùí© : \Type}
    \and\inferrule{¬†}{z ‚àà FName}
    \inferrule{
          \inferrule{
            \inferrule{
           }{\package ‚àÖ}
         }{\package (‚àÖ, ùí© : \Type)}
      }{\package (‚àÖ, ùí© : \Type, ‚Ñ¨ : \Type)}
    }
    {\package (‚àÖ, ùí© : \Type, ‚Ñ¨ : \Type, z : ùí©)}
  }
  {\package (‚àÖ, ùí© : \Type, ‚Ñ¨ : \Type, z : ùí©, s : ùí© ‚Üí ùí©)}
\end{mathpar}
\end{tiny}
#+end_export

*** A grammar for types

It is important to pause and realise that there are /three relations with ‚Äò‚à∂‚Äô in
their name/ ---which may include spaces as part of their names.
1. /Function symbol to sort adjacency/: $f : s‚ÇÅ √ó ‚ãØ √ó s‚Çô ‚Üí s$ /abbreviates/
   $\mathsf{src}\, f = [s‚ÇÅ, ‚Ä¶, s‚Çô] ‚àß \mathsf{tgt}\, f = s$
2. /Sort symbol membership:/ $s : \mathsf{Type}$ /abbreviates/ $s ‚àà ùíÆ$
3. /Pair formation within contexts Œì/: $\;x : t$ /abbreviates/ $(x , t)$

#+latex: \noindent
Consequently, we have stumbled upon a grammar src_haskell[:exports code]{TYPE}
for types ---called the /types for signature Œ£/ over a collection of variable
names ùí±.  {{{code(Induced Grammar for Types)}}}
#+begin_src haskell
TYPE ::= Type         -- An opaque symbol; ‚Äúthe type of types‚Äù
      |  œÑ            -- œÑ is a sort symbol; a value of ùíÆ
      |  x            -- A variable; an element of ùí±
      |  TYPE ‚Üí TYPE  -- _‚Üí_  and _√ó_ each take
      |  TYPE √ó TYPE  --  two TYPE arguments
      |  ùüô
#+END_SRC
The type ùüô is used for constants‚à∂ With this grammar a constant $c ‚à∂ œÑ$ would
have type ~c ‚à∂ ùüô ‚Üí œÑ~. The symbol ùüô is used simply to indicate that the function
symbol =c= takes no arguments. The introduction of ùüô saves us from having to
account for the constant-typing relationship [[margin:][Defined above by \newline ~c ‚à∂ œÑ ‚â° src c = [] ‚àß tgt c = œÑ~.]] as if it were a primitive predicate.

We may now form type /expressions, terms,/ $Œ± ‚Üí Œ≤$ and $Œ± √ó Œ≤$ but there is no way
for the type ~Œ≤~ to depend on the type ~Œ±~.  In particular, recall that in Freshmen
we wanted to have ~s ‚âà t~ to be a well-formed term of type $\Boolean$ /provided/ =s=
and =t= have the /same/ type, either $\Number$ or $\Boolean$.  That is, =_‚âà_= wants to
have /both/ {{{mbox($\Number √ó \Number ‚Üí \Boolean$)}}} /and/ {{{mbox($\Boolean √ó
\Boolean ‚Üí \Boolean$)}}} as types ---since it is reasonable to compare either
numbers /or/ truth values for equality.  But a function symbol can have only /one/
type ---since $\src$ and $\tgt$ are (deterministic) functions [[margin:][A /function/ is an
association of ‚Äòinputs‚Äô to unique ‚Äòoutputs‚Äô.]] $\!\!$. If we had access to
variables which stand-in for types, we could type equality as $Œ± √ó Œ± ‚Üí \Boolean$
/for any type Œ±/.
#+begin_export latex
\begin{mathpar}
    \inferrule{¬†}{Œ± : \Type \quad‚ä¢\quad \_{}‚âà\_{} \,:\, Œ± √ó Œ± ‚Üí \Boolean}
\end{mathpar}
#+end_export

Even though types /constrain/ terms, there seems to be a subtle repetition: The
src_haskell[:exports code]{TYPE} grammar resembles the =Term= grammar. In fact, if
we pretend =Type, ùüô, _√ó_, _‚Üí_= /are/ function symbols, then =TYPE= is subsumed by =Term=.
Hence, we may conflate the two into one declaration to obtain /dependently-typed
terms/ ---a concern which we will return to at a later time
#+begin_margin :width "0.45\\textwidth"
For now, we may summarise our progress with the following figure.
#+begin_export latex
\color{black}
\maxsizebox{1.1\textwidth}{\textheight}{
\smartdiagram[descriptive diagram]{
{\!\!\mbox{Signatures}, Names that act as ‚Äútypes‚Äù and ‚Äúfunctions‚Äù},
{Typing, The ‚Äú$Œì‚ä¢t‚à∂œÑ$‚Äù relation},
{\mbox{Contexts}, Signatures presented using typing relations},
{\mbox{Packages}, Contexts with later names typed by earlier names},
}}
#+end_export
#+end_margin
.

** Presentations of Signatures ---Œ† and Œ£

<<sec:packages_and_their_parts:sigma_pi>>
# +latex: \label{sec:packages_and_their_parts:sigma_pi}

Since a signature's types also have a grammar, viz src_haskell[:exports
code]{TYPE}, we can present a signature in the natural style of ‚Äúname ‚à∂
type-term‚Äù pairs.  That is, a signature may be presented as a context; i.e.,
sequence of declarations ~Œ¥‚ÇÅ, Œ¥‚ÇÇ, ‚Ä¶, Œ¥‚Çô~ /such that/ each =Œ¥·µ¢= is of the form =name·µ¢ ‚à∂
type·µ¢= where /name·µ¢/ are unique names but /type·µ¢/ are /terms/ from the
src_haskell[:exports code]{TYPE} grammar.  /Conversely/
#+begin_margin :width "0.45\\textwidth"
*Proof of the claim:*
1. By induction on the number /n/.
2. When /n = 0/, there are no declarations
   and the outline construction
   yields the fully empty signature $(‚àÖ, ‚àÖ, ‚àÖ, ‚àÖ)$.
3. When /n ‚â• 1/, let Œ¥‚Çô be the final declaration.  Then, by induction, the
   previous /n - 1/ declarations constitute a signature $(ùíÆ‚Ä≤, ‚Ñ±‚Ä≤, \src‚Ä≤, \tgt‚Ä≤)$.
   Decompose $Œ¥‚Çô = (Œ∑ : œÑ)$. There are two cases to consider.
   a. ~œÑ = Type~: Since we assumed the names are unique, we have $Œ∑ ‚àâ ùíÆ‚Ä≤$ and so
      $(ùíÆ‚Ä≤ ‚à™ \{n\}, ‚Ñ±‚Ä≤, \src‚Ä≤, \tgt‚Ä≤)$ is a signature.
   b. ~œÑ ‚â† Type~: It must thus be a construction involving one of ‚Äò‚Üí, √ó, ùüô‚Äô; by
      definition of the src_haskell[:exports code]{TYPE} /assuming no
      variables/. In any case, we have a function symbol.  Since we assumed the
      names are unique, we have $Œ∑ ‚àâ ‚Ñ±‚Ä≤$ and so $\src‚Ä≤, \tgt‚Ä≤$ do not assign any
      type to $Œ∑$. Hence, we may define $\src s$ to be $\src‚Ä≤ s$ unless $s = Œ∑$
      in which case we yield the antecedent of œÑ if any, or ùüô otherwise.
      Likewise, define $\tgt$ to behave as $\tgt‚Ä≤$ except for Œ∑ in-which case
      yield the consequent of œÑ if any, or all of œÑ otherwise.
#+end_margin
such a presentation gives
rise to a unique signature $(ùíÆ, ‚Ñ±, \src, \tgt)$ where:
+ /ùíÆ/ is all of the /name·µ¢/ where /type·µ¢/ is =Type=;
+ ‚Ñ± is the remaining /name·µ¢/ symbols;
+ $\src, \tgt$ are defined by the following equations, where the right side,
  involving ~_:_‚Üí_~ and ~_:_~, are given in the context of =Œ¥·µ¢=.
  | $\src f = [œÑ‚ÇÅ, ‚Ä¶, œÑ‚Çô]$ | ‚àß | $\tgt f = œÑ$ | ‚â° | $f : œÑ‚ÇÅ √ó ‚ãØ √ó œÑ‚Çô ‚Üí œÑ$ |
  | $\src f = []$          | ‚àß | $\tgt f = œÑ$ | ‚â° | $f : œÑ$               |

  These equations ensure $\src, \tgt$ are functions /provided/ each name occurs at
  most once as the name part of a declaration.

# The purpose of the example was to make use of existing, common, phrases such as
#     ‚Äúschool smart‚Äù (people) vs ‚Äústreet smart‚Äù (people). The kind of people
#     one is speaking about is indexed by values of the location type.
#
This is one of the first instances of a syntax-to-semantics relationship: *A
context is a syntactic representation of a (generalised) signature*.
[[margin:][Signatures are all syntax; so we are interpreting contexts as a
syntax for another syntax (signatures).]]  However, with a bit of
experimentation one quickly finds that the syntax is ‚Äútoo powerful‚Äù: There are
contexts that do /not/ denote signatures. Consider the following grammar which
models ‚Äòsmart‚Äô people and their phone numbers. Observe that the ‚Äòsmartness‚Äô of a
person /varies/ according to their location; for example, in, say, a school
setting we have ‚Äòbook smart‚Äô people whereas in the city we have ‚Äòstreet smart‚Äô
people and, say, in front of a television we have ‚Äòno smart‚Äô people.  Moreover,
the function symbol =call= for obtaining the phone number of a ‚Äòsmart person‚Äô must
necessarily have a variable that accounts for how the smart type /depends/ on
location.  However, if variables are not permitted, then =call= cannot have a type
---which is unreasonable: We do not need /arbitrary/ stand-ins, but rather /local/
pronouns, variables.  It is a well-defined context, but it does not denote a
signature
#+begin_margin :width "0.45\\textwidth"
/Ignoring/ ~Smart~ and ~call~, the figure to the left yields the following signature.
+ ~ùíÆ = {Location, Phone}~
+ ~‚Ñ± = {School, Street, TV}~
+ $\src f = []$, for all $f : ‚Ñ±$, and
+ $\tgt f = \mathsf{Location}$, for all $f : ‚Ñ±$.
#+end_margin
.  {{{code(Calling-smart-people Context)}}}
#+begin_src haskell
Location : Type

School   : Location
Street   : Location
TV       : Location

Smart    : Location ‚Üí Type

Phone    : Type
call     : Smart ‚Ñì ‚Üí Phone  -- A variable?!
#+end_src

#+latex: \def\source{\mathsf{source}\,}
The first problem, the type of =Smart=, is easily rectified: We take the sorts ùíÆ
to be /all/ names œÑ‚ÇÅ from declarations $œÑ‚ÇÅ : œÑ‚ÇÇ$ in the context that produce a
src_haskell[:exports code]{TYPE} term; i.e., for which there exists a
sub-context $Œì$ such that $Œì ‚ä¢ œÑ‚ÇÇ : \Type$.  Sorts now may /vary/ or /depend/ on
other sorts.

*** Motivating the need for Œ† and Œ£

The second problem, the type of =call=, requires the introduction of a new[fn:24]
type operation. The operation =Œ†_‚à∂_‚Ä¢_= will permit us to type function symbols
that have variables in their types even when there is no variable collection ùí±.

#+latex: \begin{tcolorbox}[title = Dependent Function Type]
|   | $Œ†\, a : A \;‚Ä¢\; B\, a$                                  |
| ‚â° | ‚ÄúValues of /type/ $B\, a$, for each value $a$ of type $A$‚Äù |

#+latex: \tcblower

An element of $Œ†\, a : A ‚Ä¢ B\, a$ is a function $f$ which assigns to each $a :
A$ an element of $B\, a$. Such methods $f$ are /choice functions/: For every $a$,
there is a collection $B\, a$, and $f\, a$ picks out a particular $b$ in $a$'s
associated collection.

--------------------------------------------------------------------------------

The /values/ of function types are expressed as =Œª x ‚à∂ œÑ ‚Ä¢ t=; this /denotes/ the
function that takes input =x ‚à∂ œÑ= and yields output =t=. One then writes =f e=, or
~f(e)~, to denote the application of the function =f= on input term =e=.
#+latex: \end{tcolorbox}

The type of =call= is now =Œ† ‚Ñì ‚à∂ Location ‚Ä¢ (Smart ‚Ñì ‚Üí Phone)=.  That is, /given/ any
location ‚Ñì, =call ‚Ñì= specialises to a function symbol of type =Smart ‚Ñì ‚Üí Phone=,
then given any ‚Äúsmart person /s/ in location ‚Ñì‚Äù, src_haskell[:exports code]{call ‚Ñì
s} would be their phone number.  Moreover, if /s/ is a street-smart person then
=call School s= is /ill-typed/: The type of =s= must be =Smart School= not =Smart
Street=. Hence, /later inputs may be constrained by earlier inputs./ This is a new
feature that simple signatures did not have.

Before extending the previous definition of formal signatures, there is a
practical\footnote{Motivating Œ£!} subtlety to consider.  Suppose we want to talk
about smart people /regardless/ of their location, how would you express such a
type?  The type of {{{mbox(=call ‚à∂ (Œ† ùìÅ ‚à∂ Location ‚Ä¢ Smart ùìÅ ‚Üí Phone)=)}}} reads‚à∂
/After/ /picking a particular location ‚Ñì, you may get the phone numbers of the
smart people at that location./ More specifically, ~Smart ‚Ñì~ is the type of smart
people *at a particular* location ‚Ñì.  Since, in this case, we do not care about
locations, we would like to simply pick a person who is located *somewhere*.  The
ability to ‚Äúbundle away‚Äù a varying feature of a type, instead of fixing it at a
particular value, is known as the *(un)bundling problem[fn:23]*. It is addressed
by introducing a new[fn:25] type operator =Œ£_‚à∂_‚Ä¢_= ---the symbol ‚ÄòŒ£‚Äô is
conventionally used both for the name of signatures and for this new type
operator.

#+latex: \noindent\begin{tcolorbox}[title = Difference between Œ† and Œ£]
#+latex: \maxsizebox{0.85\textwidth}{!}{\begin{minipage}{\textwidth}
| =Œ† ‚Ñì ‚à∂ Location ‚Ä¢ Smart ‚Ñì= | ‚ÄúPick a location, then pick a person‚Äù            |
| =Œ£ ‚Ñì ‚à∂ Location ‚Ä¢ Smart ‚Ñì= | ‚ÄúPick a person, who is located \emph{somewhere}‚Äù |
#
More generally,
#+latex: \vspace{-.5em}
| =Œ† a ‚à∂ A ‚Ä¢ B a= | ‚ÄúPick a value =a ‚à∂ A=, to get =B a= values‚Äù              |
| =Œ£ a ‚à∂ A ‚Ä¢ B a= | ‚ÄúPick a value =b ‚à∂ B a=, which is tagged by /some/ \texttt{a ‚à∂ A}‚Äù |
# Values are pairs =(a, b)= with =a ‚à∂ A= and =b ‚à∂ B a=
#+latex: \end{minipage}}\end{tcolorbox}

# +latex: \vspace{-2em}
#+latex: \begin{tcolorbox}[title = Dependent Product Type]
 |   | $Œ£\, a : A \;‚Ä¢\; B\, a$                                            |
 | ‚â° | ‚ÄúPairs $(a, b)$, with $a : A$ and $b$ is a value of /type/ $B\, a$‚Äù |

#+latex: \tcblower

An element of $\;Œ£\, a : A ‚Ä¢ B\, a\;$ is a pair $(a, b)$ consisting of an element
$a : A$ along with an element $b : B\, a$.  Such pairs are /tagged values/: We
have values $b$ which are ‚Äòtagged‚Äô by the collection-/index/ $a$ with which they
are associated.

--------------------------------------------------------------------------------

Thinking of type families $B : A ‚Üí \Type$ as /predicates/ or /constraints/, or
/interfaces/, then one may think of $B\, a$ as the collection of /proofs/ of the
proposition $B\, a$, or as a /witness/ to the constraint, or as an implementation
to the interface. As such, Œ£-types $\;Œ£\, a : A ‚Ä¢ B\, a\;$ are sometimes denoted
using set notation $\;\{a : A \,‚ùô\, B\, a\}\;$ (‚Äòrefinement types‚Äô) and using
logical notation $\;‚àÉ a : A ‚Ä¢ B\, a\;$.

--------------------------------------------------------------------------------

The /values/ of product types are expressed as =(x , w)=; this /denotes/ pair of items
where the second may depend on the first.  One then writes src_haskell[:exports
code]{let (x, w) ‚âî Œ≤ in e} to ‚Äòunpack‚Äô the pair value =Œ≤= as the pair =(x, w)= for
use in term =e=.
#+latex: \end{tcolorbox}

*Old ideas as abbreviations:* The type operator =_‚Üí_= did not accommodate dependence
but Œ† does; indeed if $B$ does not depend on values of type $A$, then $Œ† a : A ‚Ä¢
B$ is just =A ‚Üí B=. Likewise
#+begin_margin :width "0.45\\textwidth"
Since Œ†/Œ£ are the /varying/ generalisations of ‚Üí/√ó, sometimes Œ†/Œ£ are written as
$(a : A) ‚Üí B\, a$ and $(a : A) √ó B\, a$, respectively.
#+end_margin
#+latex: \!\!,
Œ£ generalises =_√ó_=.  That is, provided $B$ is a type that does not vary:
| $A ‚Üí B$ | ‚â° | $Œ†\, x : A ‚Ä¢ B$ |
| $A √ó B$ | ‚â° | $Œ£\, x : A ‚Ä¢ B$ |

*** no margins :ignore:
#+latex: \nomargins
*** Examples: Œ†/Œ£ or ‚Üí/√ó

Before returning to the task of defining signatures, let us present a number of
examples to showcase the differences between dependent and non-dependent types.
#+latex: \def\birthday{\mathtt{Birthday}\,}
#+latex: \def\weekday{\mathtt{Weekday}}
#+latex: \def\people{\mathtt{People}}
#+latex: \def\english{\mathtt{English}}

#+latex: \begin{myexamplebox}{Example 1: People and their birthdays }

   Let $\birthday : \weekday ‚Üí \Type$ denote the collection of all people who
   have a birthday on a given weekday.  One says, /$\birthday$ is the collection
   of all people, *indexed* by their birth day of the week./ Moreover, let
   $\people$ denote the collection of all people in the world.

   #+latex: \tcbsubtitle{$Œ†\, d : \weekday ‚Ä¢ \birthday d$
   #+latex:      is the type of \emph{functions} that given any weekday $d$,
   #+latex:      yield a person whose birthday is on that weekday.}

       #+begin_parallel
     Example functions in this type are $f$ and $g$ below...
     #+begin_example haskell
     f Monday  = Jim
     f Tuesday = Alice

     g Monday  = Mark
     g Tuesday = Alice
     #+end_example

  #+columnbreak:
  ... /provided/ we live in a tiny world consisting of three people and only two weekdays.
  | Person | Birthday |
  |--------+----------|
  | Jim    | Monday   |
  | Alice  | Tuesday  |
  | Mark   | Monday   |
  #+end_parallel

     In contrast,
     $\weekday ‚Üí \people$ is the collection of functions associating
     people to weekdays ---no constraints whatsoever.
     E.g., =f d = Jim= is the function that associates =Jim= to every weekday =d=.

   #+latex: \tcbsubtitle{$Œ£\, d : \weekday ‚Ä¢ \birthday d$
   #+latex:   is the type of \emph{pairs} $(d, p)$ of a weekday $d$
   #+latex:   and a person whose birthday is that weekday.}

     Below are two values of this type (‚úì) and a non-value (√ó).  The third one
   is a pair $(d, p)$ where $d$ is the weekday =Tuesday= and so the $p$ must be
   /some/ person born on that day, and =Mark= is not such a person in our tiny world.
     #+begin_example haskell
     ‚úì (Monday, Jim)
     ‚úì (Tuesday, Alice)
     √ó (Tuesday, Mark)
     #+end_example

     In contrast,
     $\weekday √ó \people$ is the collection of pairs $(w, p)$ of
     weekdays and people ---no constraints whatsoever.
     E.g., =(Tuesday, Mark)= is a valid such value.
#+latex: \end{myexamplebox}

#+latex: \begin{myexamplebox}{Example 2: English words and their lengths }
   Let $\english_{‚â§ n}$ denote the collection of all English
   words that have at most /n/ letters; let $\english$ denote
   /all/ English words.

   #+latex: \tcbsubtitle{$Œ†\, n : ‚Ñï ‚Ä¢ \english_{‚â§ n}$ is the type of \emph{functions}
   #+latex:        that given a length $n$, yield a word of that length.}
     Below is part of a such a function =f=.
     #+begin_example haskell
     f 0 = ""   -- The empty word
     f 1 = "a"  -- The indefinite article
     f 2 = "to"
     f 3 = "the"
     f 4 = "more"
     ‚ãØ
     #+end_example

     In contrast, an $f : ‚Ñï ‚Üí \english$ is just a list of English words
     with the /i/-th element in the list being $f\, i$.

   #+latex: \tcbsubtitle{$Œ£\, n : ‚Ñï ‚Ä¢ \english_{‚â§ n}$ is the type of \emph{values} $(n, w)$ where $n$ is a
   #+latex: number and $w$ is an English word of that length.}

   For instance, ~(5, "hello")~ is an example such value; whereas ~(2, "height")~ is
   not such a value ---since the length of ="height"= is /not/ 2.

   #+latex: \vspace{1ex}
   In contrast, $‚Ñï √ó \english$ is any number-word pair, such as =(12, "hi")=.

   #+latex: \vspace{1ex}
   /Notice that dependent types may *encode properties* of values./

#+latex: \end{myexamplebox}

#+latex: \begin{myexamplebox}{Example 3: ‚ÄúAll errors are type errors‚Äù }
   Suppose =get i xs= is the /i/-th element in a list
   =xs = [x‚ÇÄ, x‚ÇÅ, ‚Ä¶, x‚Çô]=, what is the type of such a method =get=?

   #+latex: \vspace{1ex}
   Using =get ‚à∂ Lists ‚Üí ‚Ñï ‚Üí Value= will allow us to write =get [x‚ÇÅ, x‚ÇÇ] 44= which
   makes no sense‚à∂ There is no 44-th element in that 2-element list! Hence, the
   =get= operation must constrain its numeric argument to be at most the length of
   its list argument.  That is, =get ‚à∂ (Œ† (xs ‚à∂ Lists) ‚Ä¢ ‚Ñï< (length xs) ‚Üí Value)=
   where =‚Ñï< n= is the collection of numbers less than /n.  Now the previous call,
   =get [x‚ÇÅ, x‚ÇÇ] 44= does not need to make sense since it is ill-typed/: The second
   argument does not match the required constraining type.

   #+latex: \vspace{1ex}
   In fact, when we speak of lists we implicitly have a notion of the kind of
   value type they contain. As such, we should write =List X= for the type of
   lists with elements drawn from type =X=. Then what is the type of =List=? It is
   simply =Type ‚Üí Type=.  With this form, =get= has the type =Œ† X ‚à∂ Type ‚Ä¢ Œ† xs ‚à∂
   List X ‚Ä¢ ‚Ñï< (length xs) ‚Üí X=.

   #+latex: \vspace{1ex}
   Interestingly, lists of a particular length are known as /vectors/. The type of
   which is denoted =Vec X n=; this is a type that is /indexed/ by /both/ another /type/
   =X= and an /expression/ =n=. Of course =Vec ‚à∂ Type ‚Üí ‚Ñï ‚Üí Type= and, with vectors, =get=
   may be typed \newline =Œ† X ‚à∂ Type ‚Ä¢ Œ† n ‚à∂ ‚Ñï ‚Ä¢ Vec X n ‚Üí ‚Ñï< n ‚Üí X=; in-particular notice
   that the /external computation/ =length xs= in the previous typing of =get= is
   replaced by the /intrinsic index/ =n=; that is, *dependent types allow us to
   encode properties of elements at the type level!*

#+latex: \tcbsubtitle{Proof Sketch}

 Suppose we want to avoid the erroenous situation ùë¨ which can be expressed in
 higher order logic. Then we can type our program so that its output type is a
 dependent product $Œ£\, o : ùë∂ ‚Ä¢ ¬¨ ùë¨$, involving the intended output type ùë∂ and a
 proof obligation ---i.e., a value, witnessing the impossibility of ùë¨.
#+latex: \end{myexamplebox}

:TypeFamilies:
3. (‚ÄúType families‚Äù)

   =doit : ‚Ñï ‚Üí Type=
   #+begin_src haskell
   doit 0 = ‚Ñï
   doit 1 = ùîπ
   doit 2 = (‚Ñï ‚Üí ùîπ)
   doit 3 = ùîπ √ó ùîπ
   doit _ = Words
   #+end_src
:End:

*** yesmargins :ignore:
#+latex: \yesmargins

*** Defining Generalised Signatures

#+latex: \label{sec:GTT}

Anyhow, back to the task at hand ---formally defining signatures (packages).

#+latex: \def\type{\mathsf{type}\,}
#+latex: \def\definition{\mathsf{definition}\,}
#+latex: \def\Term{\mathsf{Term}}

For any set of ‚Äònames‚Äô ùí∞, suppose [[margin:][The subscript is omitted when there is no
ambiguity.]] $\Term_ùí∞$ is a set of ‚Äòterms‚Äô [[margin:][Any collection, possibly generated by a
grammar.]].  Moreover, suppose: (1) Every name is a term; i.e., $ùí∞ ‚äÜ \Term_ùí∞$.
\newline (2) There is a dedicated
#+begin_margin :width "0.45\\textwidth"
It serves to provide a uniform way to identify ‚Äòtypes‚Äô ---uniform in that it
mirrors the way values are typed.  Otherwise we would need a /dedicated/
predicate, such as ~_‚ä¢_ :Type~ from the previous section.  It answers the question
‚ÄúSome terms are types, how do we find them?‚Äù
#+end_margin
#+latex:$\,$
name ~Type~.  (3) $\Term_ùí∞$ is endowed with a ‚Äútyping judgement relation
$\_{}‚ä¢\_{}:\_{}$‚Äù; i.e., a ternary predicate on ‚Äòcontexts‚Äô-‚Äòterms‚Äô-‚Äòtypes‚Äô--- a
‚Äòcontext‚Äô is a list of name-to-term pairs and a ‚Äòtype‚Äô œÑ is any term for which
there is some context Œì and term ~t~ such that $Œì ‚ä¢ t : œÑ$.  We refer
#+begin_margin :width "0.45\\textwidth"
A *variable* is a name ~x~ of ùí∞ for which ~Œì ‚ä¢ x : œÑ~ can only happen when Œì contains
the association of ~x~ to œÑ; i.e., a variable is a name about which information is
known /only when the information is hypothesised/.  A non-variable is known as a
*value* or /well-defined name/.  If =Œì ‚ä¢ t ‚à∂ œÑ= and =Œì ‚ä¢ œÑ ‚à∂ Type= we refer to =t= as an
*expression* or *term*, to œÑ as a *type*, and to =Type= as a *kind*.  More accurately,
when Œì is a minimal context such that ~Œì ‚ä¢ œÑ ‚à∂ Type~ then we say œÑ is a *type*
precisely when Œì is empty, and otherwise speak of a *type constructor,
construction*; moreover, if Œì associates variables to terms besides ~Type~, then we
speak of a *dependently-typed construction* ---e.g., Œ† and Œ£. This is important
enough that it occurs in the main text and in the margin.
#+end_margin
to such triples $(ùí∞, \Term_ùí∞, \_{}\!‚ä¢\!\_{}\!:\!\_{})$ as *generalised type theories* [[margin:][An
example is shown in the next section!]] (GTT).

GTTs allow us to speak of arbitrary typed expressions and varying degrees of
actual typing. For instance, as previously discussed, every signature gives rise
to a typing relation that ignores any presence of variables.  However, GTTs are
strictly more powerful than classical signatures since they allow not only
nullary types (primitive sorts), but also /type constructors/ and /dependent-types/:
When Œì is a minimal context such that ~Œì ‚ä¢ œÑ ‚à∂ Type~ then we say œÑ is a *(nullary)
type* precisely when Œì is empty, and otherwise speak of a *type constructor,
construction*; moreover, if Œì associates variables to terms besides ~Type~, then we
speak of a *dependently-typed construction*.

For instance, let $ùí∞ = \{A\}$ and let $\Term$ be the set generated by the
following grammar
#+begin_margin :width "0.45\\textwidth"
As done before, the first clause of this grammar is an invisible constructor
injecting names of ùí∞ into the set of terms.
#+end_margin
.
{{{code(Term grammar for an example GTT)}}}
#+begin_src haskell
Term  ::=  ùí∞  |  ‚Ñï  |  Vec Term Term
#+end_src
\noindent Finally, we may take the typing relation to be generated by two clauses, for any
context Œì: (1) ~Œì ‚ä¢ ‚Ñï ‚à∂ Type~ and (2) ~Œì, œÑ ‚à∂ Type, n : ‚Ñï ‚ä¢ Vec œÑ n ‚à∂ Type~.  If we
take Œì to be the empty context, we find that ‚Ñï is a (nullary) type, whereas ~Vec~
is a type construction ---in fact, a dependent type, since the minimal context
required to type it associates the variable ~n~ to the non-~Type~ term ~‚Ñï~. Moreover,
the typing relation does not associate a type with any names (variables) of ùí∞,
but
#+begin_margin :width "0.45\\textwidth"
Since this example's typing relation is inductively defined, such a supposition
is absurd.
#+end_margin
/under the supposition/ that the variable name ~A~ were typed ~Type~, and ~n~ is typed
~‚Ñï~, then ~Vec A n~ would be a type.

Informally, in our exploratory investigation into a convenient /presentation/ of
signatures, we were inexorably led to having later declared types depend on
earlier types. Likewise, the previous GTT example could be rendered as follows:
{{{code(Example: An entire GTT viz a single context )}}}
#+begin_src haskell
‚Ñï   : Type
Vec : Type ‚Üí ‚Ñï ‚Üí Type
#+end_src
#+latex: \noindent
We regain a canonical GTT from such a presentation as follows: (0) The name set
ùí∞ is the infinitely countable set of strings formed from all possible
non-whitespace written ligatures, which includes the set of all names preceding
the first ‚Äò:‚Äô in each line of the presentation.  The set $\Term ùí∞$ is defined
inductively by the next two clauses. (1) All names are included in the set of
terms $\Term ùí∞$.  (2) Names for which the right side of the ‚Äò:‚Äô contains $n$
occurances of the ‚Äò‚Üí‚Äô symbol are constructors that (inductively) consume $n$
arguments of the term set being defined. (3) Finally, the typing relation ~_‚ä¢_‚à∂_~
is defined inductively with clauses
#+latex: \vspace{-.3em}
| ~Œì, t‚ÇÅ ‚à∂ œÑ‚ÇÅ, t‚ÇÇ ‚à∂ œÑ‚ÇÇ, ‚Ä¶, t‚Çô ‚à∂ œÑ‚Çô ‚ä¢ Œ∑ t‚ÇÅ t‚ÇÇ ‚Ä¶ t‚Çô ‚à∂ Type~ |
#+latex: \vspace{-.3em}
for every declaration [[margin:][When $n = 0$, we have declarations ~Œ∑ ‚à∂ Type~ and so typing
judgements ~Œì ‚ä¢ Œ∑ ‚à∂ Type~.]] ~Œ∑ ‚à∂ œÑ‚ÇÅ ‚Üí œÑ‚ÇÇ ‚Üí ‚ãØ ‚Üí œÑ‚Çô ‚Üí Type~.

That we are able to reconcile our presentation language with a sound formalising
is promising. However, as it stands, our GTT example has ~Vec~ /built-in/,
statically, and the only thing that can vary ---with respect to that example---
is the collection of variables [[margin:][It can't vary much if we use all ligatures!]]. It
would be nice if we had a way to /append/ GTTs with extra structure as we see fit;
e.g., to dynamically declare names to be new types or type constructions or
members of a type. Such ‚Äòdynamically extendable GTT-like structures‚Äô are what we
have been calling /generalised signatures/.

A *generalised signature*, with respect to a chosen GTT \newline $(ùí∞, \Term_ùí∞,
\_{}\!‚ä¢\!\_{}\!:\!\_{})$, is a set of triples
#+begin_margin :width "0.45\\textwidth"
Alternatively, we have a triple $(‚Ñ¨, \type, \definition)$ where $‚Ñ¨ ‚äÜ ùí∞$,
$\type : ‚Ñ¨ ‚Üí \mathsf{Context} √ó \Term_ùí∞$, and $\definition : ‚Ñ¨ ‚Üí \Term_ùí∞$ is a
/partial/ function.  Then one sets $‚Ñ¨ = \{Œ≤·µ¢\}_i$ and $(Œì·µ¢, œÑ·µ¢) = \type Œ≤·µ¢$ and
$Œ¥·µ¢ = \definition Œ≤·µ¢$ if defined or ‚Äò-‚Äô otherwise.

$\vspace{.5em}$

We /interpret/ src_haskell[:exports code]{Type} as the type of all
types; whereas the $Œ≤·µ¢$ let us /suppose/ a collection of /names/ for either
types/sorts /or/ function symbols, and they may be /aliases/ to existing terms $Œ¥·µ¢$.
#+end_margin
$(Œ≤·µ¢, Œì·µ¢, œÑ·µ¢, Œ¥·µ¢)$ where the $Œ≤·µ¢$ are /unique/ names drawn from ùí∞, the $Œì·µ¢$ are
name-to-term associations, the $œÑ·µ¢$ are terms, and the $Œ¥·µ¢$ are either terms or
the special symbol ‚Äò-‚Äô. One then /extends/ the underlying typing judgement by the
rules ${ \over \displaystyle Œì·µ¢ \;‚ä¢\; Œ≤·µ¢ : œÑ·µ¢}$, /and then/ ensures the resulting
system is /coherent/:
0. The claimed types are recognised by the theory as types: $Œì·µ¢ ‚ä¢ œÑ·µ¢ : \Type$
   for all $i$;
1. Definitions match types: $Œì·µ¢ ‚ä¢ Œ¥·µ¢ : œÑ·µ¢$ for all $i$;
2. Types are unique; i.e., whenever $Œì ‚ä¢ t : œÑ$ and $Œì ‚ä¢ t : œÑ‚Ä≤$
   @@latex:then\footnote{To allow subtyping, inclusion instead of equality would be
   required.}@@ $œÑ ‚â° œÑ‚Ä≤$ ---we will return to propositional equality in a later
   section.

Due to the latter two coherence conditions, the tuples $(Œ≤·µ¢, Œì·µ¢, œÑ·µ¢, Œ¥·µ¢)$ are
/presented/
#+begin_margin :width "0.45\\textwidth"
We are now overloading the existing colon ‚Äò:‚Äô relation to be part of a mixfix
name, $\_{}:\_{}‚Üí\_{}=\_{}$ to denote tuples. The use of contexts this way
occurs later as *telescopes* when we get to Agda.

Another reasonable notation would be $Œì·µ¢ ‚ä¢ Œ≤·µ¢ : œÑ·µ¢ = Œ¥·µ¢$, overloading the
judgement relationship name.
#+end_margin
as $Œ≤·µ¢ : Œì·µ¢ ‚Üí œÑ·µ¢ = Œ¥·µ¢$ when $Œ¥·µ¢$ is not the special symbol ‚Äò-‚Äô and otherwise
presented as $Œ≤·µ¢ : Œì·µ¢ ‚Üí œÑ·µ¢$.

#+latex: \def\pit{\mathsf{pit}}
For instance, continuing with the previous GTT example, we can form a
generalised signature with the two /tuples/ $ùîπ : \Type ‚ä¢ \pit : ùîπ$ and $\;‚ä¢ ùîπ :
\Type$ . Notice that the formal tuples are not as economical as the sequential
line-by-line presentation, due to the repetition of the newly minted value $ùîπ :
\Type$. Moreover, note that ùîπ is a /value/ in the second tuple ---since, by
definition, the name ùîπ is typeable---; however, if we omit the first clause,
then ùîπ is, by definition, a variable and we have declared $\pit$ to be a
polymorphic value of any given type.

:Equivalently:
*Equivalently*, a Generalised Signature is an ordered list of ‚Äòdeclarations‚Äô
$Œ¥‚ÇÅ, ‚Ä¶, Œ¥‚Çô$ where each $Œ¥·µ¢$ is a tuple from $Name √ó Term √ó (Term ‚à™ \{-\})$
---for an inferred set /Name/--- with the following constraints:
1. Each tuple $Œ¥·µ¢ = (Œ∑·µ¢, œÑ·µ¢, d·µ¢)$ is written as $Œ∑·µ¢ ‚à∂ œÑ·µ¢ ‚âî d·µ¢$ or
  as $Œ∑·µ¢ ‚à∂ œÑ·µ¢$ when $d·µ¢$ is the special symbol ‚Äú-‚Äù.
   a. We refer to $Œ∑·µ¢, œÑ·µ¢, d·µ¢$ as the /name, type/, and /definition/ of $Œ¥·µ¢$, respectively.
2. Declaration names must be unique.
3. $Œ¥‚ÇÅ, ‚Ä¶, Œ¥‚Çñ‚Çã‚ÇÅ ‚ä¢ Œ¥‚Çñ$ for all $k : 1..n$.

We refer to the second definition as a *contextual presentation* of Generalised
Signatures. In practice, we replace the separating commas of $Œ¥‚ÇÅ, ‚Ä¶, Œ¥‚Çô$ with
line breaks, and write $Œ∑ ‚à∂ œÑ ‚âî d$ as two lines: One with $Œ∑ ‚à∂ œÑ$ and another
with $Œ∑ = d$, if $d$ is not the opaqueness-value ‚Äú-‚Äù.  Moreover, in the case of
$Œ∑ = (Œª x ‚à∂ Œ± ‚Ä¢ e)$ we elide this as $Œ∑\, x = e$.
:End:

In summary, /a generalised signature extends a generalised type theory by
declaring some names/ /to be values (such as type constructions) and possibly
outright defining them explicitly./ Crucially, a generalised signature may be
presented as a sequence of declarations $d‚ÇÅ, ‚Ä¶, d‚Çô$ where each $d·µ¢$ is of the
form ‚Äú$name ‚à∂ term = term$‚Äù where the ‚Äú$= term$‚Äù portion is optional and the
names are unique.  When presented with multiple lines, we replace commas by
newlines, and split ‚Äú$name ‚à∂ type = definition$‚Äù into two lines: The first being
‚Äú$name ‚à∂ type$‚Äù and the second
#+begin_margin :width "0.45\\textwidth"
In the next example, MLTT, declarations of functions {{{mbox(=name = (Œª x ‚à∂ œÑ ‚Ä¢
e)=)}}} are instead simplified to {{{mbox(=name x = e=)}}}.
#+end_margin
$\!$, if any, being ‚Äú$name = definition$‚Äù.

*** MLTT: An example generalised type theory

A portion [[margin:][Only a portion is shown since we will cover the omitted features in
the section \ref{sec:agda_tour}, using Agda.]]
#+latex: Martin-L\"{o}f Type Theory
(MLTT) [[margin:][On which Agda is based.]]  citet:LogicHandbookVol5,DBLP:journals/fac/BackhouseC89 is
presented as the GTT having the terms generated inductively by the grammar and
rules below ---for any set of names ùí∞.
#+begin_margin :width "0.45\\textwidth"
+ ùí∞ and src_haskell[:exports code]{Type} together form the ‚Äúsort structure‚Äù
+ Œ†, Œª, and (the invisible) application form the ‚Äúfunctional structure‚Äù
+ Œ£, ~let~, and tupling form the ‚Äúrecord/packaging structure‚Äù

# This collection constructs a number of different kinds of things:
Recall: If =t ‚à∂ œÑ= and =œÑ ‚à∂ Type= we refer to =t= as an *expression*, to œÑ as a *type*, and
to =Type= as a *kind*.
# - The term =Type= is usually called a */kind/*;
# - The terms =œÑ= of type =Type= are called */types/*;
# - All other terms, those =t ‚à∂ œÑ= for =œÑ ‚à∂ Type=, are called */expressions/*.

# The following table provides an intuitive interpretation of these terms.
#+end_margin
{{{code(Generalised Terms)}}}
#+begin_src haskell
Term
    ‚à∑= x            -- A ‚Äúvariable, name‚Äù; a value of ùí∞
     | Type         -- The type of types
     -- For previously constructed types œÑ and œÑ',
     -- previously constructed terms t·µ¢,
     -- and variable name x:
    | (Œ† x : œÑ ‚Ä¢ œÑ') | (Œª x : œÑ ‚Ä¢ t)          |  t‚ÇÅ t‚ÇÇ
    | (Œ£ x : œÑ ‚Ä¢ œÑ') | let (t‚ÇÅ, t‚ÇÇ) ‚âî t‚ÇÉ in t‚ÇÑ | (t‚ÇÅ, t‚ÇÇ)
#+end_src


# Alreadt covered, incrementlly
:Intended_Interpretations_of_Generalised_Terms:
#+latex: \begin{tcolorbox}[title = Intended Interpretations of Generalised Terms]
| Symbols             | Intended Interpretation                                  |
|---------------------+----------------------------------------------------------|
| =Type=                | The type of all types                                    |
| =ùüô=                   | The type with one element; an example of a base symbol   |
|---------------------+----------------------------------------------------------|
| =Œ† a ‚à∂ A ‚Ä¢ B a=       | Values of /type/ =B a=, for each value =a= of type =A=           |
| =Œª x ‚à∂ œÑ ‚Ä¢ t=         | The function that takes input =x ‚à∂ œÑ= and yields output =t=  |
| =f e=                 | Apply the function =f= on input term =e=                     |
|---------------------+----------------------------------------------------------|
| =Œ£ a ‚à∂ A ‚Ä¢ B a=       | Pairs =(a, b)= where =a ‚à∂ A= and =b= is a value of /type/ =B a=    |
| =(x , w)=             | A pair of items where the second may depend on the first |
| =let (x, w) ‚âî Œ≤ in e= | Unpack the pair =Œ≤= as the pair =(x, t)= for use in term =e=   |

*Abbreviations*:
Provided $B$ is a type that does not vary,
| Symbol  |   | Elaboration     |   | Intended Interpretation                      |
|---------+---+-----------------+---+---------------------------------------------|
| $A ‚Üí B$ | ‚â° | $Œ†\, x : A ‚Ä¢ B$ |   | The functions from /A/ to /B/                   |
| $A √ó B$ | ‚â° | $Œ£\, x : A ‚Ä¢ B$ |   | Pairs of values /(a, b)/ with /a : A/ and /b : B/ |
#+latex: \end{tcolorbox}
:End:

The rules [[margin:][There are numerous other useful rules, which we have omitted for
brevity.]]  below classify the well-formed generalised terms.

# +latex: \begin{tcolorbox}[colframe=red!75!black, title=
# *[Judgements for Generalised Terms]*
#+latex: \dotfill

First are rules about contexts in general.  For instance, the second rule
#+begin_margin :width "0.45\\textwidth"
#+latex: The \textsc{Variables} rule is also known as \textsc{Assumption} or \textsc{Reflexivity}
and may be rendered as follows.
#+begin_tree
+ Variables :: x‚ÇÅ : œÑ‚ÇÅ,\, ‚Ä¶,\, x‚Çô : œÑ‚Çô \;‚ä¢\; x·µ¢ : œÑ·µ¢
  -
#+end_tree
#+end_margin
says /if Œì associates x to œÑ, then indeed it does so/.  The third rule [[margin:][The
weakening rule is helpful for ignoring ‚Äúunnecessary‚Äù assumptions.]]  /introduces
new names/ into a context.

 #+begin_tree
+ Type-in-Type :: Œì \;‚ä¢\; \Type : \Type
  - {}

+ Variables :: Œì \;‚ä¢\; x : œÑ
  - Œì(x) = œÑ

+ Weakening :: Œì, x : Œ± ‚ä¢ t : œÑ
  - Œì ‚ä¢ t : œÑ
  - x \text{ is not a name in } Œì
  - Œì ‚ä¢ Œ± : \Type
#+end_tree

Next
#+begin_margin :width "0.45\\textwidth"
The notation $E[x := F]$ means ‚Äúreplace every /free/ occurrence of the name $x$
within term $E$ by the term $F$.‚Äù  This ‚Äòfind-and-replace‚Äô operation is formally
known as \emph{textual substitution}.
#+end_margin
are the rules for dependent functions.
#+begin_tree
+ Œ†-Formation :: Œì ‚ä¢ (Œ†\, x : œÑ ‚Ä¢ œÑ') : \Type
  - Œì, x : œÑ \;‚ä¢\; œÑ' : \Type

+ Œ†-Introduction :: Œì \;‚ä¢\; (Œª\, x : œÑ ‚Ä¢ t) \,:\,(Œ†\, x : œÑ ‚Ä¢ œÑ')
  - Œì, x : œÑ \;‚ä¢\; t : œÑ'

+ Œ†-Elimination :: Œì \;‚ä¢\; Œ≤\, t \,:\, œÑ'[x ‚âî t]
  - Œì \;‚ä¢\; Œ≤ : (Œ†\, x : œÑ ‚Ä¢ œÑ')
  - Œì \;‚ä¢\; t : œÑ
#+end_tree

Then
#+begin_margin :width "0.45\\textwidth"
Just as Œ£ is the dual to Œ†, in some suitable sense, so too the /eliminator/ =let=
is dual to the /constructor/ lambda Œª.
#+end_margin
the rules for dependent sums.
#+begin_tree
+ Œ£-Formation :: Œì \;‚ä¢\; (Œ£\, x : œÑ ‚Ä¢ œÑ') : \Type
  - Œì, x : œÑ \;‚ä¢\; œÑ' : \Type

+ Œ£-Introduction :: Œì \;‚ä¢\; (e, t) \,:\, (Œ£\, x : œÑ ‚Ä¢ œÑ')
  - Œì \;‚ä¢\; e : œÑ
  - Œì \;‚ä¢\; t : œÑ'[x ‚âî e]

+ Œ£-Elimination :: Œì \;\;‚ä¢\;\; \mathsf{let}\; (x, t) ‚âî Œ≤ \;\mathsf{in}\; Œ≥\;:\; œÑ‚Ä≥
  - Œì \;‚ä¢\; Œ≤ : (Œ£\, x : œÑ ‚Ä¢ œÑ')
  - Œì, x : œÑ, t : œÑ' \;‚ä¢\; Œ≥ : œÑ‚Ä≥
#+end_tree

Finally, provided $B$ is a type that does not vary; i.e., the variable ~x~ does
not occur in $B$,
#+begin_tree
+ Abbreviation :: Œì \;‚ä¢\; t : (Œ£\, x : A ‚Ä¢ B)
  - Œì \;‚ä¢\; t : A √ó B

+ Abbreviation :: Œì \;‚ä¢\; t : (Œ†\, x : A ‚Ä¢ B)
  - Œì \;‚ä¢\; t: A ‚Üí B
#+end_tree
:Also:
#+begin_tree
+ Abbreviation :: Œì \;‚ä¢\; (Œ£\, x : A ‚Ä¢ B) : \Type
  - Œì \;‚ä¢\; A √ó B : \Type

+ Abbreviation :: Œì \;‚ä¢\; (Œ†\, x : A ‚Ä¢ B) : \Type
  - Œì \;‚ä¢\; (A ‚Üí B) : \Type
#+end_tree
:End:

#+latex: \dotfill

The rules for Œ† and Œ£ show that they are /families/ of types ‚Äòindexed‚Äô by the
first type. The rules only allow the construction of types and variable values,
to construct /values of types/ we will need some starting base types, whence the
need [[margin:][A GTT is a core theory that one builds on to solve interesting problems!]]
for signatures.

*** nomargins                                                        :ignore:
#+latex: \nomargins

#+latex: \begin{myexamplebox}{Œ† and Œ£ together allow the meta-language to be expressed in the object-language}

Recall that a phrase /‚ÄúŒì ‚ä¢ t : œÑ‚Äù/ denotes a property that *we* check using
day-to-day mathematical logic in conjunction with the provided rules for it.  In
turn, the property *talks about* terms /t/ and /œÑ/ which are related provided
assumptions Œì are true. In particular, contexts and the entailment relation are
/not/ expressible as terms of the object language; i.e., they cannot appear in the
$t$ nor the $œÑ$ positions ‚Ä¶ that is, until now.

#+latex: \tcbsubtitle{Œ† types \emph{internalise} contexts}
Contextual information is ‚Äòabsorbed‚Äô as a Œª-term; that is, \newline $x‚ÇÅ : œÑ‚ÇÅ, ‚Ä¶,
x‚Çô : œÑ‚Çô ‚ä¢ t : œÑ$ is essentially \newline $‚ä¢ (Œª x‚ÇÅ : œÑ‚ÇÅ ‚Ä¢ ‚ãØ ‚Ä¢ Œª x‚Çô : œÑ‚Çô ‚Ä¢ t) : (Œ†
x‚ÇÅ : œÑ‚ÇÅ ‚Ä¢ ‚ãØ ‚Ä¢ Œ† x‚Çô : œÑ‚Çô ‚Ä¢ œÑ)$.

Recall that initially we remarked that terms-in-context are essentially
functions /provided/ we have some form of semantics operation =‚ü¶_‚üß=.  However, in
the presence of Œ† types, terms-in-context correspond to functional terms in the
/empty/ context. The @@latex: {\sc Œ†-Formation}@@ rule ‚Äúexplains away‚Äù the new
Œª-terms using the old familiar notion of contexts.

#+latex: \tcbsubtitle{Œ£ types \emph{internalise} pairing contexts}
Multiple contexts are ‚Äòfused‚Äô as a Œ£-type term; that is,
/multiple/ premises in a judgement rule can be replaced by a /single/
premise by repeatedly using @@latex: {\sc Œ£-Formation}@@.

#+latex: \end{myexamplebox}

Crucially, generalised signatures may be presented as a sequence of ‚Äúsymbol ‚à∂
type‚Äù pairs where the symbols are unique names and each type is a generalised
term. Below is an example similar to the calling-smart-people example discussed
previously.  In this example, =A= denotes a collection that each member =a ‚à∂ A= of
which determines a collection =B a= which each have a ‚Äòselected point‚Äô =it a ‚à∂ B a=.
More concretely, thinking of =A= as the countries in the world from which =B= are
the households in each country, then =it= selects a representative member of a
household =B a= for each country =a ‚à∂ A=.
#+begin_parallel
{{{code(Pointed Families)}}}
#+begin_src haskell
A  : Type
B  : A ‚Üí Type
it : Œ† a : A ‚Ä¢ B a
#+end_src
#+columnbreak:
#+begin_center
This is a generalised signature /within/ the above GTT.
#+end_center
#+end_parallel

Since the names are completely new and there are unique declarations for each
name, we have unique types; moreover since there are no definitions, and so
there is only one condition to check in order to satisfy the required coherency
constraint on generalised signatures. Namely, there the claimed types are
actually recognised as types by the underlying theory /after/ we extend the typing
judgement with these new relationships; i.e., we need to show:
1. $‚ä¢ \Type : \Type$ ---since $Œì‚ÇÅ$ is the empty context and $œÑ‚ÇÅ = \Type$.
2. $‚ä¢ (A ‚Üí \Type) : \Type$ ---since $Œì‚ÇÇ$ is the empty context.
3. $‚ä¢ (Œ† a : A ‚Ä¢ B\, a) : \Type$

#+begin_export latex
\noindent
The first is just the {\sc Type-in-Type} rule, the second
is a mixture of the {\sc Abbreviation} and {\sc Œ†-Formation} rules; the third
one is the most involved, so we verify it as an example derivation.
(We abbreviate  {\sc Declaration, Abbreviation, Weakening} by  {\sc Decl, Abv, Weak}, respectively.
Incidentally, this \emph{practical} issue is why proof trees are seldom used for ‚Äúreal‚Äù work; instead
one uses a composition of constructors of an algebraic data type ---to be fleshed out later.)
#+end_export
# a mixture of the {\sc Œ†-Formation}, {\sc Base Symbol Introduction}, and {\sc Œ†-Elimination} rules.
#+begin_tree
+ Œ†-Intro :: ‚ä¢ (Œ† a : A ‚Ä¢ B\, a) : \Type
  - Œ†-Elim :: a : A ‚ä¢ B\, a : \Type
    - Abv :: a : A ‚ä¢ B : (Œ† a : A ‚Ä¢ \Type)
      - Weak :: a : A ‚ä¢ B : A ‚Üí \Type
        - Decl :: ‚ä¢ B : A ‚Üí \Type
          -
    - Vars :: a : A ‚ä¢ a : A
      -
#+end_tree

:Cute_calc:
Moreover, notice that ¬† =it a= ¬†is a valid term /provided/ =a ‚à∂ A= as shown in the
following derivation.
#+latex: \def\it{\mathtt{it}\,}
# :terminate-leaves: \checkmark
#+begin_tree
+ Œ†-Elim :: a : A \;‚ä¢\; \it a \,:\, B\, a
  -
+ Symbol Intro :: a : A \;‚ä¢\; \it : (Œ†\, x : A ‚Ä¢ B x)
  -
+ Variables :: a : A \;‚ä¢\; a : A
  -
#+end_tree
:End:

Signatures are a staple of computing science since they formalise interfaces and
generalise graphs and type theories.  Our generalised signatures have been
formalised ‚Äúafter the fact‚Äù from the creation of the prototype for packages
---see Chapter \ref{sec:PF}.  In the literature, our definition of generalised
signatures is essentially a streamlined presentation of Cartmell's ‚Äògeneralised
algebraic
#+latex: theories‚Äô\footcitet{DBLP:journals/apal/Cartmell86}$^,$\FOOTNOTE{
Quoting Cartmell: /Thus, a generalised algebraic theory consists of (i) a set of
sorts, each with a specified role either as a constant type or else as a/
/variable type varying in some way, (ii) a set of operator symbols, each one with
its argument types and its value type specified (the value type may vary/ /as the
argument varies), (iii) a set of axioms. Each axiom must be an identity/ /between/
/similar well-formed expressions, either between terms of the same possibly
varying type or else between type expressions./
#+latex: }
expect that we do not allow arbitrary equational ‚Äòaxioms‚Äô instead using ‚Äúname =
term‚Äù rather than ‚Äúterm = term‚Äù axioms which serve as /default implementations/ of
names.  Support for default definitions is to place the prototype on a sound
footing, but otherwise we do not make much use of such a feature outside that
chapter.
#   The tuples (ùíÆ, ‚Ñ±, src, tgt) that I use for signatures meet his definition:
#     (i) is ùíÆ, (ii) is ‚Ñ± along with src and tgt, and his (iii) is met by my
#     allowing function symbols to have optional definitions.

#+latex: \begin{tcolorbox}
Readers familiar with elementary computing may note that our contextual
presentations, when omitting types, are essentially ‚ÄúJSON objects‚Äù; i.e.,
sequences of key-value pairs where the keys are operation names and the values
are term descriptions, possibly the ‚Äúnull‚Äù description ‚Äú$-$‚Äù.
#+latex: \end{tcolorbox}

# We now turn to extending the current setup to permit optional definitions.

*** COMMENT Permitting Optional Definitions :Not_really_needed:
# \subsection*{Permitting Optional Definitions}


#+latex: \tcbset{colback=green!10!white} \def\type{\mathsf{type}\,} \def\Type{\mathsf{Type}}

#+begin_parallel

The example packages from this chapter's introduction, one of which is shown
below for convenience, can /almost/ be understood as presentations of generalised
signatures. What is lacking is the ability for /optional/ definitions, as is the
case with =purple= and =dark= below.

{{{code(A dynamical system -- Colours)}}}
#+begin_src haskell
Colour : Type
red    : Colour
green  : Colour
blue   : Colour
mix    : Colour √ó Colour ‚Üí Colour
purple : Colour
purple = mix red blue
dark   : Colour ‚Üí Colour
dark c = mix c blue
#+end_src

#+end_parallel

Recall that the crucial feature of generalised signatures is that they may be
presented as a sequence of /declarations/ $Œ¥‚ÇÅ, ‚Ä¶, Œ¥‚Çô$. When written with multiple
lines, the commas are replaced by newlines ---as with =Colour= above.  Originally,
each $Œ¥·µ¢$ is of the form ‚Äú$name : type$‚Äù, but above we have a definition for
=purple=, so the first step is to redefine /declaration/ so that each $Œ¥·µ¢$ is of the
form ‚Äú$Œ∑ : œÑ = d$‚Äù where the first term $œÑ$ is of type =Type= and the second term
$d : œÑ$. In the multi-line rendition, $Œ∑ : œÑ = d$ occurs as two lines: One with
$Œ∑ : œÑ$ and one with $Œ∑ = d$; c.f., =purple= above. The only ingredient missing is
the variable support in =dark= above: What could =Œ∑ x = d= mean? Since =d= is defined
/in the context/ of =x= and Œª-terms internalise contexts, as discussed above, we can
take =Œ∑ x = d= to be an abbreviation for =Œ∑ = (Œª x ‚à∂ œÑ ‚Ä¢ d)= for a suitable type =œÑ=.


:Hide:
The first step in  *amend* the definition of generalised signatures
is to introduce a new syntactic representation for functional
definitions. The =Term= obtains a new clause.
{{{code(Augmenting The Grammar for Generalised Terms)}}}
#+begin_src haskell
Term ‚à∑= ‚Ä¶
      | Œª x : œÑ ‚Ä¢ e {- For variable x, and terms œÑ, e -}
#+end_src
The usages of this new string of symbols is governed by the following
well-definedness rule. Essentially, one treats
/Œª x : œÑ ‚Ä¢ e/ as the function that on input /x/ of type /œÑ/ it yields
/e/.
#+begin_rule org
+ Œ†-Introduction :: Œì ‚ä¢ (Œª x : œÑ ‚Ä¢ e) : (Œ† x : œÑ ‚Ä¢ œÑ')
  - Œì, x : œÑ ‚ä¢ e : œÑ'
#+end_rule




#+latex: \begin{myexamplebox}{Example 4: Colours as Generalised Signatures}

For example, the =Colours= context above is a generalised signature, as follows
---where, for brevity, we write ùë™ in place of =Colour=.
#+begin_footnotesize org
| ‚Ñ¨          |  ùë™   | =Red= | =green= | =blue= |     =mix=     |                     =purple=                      |                     =dark=                     |
|            | <c>  | <c> |  <c>  | <c>  |     <c>     |                       <c>                       |                     <c>                      |
|------------+------+-----+-------+------+-------------+-------------------------------------------------+----------------------------------------------|
| =type=       | =Type= |  ùë™  |   ùë™   |  ùë™   | $ùë™ √ó ùë™ ‚Üí ùë™$ |                        ùë™                        |                   $ùë™ ‚Üí ùë™$                    |
| =definition= |  -   |  -  |   -   |  -   |      -      | $\mathsf{mix}\, \mathsf{red}\, \mathsf{blue}$  | $Œª c ‚à∂ ùë™ ‚Ä¢ \mathsf{mix}\, c\, \mathsf{blue}$ |
#+end_footnotesize

#+latex:  \end{myexamplebox}

#+latex: \begin{myexamplebox}{Example 5: Disjoin Sums as Generalised Signatures}

# As another example, we show how disjoint sums can be defined.

The type =X + Y= denotes the collection of values of the form ‚Äúin left‚Äù =inl x= or
‚Äúin right‚Äù =inr y= for all =x ‚à∂ X= and =y ‚à∂ Y=.  That is, =X + Y= is the disjoint union
of collections =X= and =Y=.  Below are ‚Äúdefault implementations‚Äù for =_+_, inl, inr=;
however, there are other ways to encode sum types.

{{{code(Sums from Œ£ and ùîπ)}}}
#+begin_src haskell
ùîπ             : Type
True          : ùîπ
False         : ùîπ
_if_then_else_ : Œ† A : Type ‚Ä¢ ùîπ ‚Üí A ‚Üí A ‚Üí A

_+_ : Type ‚Üí Type ‚Üí Type
_+_ X Y  =  Œ£ tag : ùîπ  ‚Ä¢  Type if tag then X else Y

inl : Œ† X : Type ‚Ä¢ X ‚Üí ùîπ √ó X
inl X x = (True, x)

inr : Œ† Y : Type ‚Ä¢ Y ‚Üí ùîπ √ó Y
inr Y y = (False, y)
#+end_src

#+latex:  \end{myexamplebox}


:Terms_with_ùüô_and_PropositionalEquality:
#+begin_src haskell
Term ‚à∑= x              -- A ‚Äúvariable‚Äù; a value of ùí±
      | Œ≤ t‚ÇÅ t‚ÇÇ ‚Ä¶ t‚Çô   -- A ‚Äúbase symbol of arity n‚Äù; a value of ‚Ñ¨
      | Œ† a : œÑ ‚Ä¢ œÑ'   -- For previously constructed types œÑ and œÑ'
      | Œ£ a : œÑ ‚Ä¢ œÑ'   --     and variable ‚Äúa‚Äù
      | (Œª a : œÑ ‚Ä¢ œÑ') -- ‚ÄúLambdas‚Äù; i.e., functional expressions
      | (œÑ, œÑ')        -- ‚ÄúPairs‚Äù
      | ùüô              -- ‚Äúunit type‚Äù
      | tt             -- The only value in the unit type
      | œÑ ‚â° œÑ'         -- ‚ÄúPropositional equality‚Äù type
      | refl x         -- ‚ÄúReflexivity proofs‚Äù
#+end_src

#+latex: \def\tt{\mathtt{tt}}
#+begin_rule org
:multiple-rules: yes

+ Unit Type :: $Œì \;‚ä¢\; ùüô : \Type$
  - ${}$

+ ùüô-Intro :: $Œì \;‚ä¢\; \tt : ùüô$
  - ${}$

+ Propositional Equality Type :: $Œì \;‚ä¢\; (l ‚â° r) : \Type$
  - $Œì \;‚ä¢\; l : œÑ$
  - $Œì \;‚ä¢\; r : œÑ$

+ Equality Introduction :: $Œì \;‚ä¢\; \mathtt{refl}_x \,:\, (x ‚â° x)$
  - $Œì \;‚ä¢\; x : œÑ$
#+end_rule
:End:

Of course contexts now associate /both/ a type and an optional definition with a
given name, and so $Œì : \mathsf{Name} ‚Üí \mathsf{Term} √ó (\mathsf{Term} ‚à™ \{-\})$
where ‚Äú$-$‚Äù denotes ‚Äúno definition‚Äù.  That is, we essentially have two judgement
relations $Œì ‚ä¢ Œ∑ : œÑ$ and $Œì ‚ä¢ Œ∑ : œÑ ‚âî d$ where the extra information in the
second can be dropped to get back to the first relation ---c.f., @@latex: {\sc
‚âî-Elimination}@@ below.  We augment our rules with the following two to
accommodate this extended capability.
#+begin_tree
+ ‚âî-Introduction :: Œì \;‚ä¢\; Œ∑ : œÑ ‚âî d
  - Œì(Œ∑) = (œÑ, d)

+ ‚âî-Elimination :: Œì \;‚ä¢\; Œ∑ : œÑ
  - Œì \;‚ä¢\; Œ∑ : œÑ ‚âî d
#+end_tree

# Perhaps make as a footnote?
Readers familiar with elementary computing may note that our contextual
presentations, when omitting types, are essentially ‚ÄúJSON objects‚Äù; i.e.,
sequences of key-value pairs where the keys are operation names and the values
are term descriptions, possibly the ‚Äúnull‚Äù description ‚Äú$-$‚Äù.
** nomargins                                                :ignore:
#+latex: \nomargins
** A Whirlwind Tour of Agda
 <<sec:what_is_DTL>>
 # +latex: \label{sec:what_is_DTL}

 <<sec:agda_tour>>
 # +latex: \label{sec:agda_tour}

#+latex: \tcbset{colback=green!10!white}

 We have introduced a number of concepts and it can be difficult to keep track
 of when relationships $Œì ‚ä¢ t : œÑ$ are in-fact derivable. The
 #+latex: Agda\footcitet{why_dependent_types_matter}$^,$\footcitet{dependent_matching_is_just_K}$^,$\footcitet{curry_howard}$^,$\footcitet{agda_plf}
 programming language will provide us with the expressivity of generalised
 signatures and it will keep track of contexts Œì for us. This section recasts
 many ideas of the previous sections using Agda notation, and introduces some
 new ideas. In particular, the ‚Äòtype of types‚Äô =Type= is now cast as a hierarchy
 of types which can contain types at a ‚Äòsmaller‚Äô level: One writes =Set·µ¢= to
 denote the type of types at /level/ $i : ‚Ñï$. This is a technical subtlety and may
 be ignored; instead treating every occurrence of =Set·µ¢= as an alias for =Type=.

 # Those circles at the start of ¬ß2.4 also try to bridge the content from the
 # start of ¬ß2 to where we are now in ¬ß2.4.
#+begin_parallel
#+begin_export latex
\maxsizebox{\textwidth}{\textheight}{
\smartdiagram[bubble diagram]{
Agda, \texttt{data} / ùí≤ \\ (Grammars), \texttt{record}  / Œ£ \\ (Context), \texttt{module} / Œ† \\ (Namespacing)
}}
#+end_export

# The tour assumes readers have actually read ¬ß2.2,3 and so the motivation for
# things, such as Œ†, is not repeated.
#+latex: \baselineskip2.2ex
#+latex: {\color{gray!90}\footnotesize
*Organisation Commentary.* Since Agda is a DTL, it makes sense to begin with Œ† and
DTs since one would expect them to occur everywhere else in a DTL ---the
motivation for things, such as Œ†, is in section
\ref{sec:packages_and_their_parts:sigma_pi}.  After Œ†, only may reasonable
wonder about Œ£ since their close relationship was pointed out in section
\ref{sec:packages_and_their_parts:sigma_pi}, Œ£ is not next on the tour since
Agda records are syntactic sugar for data declarations having one constructor,
so we need to discuss src_agda[:exports code]{data} after Œ†.  Okay, we show
‚Äòdata‚Äô and make use of the DTs already introduced; what's next?  We show a
concrete example of an ADT, namely ‚Äò‚â°‚Äô since it will be used later on in
examples in Chapter \ref{sec:contexts}. Now that we're comfy with ADTs, we can
go to ones with a single constructor, src_agda[:exports code]{record}s. But
wait, Agda records behave like Agda modules, so let's talk about Agda
src_agda[:exports code]{module}s first. After that, we can finally get to
records (Œ£-types) and we can do so very briefly since their underlying
module/ADT nature has already been explained.  In the next sibling section,
\ref{sec:module_interdefinability}, we show the interdefinability of packaging
notions using Agda's syntactic sugar.
#+latex: }
#+end_parallel

:OldIntro:
 Agda
 citet:why_dependent_types_matter,dependent_matching_is_just_K,curry_howard,agda_plf
 is based on Martin-{{{lof}}}'s intuitionistic type theory. By identifying types
 with terms, the type of small types is a larger type; e.g., ~‚Ñï ‚à∂ Set‚ÇÄ~ and ~Set·µ¢ ‚à∂
 Set·µ¢‚Çä‚ÇÅ~ ---the indices ~i~ are called /levels/ and the small type ~Set‚ÇÄ~ is abbreviated
 as ~Set~. In some regard, Agda adds /harmonious/ support for dependent types to
 Haskell.
:End:

#+latex: \begin{tcolorbox}[colframe=red!75!black, title=Unicode Notation]
 Unlike most languages, Agda not only allows arbitrary mixfix Unicode lexemes,
 identifiers, but their use is encouraged by the community as a whole. Almost
 anything can be a valid name; e.g., ~[]~ and ~_‚à∑_~ to denote list constructors
 ---underscores are used to indicate argument positions. Hence it is important to
 be liberal with whitespace; e.g., ~e‚à∂œÑ~ is a valid identifier, whereas ~e ‚à∂ œÑ~
 declares term ~e~ to be of type ~œÑ~. Agda's Emacs interface allows entering Unicode
 symbols in traditional LaTeX-style; e.g., ~\McN, \_7, \::, \to~ are replaced by ~ùí©,
 ‚Çá, ‚à∑, ‚Üí~. Moreover, the Emacs interface allows programming by gradual refinement
 of incomplete type-correct terms. One uses the ‚Äúhole‚Äù marker ~?~ as a placeholder
 that is used to stepwise write a program.
#+latex: \end{tcolorbox}

*** Dependent Functions --- Œ†-types

  A /[[gls:dependent-function][dependent function]] type/ has those functions whose result /type/ depends on the
  /value/ of the argument. If ~B~ is a type depending on a type ~A~, then ~(a ‚à∂ A) ‚Üí B
  a~ is the type of functions ~f~ mapping arguments ~a ‚à∂ A~ to values ~f a ‚à∂ B a~.
  Vectors, matrices, sorted lists, and trees of a particular height are all
  examples of dependent types. One also sees the notations @@latex: \newline@@ ~‚àÄ
  (a ‚à∂ A) ‚Üí B a~ and ~Œ† a ‚à∂ A ‚Ä¢ B a~ to denote dependent types.

  For example, /the/ generic identity function takes as /input/ a type ~X~ and returns
  as /output/ a function ~X ‚Üí X~. Here are a number of ways to write it in Agda.
  {{{code(The Identity Function, in four ways)}}}
  #+BEGIN_SRC agda :tangle AgdaReview.agda
id‚ÇÄ : (X : Set) ‚Üí X ‚Üí X
id‚ÇÄ X x = x

id‚ÇÅ id‚ÇÇ id‚ÇÉ : (X : Set) ‚Üí X ‚Üí X

id‚ÇÅ X = Œª x ‚Üí x
id‚ÇÇ   = Œª X x ‚Üí x
id‚ÇÉ   = Œª (X : Set) (x : X) ‚Üí x
  #+END_SRC

  All these functions explicitly require the type ~X~ when we use them, which is
  unfortunate since it can be inferred from the element ~x~. Curly braces make an
  argument /implicitly inferred/ and so it may be omitted. E.g., the ~{X ‚à∂ Set} ‚Üí ‚ãØ~
  below lets us make a polymorphic function since ~X~ can be inferred by
  inspecting the given arguments. This is akin to informally writing
  $\mathsf{id}_X$ versus $\mathsf{id}$.

  #+begin_parallel
  {{{code(Inferring Arguments...)}}}
  #+BEGIN_SRC agda
id : {X : Set} ‚Üí X ‚Üí X
id x = x

sad : ‚Ñï
sad = id‚ÇÄ ‚Ñï 3

nice : ‚Ñï
nice = id 3
  #+END_SRC
  #+latex: \columnbreak
  {{{code(...and Explicitly Passsing Implicits)}}}
  #+BEGIN_SRC agda
explicit : ‚Ñï
explicit = id {‚Ñï} 3

explicit' : ‚Ñï
explicit' = id‚ÇÄ _ 3


.
  #+END_SRC
  #+end_parallel

  #+latex: \vspace{-1em}
  Notice that we may provide an implicit argument /explicitly/ by enclosing the
  value in braces in its expected position. Values can also be inferred when the
  ~_~ pattern is supplied in a value position. Essentially wherever the typechecker
  can figure out a value ---or a type---, we may use ~_~. In type declarations, we
  have a contracted form via ~‚àÄ~ ---which is *not* recommended since it slows down
  typechecking and, more importantly, types /document/ our understanding and it's
  useful to have them explicitly.

  In a type, ~(a ‚à∂ A)~ is called a /telescope/ and they can be combined for convenience.
  #+BEGIN_EXAMPLE agda
   (a‚ÇÅ : A) ‚Üí {a‚ÇÇ : A} ‚Üí {z : _} ‚Üí (b : B) ‚Üí ‚ãØ
‚âà  (a‚ÇÅ {a‚ÇÇ} : A) {z : _} (b : B) ‚Üí ‚ãØ
‚âà  ‚àÄ a‚ÇÅ {a‚ÇÇ z} b ‚Üí ‚ãØ
  #+END_EXAMPLE

  #+latex: \vspace{-1em}

  Agda supports the ‚àÄ and the $(a : A) ‚Üí B\, a$ notations for dependent types;
  the following declaration allows us to use the Œ† notation.
  {{{code(Œ† Notation in Agda)}}}
  #+begin_src agda
Œ†‚à∂‚Ä¢ : ‚àÄ {a b} (A : Set a) (B : A ‚Üí Set b) ‚Üí Set _
Œ†‚à∂‚Ä¢ A B = (x : A) ‚Üí B x

infix -666 Œ†‚à∂‚Ä¢
syntax Œ†‚à∂‚Ä¢ A (Œª x ‚Üí B) = Œ† x ‚à∂ A ‚Ä¢ B -- The ‚Äò‚à∂‚Äô is Ghost colon, \:
  #+end_src

  The ‚Äú =syntax function args = new_notation= ‚Äù clause treats occurrences of
  =new_notation= as aliases for proper function calls =f x‚ÇÅ x‚ÇÇ ‚Ä¶ x‚Çô=. The =infix=
  declaration indicates how complex expressions involving the new notation
  should be parsed; in this case, the new notation binds less than any operator
  in Agda.

*** Dependent Datatypes --- ADTs
 <<sec:agda_tour:ADTs>>
 # +latex: \label{sec:agda_tour:ADTs}

Recall that grammars permit a method to discuss ‚Äúpossible scenarios‚Äù, such as a
verb clause or a noun clause; in programming, it is useful to be able to have
‚Äòpossible scenarios‚Äô and then program by considering each option.  For instance,
a natural number is either zero or the successor of another number, and a door
is either open, closed, or ajar to some degree.

{{{code(Informal Grammar Notation)}}}
#+begin_src haskell
Door ‚à∑= Open | Closed | Ajar ‚Ñï
#+end_src
{{{code(Agda Rendition of Grammars)}}}
#+begin_src agda
data Door : Set where
    Open   : Door
    Closed : Door
    Ajar   : ‚Ñï ‚Üí Door
#+end_src
While the Agda form looks more verbose, it allows more possibilities that are
difficult to express in the informal notation ---such as, having
#+latex: \emph{parameterised}\FOOTNOTE{
With the ‚Äútypes as languages‚Äù view, one may treat a ‚Äúparameterised type‚Äù as a
‚Äúlanguage with dialects‚Äù. For instance, instead of a single language =Arabic=, one
may have a /family of languages/ =Arabic ‚Ñì= that depend on a location =‚Ñì=.  Then, some
words/constructors may be accessible in /any/ dialect ‚Ñì, whereas other words can
only be expressed in a /particular/ dialect. More concretely, we may declare
=SalamunAlaykum : ‚àÄ {‚Ñì} ‚Üí Arabic ‚Ñì= since the usual greeting ‚Äúhello‚Äù (lit. ‚Äúpeace
be upon you‚Äù) is understandable by all Arabic speakers, whereas we may declare
=ShakoMako : Arabic Iraq= since this question form ‚Äúhow are you‚Äù (lit. ‚Äúwhat is
your colour‚Äù) is specific to the Iraqi Arabic dialect.
#+latex: }
languages/types for which the constructors make words belonging to a /particular/
parameter only; the =Vec= example below demonstrates this idea.

Languages, such as C, which do not support such an ‚Äúalgebraic‚Äù approach, force
you, the user, to actually choose a particular representation ---even though, it
does not matter, since we only want /a way to speak of/ ‚Äúdifferent cases, with
additional information‚Äù. The above declaration makes a new datatype with three
different scenarios: The =Door= collection has the values =Open=, =Closed=, and =Ajar n=
where =n= is any number ---so that =Ajar 10= and =Ajar 20= are both values of =Door=.

{{{code(Interpreting the Door Values as Options)}}}
#+begin_src agda
-- Using Door to model getting values from a type X.
-- If the door is open, we get the ‚Äúyes‚Äù value
-- If the door is closed, we get the ‚Äúno‚Äù value
-- If the door is ajar to a degree n, obtain the ‚Äújump n‚Äù X value.
walk : {X : Type} (yes no : X) (jump : ‚Ñï ‚Üí X) ‚Üí Door ‚Üí X
walk yes no jump Open     = yes
walk yes no jump Closed   = no
walk yes no jump (Ajar n) = jump n
#+end_src

*What is a constructor?* A grammar defines a language consisting of sentences
built from primitive words; a /constructor/ is just a word and a word's /meaning/ is
determined by how it is used ---c.f., =walk= above and the =Vec= construction below
which gives us a way to talk about lists. The important thing is that a grammar
defines languages, via words, without reference to meaning.  Programmatically,
constructors could be implemented as ‚Äú(value position, payload data)‚Äù; i.e.,
pairs =(i, args)= where =i= is the position of the constructor in the list of
constructors and =args= is a tuple values that it takes; for instance, =Door='s
constructors could be implemented as =(0,()), (1, ()), (2, (n))= for =Open, Closed,
Ajar n= where we use =()= to denote ‚Äúthe empty tuple of arguments‚Äù.  The *purpose* of
such types is that we have a number of /distinct/ scenarios that may contain a
‚Äòpayload‚Äô of additional information about the scenario; it is preferable to have
*informative* (typed) names such as =Open= instead of strange-looking pairs =(0, ())=.
In case it is not yet clear, unlike functions, a value construction such as ~Ajar
10~ cannot be simplified any further; just as the pair value ~(2, 5)~ cannot be
simplified any further. Table ref:tbl:utility-of-adts below showcases how many
ideas arise from grammars.

# Tables cannot be in tcolorbox easily.
# +latex: \begin{tcolorbox}[colframe=red!75!black]
#+caption: Many useful ideas arise as grammars
#+name: tbl:utility-of-adts
| Concept                  | Formal Name        | Scenarios                             |
|--------------------------+--------------------+---------------------------------------|
| ‚ÄúTwo things‚Äù             | Œ£, =A √ó B=, records  | One scenario with two payloads        |
| ‚ÄúOne from a union‚Äù       | Sums =A + B=, unions | Two scenarios, each with one payload  |
| ‚ÄúA sequence of things‚Äù   | Lists, Vectors, ‚Ñï  | Empty and non-empty scenarios         |
| ‚ÄúTruth values‚Äù           | Booleans ùîπ         | Two scenarios with /no/ payloads        |
| ‚ÄúA pointer or reference‚Äù | =Maybe œÑ=            | Two scenarios; successful or =null=     |
| ‚ÄúEquality of two things‚Äù | Propositional =_‚â°_=  | One scenario; discussed later         |
| ‚ÄúA convincing argument‚Äù  | Proof trees        | A scenario for each logical construct |
# +latex: \end{tcolorbox}

Such ‚Äúenumerated type with payloads‚Äù are also known as *algebraic data types*
(ADTs). They have as values =C·µ¢ x‚ÇÅ x‚ÇÇ ‚Ä¶ x‚Çô=, a constructor =C·µ¢= with payload values
=x·µ¢=. Functions are then defined by ‚Äòpattern matching‚Äô on the possible ways to
/construct/ values; i.e., by considering all of the possible cases =C·µ¢= ---see =walk=
above. In Agda, they are introduced with a ~data~ declaration; an intricate
example below defines the datatype of lists of a particular length.

   {{{code(Vectors ---‚Ñï-indexed Lists)}}}
   #+BEGIN_SRC agda
data Vec {‚Ñì : Level} (A : Set ‚Ñì) : ‚Ñï ‚Üí Set ‚Ñì where
  []  : Vec A 0
  _‚à∑_ : {n : ‚Ñï} ‚Üí A ‚Üí Vec A n ‚Üí Vec A (1 + n)
   #+END_SRC

  Notice that, for a given type ~A~, the type of ~Vec A~ is ~‚Ñï ‚Üí Set~. This means that
  ~Vec A~ is a family of types indexed by natural numbers: For each number ~n~, we
  have a type ~Vec A n~. One says ~Vec~ is /parameterised/ by ~A~ (and ‚Ñì), and /indexed/
  by ~n~. They have different roles: ~A~ is the type of elements in the vectors,
  whereas ~n~ determines the ‚Äòshape‚Äô ---length--- of the vectors and so needs to
  be more ‚Äòflexible‚Äô than a parameter; in particular, the parameter values need
  to be the same in all constructor result type.

  Notice that the indices say that the only way to make an element of ~Vec A 0~ is to
  use ~[]~ and the only way to make an element of ~Vec A (1 + n)~ is to use ~_‚à∑_~.
  Whence, we can write the following safe function since ~Vec A (1 + n)~ denotes
  non-empty lists and so the pattern ~[]~ is impossible.
  {{{code( Safe Head )}}}
  #+BEGIN_SRC agda
head : {A : Set} {n : ‚Ñï} ‚Üí Vec A (1 + n) ‚Üí A
head (x ‚à∑ xs) = x
  #+END_SRC

  The ~‚Ñì~ argument means the ~Vec~ type operator is /universe polymorphic/: We can make
  vectors of, say, numbers but also vectors of types. Levels are essentially
  natural numbers: We have ~lzero~ and ~lsuc~ for making them, and ~_‚äî_~ for taking the
  maximum of two levels. /There is no universe of all universes:/ ~Set‚Çô~ has type
  ~Set‚Çô‚Çä‚ÇÅ~ /for any n/, however the /type/ ~(n¬†‚à∂¬†Level)¬†‚Üí¬†Set¬†n~ is /not/ itself typeable
  ---i.e., is not in ~Set‚Çó~ for any ~l~--- and Agda errors saying it is a value of
  ~Setœâ~.

  Functions are defined by pattern matching, and must cover all possible cases.
  Moreover, they must be terminating and so recursive calls must be made on
  structurally smaller arguments; e.g., ~xs~ is a sub-term of ~x ‚à∑ xs~ below and
  catenation is defined recursively on the first argument. Firstly, we declare a
  /precedence rule/ so we may omit parenthesis in seemingly ambiguous expressions.
 {{{code( Catenation is a ++‚ü∂+ Homomorphism )}}}
   #+BEGIN_SRC agda
infixr 40 _++_

_++_ : {A : Set} {n m : ‚Ñï} ‚Üí Vec A n ‚Üí Vec A m ‚Üí Vec A (n + m)
[]       ++ ys  =  ys
(x ‚à∑ xs) ++ ys  =  x ‚à∑ (xs ++ ys)
  #+END_SRC
  Notice that the *type encodes a useful property*: The length of the catenation is
  the sum of the lengths of the arguments.

#+latex: {\footnotesize \color{gray!80} \textbf{Extended Commentary on Proof Trees:}
In section \ref{sec:signatures}, we discussed how terms and trees coincide, but
when focusing on /proof trees/ the relationship gives us more.  For instance, /the/
/introduction and elimination rules of a type of trees correspond to the
constructors and destructor of the type's grammar (ADT)./

Let me try to clarify what it means to say that ‚Äúsyntactic proof is an
alternative to exhaustive case analysis‚Äù (valuations).

Solutions to families of problems can be phrased using names that can be defined
using sets and functions between them; this is a /denotational semantics:/ One
solves a problem by looking up the definitions, denotations, of the names. In
contrast, using ADTs provides a *proof system* to a problem: To solve a problem,
one merely considers the ‚Äúshape‚Äù of the problem to identify which rule (ADT
constructor) to apply and continue this process recursively. That is, ADT proof
systems generally provide a guidance to finding solutions. E.g., a propositional
logic formula can be shown to be valid by showing every /valuation/ (an assignment
of values to variables) of its variables results in $\mathsf{true}$ --- i.e.,
one must produce a function that takes in an arbitrary valuation and returns a
proof of equality that the application of the valuation to the formula is
$\mathsf{true}$ ---; in contrast *natural deduction* is a collection of rules and
one proves a formula is valid by constructing a tree whose conclusion is that
formula; moreover, the shape of the formula usually determines (or, guides the
construction of) the tree.

That is, ADTs give us a notion of proof that avoids checking all possible values
for the variables. The ADT we design usually has its constructors ---i.e., proof
rules--- to be sensible to the kind of problems we're interested in. This
property is usually built-into the datatype; it is known as *soundness*: /The ADT/
/only allows us to prove (i.e., form things) sensible with our intended
interpretation; i.e., provable things are true./ The contrapositive ---viz
/non-true statements are not provable/--- allow us to stop searching for a proof
if we can find a counterexample.  The converse ---viz /true statements are
provable; i.e., constructible via the ADT/--- is called *completeness* and it is
not as /practical/ since one usually designs an ADT for a particular kind of
problem ---with a constrained amount of operations--- rather than all kind of
problems. Moreover, even if a true statement is provable, it may require an
absurd amount of time to prove ---e.g., the Ackermann function always
terminates, and calling it on, say, $(4,2)$ still has it terminating but long
after I have died; or, more realistically, Agda will run out of resources and
crash.  By the same reasoning, typechecking in a DTL involves performing
arbitrary computations, such as the Ackermann function, and so DTL type-checkers
are not (practically) complete ---however, in practice this is not an issue.
# Completeness: All possible cases must be handled.

# Which is exponentiale in the number of variables used and so inefficient!

#+latex: }
#
# Then mention how ADTs give a syntax to proofs, both via CH and observation that
# proof trees are ADTs! Then discuss how this perspective gives rise to
# proof-relevant computations and so proof erasure is not necessairly ideal.

More accurately, Agda's ADTs are known as Generalised Algebraic DataTypes
(GADTs) in other settings ---i.e., a GADT is an ADT with, not only parameters,
but also indices.  Indeed, GADTs bring no extra power in the presence of
dependent types; i.e., in a DTL, GADTs are a /convenient abbreviation/ for ADTs
and a ‚Äòtyping‚Äô function. For instance, the vectors GADT above has its
constructors indexed by their length, but we may split up the constructors and
the length into the two parts ~œâVec~ and ~œÑŒ≥œÅŒµ~ below, then combine them together to
regain (an isomorphic copy of) the vectors datatype.

{{{code(Starting with ‚Äòuntyped‚Äô terms than ‚Äòtyping‚Äô them afterwards)}}}
#+begin_src agda
mutual

  Vec‚Ä≤  =  Œª A n  ‚Üí  Œ£ v ‚à∂ œâVec A  ‚Ä¢  œÑŒ≥œÅŒµ v  ‚â°  n

  data œâVec {‚Ñì : Level} (A : Set) : Set where
    œâ[] : œâVec A
    _œâ‚à∑_ : {n : ‚Ñï} (x : A) (xs : Vec‚Ä≤ A n) ‚Üí œâVec A

  œÑŒ≥œÅŒµ : {A : Set} ‚Üí œâVec A ‚Üí ‚Ñï
  œÑŒ≥œÅŒµ œâ[] = 0
  œÑŒ≥œÅŒµ (_œâ‚à∑_ {n} _ _) = suc n
#+end_src

\noindent The ‚Äò‚â°‚Äô is a particular GADT defined in the next sibling section; the
only value of ~x ‚â° y~ is ~refl~ ---it witnesses that ~x~ and ~y~ are actually the same
thing after simplifying.  The (formal Agda) proof of ~Vec‚Ä≤ A n ¬†‚âÖ¬† Vec A n~ offers
little insight, so we omit it in-preference to showing the general case (which
is almost exactly the proof for this particular case).

*‚ÄúBundling theorem for GADTs‚Äù:* Every indexed type (GADT) is a ‚Äòtyped language‚Äô;
i.e., for a parameterised and indexed language src_agda[:exports code]{ùëª : œÅ ‚Üí Œπ
‚Üí Set} we can form an untyped language src_agda[:exports code]{œâùëª : œÅ ‚Üí Set} and
a (constant-time) typing function {{{mbox(src_agda[:exports code]{œÑŒ≥œÅŒµ : ‚àÄ {p :
œÅ} ‚Üí œâùëª p ‚Üí Œπ})}}} such that src_agda[:exports code]{‚àÄ {p : œÅ} {i : Œπ}¬†‚Üí¬† ùëª p i
¬†‚âÖ¬† Œ£ t : œâùëª p ‚Ä¢ œÑŒ≥œÅŒµ t ‚â° i}.

This claim can be proved by constructing ~œâùëª~ and ~œÑŒ≥œÅŒµ~ mutually with the help of
the alias {{{mbox(src_agda[:exports code]{ùëª‚Ä≤ ¬†=¬† Œ£ t ‚à∂ œâùëª p ¬†‚Ä¢¬† œÑŒ≥œÅŒµ t ¬†‚â°
i})}}}, which occurs in the theorem statement. (The definition of ùëª‚Ä≤ from ùëª is
known as ‚ÄúŒ£-padding‚Äù and is discussed in Chapter
\ref{sec:examples_from_the_wild}.)  We proceed, constructively, as follows.
1. Construct œâùëª:
   a. Look at the GADT definition of ùëª.
   b. Drop all indices; i.e., ‚Äú src_agda[:exports code]{data ùëª params : indices ‚Üí
      Set ‚Ñì} ‚Äù \newline becomes ‚Äú src_agda[:exports code]{data ùëª params : Set ‚Ñì}, ‚Äù
   c. In the constructors, for every recursive call to ùëª, replace every
       textual occurrence of ùëª with ùëª‚Ä≤; i.e.,
       ‚Äú src_agda[:exports code]{c : ‚ãØùëª p‚ãØ ‚Üí ùëª q} ‚Äù  becomes
        ‚Äú src_agda[:exports code]{c : ‚ãØùëª‚Ä≤ p‚ãØ ‚Üí ùëª q}, ‚Äù
   d. Finally, prefix all constructors and the type name by the symbol ‚Äòœâ‚Äô.

2. Define the typing function src_agda[:exports code]{œÑŒ≥œÅŒµ : ‚àÄ {p : œÅ} ‚Üí œâùëª p ‚Üí
   Œπ} by the clauses \newline {{{mbox(src_agda[:exports code]{œÑŒ≥œÅŒµ (œâc‚Çñ args‚Çñ) =
   i‚Çñ})}}} for each ùëª-constructor src_agda[:exports code]{c‚Çñ : args‚Çñ ‚Üí ùëª p‚Çñ i‚Çñ};
   notice that src_agda[:exports code]{œÑŒ≥œÅŒµ}, by definition, is constant-time
   and makes no-recursive calls.

   That is, the typing definition just returns the intended index for each
   constructor.

3. Next, the inverse functions witnessing the purported equivalence are
   defined with as many clauses as there are ùëª-constructors.

   #+latex: \vspace{-.5em}
     {{{code()}}}
   #+begin_src agda
to : ‚àÄ {p : œÅ} {i : Œπ} ‚Üí ùëª p i ‚Üí ùëª‚Ä≤ p i
to (c‚Çñ args‚Çñ) = œâc‚Çñ ‚Äúmap to args‚Çñ‚Äù, refl  --- for each constructor c‚Çñ
   #+end_src

   #+latex: \vspace{-.5em}
   In this definition, ~refl~ is a sufficient proof, since, by construction, ~œÑŒ≥œÅŒµ~
   of ~œâc‚Çñ~ is exactly the index of ~c‚Çñ~, which happens to be ~i~.

   #+latex: \vspace{-.5em}
   #+begin_src agda
from : ‚àÄ {p : œÅ} {i : Œπ} ‚Üí ùëª‚Ä≤ p i ‚Üí ùëª p i
from (œâc‚Çñ args‚Çñ, refl) = c‚Çñ ‚Äúmap from args‚Çñ‚Äù --- for each constructor œâc‚Çñ
   #+end_src

#+latex: \vspace{-.5em}
Pattern matching on (~refl~) the equality constraint within the ùëª‚Ä≤ ensures that we
have values of the right index for ùëª; conversely, src_emacs-lisp[:exports
code]{to} structurally prepends constructors with ‚Äòœâ‚Äô and uses the definition of
src_emacs-lisp[:exports code]{œÑŒ≥œÅŒµ} to ensure that the required proofs are
~refl~. Hence, these two are inverse. More formally, using Agda's ~rewrite~ utility
to simplify goals according to given equality proofs:

#+latex: \vspace{-.5em}
{{{code()}}}
#+begin_src agda
to‚àòfrom : ‚àÄ {p : œÅ} {i : Œπ} (t : ùëª‚Ä≤ p i) ‚Üí to (from t) ‚â° t
to‚àòfrom (œâc‚Çñ args‚Çñ, refl)  rewrite to‚àòfrom args‚Çñ  =  refl
 -- The ‚Äòrewrite‚Äô is if c‚Çñ has recursive calls.

from‚àòto : ‚àÄ {p : œÅ} {i : Œπ} (t : ùëª p i) ‚Üí from (to t) ‚â° t
from‚àòto (c‚Çñ args‚Çñ)  rewrite  from‚àòto args‚Çñ  =  refl
#+end_src

#+latex: \yesmargins
/Dependent-types conflate different features of non-dependently-typed languages./

*** ADT Example: Propositional Equality

     <<sec:propositional-equality>>
 # +latex: \label{sec:propositional-equality}

 In this section, we present a notion of equality as an algebraic data type.
 Equality is a notoriously difficult concept, even posing it is non-trivial:
 ‚ÄúWhen are two things equal?‚Äù sounds absurd, since the question speaks about two
 things and two different things cannot be the same one thing.  /Equality,
 whatever it means,/
#+begin_margin :width "0.45\\textwidth"
An *equivalence relation* ~_‚âà_~ is a relationship that models /similarity/, thereby
generalising the idea of equality. For ~_‚âà_~ to be called ‚Äúsimilarity,
equivalence‚Äù, it should satisfy:
1. (*Reflexivity*) ‚ÄúEverything is similar to itself‚Äù; i.e., $x ‚âà x$ is true for all $x$
2. ‚ÄúSimilarity is a mutual relationship‚Äù
3. ‚ÄúSimilarity is a transitive relationship‚Äù
#+end_margin
/is about ignoring certain ‚Äòuninteresting‚Äô properties/;
#+begin_margin :width "0.45\\textwidth"
An informal code of conduct among mathematicians is that /interesting properties
should be invariant under equivalence/ ---otherwise, they are [[https://ncatlab.org/nlab/show/principle+of+equivalence][‚Äòevil‚Äô]] properties
and should be used with caution.  That is, for any interesting property $P$, one
must have $P\, x \,=\, P\, y$ whenever $x$ and $y$ are ‚Äúthe same‚Äù ---whatever
that means. Working with equivalence-invariant properties is tantamount to
working with an interface, a specfication, rather than a particular implementation.
@@ignore: e.g., working with objects that satisfy universal properties,
whcih characterised them up to isomorphism.@@
   #+end_margin
below is a short hierarchy of ‚Äòsameness‚Äô with examples on ‚Ñïatural numbers.

1. *Syntactic equality:* ‚Äú$l = r$‚Äù is true whenever $l$ and $r$ are literally the
   same string of symbols. E.g., 2 = 2, or \newline {{{mbox(src_agda[:exports code]{suc
   suc zero = suc suc zero})}}}.

   This is sometimes known as /intentional equality/; the equality of two
   expressions is ‚Äòbuilt-in‚Äô the expressions themselves.  [[margin:][Pedantically, 2 is not
   the same as 2 viz ‚Äú2 = 2‚Äù, since the /actual occurrences/ occupy different
   physical locations in this sentence.]]

2. *Definitional/judgemental equality:*
      @@latex: \ignore{ [[margin:][In classical mathematics, operators are
   usually /specified/ by a set of laws ---or universally characterised in
   category theory--- and so users work with a specification rather than any
   particular set of definitional clauses. For instance, Cartesian products can
   be defined in numerous ways, but their universal mapping property suffices to
   characterise them and is powerful enough as an interface. In computing, the
   /choice of implementation/ can make certain problems easier, more efficient,
   than others. For instnace, a stack of digits having at most $n$ positions can
   be implemented by an array of length $n$ or, much more efficiently, as an
   integer of $n$ digits: Either approach gives us the stack interface ---the
   methods ~push, pop, insert, isempty~--- but one is much more efficient.]] }@@ ‚Äú$l
   = r$‚Äù is true whenever one looking-up definitions and applying them leads to
   syntactic equality.  E.g., src_agda[:exports code]{suc zero + suc zero = suc
   suc zero}; i.e., 1 + 1 = 2.

   Definitional equality is generally the form of equality taught at schools:
   Two expressions are equal if they both simplify, as much as possible, to the
   same thing.  However, this approach ---of ‚Äò=‚Äô as an alias for a reflexive
   transitive reduction relation that permits a notion of ‚Äòsimplification‚Äô or
   ‚Äòcomputation‚Äô--- emphasises /operational behaviour/ rather than /properties/ of
   equality.

   This is also known as ‚Äúnormal form equality‚Äù: One simplifies the two
   expressions, using definitions, until the two are syntactically
   indistinguishable.  (The /normal form/ of an expression is the most direct way
   of writing it; i.e., it consists of only constructors.)  That is to say,
   definitional equality is the equivalence closure of a reduction relation
   ---namely, the evaluation scheme of the programming language.  In classical
   mathematics, this appears in the form of ‚Äúsemantic equality‚Äù: Two things are
   equal when the values they /denote/ coincide; e.g., ‚Äú2 + 2‚Äù and ‚Äú4‚Äù are clearly
   different, the first consisting of 3 symbols and the latter of 1 symbol, but
   after evaluation they denote the same value and so are treated equal.  This
   is sometimes known as /extensional equality/;
   citet:OnDenoting_what,OnDenoting_making_sense,OnDenoting_Russell.

3. *‚Äú‚â°‚Äù Propositional equality:* ‚Äú$l = r$‚Äù is true exactly when one must perform
   some sort sort of case analysis of variables (i.e., induction) to arrive at a
   definitional equality. \newline E.g., src_agda[:exports code]{suc m + suc
   zero = suc suc m}.

   In Agda, as shown below, the typing /judgement/ src_agda[:exports code]{refl :
   l ‚â° r} expresses that $l$ and $r$ as /judgmentally/ (definitionaly) equal;
   i.e., a particular /term/ is what signifies the equality as definitional.  The
   equality that /can/ be mentioned solely at the type level, and so /reasoned
   about/, is propositional equality: Two expressions, $l$ and $r$, are
   propositionally equal, src_agda[:exports code]{‚àÄ {x} ‚Üí l ‚â° r}, exactly when
   /any instantiation of the free variables/, $x$, results in definitionaly equal
   terms.

   It is important to remember: ‚Äúsyntactic ‚äÜ definitional ‚äÜ propositional
   equality‚Äù.  The next kind of equality below, is orthogonal.

4. *Setoids / groupoids / equivalence relations:* ‚Äú$l ‚âà r$‚Äù is proven using the
   assumption that src_agda[:exports code]{_‚âà_ : œÑ ‚Üí œÑ ‚Üí Set} is an equivalence
   relation and any properties of the type œÑ.

   For instance:

   a. *Extensionality:* $f ‚âê g$ is proven for two /functions/ by showing that $f\, x
      = g\, x$ for all appropriate arguments $x$. [[margin:][In classical maths,
      extensionality is equal to equality: ‚Äú‚âê = =‚Äù.]]  ‚ÄúExtensionality is
      essential for abstraction‚Äù; i.e., functions are abstractions determined
      only by their input-output relationships ---this is not true in computing,
      where efficiency is important and one speaks of algorithmic complexity.
      citet:algos_kaldewaij,eq:irrelevance
      # citet:algos_cormen,algos_FP,algos_kaldewaij

   b. *Isomorphism:* $A ‚âÖ B$ is proven by exhibiting a non-lossy protocol between
      the two /types/ $A$ and $B$.  [[margin:][HoTT's univalence axiom, \cite{hottbook}, says
      ‚Äúisomorphism is isomorphic to equality‚Äù (‚Äú‚âÖ = =‚Äù) i.e., if two types are
      /essentially indistinguishable (‚Äò‚âÖ‚Äô)/ then we might as well treat them as
      /indistinguishable (‚Äò‚â°‚Äô)/; which is what classical mathematicians do;
      compare with function extensionality.  HoTT's univalence axiom wonderfully
      induces the expected definition of equality that one actually finds
      useful; e.g., categories are equal when they are equivalent.]]

   #+latex: {\footnotesize \color{gray!80} \textbf{Extended Commentary:}
   Experience has shown that, in Agda at least, the use of explicit equivalence
   relations is preferable to the use of propositional equality ---i.e., ~_‚â°_~ is
   generally too strong, coarse, and one must generally use a finer equivalence
   relation.  More generally, the use of setoids is the move from ‚Äòglobal
   identity types‚Äô ~(A, _‚â°_)~ to ‚Äòlocally-defined identity types‚Äô ~(A, _‚âà_)~, and more
   generally is /the move from sets to groupoids/: Two things are ‚Äòequal‚Äô exactly
   when there is a (necessarily invertible) morphism between them. Since Agda is
   constructive citet:Bauer2010AcceptingConstructiveMath, its setoids could just
   as well have been called groupoids.
   #+latex: }

As a middle-ground, the /propositional equality datatype/ is defined as follows.
For a type ~A~ and an element ~x~ of ~A~, we define the family of types/proofs of
‚Äúbeing equal to $x$‚Äù by declaring only one inhabitant at index ~x~.

 {{{code( Propositional Equality )}}}
   #+BEGIN_SRC agda
data _‚â°_ {A : Set} : A ‚Üí A ‚Üí Set
  where
    refl : {x : A} ‚Üí x ‚â° x
   #+END_SRC

This states that src_agda[:exports code]{refl {x}} is a proof of
src_agda[:exports code]{l ‚â° r} whenever src_emacs-lisp[:exports code]{l} and
src_emacs-lisp[:exports code]{r} simplify, by definition chasing only, to
src_emacs-lisp[:exports code]{x} ---i.e., both src_emacs-lisp[:exports code]{l}
and src_emacs-lisp[:exports code]{r} have src_emacs-lisp[:exports code]{x} as
their normal form. This definition makes it easy to prove [[https://en.wikipedia.org/wiki/Identity_of_indiscernibles][Leibniz's
substitutivity rule]], ‚Äúequals for equals‚Äù: {{{code( Transport along proofs )}}}
 #+BEGIN_SRC agda
{- If l ‚â° r and we have P l, then we also have P r too! -}
subst : {A : Set} {P : A ‚Üí Set} {l r : A}
      ‚Üí  l ‚â° r  ‚Üí  P l  ‚Üí  P r
subst refl it = it

substÀò : ‚àÄ {A : Set} {x y : A}
        ‚Üí (‚àÄ (P : A ‚Üí Set) ‚Üí P x ‚Üí P y)
        ‚Üí x ‚â° y
substÀò {A} {x} indistinguishable = indistinguishable (_‚â°_ x) refl

-- Alternativelly...
cong : {A B : Set} {l r : A} (f : A ‚Üí B)
     ‚Üí  l ‚â° r  ‚Üí  f l ‚â° f r
cong refl = refl

congÀò : ‚àÄ {A : Set} {x y : A}
        ‚Üí (‚àÄ {B : Set} (f : A ‚Üí B) ‚Üí f x ‚â° f y)
        ‚Üí x ‚â° y
congÀò indistinguishable = indistinguishable (Œª a ‚Üí a)
#+END_SRC
How does src_agda[:exports code]{subst} work? An element of src_agda[:exports
code]{l ‚â° r} must be of the form src_agda[:exports code]{refl {x}} for some
canonical form ~x~; but if ~l~ and ~r~ are both ~x~, then ~P l~ and ~P r~ are the /same
type/. Pattern matching on a proof of \newline src_agda[:exports code]{l ‚â° r}
gave us information about the rest of the program's type. By the same reasoning,
we can prove that equality is the smallest possible reflexive
relation.
#+begin_margin :width "0.45\\textwidth"
Any relation ‚Ñõ that relates things to themselves ---such that $x\, ‚Ñõ\, x$ for
any /x/--- must necessarily contain the propositional equality relation; i.e., $\_{}‚â°\_{}
‚äÜ ‚Ñõ$.

#+latex: {\renewenvironment{tcolorbox}[1][\unskip]{}{}
{{{code( Propositional equality is ‚Äúthe‚Äù least reflexive relation )}}}
 #+ATTR_LATEX: :options fontsize=\scriptsize
#+begin_src agda
module _ {X} (_‚Ñõ_ : X ‚Üí X ‚Üí Set)
  where

  ‚Ñõ-contains-‚â° : Set
  ‚Ñõ-contains-‚â°
   = ‚àÄ {x y}  ‚Üí  x ‚â° y  ‚Üí  x ‚Ñõ y

  ‚Ñõ-reflexive : Set
  ‚Ñõ-reflexive  =  ‚àÄ {x} ‚Üí x ‚Ñõ x

  lrr :  ‚Ñõ-reflexive
      ‚Üí ‚Ñõ-contains-‚â°
  lrr refl·µ£ refl = refl·µ£

  lrrÀò :  ‚Ñõ-contains-‚â°
       ‚Üí ‚Ñõ-reflexive
  lrrÀò go = go refl
#+end_src
#+latex: }
/‚Äú‚Ñõ is reflexive precively when it contains $\_{}‚â°\_{}$‚Äù/ follows from (lrr)
and (lrrÀò), and is sometimes ‚Äúthe‚Äù definition of reflexivity.
#+end_margin

The Leibniz rule ---/equals-for-equals:/ src_agda[:exports code]{‚àÄ {x y} ‚Üí x ‚â° y ‚Üí
f x ‚â° f y} for any function /f/--- is perhaps the most useful principle of
equality.  In Agda, if we know $x ‚â° y$ by definitional (which includes
syntactic) equality, then $f\, x \;‚â°\; f\,y$ is true /silently, automatically/:
#+begin_margin :width "0.45\\textwidth"
That is, if src_agda[:exports code]{refl : x ‚â° y}, then, we can apply the
definition of src_emacs-lisp[:exports code]{cong}, to obtain src_agda[:exports
code]{refl : f x ‚â° f y}. That is, src_agda[:exports code]{cong refl} normalises
to src_agda[:exports code]{refl}; whereas src_agda[:exports code]{cong p} cannot
normalise since the definition of src_agda[:exports code]{cong} requires its
argument to be the shape src_agda[:exports code]{refl} before any normalisation
can occur. Hence, arbitrary propositional equality proofs src_agda[:exports
code]{p : x ‚â° y} lead to expression src_agda[:exports code]{cong f p : f x ‚â° f
y} which /can only/ simplify in the same cases that allow src_emacs-lisp[:exports
code]{p} to simplify to src_agda[:exports code]{refl}.

\vspace{1ex} There's only one constructor for equalities, so isn't every
equality proof just ~refl~?  ‚ÄòFor the most part‚Äô, /yes/ ---for more, see HoTT
cite:hottbook.  However, an arbitrary term src_agda[:exports code]{p : l ‚â° r} is
a /witness/ that (1) both computations src_emacs-lisp[:exports code]{l} and
src_emacs-lisp[:exports code]{r} terminate, and (2) they have the same normal
form; and the definition of ~cong~ only works, computes, when we actually have
~refl~ in hand, so the issue becomes a matter of when can reduction happen.
#+end_margin
Without ceremony, we can interchange one with the other.  However, if
src_agda[:exports code]{p : x ‚â° y} is a proof of a propositional equality, then
{{{mbox(src_agda[:exports code]{cong f p : f x ‚â° f y})}}}; i.e., we need to invoke the
/particular/ proof src_emacs-lisp[:exports code]{p} in order to obtain the new
proof.  Finally, for setoid equivalence relations, one needs to prove the
theorem src_agda[:exports code]{f-cong : ‚àÄ {x y} ‚Üí x ‚âà y ‚Üí f x ‚âà f y} on a
case-by-case basis, for each src_emacs-lisp[:exports code]{f} one is interested
in ---think ‚Äòsets quotiented by an equivalence‚Äô.  /Definitionally equal terms can
be interchanged anywhere, silently,/ and it is this property that makes them so
remarkable.

# Not precise; see above code block.
#
# Unsurprisingly, the Leibniz rule is so useful that it is sometimes used as /the/
# definition [[margin:][To wit: \[x = y \quad=\quad (‚àÄ P\, ‚Ä¢\, P\, x = P\, y)\] The three
# occurrences of ‚Äò=‚Äô above are all different!]] of equality, also known as ‚ÄúThe Law
# of Indiscernibles‚Äù: src_agda[:exports code]{x ‚â° y} exactly when, for every
# property ~P~ we have ~P x ‚â° P y~ ---two things are indistinguishable exactly when
# they share the same properties.  That is, general equality is reduced to an
# already accepted notion of equality of truth values.  One half of this rule is
# src_emacs-lisp[:exports code]{cong}, proved above, but we do not have the other
# half: The extensionality principle {{{mbox(src_agda[:exports code]{(‚àÄ P ¬†‚Üí¬† P x
# ‚â° P y) ¬†‚Üí¬† x ‚â° y})}}} is no longer true ---indeed, observationally
# indistinguishable expressions are not necessarily equal since they may have been
# constructed (in syntactically) differently (ways). This is not surprising since
# propositional equality is intentional ---after all it is based on syntactic
# indistinguishability. One way citet:eq:pers_as_types,eq:observational to regain
# extensionality is to start with unityped terms /then/ to define a type ùíØ to be
# partial-equivalence relation ---i.e., an equivalence lacking reflexivity---,
# then/ define judgements $t : ùíØ$ to mean $t \,ùíØ\, t$; then every type is/comes
# with an equivalence relation and so one speaks of ‚Äúequality at a type‚Äù with $l =
# r : ùíØ$ meaning $l \,ùíØ\, r$.
#

# To.regain extensionaloty, some theories define types to be pers over unityped
# lamda calculus terms. Then x : T means xTx holds. Pers are used instead
# of.equivalence relations since otherwise we'd be able to show that every term
# inhabits every type!

Is the ~_‚â°_~ datatype really equality? The name is definitely biased; below we
change the names.  {{{code( Discrete graphs with only self-loops )}}}
   #+BEGIN_SRC agda
data _‚ü∂_ {Node : Set} : Node ‚Üí Node ‚Üí Set
  where
    loop : {x : Node} ‚Üí (x ‚ü∂ x)
   #+END_SRC
#+latex: \noindent
Instead of ‚Äò‚â°‚Äô we have the long arrow ‚Äò‚ü∂‚Äô, instead of ~A~ we have named the type
parameter ~Node~, and ~refl~ became ~loop~.  We may /interpret/ the given type ~Node~ as a
bunch of dots on a sheet of paper and a term src_agda[:exports code]{a : x ‚ü∂ y}
as an arc, arrow, from the dot named $x$ to the dot named $y$.  Whether we use
this graphical [[margin:][This is the groupoids interpretation! Moreover, whether we
intepret the datatype as a /proposition/ (equality) or as a /datastructure/ (graph)
is an example of the *propositions-as-types* interpretation used in DTLs.]]
interpretation or the equality one is up to us, the users: The datatype itself
carries no one, fixed, semantics.  The change in perspective can offer great
dividends; for instance, specialising the notion of a surjective graph
homomorphism to this particular graph yields the observation that, in general,
/injective means surjective on equations/:
#+begin_margin :width "0.45\\textwidth"
A more general definition of surjectivity can be seen in Baez ad Shulman's
[[https://arxiv.org/abs/math/0608420][Lectures in /n/-categories and Cohomology]] cite:baez06:_lectur_categ_cohom.
#+end_margin
For every proof src_agda[:exports code]{q : f x ‚â° f y} there is a proof
src_agda[:exports code]{p : x ‚â° y} such that \newline src_agda[:exports
code]{cong f p ‚â° q}.

As a slightly concrete example, if we define [[margin:][There are multiple, equivalent,
definitions of addition; but we actually have to write one down in order to use
it; and then this particular one is given special status by the programming
language: The particular defining clauses are automatically theorems of addition
(having zero-length proofs). More concretely, for our example, ~0 + n~ and ~n~ are
indistinguishable to Agda, and so we can freely use such an identity law
silently without mention; but the other identity law ~n + 0 = n~ requires explicit
mention!.  For instance, if ~xs ‚à∂ Vec A (0 + n)~ then ~xs ‚à∂ Vec A n~; but if ~xs ‚à∂
Vec A (n + 0)~ then ~subst p _ ‚à∂ Vec A n~ where we must ceremonially transport ~xs~,
‚Äòcoerce‚Äô, along the proof ~p ‚à∂ n + 0 ‚â° n~. This issue pops up in the wild in
useful, simple, programs such as the catenation of vectors; try it!]]  addition on
the natural numbers inductively on the first argument ---i.e., src_agda[:exports
code]{0 + n = n} and src_agda[:exports code]{suc m + n = suc (m + n)}--- then
one can show that 0 is the left identity of addition very /quickly/ but to show
that it is a right identity means we need to perform case analysis (i.e.,
induction) in order to make any progress (viz invoking the definition of +). We
have two proofs of equality but one has a /shorter/ proof length than the other:
src_agda[:exports code]{0 + n ‚â° n} is ~refl~ /immediately/, whereas
src_agda[:exports code]{n + 0 ‚â° n} /becomes ~refl~ after/ performing $n$ reduction
steps to get into normal form.

 In summary, one says ~ùìÅ ‚â° ùìá~ is <<</definitionally equal/>>>
 #+latex: \label{</definitionally equal/>}
 when both sides are indistinguishable after all possible definitions in the
 terms ~ùìÅ~ and ~ùìá~ have been used. In contrast,
 #+latex: the equality is
 <<</propositionally equal/>>> when one must perform actual work, such as using
 inductive reasoning.  In general, if there are no variables in ~ùìÅ ‚â° ùìá~ then we
 have definitional equality ---i.e., simplify as much as possible then
 compare--- otherwise we have propositional equality ---real work to do. Below
 is an example about the types of vectors.  {{{code(Examples of Propositional
 and Definitional Equality)}}}
 #+BEGIN_SRC agda :tangle list-is-not-vec.agda
definitional : ‚àÄ {A} ‚Üí Vec A 5 ‚â° Vec A (2 + 3)
definitional = refl

propositional : ‚àÄ {A m n} ‚Üí Vec A (m + n) ‚â° Vec A (n + m)
propositional v = subst +-sym v
                  -- where +-sym : ‚àÄ {n m}  ‚Üí  m + n ‚â° n + m
 #+END_SRC

 #+latex: \noindent
 That is, whenever one has a proof src_agda[:exports code]{p : l ‚â° r}, if
 src_emacs-lisp[:exports code]{p} is the src_agda[:exports code]{refl}
 /constructor/, then /l and r are equal by definition chasing/; otherwise, they
 require a ‚Äònon-trivial‚Äô proof and are thus /propositionally equal/.  In
 particular, to type check src_agda[:exports code]{refl : f(x) = y} for some
 function src_emacs-lisp[:exports code]{f}, the system must actually perform the
 computation src_emacs-lisp[:exports code]{f} on input src_emacs-lisp[:exports
 code]{x} /then/ check for syntactic equality against src_emacs-lisp[:exports
 code]{y}. Hence, equalities may contain non-trivial computational content and
 typechecking may involve non-trivial computational effort; e.g.,
 $\mathsf{refl} : 2^{100} ‚â° 2^{100}$ takes some ‚Äòtime‚Äô to typecheck.

:John_Major_Equality:
In the above example, we /know/ that ~m + n~ and ~n + m~ will /simplify/ to the same
thing, for any actually chosen ‚Ñïumeric values for ~m~ and ~n~; as such, we want to
write just ~v~ instead of ~subst +-sym v~. Within non-trivial programs, ~subst~'s can
be quite involved and deeply nested, and when we /know/ the type of what we have
in hand, say ~it ‚à∂ Œ±~, is provably the type of what is required in the current
context, say type Œ≤, then we may prefer to outright provide ~it~ rather than ~subst
? it~ where ‚Äò?‚Äô is a proof obligation of type ~Œ± ‚â° Œ≤~.

Heterogeneous equality is most commonly defined with John Major equality

data JMeq : (A B : Set) ‚Üí A ‚Üí B ‚Üí Set where JMrefl : (A : Set)(x : A) ‚Üí JMeq A A x x

This is termed after a British politician since while it promises that any two
terms can be equal regardless of their class (type), only two things from the
same class can ever be equal.

The above definition doesn‚Äôt typecheck in Agda!  That‚Äôs because Agda is
predicative, meaning that a type constructor can‚Äôt quantify over the same
universe it occupies. We can however, cleverly phrase JMeq so to avoid this

data JMeq (A : Set) : (B : Set) ‚Üí A ‚Üí B ‚Üí Set where JMrefl : (a : A) ‚Üí JMeq A A a a

Now the constructor avoids quantifying over Set and therefore fits inside the
same universe as A and B.
:End:

*** nomargins                                                      :ignore:
#+latex: \nomargins
*** Modules ---Namespace Management; Œ†Œ£-types

     #+latex: \hspace{-1.3em}

For now, Agda modules are not
#+latex: first-class\FOOTNOTE{
Following common usage, we define a /first-class citizen/ to be a citizen that is
not treated differently by having their rights reduced. In particular,
first-class citizens may be serviced (‚Äòtreated as data‚Äô) by other citizens;
/second-class citizens/ can only provide a service and do not themselves have the
right to be serviced.
#+latex: }
constructs and essentially only serve to delimit (possibly parameterised)
namespaces, thereby avoiding name clashes ---as such, there are only a few
associated keywords, which we show briefly in this section.  The use of modules
is exemplified by the following snippets.

   #+begin_parallel 4
   #+latex: \vspace{0.5em}
 {{{code( A¬†Simple¬†Module )}}}
   #+BEGIN_SRC agda
module A where

  ùí© : Set
  ùí© = ‚Ñï

  private
    x : ‚Ñï
    x = 3

  y : ùí©
  y = x + 1
   #+END_SRC
   #+latex: \columnbreak
   #+latex: \vspace{0.5em}
 {{{code( Using It )}}}
   #+BEGIN_SRC agda
use‚ÇÄ : A.ùí©
use‚ÇÄ = A.y

use‚ÇÅ : ‚Ñï
use‚ÇÅ = y
  where open A

open A

use‚ÇÇ : ‚Ñï
use‚ÇÇ = y
   #+END_SRC
   #+latex: \columnbreak
   #+latex: \vspace{0.5em}
 {{{code( Parameterised Modules )}}}
   #+BEGIN_SRC agda
module B
    (x : ‚Ñï)
  where
    y : ‚Ñï
    y = x + 1
   #+END_SRC
   #+latex: \vfill
   #+latex: \vspace{0.2em}
 {{{code( Name¬†=¬†Function )}}}
   #+BEGIN_SRC agda
exposed
   : (x : ‚Ñï)
   ‚Üí ‚Ñï
exposed = B.y
   #+END_SRC
   #+latex: \columnbreak

   #+latex: \vspace{0.5em}
 {{{code( Using Them )}}}
   #+BEGIN_SRC agda
use'‚ÇÄ : ‚Ñï
use'‚ÇÄ = B.y 3

module C = B 3

use : ‚Ñï
use = C.y

use'‚ÇÅ : ‚Ñï
use'‚ÇÅ = y
  where
    open B 3
   #+END_SRC

   #+end_parallel

  When opening a module, we can control which names are brought into scope with
  the ~using, hiding,~ and ~renaming~ keywords.
  #+caption: Module combinators supported in the current implementation of Agda
  | ~open M hiding (ùìÉ‚ÇÄ; ‚Ä¶; ùìÉ‚Çñ)~               | Essentially treat ~ùìÉ·µ¢~ as private      |
  | ~open M using  (ùìÉ‚ÇÄ; ‚Ä¶; ùìÉ‚Çñ)~               | Essentially treat /only/ ~ùìÉ·µ¢~ as public  |
  | ~open M renaming (ùìÉ‚ÇÄ to ùìÇ‚ÇÄ; ‚Ä¶; ùìÉ‚Çñ to ùìÇ‚Çñ)~ | Use names ~ùìÇ·µ¢~ instead of ~ùìÉ·µ¢~ |
#   + ~open M public~: Treat the contents of ~M~ as if they were public contents of
# the current module.

# Within a module, we may have nested module declarations.

All names in a module are public, unless declared ~private~.  Public names may be
accessed by qualification or by opening them locally or globally. Modules may be
parameterised by arbitrarily many values and types ---but not by other modules.

Modules are essentially implemented as syntactic sugar: Their declarations are
treated as top-level functions that take the parameters of the module as extra
arguments. In particular, it may appear that module arguments are ‚Äòshared‚Äô among
their declarations, but this is not so ---see the =exposed= function above.

Parameterised Agda modules are generalised signatures that have all their
parameters first then followed by only by named symbols that must have term
definitions.  Unlike generalised signatures which do not possess a singular
semantics, Agda modules are pleasant way to write Œ†Œ£-types ---the parameters are
captured by a Œ† type and the defined named are captured by Œ£-types as in ‚Äú =Œ†
parameters ‚Ä¢ Œ£ body= ‚Äù.

# Agda records are closed to being generalised signatures, so we turn
# to them next.

#   ‚ÄúUsing Them‚Äù:
#   + This explains how names in parameterised modules are used: They are treated as functions.
#   + We may prefer to instantiate some parameters and name the resulting module.
#   + However, we can still ~open~ them as usual.

**** COMMENT Anonymous Modules and Variables

  Anonymous modules correspond to named-then-immediately-opened modules,
  and serve to approximate the informal phrase ‚Äúfor any ~A ‚à∂ Set~ and ~a ‚à∂ A~, we have ‚ãØ‚Äù.
  This is so [[https://people.inf.elte.hu/divip/AIMXXVIII.pdf][common]] that the ~variable~ keyword was introduced and it's [[https://agda.readthedocs.io/en/v2.6.0.1/language/generalization-of-declared-variables.html][clever]]:
  Names in ~‚ãØ~ are functions of /only/ those ~variable~-s they actually mention.

  #+begin_parallel
  #+BEGIN_EXAMPLE agda
   module _ {A : Set} {a : A} ‚ãØ
‚âà
   module T {A : Set} {a : A} ‚ãØ
   open T
  #+END_EXAMPLE
  #+latex: \columnbreak
  #+BEGIN_EXAMPLE agda
variable
  A : Set
  a : A
‚ãØ
  #+END_EXAMPLE
  #+end_parallel \vspace{-1em}

**** COMMENT Module efficiency                                       :ignore:

  Splitting a program over several files will improve type checking performance,
  since when you are making changes the type checker only has to check the files
  that are influenced by the change.
  + ~import X.Y.Z~: Use the definitions of module ~Z~ which lives in file ~./X/Y/Z.agda~.

  So much for Agda modules.
*** Records --- Œ£-types

     An Agda record type is /presented/ like a generalised signature, except
     parameters may either appear immediately after the record's name
     declaration or may be declared with the =field= keyword; other named symbols
     must have an accompanying term definition. Unlike generalised signatures
     which do not possess a singular semantics, Agda records are essentially a
     pleasant way to write Œ£-types. The nature of records is summarised by the
     following equation.

     | ~record~ | ‚âà | ~module~ +  ~data~ with one constructor |

   #+begin_parallel
 {{{code( The class of types along with a value picked out )}}}
   #+BEGIN_SRC agda
record PointedSet : Set‚ÇÅ where
  constructor MkIt  -- Optional
  field
    Carrier : Set
    point   : Carrier

  -- It's like a module,
  -- we can add definitions
  blind : {A : Set}
        ‚Üí A ‚Üí Carrier
  blind = Œª a ‚Üí point
   #+END_SRC
   #+latex: \columnbreak
 {{{code( Defining Instances )}}}
   #+BEGIN_SRC agda
ex‚ÇÄ : PointedSet
ex‚ÇÄ = record { Carrier = ‚Ñï
             ; point   = 3 }

ex‚ÇÅ : PointedSet
ex‚ÇÅ = MkIt ‚Ñï 3

open PointedSet

ex‚ÇÇ : PointedSet
Carrier ex‚ÇÇ = ‚Ñï
point   ex‚ÇÇ = 3
   #+END_SRC
   #+end_parallel
   #+latex: \vspace{-1em}

   #    Within the Emacs interface, start with ~ex‚ÇÇ = ?~, then in the hole enter
   # ~C-c C-c RET~ to obtain the /co-pattern/ setup.

   Two tuples are the same when they have the same components, likewise a record
   is (extensionaly) defined by its projections, whence /co-patterns/: The
   declarations @@latex: \newline@@ ~r = record {f·µ¢ = d·µ¢}~ and =f·µ¢ r = d·µ¢=, for field names =f·µ¢=, are the
   same; they define values of record types. See =ex‚ÇÇ= above for such an example.

   # If you are using many local definitions, you likely want to use
   # co-patterns.

   To allow projection of the fields from a record, each record type comes with a
   module of the same name. This module is parameterised by an element of the
   record type and contains projection functions for the fields.

   #+begin_parallel
 {{{code( Simple Uses )}}}
   #+BEGIN_SRC agda
use‚Å∞ : ‚Ñï
use‚Å∞ = PointedSet.point ex‚ÇÄ

use¬π : ‚Ñï
use¬π = point
    where open PointedSet ex‚ÇÄ

open PointedSet

use¬≤ : ‚Ñï
use¬≤ = blind ex‚ÇÄ true
   #+END_SRC
   #+latex: \columnbreak

  #+macro: newline @@latex: \newline@@
   #    Notice that we could  pattern match on records {{{newline}}} ---they're
   # just ~data~ after all!

   #+latex: \vspace{1ex}
 {{{code( Pattern Matching on Records )}}}
   #+BEGIN_SRC agda
use¬≥ use‚Å¥ : (P : PointedSet)
           ‚Üí Carrier P

use¬≥ record {Carrier = C
            ; point = x}
  = x

use‚Å¥ (MkIt C x)
  = x
   #+END_SRC
   #+end_parallel
   #+latex: \vspace{-1em}


   Records are =data= declarations whose one and only constructor is named
   @@latex: \newline @@ =record {f·µ¢ = _}=, where the =f·µ¢= are the filed names; above
   we provided =MkIt= as an optional alias. As such, above we could pattern match
   on records using either constructor name.

  #+latex: So much for records.\FOOTNOTE{
  Agda src_agda[:exports code]{record}s are particular ADTs/src_agda[:exports
  code]{data}, which have been discussed in detail up to this point. They have
  src_agda[:exports code]{module}-like beavhiour, which has also been discussed,
  and so, reasonably, the discussion on records is terse.
  #+latex: }

* yesmargins                                                 :ignore:
#+latex: \yesmargins
* Examples from the Wild
:PROPERTIES:
:CUSTOM_ID: Motivating-the-problem-Examples-from-the-Wild
:END:

# Motivating the problem ---Examples from the Wild

#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

  #+latex_header: \newunicodechar{‚à•}{\ensuremath{\mid\mid}}

#+latex: \newcounter{QAndA}[section]
# +latex: \newenvironment{definition}[1][]{\refstepcounter{definition}\par\medskip
#+latex_header: \newunicodechar{‚á®}{  JC \theQAndA\refstepcounter{QAndA} }
#+latex_header: \newunicodechar{‚á¶}{  MA \theQAndA }

#+latex_header: \newunicodechar{ ÃÄ}{MA}
#+latex_header: \newunicodechar{‚àé}{\ensuremath{\blacksquare}}
#+latex: \def\qedsymbol{\blacksquare}

<<sec:examples_from_the_wild>>
# +latex: \label{sec:examples_from_the_wild}

:To_consider_futher:
Also, I think your analysis of what ‚Äúproblem‚Äù is highlighted by each example is
not refined enough. Your shallow analysis makes it seem like ‚Äúunbundle
everything‚Äù is ‚Äòthe‚Äô solution (which is more-or-less the choice made in Unimath
BTW), but that is also not true. The analysis of the ‚Äòbundling‚Äô problem by
Spitters et al. is much more refined here.
:end:

:TODO:
3. each (sub-sub-)section should first show an example of (real) code that is
   ‚Äòproblematic‚Äô, with an explanation of what the code does / tries to do,
   followed by an analysis of what is, in fact, wrong with it [with references
   to the literature to others who have commented on the same already], and a
   summary of ‚Äòthe problem that needs solved‚Äô.

      ‚á¶ That does sound like a good approach; ‚Äúhere's a problem you might want to
        solve, oh no somethings is wrong‚Äù. :-)

6. your explanations should be more fine-grained

7. keep your editorializing to a minimum! Point out the problems for which you
   will provide a solution in the text. If you feel you must editorialize, then
   put them in side-notes instead of in the text itself.
:END:

** Introduction :ignore:
:PROPERTIES:
:CUSTOM_ID: Introduction
:END:

#+latex: \remark{
‚Üª /Tedium is for machines; interesting problems are for people./ ‚Ü∫
#+latex: } \vspace{-1cm}

# In this section, we showcase a number of problems that occur in developing
# libraries of code /within/ dependently-typed languages.
In this
#+begin_margin :width "0.45\\textwidth"
This chapter lays out the problems; there's nothing ‚Äúnew‚Äù here /besides/
collecting existing problems in DTLs and the current ways they are handled by DTL
practitioners.
#+end_margin
chapter, we motivate the problems ---for which we will find solutions for--- by
finding examples within public libraries of code developed in dependently-typed
languages.  We will refer back to these real-world examples later on when
developing our frameworks for reducing their tedium and size.  The examples are
extracted from Agda libraries focused on mathematical domains, such as algebra
and category theory. It is not important to understand the application domains,
but how modules are organised and used.  Encouraged by program correctness
activities, our focus will inexorably lead to embedding program specifications
at the /type level/, but we will see that /sometimes/ it is more pragmatic to
relocate the specification to the /value level/ (section
ref:sec:examples:readability); this then leads to choosing more apt names
(section ref:sec:examples:renaming) and to mixing-in features to an existing
module (sections ref:sec:examples:IsX, ref:sec:examples:redundancy,
ref:sec:examples:extensions).  To illustrate the core concepts, we will use the
#+latex: \label{<Magma>}
algebraic structures <<<Magma>>>, <<<Semigroup>>>, and <<<Monoid>>>
@@latex:\label{<Semigroup>>>, and <<<Monoid>}@@
#+begin_margin :width "0.45\\textwidth"
A /magma/ =(C, ‚®æ)= is a set =C= and a binary operation =_‚®æ_ ‚à∂ C ‚Üí C ‚Üí C= on it; a
/semigroup/ is a magma whose operation is associative, ~‚àÄ x, y, z ‚Ä¢ (x ‚®æ y) ‚®æ z = x
‚®æ (y ‚®æ z)~; and a /monoid/ is a semigroup that has a point ~Id ‚à∂ C~ acting as the
identity of the binary operation: ~‚àÄ x ‚Ä¢ x ‚®æ Id = x = Id ‚®æ x~.  For example, real
numbers with subtraction ~(‚Ñù, -)~ are only a magma whereas numbers with addition
~(‚Ñù, _+_, 0)~ form a monoid.  The /canonical models/ of magma, semigroup, and monoid
are trees (with branching), non-empty lists (with catenation), and possibly
empty lists, respectively ---these are discussed again in section
ref:sec:free-datatypes.
#+end_margin
.

Incidentally, the common solutions to the problems presented may be construed as
*design patterns for dependently-typed programming*. Design patterns
#+begin_margin :width "0.45\\textwidth"
[[https://en.wikipedia.org/wiki/Software_design_pattern][Definition]]: /A general, reusable solution to a commonly occurring
problem./
#+end_margin
are algorithms
#+begin_margin :width "0.45\\textwidth"
Definition: /A finite sequence of instructions to be followed to accomplish a
goal./
#+end_margin
yearning to be formalised. The power of
the host language dictates whether design patterns remain as informal directions
to be implemented in an ad-hoc basis then checked by other humans, or as a
library methods that are written once and may be freely applied by users. For
instance, the Agda ~Algebra.Morphism.Structures~ ‚Äúlibrary‚Äù
#+begin_margin :width "0.45\\textwidth"
All references to the Agda Standard Library refer to the current version 1.3.
The library can be accessed at https://github.com/agda/agda-stdlib.
#+end_margin
presents /only/ examples of the homomorphism design
pattern ---which shows how to form operation-preserving functions for a few
chosen algebraic
structures. Examples, rather than a library method, is all that can be done
since the current implementation of Agda does not have the necessary
meta-programming utilities to construct new types in a practical way ---at
least, not out of the box.
# #
# + The procedure is essentially the same for other algebraic structures.
# + It takes time to do form these explicitly, even for the common structures.

#+latex: \begin{fullwidth}
{{{localtoc}}}
#+latex: \end{fullwidth}

** Simplifying Programs by Exposing Invariants at the Type Level
:PROPERTIES:
:CUSTOM_ID: Simplifying-Programs-by-Exposing-Invariants-at-the-Type-Level
:END:
<<sec:examples:readability>>
# +latex: \label{sec:examples:readability}
# Adding Zero then Multiplying by One Results in a Type Error

#+latex: \remark{
In particular, this section is about
‚Äúhow a user may wish things were bundled‚Äù and a suggestion to ‚Äúhow a library
designer should bundle data‚Äù.
#+latex: } \vspace{-1cm}

In this section, we want to discuss how ‚Äúunbundled (possibly
value-parameterised) presentations‚Äù can be used to simplify programs and
statements about elements of shared types.  We begin with a ubiquitous
problem[fn:48] that happens in practice: Given a list ~[x‚ÇÄ, x‚ÇÅ, ‚Ä¶, x‚Çô‚Çã‚ÇÅ]~, how do
we get the $k^{th}$ element of the list?  Unless $0 ‚â§ k < n$, we will have an
error. The issue is clearly at the ‚Äòbounds‚Äô, $0$ and $n$, and so, for brevity,
we focus on the problem of extracting the first element of a list ---i.e., the
first bound.  The resulting unbundling solution has its own problems, so
afterward, we consider how to phrase composition of programs in general and
abstract that to phrasing distributivity laws.  Finally, from the previous two
discussions, we conclude with a promising suggestion that may improve library
design.

*** Avoiding ‚ÄúOut-of-bounds‚Äù Errors
:PROPERTIES:
:CUSTOM_ID: Avoiding-Out-of-bounds-Errors
:END:

<<sec:examples:safe_head>>
# +latex: \label{sec:examples:safe_head}


Let us ‚Äúsee the problem‚Äù by writing a function ~head~ that gets the first element
of a list ---a very useful and commonly used operation.

#+latex: \vspace{-0.2cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Lists as Algebraic Data Types)}}}
 #+ATTR_LATEX: :options fontsize=\large
#+begin_src agda
data List (A : Set) : Set where
  []  : List A
  _‚à∑_ : A ‚Üí List A ‚Üí List A
#+end_src
#+latex: }} \vspace{-2.3cm}

A list ~[x‚ÇÄ, x‚ÇÅ, ‚Ä¶, x‚Çô‚Çã‚ÇÅ]~ is composed by repeatedly prepending new elements to
the front of existing lists, starting from an empty list.  That is, the informal
notation ~[x‚ÇÄ, x‚ÇÅ, ‚Ä¶, x‚Çô‚Çã‚ÇÅ]~ is represented formally as ~x‚ÇÄ ‚à∑ (x‚ÇÅ ‚à∑ (‚ãØ ‚à∑ (x‚Çô ‚à∑
[])))~ using a prepending constructor ~_‚à∑_~ and an empty list constructor ~[]~.

#+latex: \remark{
/Trying/ to define the ~head~ function.
#+latex: }

#+latex: $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Partially defined \texttt{head})}}}
 #+ATTR_LATEX: :options fontsize=\large
#+BEGIN_SRC agda :tangle no
head : ‚àÄ {A} ‚Üí List A ‚Üí A
head []       = {! !}
head (x ‚à∑ xs) = x
#+END_SRC
#+latex: }}\vspace{-2.5cm}

Then, to define ~head l~ for any list ~l~, we consider the /possible shapes/ of the
variable list ~l~. The two possible shapes are an empty list ~[]~ and a prepending
of an element ~x~ to another list ~xs~. In the second case, the the list has ~x~ as
the first element and so we yield that. Unfortunately, in the scenario of an
empty list, there is no first element to return! However, =head= is typed =List A ‚Üí
A= and so it must somehow produce an =A= value from any given ~List A~ value.  In
general, this is not possible: If ~A~ is an empty type, having no values at all,
then ~[]~ is the only possible list of ~A~'s, and so ~head []~ is a value of ~A~, which
contradicts the fact that ~A~ is empty. Hence, either ~head~ remains a
partially-defined[fn:62] function or one has to ‚Äúadd fictitious elements to
every type‚Äù[fn:63] such as $\mathsf{undefined}_A : A$. However, in a DTL, we can
/add the non-emptiness condition/ ~l ‚â† []~ to the type level and have it /checked at
compile-time by the machine rather than by the user/.

#+latex: \vspace{2cm}$\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Non-emptiness Predicate)}}}
 #+ATTR_LATEX: :options fontsize=\large
#+BEGIN_SRC agda :tangle list-is-not-vec.agda
data _‚â†[] {A : Set} : List A ‚Üí Set where
  indeed : ‚àÄ {x xs} ‚Üí (x ‚à∑ xs) ‚â†[]
#+END_SRC
#+latex: }}\vspace{-3.5cm}

We define the /predicate/ ~l ‚â†[]~ as a data-type whose values /witness/ the truth of
the statement ‚Äú\texttt{l} is not an empty list‚Äù. As with ~head~, it suffices to consdier
the possible shapes of ~l~. When ~l~ is a non-empty list ~x ‚à∑ xs~, then we shall
include a constructor, call it ~indeed~, whose type is ~(x ‚à∑ xs) ‚â†[]~; i.e., ~indeed~
is a ‚Äòproof‚Äô that the predicate holds for ~_‚à∑_~ constructions.  Since ~[]~ is an
empty list, we do not include any constructors of the type ~[] ‚â†[]~, since that
would not capture the non-emptiness predicate.

#+latex: \remark{
In this definition, we pattern match on the possible ways to form a list
---namely, ~[]~ and ~_‚à∑_~. In the first case, we perform /case analysis/ on the shape
of the proof of ~[] ‚â†[]~, but there is no way to form such a proof and so we have
‚Äúdefined‚Äù the first clause of ~head~ using /a definition by zero-cases/ on the ~[]
‚â†[]~ proof. The ‚Äòabsurd pattern‚Äô ~()~ indicates the impossibility of a
construction. The second clause is as before in the previous attempt to define
~head~. This approach to ‚Äúpadding‚Äù the list type with auxiliary constraints /after
the fact/ is known as ‚ÄòŒ£-padding‚Äô and is discussed in section
ref:sec:examples:IsX.
#+latex: } \vspace{0ex}
\noindent
With the non-emptiness predicate/type, we can now form ~head~ as a totally defined
function.
{{{code(Non-emptiness proviso at the type level ---Using an auxilary type)}}}
#+BEGIN_SRC agda :tangle list-is-not-vec.agda :prologue "module list-is-not-vec where \nopen import Notation \n"
head : ‚àÄ {A}  ‚Üí  Œ£ l ‚à∂ List A ‚Ä¢ l ‚â†[]  ‚Üí  A
head ([] , ())
head (x ‚à∑ xs , indeed) = x
#+END_SRC

# +latex: \noindent
# and is covered later in section ref:sec:absurd_pattern.

The need to introduce an auxiliary type was to ‚Äúkeep track‚Äù of the fact that the
given list's length is not 0 and so it has an element to extract.  Indeed, some
popular languages have list types that ‚Äúknow their own length‚Äù but it is a /value
field/ of the type that is not observable at the type level.  In a
dependently-typed language, we can form a type of lists that ‚Äúdocument the
length‚Äù of the list /at the type level/ ---these are ‚Äòvectors‚Äô.

{{{code(Exposing Information At the Type Level)}}}
#+BEGIN_SRC agda :tangle list-is-not-vec.agda :prologue "module list-is-not-vec where \nopen import Notation \n"
data Vec (A : Set) : ‚Ñï ‚Üí Set where
  []  : Vec A 0
  _‚à∑_ : ‚àÄ {n} ‚Üí A ‚Üí Vec A n ‚Üí Vec A (suc n)
#+END_SRC


\noindent Our type of vectors[fn:49] is defined intentionally using the same
constructor names as that of lists, which Agda allows.  Notice that the first
constructor is declared to be a member of the type ~Vec A 0~, whereas the second
declares ~x ‚à∑ xs~ to be in ~Vec A (suc n)~ when ~xs~ is in ~Vec A n~, and so ~l ‚à∂ Vec A n~
implies that the length of ~l~ is ~n~. In particular, if ~l ‚à∂ Vec A (suc n)~ then ~l~
has a positive length and so is non-empty; i.e., non-emptiness can be expressed
directly in the type of ~l~.

{{{code(Non-emptiness proviso at the type level)}}}
#+BEGIN_SRC agda :tangle list-is-not-vec.agda :prologue "module list-is-not-vec where \nopen import Notation \n"
head' : ‚àÄ {A n} ‚Üí Vec A (suc n) ‚Üí A
head' (x ‚à∑ xs) = x
#+END_SRC

#+latex: \vspace{-2.2cm}\remark{
As usual, this function is defined on the shape of its argument.  Since its
argument is a value of ~Vec A (suc n)~, only the prepending constructor ~_‚à∑_~ of the
~Vec~ type is possible, and so the definition has only one clause; from which we
immediately extract an ~A~-value, namely ~x~.
#+latex: }\vspace{1.3cm}

Before we conclude this section, it is interesting to note that we could have
used a type src_agda[:exports code]{Vec' : (A : Set) (empty-or-not : ùîπ) ‚Üí Set}
that only documents whether a list is empty or not. However, this option is less
useful than the one that keeps track of a list's length. Indeed, a list's length
is useful as a ‚Äúquick sanity check‚Äù when defining operations on lists, and so
having this simple correctness test embedded at the (/machine-checkable!/) type
level results in a form of ‚Äúsimple specfication‚Äù of functions. For example, the
types of common list operations can have some of their behaviour reflected in
their type via lengths of lists:

{{{code(Simple Partial Specfications of List Operations)}}}
#+begin_src agda
{- Neither length nor value type changes -}
reverse : ‚àÄ {A n} ‚Üí Vec A n ‚Üí Vec A n

{- Only the type changes, the length stays the same -}
map     : ‚àÄ {A B n} ‚Üí (A ‚Üí B) ‚Üí Vec A n ‚Üí Vec B n

{- Length of the result is sum of lengths of inputs -}
_++_    : ‚àÄ {A m n} ‚Üí Vec A m ‚Üí Vec A n ‚Üí Vec A (m + n)

                      #+end_src

In theory, lists and vectors are the same[fn:47] ---where the latter are
essentially lists indexed by their lengths. In practice, however, the additional
length information stated up-front as an integral part of the data structure
makes it not only easier to write programs that would otherwise be awkward or
impossible[fn:50] in the latter case. For instance, above we demonstrated that
the function ~head~, which extracts the first element of a non-empty list, not
only has a difficult type to read, but also requires an auxiliary relation/type
in order to be expressed. In contrast, the vector variant has a much simpler
type with the non-emptiness proviso expressed by requesting a positive length.

#+latex: \remark{
#+begin_center
*/Equivalent structures, but different usability profiles./*
#+end_center
#+latex: } \vspace{-1cm}

\noindent It seems that vectors are the way to go ---but that depends on where
one is /going/. For example, if we want to keep only elements of a vector that
satisfy a predicate ~p~, as shown below. To type such an operation we need to
either know how many elements =m= satisfy the predicate ahead of time, and so the
return type is ~Vec A m~; or we ‚ÄòŒ£-pad‚Äô the length parameter to essentially demote
it from the type level to the body level of the program.

{{{code(Eek!)}}}
#+begin_src agda
filter : ‚àÄ {A n} ‚Üí (A ‚Üí ùîπ) ‚Üí Vec A n ‚Üí Œ£ m ‚à∂ ‚Ñï ‚Ä¢ Vec A m
filter p [] = 0 , []
filter p (x ‚à∑ xs) with p x
...| true  = let (m , ys) = filter p xs in 1 + m , x ‚à∑ ys
...| false = filter p xs
#+end_src

*** ‚ÄúTo Bundle or Not To Bundle‚Äù: Structure vs Predicate Style Presentations
:PROPERTIES:
:CUSTOM_ID: Obviously-sharing-the-same-type-requires-do-nothing-conversion-functions-Unbundling
:END:

/Given two different structures that share some sub-component, expressing that/
/sharing post-facto can be very cumbersome, while if the sharing is expressed via
parameters, things are simple ---even though both encodings are equivalent./
(This is ‚Äòessentially‚Äô the same problem as discussed in the previous section but
in a different guise, as a stepping stone to the more general situation.)

#+latex: \remark{
That is, the ‚Äúsame problem‚Äù arises when, for example, discussing the interaction
between sequential program composition ~_‚®æ_~ and parallel program composition ~_‚à•_~:
The /simultaneous/ execution of programs ~P~-then-~P'~ and ~Q~-then-~Q'~ results in the
same behaviour as the /sequential/ execution of ~P~-and-simultaneously-~Q~ then
~P'~-and-simultaneously-~Q'~.  That is, ~(P ‚®æ P') ‚à• (Q ‚®æ Q') = (P ‚à• Q) ‚®æ (P' ‚®æ Q')~.
#+latex: } \vspace{-1cm}

The phenomenon of exposing attributes at the type level to gain flexibility
applies not only to derived concepts such as non-emptiness, but also to explicit
features of a datatype. A common scenario is when two instances of an algebraic
structure share the same carrier and thus it is reasonable to connect the two
somehow by a coherence axiom.  But for such an equation to be well-typed, we
need to /know/ that the composition operators work on the /same kind/ of programs
phrases ---it is surprisingly not enough to know that each combines certain
kinds of program phrases that happen to be the same kind.

#+latex: \remark{
For brevity, rather than consider program language phrases and operators on
them, we abstract to bi-magmas ---which will be seen again in Chapter
\ref{sec:PF}!
#+latex: } \vspace{-1cm}

Consider what is perhaps the most popular instance of structure-sharing known to
many from childhood, in the setting of rings: We have an additive structure ~(R,
+)~ and a multiplicative structure ~(R, √ó)~ on the same underlying set ~R~, and their
interaction is dictated by distributivity axioms, such as $a \times (b + c) = (a
\times b) + (a \times c)$. As with ~head~ above, depending on which features of
the structure are exposed upfront, such axioms [[margin:][‚ÄúObviously sharing the same type‚Äù
requires ‚Äòdo-nothing‚Äô conversion functions!]] may be either difficult to express
or relatively easy. Below are the two possible ways to present a structure
admiting a type and a binary operation on that type.

{{{code(To bundle or to not bundle?)}}}
#+BEGIN_SRC agda :tangle Distributivity.agda :prologue "module Distributivity where \nopen import Notation hiding (_+_) \n"
record Magma‚ÇÄ : Set‚ÇÅ where
  constructor ‚ü®_,_‚ü©‚ÇÄ
  field
    Carrier : Set
    _‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier

record Magma‚ÇÅ (Carrier : Set) : Set‚ÇÅ where
  constructor ‚ü®_‚ü©‚ÇÅ
  field
    _‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier
#+END_SRC

#+latex: \vspace{-5cm} \remark{
A ~Magma‚ÇÄ~ *is a* pair ~‚ü®C, op‚ü©~ of a type ~C~ and an operation ~op~ on that type!
#+latex: }

#+latex: \vspace{1cm} \remark{
A ~Magma‚ÇÅ~ *on* a given type ~C~ *is a* one-tuple ~‚ü®op‚ü©~ consisting of a binary operation
on that type!
#+latex: } \vspace{2cm}

#+begin_src agda :exports none
{- An algebraic structure of a type and an operation on that type -}
record Magma‚ÇÄ : Set‚ÇÅ where
  constructor ‚ü®_,_‚ü©‚ÇÄ
  field
    Carrier : Set
    _‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier

{- A magma ‚Äúon‚Äù a given type is a binary operation on that type -}
record Magma‚ÇÅ (Carrier : Set) : Set‚ÇÅ where
  constructor ‚ü®_‚ü©‚ÇÅ
  field
    _‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier

open import Data.Product
open import Relation.Binary.PropositionalEquality

to : ‚àÄ {C} ‚Üí Magma‚ÇÅ C ‚Üí Œ£ Magma‚ÇÄ (Œª M ‚Üí Magma‚ÇÄ.Carrier M ‚â° C)
to {C} ‚ü® _‚®æ_ ‚ü©‚ÇÅ = ‚ü® C , _‚®æ_ ‚ü©‚ÇÄ , refl

from : ‚àÄ {C} ‚Üí Œ£ Magma‚ÇÄ (Œª M ‚Üí Magma‚ÇÄ.Carrier M ‚â° C) ‚Üí Magma‚ÇÅ C
from (‚ü® Carrier , _‚®æ_ ‚ü©‚ÇÄ , refl) = ‚ü® _‚®æ_ ‚ü©‚ÇÅ

to‚àòfrom : ‚àÄ {C} (M : Magma‚ÇÅ C) ‚Üí from (to M) ‚â° M
to‚àòfrom ‚ü® _‚®æ_ ‚ü©‚ÇÅ = refl

from‚àòto : ‚àÄ {C}  (M : Œ£ Magma‚ÇÄ (Œª M ‚Üí Magma‚ÇÄ.Carrier M ‚â° C)) ‚Üí to (from M) ‚â° M
from‚àòto (‚ü® Carrier , _‚®æ_ ‚ü©‚ÇÄ , refl) = refl

{-
to : Magma‚ÇÄ ‚Üí Œ£ Set (Œª C ‚Üí Magma‚ÇÅ C)
to M = Magma‚ÇÄ.Carrier M , ‚ü® Magma‚ÇÄ._‚®æ_ M ‚ü©‚ÇÅ

from : Œ£ Set (Œª C ‚Üí Magma‚ÇÅ C) ‚Üí Magma‚ÇÄ
from (C , ‚ü® _‚®æ_ ‚ü©‚ÇÅ) = ‚ü® C , _‚®æ_ ‚ü©‚ÇÄ

to‚àòfrom : ‚àÄ M ‚Üí from (to M) ‚â° M
to‚àòfrom ‚ü® Carrier , _‚®æ_ ‚ü©‚ÇÄ = refl

from‚àòto : ‚àÄ M ‚Üí to (from M) ‚â° M
from‚àòto (C , ‚ü® _‚®æ_ ‚ü©‚ÇÅ) = refl
-}
#+end_src

#+latex: \vspace{1ex}$\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.55\textwidth}{\textheight}{
{{{code(\texttt{Magma‚ÇÄ ‚âÖ (Œ£ C ‚à∂ Set ‚Ä¢ Magma‚ÇÅ C)})}}}
 #+ATTR_LATEX: :options fontsize=\large
#+BEGIN_SRC agda
{- Abstract out a field -}
to   :  Magma‚ÇÄ  ‚Üí  Œ£ C ‚à∂ Set ‚Ä¢ Magma‚ÇÅ C
to M = Magma‚ÇÄ.Carrier M , ‚ü® Magma‚ÇÄ._‚®æ_ M ‚ü©‚ÇÅ

{- Pack away a parameter -}
from  :  Œ£ C ‚à∂ Set ‚Ä¢ Magma‚ÇÅ C  ‚Üí  Magma‚ÇÄ
from (C , ‚ü® _‚®æ_ ‚ü©‚ÇÅ) = ‚ü® C , _‚®æ_ ‚ü©‚ÇÄ

-- These are inverse by ‚Äúdefinition chasing‚Äù (normalisation).

to‚àòfrom : ‚àÄ M ‚Üí from (to M) ‚â° M
to‚àòfrom ‚ü® Carrier , _‚®æ_ ‚ü©‚ÇÄ = refl

from‚àòto : ‚àÄ M ‚Üí to (from M) ‚â° M
from‚àòto (C , ‚ü® _‚®æ_ ‚ü©‚ÇÅ) = refl
#+END_SRC
#+latex: }} \vspace{-5cm}

In *theory*, parameterised structures are no different from their unparameterised,
or ‚Äúbundled‚Äù, counterparts. Indeed, we can easily prove src_agda[:exports
code]{Magma‚ÇÄ ‚âÖ (Œ£ C ‚à∂ Set ‚Ä¢ Magma‚ÇÅ C)} by ‚Äúpacking away the parameters‚Äù and
src_agda[:exports code]{‚àÄ (C : Set) ‚Üí Magma‚ÇÅ C ¬†‚âÖ¬† (Œ£ M : Magma‚ÇÄ ‚Ä¢ M.Carrier ‚â°
C)} by ‚Äúabstracting a field as if it were a parameter‚Äù ---this is known as
‚ÄòŒ£-padding‚Äô. Like the first isomorphism [[margin:][Proven formally in the margin!]], the
second is proven just as easily but suffers from excess noise introduced by the
Œ£-padding, namely extra phrases ‚Äú ~, refl~ ‚Äù that serve to keep track of important
facts, but are otherwise unhelpful.  The proofs generalise easily on a
case-by-case basis to other kinds of structures, but they cannot be proven
internally to Agda in full generality.

Let us consider
#+begin_margin :width "0.45\\textwidth"
A discussion of propositional equality versus equality-by-construction can be
found in section \label{sec:redundancy_derived_features_feature_exclusion}.
#+end_margin
/using/ the first presentation.  When structures ‚Äúpack away‚Äù all their features,
the simple distributivity property becomes a bit of a challenge to write and to
read.

#+latex: \hspace{-1.8em}\begin{minipage}{12cm} \maxsizebox{!}{0.35\textheight}{
{{{code(Distributivity is Difficult to Express)}}}
 #+ATTR_LATEX: :options fontsize=\small
 #+begin_src agda
record Distributivity‚ÇÄ (Additive Multiplicative : Magma‚ÇÄ)
  : Set‚ÇÅ where

  open Magma‚ÇÄ Additive       renaming (Carrier to R‚Çä; _‚®æ_ to _+_)
  open Magma‚ÇÄ Multiplicative renaming (Carrier to R‚Çì; _‚®æ_ to _√ó_)

  field shared-carrier :  R‚Çä ‚â° R‚Çì

  coe‚Çì :R‚Çä ‚ÜíR‚Çì
  coe‚Çì = subst id shared-carrier

  coe‚Çä :R‚Çì ‚ÜíR‚Çä
  coe‚Çä = subst id (sym shared-carrier)

  field
    distribute‚ÇÄ : ‚àÄ {a : R‚Çì} {b c : R‚Çä}
                ‚Üí  a √ó coe‚Çì (b + c)
                 ‚â° coe‚Çì (coe‚Çä(a √ó coe‚Çì b) + coe‚Çä(a √ó coe‚Çì c))
#+END_SRC
 #+latex: }\end{minipage}

It is a bit of a challenge to understand the type of ~distribute‚ÇÄ~. Even though
the carriers of the structures are propositionally equal, ~R‚Çä ‚â° R‚Çì~, they are not
the same by definition ---the notion of equality was defined in section
ref:sec:propositional-equality. As such, we are forced to ‚Äúcoe‚Äùrce back and
forth; leaving the distributivity axiom as an exotic property of addition,
multiplication, and coercions. Even worse, without the cleverness of declaring
two coercion helpers, the typing of ~distribute‚ÇÄ~ would have been so large and
confusing that the concept would be rendered near useless.  In particular, the
*cleverness* is captured by the solid curved arrows in the /informal/ diagram to the
right ---where the dashed lines denote inclusions or dependency relationships.

#+begin_export latex
\vspace{-5cm}\remark{\textbf{Bundled forms require (curved) coercisions}} \vspace{0.5cm}

$\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.55\textwidth}{\textheight}{
\begin{tikzpicture}
    \filldraw[color=blue!60, fill=blue!5, very thick](-0.25,2) ellipse (1cm and 1cm);
    \node at (-0.25, 2) {\footnotesize Multiplicative};

  \filldraw[color=red!60, fill=red!5, very thick](-5.25,-2) ellipse (1cm and 1cm);
  \node at (-5.25, -2) {\footnotesize Additive};

  \filldraw[color=teal!60, fill=teal!5, very thick](-0.25,-2) ellipse (1cm and 1cm);
  \node at (-.25, -2) {\footnotesize Distributivity};

  \filldraw[color=green!60, fill=green!5, very thick](-5.25,2) ellipse (1cm and 1cm);
  \node at (-5.25, 2.1) {\footnotesize Shared};
  \node at (-5.25, 1.8) {\footnotesize Carrier};

  \draw[ultra thick, dashed, ->] (-0.25, 1) to (-.25,-1);
  \draw[ultra thick, dashed, ->] (-4.25, -2) to (-1.25,-2);
  \draw[ultra thick, ->] (-4.25, 2) to  [out=120] (-1.25,2);
  \draw[ultra thick, ->] (-5.25, 1) to  [out=110] (-5.25,-1);
\end{tikzpicture}}} \vspace{-2cm}
#+end_export
 #+latex:
 # The FloatBarrier stops floats (figures are floats) from jumping over them. I
 # will need to look into passing [tbh] options to figures from org mode further.

Again, in theory, parameterised structures are no different from their
unparameterised, or ‚Äúbundled‚Äù, counterparts. However, in *practice*, even when
multiple presentations of an idea are /equivalent/ in some sense, there may be
specfic presentations that are /useful/ for particular purposes[fn:51].  That is,
in a depeendely-typed language, equivalence of structures and their usability
profiles do not necessairly go hand-in-hand.  Indeed, below we can phrase the
distributivity axiom nearly as it was stated informally earlier since the shared
carrier is declared upfront.

{{{code(Distributivity is Expressed Easily with Unbundled Structures)}}}
#+BEGIN_SRC agda :tangle Distributivity.agda
{- A magma ‚Äúon‚Äù a given type is a binary operation
   on that type -}
record Magma‚ÇÅ (Carrier : Set) : Set‚ÇÅ where
  field
    _‚®æ_      : Carrier ‚Üí Carrier ‚Üí Carrier

record Distributivity‚ÇÅ
    (R : Set) {- The shared carrier -}
    (Additive Multiplicative : Magma‚ÇÅ R)  : Set‚ÇÅ where

  open Magma‚ÇÅ Additive       renaming (_‚®æ_ to _+_)
  open Magma‚ÇÅ Multiplicative renaming (_‚®æ_ to _√ó_)

  field distribute‚ÇÅ : ‚àÄ {a b c : R}  ‚Üí     a √ó (b + c)
                                        ‚â° (a √ó b) + (a √ó c)
#+END_SRC
In contrast to the bundled definition of magmas, this form requires no
cleverness to form coercion helpers, and is closer to the informal and usual
distributivity statement. The *lack* of the aforementioned cleverness
is captured by the following diagram: There are no solid curved arrows that
/indicate how the shared component is to be found/; instead, the shared
component is explicit.
#+begin_export latex
\vspace{-5cm} \remark{\textbf{Unbundled forms have shared components stated explicitly (as parameters)}}

$\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.55\textwidth}{\textheight}{
  \begin{tikzpicture}
  \filldraw[color=blue!60, fill=blue!5, very thick](-0.25,2) ellipse (1.15cm and 1.15cm);
  \filldraw[color=green!60, fill=green!5, very thick](-0.25,2) ellipse (.6cm and .6cm);
  \node at (-.25, 2.1) {\footnotesize Shared};
  \node at (-.25, 1.8) {\footnotesize Carrier};

  \filldraw[color=red!60, fill=red!5, very thick](-5.25,-2) ellipse (1.15cm and 1.15cm);
  \filldraw[color=green!60, fill=green!5, very thick](-5.25,-2) ellipse (.6cm and .6cm);
  \node at (-5.25, -1.8) {\footnotesize Shared};
  \node at (-5.25, -2.1) {\footnotesize Carrier};

  \filldraw[color=teal!60, fill=teal!5, very thick](-0.25,-2) ellipse (1cm and 1cm);
  \node at (-.25, -2) {\footnotesize Distributivity};

  \draw[ultra thick, dashed, ->] (-0.25, 1) to  (-.25,-1);
  \draw[ultra thick, dashed, ->] (-4.25, -2) to  (-1.25,-2);

  \node at (-5.25, -1.25) {\footnotesize Additive};
  \node at (-0.25, 2.60) {\footnotesize Multiplicative};
\end{tikzpicture}}} \vspace{-0.8cm}
#+end_export

By the same arguments above, the simple statement relating the two units of a
ring $1 √ó r + 0 = r$ ---or any units of monoids sharing the same carrier--- is
easily phrased using an unbundled presentation and would require coercions
otherwise. We invite the reader to pause at this moment to appreciate the
difficulty in simply expressing this property.

# Computing is filled with exciting problems; machines should help us reduce if
# not eliminate boring tasks.

#+latex: \begin{mybox}{Unbundling Design Pattern}
If a feature of a class is shared among instances, then use an unbundled form of
the class to avoid ‚Äúcoercion hell‚Äù.  See Sections ref:sec:examples:IsX,
ref:sec:PF:problem_statement, ref:sec:problems.
#+latex: \end{mybox}

*** From ~Isùìß~ to ~ùìß~ ---Packing away components
:PROPERTIES:
:CUSTOM_ID: From-Isùìß-to-ùìß-Packing-away-components
:END:

  <<sec:examples:IsX>>
 # +latex: \label{sec:examples:IsX}

  The distributivity axiom, from above, required an unbundled structure /after/ a
  completely bundled structure was initially presented. Usually structures are
  rather large and have libraries built around them, so building and using an
  alternate form is not practical. However, multiple forms are usually
  desirable.

  For example, to accommodate the need for both forms of structure, Agda's
  Standard Library begins with a [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.Structures.html#1][type-level predicate]] such as ~IsSemigroup~ below,
  then [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.html#1][packs that up into a record]]. Here is an instance, along with comments
  from the library.  {{{code(From Isùí≥ to ùí≥ ---where ùí≥ is Semigroup)}}}
  # +caption: From the [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.html#601][Agda Standard Library on Algebra]]

# -- Some algebraic structures (not packed up with sets, operations, etc.)
  #+BEGIN_SRC agda
record IsSemigroup {a ‚Ñì} {A : Set a} (‚âà : Rel A ‚Ñì)
                   (‚àô : Op‚ÇÇ A) : Set (a ‚äî ‚Ñì) where
  open FunctionProperties ‚âà
  field
    isEquivalence : IsEquivalence ‚âà
    assoc         : Associative ‚àô
    ‚àô-cong        : ‚àô Preserves‚ÇÇ ‚âà ‚ü∂ ‚âà ‚ü∂ ‚âà
#+END_SRC

# -- Definitions of algebraic structures like monoids and rings
# -- (packed in records together with sets, operations, etc.)
#+BEGIN_SRC agda
record Semigroup c ‚Ñì : Set (suc (c ‚äî ‚Ñì)) where
  infixl 7 _‚àô_
  infix  4 _‚âà_
  field
    Carrier     : Set c
    _‚âà_         : Rel Carrier ‚Ñì
    _‚àô_         : Op‚ÇÇ Carrier
    isSemigroup : IsSemigroup _‚âà_ _‚àô_
  #+END_SRC

#+latex: \vspace{-8cm}\remark{
  If we refer to the former as src_haskell[:exports code]{Isùí≥} and the latter as
  src_haskell[:exports code]{ùí≥}, then we can see similar instances in the
  standard library for src_haskell[:exports code]{ùí≥} being:
  1. ~Monoid~
  2. ~Group~
  3. ~AbelianGroup~
  4. ~CommutativeMonoid~
  5. ~SemigroupWithoutOne~
  6. ~NearSemiring~
  7. ~Semiring~
  8. $\hspace{-0.8em}$ ~CommutativeSemiringWithoutOne~
  9. ~CommutativeSemiring~
  10. ~CommutativeRing~
#+latex: } \vspace{7cm}

  It thus seems that to present an idea src_haskell[:exports code]{ùí≥}, we
  require the same amount of space to present it unpacked or packed, and so
  doing both *duplicates the process* and only hints at the underlying principle:
  From src_haskell[:exports code]{Isùí≥} we pack away the carriers and function
  symbols to obtain src_haskell[:exports code]{ùí≥}. The converse approach,
  starting from =ùí≥= and going to src_haskell[:exports code]{Isùí≥} is not practical,
  as it leads to numerous unhelpful reflexivity proofs ---c.f., the ~indeed~ proof
  of the ~_‚â†[]~ type for lists, from section ref:sec:examples:safe_head.

  #+latex: \begin{mybox}{ Predicate Design Pattern}
 Present a concept ùí≥ first as a predicate src_haskell[:exports code]{Isùí≥} on
  types and function symbols, then as a type src_haskell[:exports code]{ùí≥}
  consisting of types, function symbols, and a proof that together they satisfy
  the src_haskell[:exports code]{Isùí≥} predicate.
 #+latex: \tcblower
  *Œ£-Padding Anti-Pattern*: Starting from a bundled up type src_haskell[:exports
  code]{ùí≥} consisting of types, function symbols, and how they interact, one may
  form the type src_haskell[:exports code]{Œ£¬†X¬†‚à∂¬†ùí≥¬†‚Ä¢¬†ùí≥.f¬†X¬†‚â°¬†ùíá‚ÇÄ} to /specialise/
  the feature src_haskell[:exports code]{ùí≥.f} to the particular choice ~ùíá‚ÇÄ~.
  However, nearly all uses of this type will be of the form src_haskell[:exports
  code]{(X , refl)} where the ~refl~ proof is unhelpful noise.
 #+latex: \end{mybox}

  Since the standard library uses the predicate pattern, src_haskell[:exports
  code]{Isùí≥}, which requires all sets and function symbols, the Œ£-padding
  anti-pattern becomes a necessary evil.  Instead, it would be preferable to
  have the family src_haskell[:exports code]{ùí≥·µ¢} which is the same as
  src_haskell[:exports code]{Isùí≥} but only[fn:64] takes ~ùíæ~-many elements ---c.f., ~Magma‚ÇÄ~
  and ~Magma‚ÇÅ~ above. However, writing these variations and the necessary
  functions to move between them is not only tedious but also error prone. Later
  on, also demonstrated in citet:DBLP:conf/gpce/Al-hassyCK19, we shall show how
  the bundled form src_haskell[:exports code]{ùí≥} acts as */the/* definition, with
  other forms being derived-as-needed.

 In summary, as the previous two discussions have shown, bundled presentations
 (as in ùí≥‚ÇÄ) suffer from the inability to declare /shared/ components between
 structures ---thereby necessitating some form of Œ£-padding--- and makes working
 with shared components non-trivial due to the need to rewrite along
 propositional equalities, as was the case with simply stating the
 distributivity law using ~Magma‚ÇÄ~. Another problem with fully bundled structures
 is that accessing deeply nested components requires lengthy projection paths,
 which is not only cumbersome but also exposes the hierarchical design of the
 structure, thereby limiting library designers from reorganising such
 hierarchies in the future.  In constrast, unbundled
 @@latex:presentations\sidenote[Œ±]{\color{gray!80} As in $ùí≥‚Çô$, for $n$ the
 number of sort and function symbols of the structure.}@@ are flexible in
 theory, but in practice one must enumerate all components to actually state and
 apply results about such structures.

  #+latex: \begin{mybox}{Typeclass Design Pattern}
  Present a concept src_haskell[:exports code]{ùí≥} as a unary predicate
  src_haskell[:exports code]{ùí≥‚ÇÅ} that associates functions and properties with a
  given type. Then, mark all implementations with src_emacs-lisp[:exports
  code]{instance} so that arbitrary src_haskell[:exports code]{ùí≥}-terms may be
  written without having to specify the particular instance.

  #+latex: \tcblower
 As discussed in section ref:sec:module_interdefinability, when there are
  multiple instance of an ùí≥-structure on a particular type, only one of them may
  be marked for instance search in a given scope.
 #+latex: \end{mybox}

 /Type Classes for Mathematics in Type Theory/ citet:typeclasses_for_maths
 discusses the numerous problems of bundled presentations as well as the issues
 of unbundled presentations and settles on using typeclasses along with their
 tremendously useful instance search mechanism. Since we view ùí≥‚ÇÅ as a particular
 choice in the family $(ùí≥_w)_{w ‚àà ‚Ñï}$, our approach is to instead have library
 designers define ùí≥‚ÇÄ and let users /easily, mechanically, declaratively,/ produce
 $ùí≥_w$ for any ‚Äòparameterisation waist‚Äô $w : ‚Ñï$.  This idea is implemented for
 Agda, as an in-language library, and discussed in chapter ref:sec:contexts.

Notice that to phrase the distributivity law we assigned superficial renamings,
aliases, to the prototypical binary operation ~_‚®æ_~ so that we may phrase the
distributivity axiom in its expected notational form. This leads us to our next
topic of discussion.

** Renaming
:PROPERTIES:
:CUSTOM_ID: Renaming
:END:
   <<sec:examples:renaming>>
# +latex: \label{sec:examples:renaming}

The use of an idea is generally accompanied with particular notation that is
accepted by its primary community. Even though the choice of bound names it
theoretically irrelevant, certain communities would consider it unacceptable to
deviate from convention. Here are a few examples:

- $x(f)$ :: Using $x$ as a /function/ and $f$ as an /argument/.; likewise
  $\frac{\partial x}{\partial f}$.

  #+latex: \vspace{-1cm}\remark{
  With the exception of discussions involving the Yoneda Lemma, or
  continuations, such a notation is simply /‚Äòwrong‚Äô/.
  #+latex: }\vspace{1cm}

- $a √ó a = a$ :: An idempotent operation denoted by multiplication; likewise for
  commutative operations.

  #+latex: \vspace{-1cm}\remark{
  It is more common to use addition or join, ‚Äò‚äî‚Äô, to denote idempotent operations.
  #+latex: }\vspace{1cm}

- $0 √ó a ‚âà a$ :: The identity of ‚Äúmultiplicative symbols‚Äù should never resemble
  ‚Äò$0$‚Äô; instead it should resemble ‚Äò$1$‚Äô or, at least, ‚Äò$e$‚Äô.
  #+latex: \vspace{-1cm}\remark{
  The use of $e$ is a standard, abbreviating /einheit/ which means /identity/, as
  used in influential algebraic works of German authors.
  #+latex: }\vspace{1cm}

- $f + g$ :: The /sequential/ composition of functions is almost universally
  denoted by multiplicative symbols, such as ‚Äò‚àò‚Äô, ‚Äò‚®æ‚Äô, and ‚Äò¬∑‚Äô.
  #+latex: \vspace{-1cm}\remark{
  Even if monoids are defined with the prototypical binary operation denoted
  ‚Äò+‚Äô, it would be /‚Äòwrong‚Äô/ to continue using it to denote functional
  composition.
  #+latex: }\vspace{1cm}

- ${\displaystyle \frac{\Xi}{\Xi}}$ :: In a context involving numerous fractions, it would be
  cruel to use ‚ÄòŒû‚Äô as a variable name.
  #  lest one encounters the abomination ‚Äú

  Likewise, ‚ÄòŒª‚Äô is great in Linear algebra where it generally denotes a scalar,
  such as an eigenvalue.  In computing, ‚ÄúŒªx‚Äù could be read as a multiplication
  of Œª and /x/, as a single identifier, or as a typo for a function such as the
  identity function $\;Œª x ‚Ä¢ x\;$ or the /everywhere x/ function $\;Œª \_{} ‚Ä¢ x\;$.
  #+latex: \vspace{-1cm}\remark{
  The underscore denotes an ‚Äòanonymous variable‚Äô (i.e., an ignored variable).
  #+latex: }\vspace{1cm}

+ $e ‚â§ Œµ ‚àà E ‚äÜ ‚àÉ$ ::
  Using typographically similar /names/ for elements and sets
  can create a bit of confusion.
  #   Likewise, ‚Äúe ‚â§ Œµ ‚àà E‚Äù ---a nice growing sequence lol.

  #+latex: \vspace{-1cm}\remark{
  I have seen the use of the existential quantifier ‚Äò‚àÉ‚Äô as a variable name;
  in-particular to denote the converse (flip) of a relation named ‚ÄòE‚Äô.
  #+latex: }\vspace{1cm}

From the few examples above, it is immediate that to even present a prototypical
notation for an idea, one immediately needs auxiliary notation when specialising
to a particular instance. For example, to use ‚Äòadditive symbols‚Äô such as $+, ‚äî,
‚äï$ to denote an arbitrary binary operation leads to trouble in the function
composition instance above, whereas using ‚Äòmultiplicative symbols‚Äô such as $√ó,
\cdot, *$ leads to trouble in the idempotent case above.
Regardless of prototypical choices, there will always be a need to rename.

#+latex: \begin{mybox}{Renaming Design Pattern}
Use superficial aliases to better communicate an idea; especially so, when the
topic domain is specialised.
#+latex: \end{mybox}

Let's now turn to examples of renaming from three libraries:
1. Agda's ‚Äústandard library‚Äù citet:agda_std_lib (version 1.3),
2. The ‚ÄúRATH-Agda‚Äù library citet:RATH (version 2.2), and
3. A recent ‚Äúagda-categories‚Äù library citet:copumpkin (version 0.1.4).

Each will provide a workaround to the problem of renaming. In particular, the
solutions are, respectively:

1. *Rename as needed.*
   - There is no systematic approach to account for the many common renamings.
   - Users are encouraged to do the same, since the standard library does it this way.

2. *Pack-up the /common/ renamings as modules, and invoke them when needed.*
   - Which renamings are provided is left at the discretion of the designer
     ---even ‚Äòexpected‚Äô renamings may not be there since, say, there are too
     many choices or insufficient man power to produce them.
   - The pattern to pack-up renamings leads nicely to consistent naming.

3. *Names don't matter.*
   - Users of the library need to be intimately connected with the Agda
     definitions and domain to use the library.
   - Consequently, there are many inconsistencies in naming.

# #
The src_agda[:exports code]{open ‚ãØ public ‚ãØ renaming ‚ãØ} pattern shown below will
be reappear later, section ref:sec:PF:practicality, as a library method.
{{{code(The ‚ÄúShape‚Äù of Renaming Blocks in Agda)}}}
#+begin_src agda
  open IsMonoid +-isMonoid public
         renaming ( assoc       to +-assoc
                  ; ‚àô-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  )
#+end_src
The content itself is not important itself: The focus is on the renaming that
takes place. As such, going forward, we intentionally render such clauses in a
tiny fontsize.
#+latex: \vspace{-1cm}\remark{
#+begin_center
Keep an eye out for all those
@@latex:\hbox{@@ src_agda[:exports code]{renaming (Œ∑‚ÇÅ to Œ∑‚ÇÅ'; ‚Ä¶; Œ∑‚Çñ to Œ∑‚Çñ')} @@latex:}@@
lines!
#+end_center
#+latex: }\vspace{1cm}

*** yesmargins :ignore:
#+latex: \nomargins
*** Renaming Problems from Agda's Standard Library
:PROPERTIES:
:CUSTOM_ID: Renaming-Problems-from-Agda's-Standard-Library
:END:

# +latex: \hspace{0em}\begin{minipage}{13cm}

[[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.Structures.html#2757][Below are four excerpts from Agda's standard library]], notice how the
prototypical notation for monoids is renamed *repeatedly* /as needed/. Sometimes it
is relabelled with additive symbols, other times with multiplicative symbols.

#+latex: \vspace{0em}
# +latex: \begin{fullwidth}
# +begin_parallel
{{{code(Additive Renaming ---IsNearSemiring)}}}
#+ATTR_LATEX: :options fontsize=\scriptsize
#+BEGIN_SRC agda
record IsNearSemiring {a ‚Ñì} {A : Set a} (‚âà : Rel A ‚Ñì)
                      (+ * : Op‚ÇÇ A) (0# : A) : Set (a ‚äî ‚Ñì) where
  open FunctionProperties ‚âà
  field
    +-isMonoid    : IsMonoid ‚âà + 0#
    *-isSemigroup : IsSemigroup ‚âà *
    distrib ≥      : * DistributesOver ≥ +
    zeroÀ°         : LeftZero 0# *

  open IsMonoid +-isMonoid public
         renaming ( assoc       to +-assoc
                  ; ‚àô-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  )

  open IsSemigroup *-isSemigroup public
         using ()
         renaming ( assoc    to *-assoc
                  ; ‚àô-cong   to *-cong
                  )
#+END_SRC

#+latex: \vspace{-2em}
{{{code(Additive Renaming Again ---IsSemiringWithoutOne)}}}
#+ATTR_LATEX: :options fontsize=\scriptsize
#+BEGIN_SRC agda
record IsSemiringWithoutOne {a ‚Ñì} {A : Set a} (‚âà : Rel A ‚Ñì)
                            (+ * : Op‚ÇÇ A) (0# : A) : Set (a ‚äî ‚Ñì)
 where
  open FunctionProperties ‚âà
  field
    +-isCommutativeMonoid : IsCommutativeMonoid ‚âà + 0#
    *-isSemigroup         : IsSemigroup ‚âà *
    distrib               : * DistributesOver +
    zero                  : Zero 0# *

  open IsCommutativeMonoid +-isCommutativeMonoid public
         hiding (identityÀ°)
         renaming ( assoc       to +-assoc
                  ; ‚àô-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  ; isMonoid    to +-isMonoid
                  ; comm        to +-comm
                  )

  open IsSemigroup *-isSemigroup public
         using ()
         renaming ( assoc       to *-assoc
                  ; ‚àô-cong      to *-cong
                  )
#+END_SRC
# +end_parallel
# +latex: \end{fullwidth}
# +latex: \end{minipage}

#+latex: \vspace{-1em}
Please keep a lookout for the src_agda[:exports code]{renaming ( ‚ãØ )} lines; it
is such a /schematic shape/ that is important ---not the actual content---;
#+latex: whence the intentionally {$\;$\scriptsize scriptsize}$\;$ font.

#+latex_header: \newunicodechar{‚Äø}{\ensuremath{\smile}}
# +begin_parallel
{{{code(Additive Renaming a 3 ≥·µà Time and Multiplicative Renaming ---IsSemiringWithoutAnnihilatingZero)}}}
#+ATTR_LATEX: :options fontsize=\scriptsize
#+BEGIN_SRC agda
record IsSemiringWithoutAnnihilatingZero
         {a ‚Ñì} {A : Set a} (‚âà : Rel A ‚Ñì)
         (+ * : Op‚ÇÇ A) (0# 1# : A) : Set (a ‚äî ‚Ñì) where
  open FunctionProperties ‚âà
  field
    +-isCommutativeMonoid : IsCommutativeMonoid ‚âà + 0#
    *-isMonoid            : IsMonoid ‚âà * 1#
    distrib               : * DistributesOver +

  open IsCommutativeMonoid +-isCommutativeMonoid public
         hiding (identityÀ°)
         renaming ( assoc       to +-assoc
                  ; ‚àô-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  ; isMonoid    to +-isMonoid
                  ; comm        to +-comm
                  )

  open IsMonoid *-isMonoid public
         using ()
         renaming ( assoc       to *-assoc
                  ; ‚àô-cong      to *-cong
                  ; isSemigroup to *-isSemigroup
                  ; identity    to *-identity
                  )
#+END_SRC

#+latex: \vspace{-1.5em}
{{{code(Additive Renaming a 4·µó ∞ Time and Second Multiplicative Renaming ---IsRing)}}}
#+ATTR_LATEX: :options fontsize=\scriptsize
#+BEGIN_SRC agda
record IsRing
         {a ‚Ñì} {A : Set a} (‚âà : Rel A ‚Ñì)
         (_+_ _*_ : Op‚ÇÇ A) (-_ : Op‚ÇÅ A) (0# 1# : A) : Set (a ‚äî ‚Ñì)
 where
  open FunctionProperties ‚âà
  field
    +-isAbelianGroup : IsAbelianGroup ‚âà _+_ 0# -_
    *-isMonoid       : IsMonoid ‚âà _*_ 1#
    distrib          : _*_ DistributesOver _+_

  open IsAbelianGroup +-isAbelianGroup public
         renaming ( assoc               to +-assoc
                  ; ‚àô-cong              to +-cong
                  ; isSemigroup         to +-isSemigroup
                  ; identity            to +-identity
                  ; isMonoid            to +-isMonoid
                  ; inverse             to -‚Äøinverse
                  ; ‚Åª¬π-cong             to -‚Äøcong
                  ; isGroup             to +-isGroup
                  ; comm                to +-comm
                  ; isCommutativeMonoid to +-isCommutativeMonoid
                  )

  open IsMonoid *-isMonoid public
         using ()
         renaming ( assoc       to *-assoc
                  ; ‚àô-cong      to *-cong
                  ; isSemigroup to *-isSemigroup
                  ; identity    to *-identity
                  )
#+END_SRC
# +end_parallel

At first glance, one solution would be to package up these renamings into helper modules.
For example, consider the setting of monoids.

{{{code(Original ---Prototypical--- Notations)}}}
#+ATTR_LATEX: :options fontsize=\footnotesize
#+BEGIN_SRC agda
record IsMonoid {a ‚Ñì} {A : Set a} (‚âà : Rel A ‚Ñì)
                (‚àô : Op‚ÇÇ A) (Œµ : A) : Set (a ‚äî ‚Ñì) where
  open FunctionProperties ‚âà
  field
    isSemigroup : IsSemigroup ‚âà ‚àô
    identity    : Identity Œµ ‚àô

record IsCommutativeMonoid {a ‚Ñì} {A : Set a} (‚âà : Rel A ‚Ñì)
                           (_‚àô_ : Op‚ÇÇ A) (Œµ : A) : Set (a ‚äî ‚Ñì) where
  open FunctionProperties ‚âà
  field
    isSemigroup : IsSemigroup ‚âà _‚àô_
    identityÀ°   : LeftIdentity Œµ _‚àô_
    comm        : Commutative _‚àô_

    ‚ãÆ
  isMonoid : IsMonoid ‚âà _‚àô_ Œµ
  isMonoid = record { ‚ãØ }
#+END_SRC
{{{code(Renaming Helper Modules)}}}
#+ATTR_LATEX: :options fontsize=\footnotesize
#+BEGIN_SRC agda
module AdditiveIsMonoid {a ‚Ñì} {A : Set a} {‚âà : Rel A ‚Ñì}
               {_‚àô_ : Op‚ÇÇ A} {Œµ : A} (+-isMonoid : IsMonoid ‚âà _‚àô_ Œµ)  where

   open IsMonoid +-isMonoid public
         renaming ( assoc       to +-assoc
                  ; ‚àô-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  )

module AdditiveIsCommutativeMonoid {a ‚Ñì} {A : Set a} {‚âà : Rel A ‚Ñì}
               {_‚àô_ : Op‚ÇÇ A} {Œµ : A} (+-isCommutativeMonoid : IsMonoid ‚âà _‚àô_ Œµ)  where

   open AdditiveIsMonoid (CommutativeMonoid.isMonoid +-isCommutativeMonoid) public
   open IsCommutativeMonoid +-isCommutativeMonoid public using ()
      renaming ( comm to +-comm
               ; isMonoid to +-isMonoid)
#+END_SRC
However, one then needs to make similar modules for /additive notation/ for
~IsAbelianGroup, IsRing, IsCommutativeRing, ‚Ä¶~. Moreover, this still invites
repetition: Additional notations, as used in ~IsSemiring~, would require
additional helper modules.
{{{code(More Necessary Renaming Helper Modules)}}}
#+BEGIN_SRC agda
module MultiplicativeIsMonoid {a ‚Ñì} {A : Set a} {‚âà : Rel A ‚Ñì}
               {_‚àô_ : Op‚ÇÇ A} {Œµ : A} (*-isMonoid : IsMonoid ‚âà _‚àô_ Œµ)  where

   open IsMonoid *-isMonoid public
         renaming ( assoc       to *-assoc
                  ; ‚àô-cong      to *-cong
                  ; isSemigroup to *-isSemigroup
                  ; identity    to *-identity
                  )
#+END_SRC

Unless carefully organised, such notational modules would bloat the standard
library, resulting in difficulty when navigating the library. As it stands
however, the new algebraic structures appear large and complex due to the
‚Äúrenaming hell‚Äù encountered to provide the expected conventional notation.

*** Renaming Problems from the RATH-Agda Library
:PROPERTIES:
:CUSTOM_ID: Renaming-Problems-from-the-RATH-Agda-Library
:END:

The impressive [[http://relmics.mcmaster.ca/RATH-Agda/RATH-Agda-2.2.pdf][Relational Algebraic Theories in Agda]] library takes a disciplined
approach: Copy-paste notational modules, possibly using a find-replace mechanism
to vary the notation. The use of a find-replace mechanism leads to consistent naming
across different notations.

# +caption: Relation.Binary.Setoid.Utils
#+begin_quote
RATH: /For contexts where calculation in different setoids is necessary, we
provide ‚Äúdecorated‚Äù versions of the ~Setoid'~ and ~SetoidCalc~ interfaces [...]/
#+end_quote
#+latex: \vspace{-5em}
{{{code(Seotoidùíü Renamings ---ùíüecorated Synonyms)}}}
#+ATTR_LATEX: :options fontsize=\scriptsize
#+BEGIN_SRC agda
module SetoidA {i j : Level} (S : Setoid i j) = Setoid' S renaming
    ( ‚Ñì to ‚ÑìA ; Carrier to A‚ÇÄ ; _‚âà_ to _‚âàA_ ; ‚âà-isEquivalence to ‚âàA-isEquivalence
    ; ‚âà-isPreorder to ‚âàA-isPreorder ; ‚âà-preorder to ‚âàA-preorder
    ; ‚âà-indexedSetoid to ‚âàA-indexedSetoid
    ; ‚âà-refl to ‚âàA-refl ; ‚âà-reflexive to ‚âàA-reflexive ; ‚âà-sym to ‚âàA-sym
    ; ‚âà-trans to ‚âàA-trans ; ‚âà-trans‚ÇÅ to ‚âàA-trans‚ÇÅ ; ‚âà-trans‚ÇÇ to ‚âàA-trans‚ÇÇ
    ; _‚ü®‚âà‚âà‚ü©_ to _‚ü®‚âàA‚âà‚ü©_ ; _‚ü®‚âà‚âàÀò‚ü©_ to _‚ü®‚âàA‚âàÀò‚ü©_ ; _‚ü®‚âàÀò‚âà‚ü©_ to _‚ü®‚âàAÀò‚âà‚ü©_
    ; _‚ü®‚âàÀò‚âàÀò‚ü©_ to _‚ü®‚âàAÀò‚âàÀò‚ü©_; _‚ü®‚â°‚âà‚ü©_ to _‚ü®‚â°‚âàA‚ü©_ ; _‚ü®‚â°‚âàÀò‚ü©_ to _‚ü®‚â°‚âàAÀò‚ü©_
    ; _‚ü®‚â°Àò‚âà‚ü©_ to _‚ü®‚â°Àò‚âàA‚ü©_ ; _‚ü®‚â°Àò‚âàÀò‚ü©_ to _‚ü®‚â°Àò‚âàAÀò‚ü©_ ; _‚ü®‚âà‚â°‚ü©_ to _‚ü®‚âàA‚â°‚ü©_
    ; _‚ü®‚âà‚â°Àò‚ü©_ to _‚ü®‚âàA‚â°Àò‚ü©_ ; _‚ü®‚âàÀò‚â°‚ü©_ to _‚ü®‚âàAÀò‚â°‚ü©_ ; _‚ü®‚âàÀò‚â°Àò‚ü©_ to _‚ü®‚âàAÀò‚â°Àò‚ü©_
    )

module SetoidB {i j : Level} (S : Setoid i j) = Setoid' S renaming
    ( ‚Ñì to ‚ÑìB ; Carrier to B‚ÇÄ ; _‚âà_ to _‚âàB_ ; ‚âà-isEquivalence to ‚âàB-isEquivalence
    ; ‚âà-isPreorder to ‚âàB-isPreorder ; ‚âà-preorder to ‚âàB-preorder
    ; ‚âà-indexedSetoid to ‚âàB-indexedSetoid
    ; ‚âà-refl to ‚âàB-refl ; ‚âà-reflexive to ‚âàB-reflexive ; ‚âà-sym to ‚âàB-sym
    ; ‚âà-trans to ‚âàB-trans ; ‚âà-trans‚ÇÅ to ‚âàB-trans‚ÇÅ ; ‚âà-trans‚ÇÇ to ‚âàB-trans‚ÇÇ
    ; _‚ü®‚âà‚âà‚ü©_ to _‚ü®‚âàB‚âà‚ü©_ ; _‚ü®‚âà‚âàÀò‚ü©_ to _‚ü®‚âàB‚âàÀò‚ü©_ ; _‚ü®‚âàÀò‚âà‚ü©_ to _‚ü®‚âàBÀò‚âà‚ü©_
    ; _‚ü®‚âàÀò‚âàÀò‚ü©_ to _‚ü®‚âàBÀò‚âàÀò‚ü©_ ; _‚ü®‚â°‚âà‚ü©_ to _‚ü®‚â°‚âàB‚ü©_ ; _‚ü®‚â°‚âàÀò‚ü©_ to _‚ü®‚â°‚âàBÀò‚ü©_
    ; _‚ü®‚â°Àò‚âà‚ü©_ to _‚ü®‚â°Àò‚âàB‚ü©_ ; _‚ü®‚â°Àò‚âàÀò‚ü©_ to _‚ü®‚â°Àò‚âàBÀò‚ü©_ ; _‚ü®‚âà‚â°‚ü©_ to _‚ü®‚âàB‚â°‚ü©_
    ; _‚ü®‚âà‚â°Àò‚ü©_ to _‚ü®‚âàB‚â°Àò‚ü©_ ; _‚ü®‚âàÀò‚â°‚ü©_ to _‚ü®‚âàBÀò‚â°‚ü©_ ; _‚ü®‚âàÀò‚â°Àò‚ü©_ to _‚ü®‚âàBÀò‚â°Àò‚ü©_
    )

module SetoidC {i j : Level} (S : Setoid i j) = Setoid' S renaming
    ( ‚Ñì to ‚ÑìC ; Carrier to C‚ÇÄ ; _‚âà_ to _‚âàC_ ; ‚âà-isEquivalence to ‚âàC-isEquivalence
    ; ‚âà-isPreorder to ‚âàC-isPreorder ; ‚âà-preorder to ‚âàC-preorder
    ; ‚âà-indexedSetoid to ‚âàC-indexedSetoid
    ; ‚âà-refl to ‚âàC-refl ; ‚âà-reflexive to ‚âàC-reflexive ; ‚âà-sym to ‚âàC-sym
    ; ‚âà-trans to ‚âàC-trans ; ‚âà-trans‚ÇÅ to ‚âàC-trans‚ÇÅ ; ‚âà-trans‚ÇÇ to ‚âàC-trans‚ÇÇ
    ; _‚ü®‚âà‚âà‚ü©_ to _‚ü®‚âàC‚âà‚ü©_ ; _‚ü®‚âà‚âàÀò‚ü©_ to _‚ü®‚âàC‚âàÀò‚ü©_ ; _‚ü®‚âàÀò‚âà‚ü©_ to _‚ü®‚âàCÀò‚âà‚ü©_
    ; _‚ü®‚âàÀò‚âàÀò‚ü©_ to _‚ü®‚âàCÀò‚âàÀò‚ü©_ ; _‚ü®‚â°‚âà‚ü©_ to _‚ü®‚â°‚âàC‚ü©_ ; _‚ü®‚â°‚âàÀò‚ü©_ to _‚ü®‚â°‚âàCÀò‚ü©_
    ; _‚ü®‚â°Àò‚âà‚ü©_ to _‚ü®‚â°Àò‚âàC‚ü©_ ; _‚ü®‚â°Àò‚âàÀò‚ü©_ to _‚ü®‚â°Àò‚âàCÀò‚ü©_ ; _‚ü®‚âà‚â°‚ü©_ to _‚ü®‚âàC‚â°‚ü©_
    ; _‚ü®‚âà‚â°Àò‚ü©_ to _‚ü®‚âàC‚â°Àò‚ü©_ ; _‚ü®‚âàÀò‚â°‚ü©_ to _‚ü®‚âàCÀò‚â°‚ü©_ ; _‚ü®‚âàÀò‚â°Àò‚ü©_ to _‚ü®‚âàCÀò‚â°Àò‚ü©_
    )
#+END_SRC

#+latex: \noindent
This keeps going to cover the entirety of the English alphabet ~SetoidD, SetoidE,
SetoidF, ‚Ä¶, SetoidZ~ then we shift to a /few/ subscripted versions ~Setoid‚ÇÄ,
Setoid‚ÇÅ, ‚Ä¶, Setoid‚ÇÑ~.

Next, RATH-Agda shifts to the need to /calculate/ with setoids:
#+begin_parallel
{{{code(SeotoidCalcùíü Renamings ---ùíüdecorated Synonyms)}}}
#+ATTR_LATEX: :options fontsize=\scriptsize
#+BEGIN_SRC agda
module SetoidCalcA {i j : Level} (S : Setoid i j) where
  open SetoidA S public
  open SetoidCalc S public renaming
    ( _‚ñ° to _‚ñ°A
    ; _‚âà‚ü®_‚ü©_ to _‚âàA‚ü®_‚ü©_
    ; _‚âàÀò‚ü®_‚ü©_ to _‚âàAÀò‚ü®_‚ü©_
    ; _‚âà‚â°‚ü®_‚ü©_ to _‚âàA‚â°‚ü®_‚ü©_
    ; _‚âà‚ü®‚ü©_ to _‚âàA‚ü®‚ü©_
    ; _‚âà‚â°Àò‚ü®_‚ü©_ to _‚âàA‚â°Àò‚ü®_‚ü©_
    ; ‚âà-begin_ to ‚âàA-begin_
    )

module SetoidCalcB {i j : Level} (S : Setoid i j) where
  open SetoidB S public
  open SetoidCalc S public renaming
    ( _‚ñ° to _‚ñ°B
    ; _‚âà‚ü®_‚ü©_ to _‚âàB‚ü®_‚ü©_
    ; _‚âàÀò‚ü®_‚ü©_ to _‚âàBÀò‚ü®_‚ü©_
    ; _‚âà‚â°‚ü®_‚ü©_ to _‚âàB‚â°‚ü®_‚ü©_
    ; _‚âà‚ü®‚ü©_ to _‚âàB‚ü®‚ü©_
    ; _‚âà‚â°Àò‚ü®_‚ü©_ to _‚âàB‚â°Àò‚ü®_‚ü©_
    ; ‚âà-begin_ to ‚âàB-begin_
    )
#+END_SRC

#+columnbreak:

This keeps going to cover the entire \newline English alphabet ~SetoidCalcC, SetoidCalcD,
SetoidCalcE, ‚Ä¶, SetoidCalcZ~ then we shift to subscripted versions ~SetoidCalc‚ÇÄ,
SetoidCalc‚ÇÅ, ‚Ä¶, SetoidCalc‚ÇÑ~.

#+latex: \vspace{3em}
/If we ever have more than 4 setoids in hand, or
prefer other decorations, then we would need to produce similar helper modules./

#+latex: \vspace{3em}
*Each src_haskell[:exports code]{Setoidùí≥ùí≥ùí≥} takes around 10 lines, for a total of
roughly 600 lines!*
#+end_parallel
:More:
module SetoidCalcC {i j : Level} (S : Setoid i j) where
  open SetoidC S public
  open SetoidCalc S public renaming
    ( _‚ñ° to _‚ñ°C
    ; _‚âà‚ü®_‚ü©_ to _‚âàC‚ü®_‚ü©_
    ; _‚âàÀò‚ü®_‚ü©_ to _‚âàCÀò‚ü®_‚ü©_
    ; _‚âà‚â°‚ü®_‚ü©_ to _‚âàC‚â°‚ü®_‚ü©_
    ; _‚âà‚ü®‚ü©_ to _‚âàC‚ü®‚ü©_
    ; _‚âà‚â°Àò‚ü®_‚ü©_ to _‚âàC‚â°Àò‚ü®_‚ü©_
    ; ‚âà-begin_ to ‚âàC-begin_
    )
:End:

#+latex: \vspace{2em}

Indeed, such renamings bloat the library, but, unlike the Standard Library, they
allow new records to be declared easily ---‚Äúrenaming hell‚Äù has been deferred
from the user to the library designer. However, later on, in ~Categoric.CompOp~,
we see the variations ~LocalEdgeSetoidùíü~ and ~LocalSetoidCalcùíü~ where decoration ~ùíü~
ranges over ~‚ÇÄ, ‚ÇÅ, ‚ÇÇ, ‚ÇÉ, ‚ÇÑ, R~. The inconsistency in not providing the other
decorations used for ~Setoidùíü~ earlier is understandable: These take time to write
and maintain.

# Various similar decorations can be found in RATH, such as for ~Semigroupoidùíü~ in
# ~Categoric.Semigroupoid~.

#+latex: \yesmargins

*** Renaming Problems from the Agda-categories Library
:PROPERTIES:
:CUSTOM_ID: Renaming-Problems-from-the-Agda-categories-Library
:END:

With RATH-Agda's focus on notational modules at one end of the spectrum, and the
Standard Library's casual do-as-needed in the middle, it is inevitable that
there are other equally popular libraries at the other end of the spectrum. The
[[https://github.com/agda/agda-categories][Agda-categories]] library @@latex:seemingly\sidenote[Œ±]{\color{gray!80} Perhaps
naming was ignored for the sake of quick development and new names may be used
in a later relsease.}@@ ignored the need for meaningful names altogether. Below
are a few notable instances.

+ Functors have fields named ~F‚ÇÄ, F‚ÇÅ, F-resp-‚âà, ‚Ä¶~.
  - This could be considered reasonable even if one has a functor named ~G~.

  # This [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/Product.agda][leads to expressions]] such as ~< F.F‚ÇÄ , G.F‚ÇÄ >~.

  # - Incidentally, and somewhat inconsistently, a ~Pseudofunctor~ has fields ~P‚ÇÄ,
  #  P‚ÇÅ, P-homomophism~ ---where the latter is documented /P preserves ‚âÉ/.

  #+latex: \vspace{-1cm}\remark{
  More meaningful names may be ~obj, mor, mor-cong~ ---which refer to a functor's
  ‚Äúobj‚Äùect map, ‚Äúmor‚Äùphism map, and the fact that the ‚Äúmor‚Äùphism map is a
  ‚Äúcong‚Äùruence.
  #+latex: }\vspace{1cm}

+ Such lack of concern for naming might be acceptable for well-known concepts
  such as functors, where some communities use ~F·µ¢~ to denote the object/0-cell
  or morphism/1-cell operations. However, considering [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/SubCategory.agda][subcategories]] one sees
  field names ~U, R, Rid, _‚àòR_~ which are wholly unhelpful.
  #+latex: \vspace{-1cm}\remark{
  Instead, more meaningful names such as ~embed, keep, id-kept, keep-resp-‚àò~ could
  have been used.
  #+latex: }\vspace{1cm}

+ The ~Iso, Inverse,~ and ~NaturalIsomorphism~ records have fields ~to / from, f
  / f‚Åª¬π,~ and ~F‚áíG / F‚áêG~, respectively.

  #  ( ~Categories.Category~ )

  Even though some of these build on one another, with Agda's namespacing
  features, all ‚Äúforward‚Äù and ‚Äúbackward‚Äù morphism fields could have been named,
  say, ~to~ and ~from~. The naming may not have propagated from ~Iso~ to other records
  possibly due to the low priority for names.

  From a usability perspective, projections like ~f~ are reminiscent of the OCaml
  community and may be more acceptable there. Since Agda is more likely to
  attract Haskell programmers than OCaml ones, such a peculiar projection name
  seems completely out of place. Likewise, the field name ~F‚áíG~ seems only
  appropriate if the functors involved happen to be named ~F~ and ~G~.

  #+latex: \vspace{-5cm}\remark{
  These unexpected deviations are not too surprising since the Agda-categories
  library seems to give names no priority at all. Field projections are treated
  little more than classic array indexing with numbers.
  #+latex: }\vspace{5cm}

#+latex: \hspace{0em}\begin{minipage}{13cm}

By largely avoiding renaming, Agda-categories has no ‚Äúrenaming hell‚Äù anywhere at
the heavy price of being difficult to read: Any attempt to read code requires
one to ‚Äúsquint away‚Äù the numerous projections to ‚Äúsee‚Äù the concepts of
relevance. Consider the [[https://github.com/agda/agda-categories/blob/master/src/Categories/Yoneda.agda][following excerpt]].

#+latex: \vspace{1ex}
{{{code(Symbol Soup)}}}
#+BEGIN_SRC agda
helper : ‚àÄ {F : Functor (Category.op C) (Setoids ‚Ñì e)}
                     {A B : Obj} (f : B ‚áí A)
                     (Œ≤ Œ≥ : NaturalTransformation Hom[ C ][-, A ] F) ‚Üí
                   Setoid._‚âà_ (F‚ÇÄ Nat[Hom[C][-,c],F] (F , A)) Œ≤ Œ≥ ‚Üí
                   Setoid._‚âà_ (F‚ÇÄ F B) (Œ∑ Œ≤ B ‚ü®$‚ü© f ‚àò id) (F‚ÇÅ F f ‚ü®$‚ü© (Œ∑ Œ≥ A ‚ü®$‚ü© id))
          helper {F} {A} {B} f Œ≤ Œ≥ Œ≤‚âàŒ≥ = S.begin
            Œ∑ Œ≤ B ‚ü®$‚ü© f ‚àò id          S.‚âà‚ü® cong (Œ∑ Œ≤ B) (id-comm ‚óã (‚ü∫ identityÀ°)) ‚ü©
            Œ∑ Œ≤ B ‚ü®$‚ü© id ‚àò id ‚àò f     S.‚âà‚ü® commute Œ≤ f CE.refl ‚ü©
            F‚ÇÅ F f ‚ü®$‚ü© (Œ∑ Œ≤ A ‚ü®$‚ü© id) S.‚âà‚ü® cong (F‚ÇÅ F f) (Œ≤‚âàŒ≥ CE.refl) ‚ü©
            F‚ÇÅ F f ‚ü®$‚ü© (Œ∑ Œ≥ A ‚ü®$‚ü© id) S.‚àé
            where module S where
                    open Setoid (F‚ÇÄ F B) public
                    open SetoidR (F‚ÇÄ F B) public
#+END_SRC

#+latex: \end{minipage}

#+latex: \noindent
Here are a few downsides of not renaming:
#+latex: \vspace{1ex}
1. The type of the function is difficult to comprehend; though it need not be.

   If we declare a few names, the type reads: If ~Œ≤ ‚âà‚ÇÄ Œ≥~ then \newline ~Œ∑ Œ≤ B ‚ü®$‚ü©
   f ‚àò id ‚âà‚ÇÅ F‚ÇÅ F f ‚ü®$‚ü© (Œ∑ Œ≥ A ‚ü®$‚ü© id).~ This is just a naturality condition,
   which are ubiquitous in categroy theory.

   #+latex: \vspace{-2cm}\remark{
   Declare ~_‚âà‚ÇÄ_~ and ~_‚âà‚ÇÅ_~ to be @@latex:{\scriptsize\hbox{@@ ~Setoid._‚âà_ (F‚ÇÄ
   Nat[Hom[C][-,c],F] (F , A))~ @@latex:}}@@ and, respectively,
   #+latex: {\scriptsize
   ~Setoid._‚âà_ (F‚ÇÄ F B)~
   #+latex: }.
   #+latex: }\vspace{1cm}

2. The short proof is difficult to read!

    The repeated terms such as ~Œ∑ Œ≤ B~ and ~Œ∑ Œ≤ A~ could have been renamed with
     mnemoic-names such as ~Œ∑‚ÇÅ, Œ∑‚ÇÇ~ or ~Œ∑‚Çõ, Œ∑‚Çú~.
     #+latex: \vspace{-1cm}\remark{
     The subscripts are for ‚Äòs‚Äôource/1 and ‚Äòt‚Äôarget/2, for a morphism
     \begin{align*}
               &f : \mathsf{source}\, f ‚Üí \mathsf{target}\, f \\
    \text{or } &f : X‚ÇÅ ‚Üí X‚ÇÇ \text{ .}
     \end{align*}
     #+latex: \centerline{‚ãÜ ‚ãÜ ‚ãÜ} }\vspace{1cm}

   The sequence of /f/'s ‚Äú ~F‚ÇÅ F f~ ‚Äù looks strange at a first glance; with the
   alternative suggested naming it just denotes ~mor F f~.
   #+latex: \vspace{-1.5cm}\remark{
   Just an application of a functor's morphism mapping.
   #+latex: }\vspace{1.5cm}

Since names are given a lower priority, one no longer needs to perform renaming.
Instead, one is content with projections. The downside is now there are too many
projections, leaving code difficult to comprehend. Moreover, this leads to
inconsistent renaming.

** Redundancy, Derived Features, and Feature Exclusion
:PROPERTIES:
:CUSTOM_ID: Redundancy-Derived-Features-and-Feature-Exclusion
:END:
<<sec:redundancy_derived_features_feature_exclusion>>
# +latex: \label{sec:redundancy_derived_features_feature_exclusion}
<<sec:examples:redundancy>>
# +latex: \label{sec:examples:redundancy}

 A tenet of software development is not to over-engineer solutions.  For
 example, if we need a notion of untyped composition, we may use
 ~Monoid~. However, at a later stage, we may realise that units are
 inappropriate
 #+begin_margin :width "0.45\\textwidth"
 For instance, if we wish to model finite functions as hashmaps, we need to omit
 the identity functions since they may have infinite domains; and we cannot
 simply enforce a convention, say, to treat empty hashmaps as the identities
 since then we would lose the empty functions. Incidentally, this example, among
 others, led to dropping the identity features from Categories to obtain
 so-called Semigroupoids.
 #+end_margin
 and so we need to drop them to obtain the weaker notion of ~Semigroup~. In weaker
 languages, we could continue to use the monoid interface at the cost of
 ‚Äúthrowing an exception‚Äù whenever the identity is used. However, this breaks the
 /Interface Segregation Principle: Users should not be forced to bother with
 features they are not interested in/ citet:old-design-patterns-solid. A
 prototypical scenario is exposing an expressive interface, possibly with
 redundancies, to users, but providing a minimal self-contained counterpart by
 dropping some features for the sake of efficiency or to act as a ‚Äúsmart
 constructor‚Äù that takes the least amount of data to reconstruct the rich
 interface. Tersely put: One axiomatisation may be ideal for verifying
 instances, whereas an equivalent but possibly longer axiomatisation may be more
 amicable for calculation and computation.

 More concretely, in the Agda-categories library one finds concepts with
 expressive interfaces, with redundant features, prototypically named ~ùí≥~, along
 with their minimal self-contained versions, prototypically named ~ùí≥Helper~.
 #+latex: \vspace{-1cm}\remark{
 In particular, the [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/Core.agda][Category]] type and the [[https://github.com/agda/agda-categories/blob/master/src/Categories/NaturalTransformation/NaturalIsomorphism.agda][natural isomorphism]] type are instances
 of such a pattern.
#+latex: }\vspace{1cm}
 The redundant features are there to make the lives of users easier; e.g.,
 quoting Agda-categories, /We add a symmetric proof of associativity so that the/
 /opposite category of the opposite category is definitionally equal to the
 original category./ To underscore the intent, to the right we have presented a
 minimal setup needed to express the issue. The semigroup definition contains a
 redundant associativity axiom ---which can be obtained from the first one by
 applying symmetry of equality.  This is done purposefully so that the
 ‚Äúopposite, or dual, transformer‚Äù ~_Àò~ is self-inverse on-the-nose; i.e.,
 definitionally rather than propositionally equal.  Definitionally equality does
 not need to be ‚Äòinvoked‚Äô, it is used silently when needed, thereby making the
 redundant setup ‚Äòworth it‚Äô ---see section \ref{sec:propositional-equality} for
 a discussion on equality.

#+latex: \vspace{-4.8cm} $\,$ \hfill \hspace{.95\textwidth} { \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(\LARGE Redundancy can lead to silently used equalities)}}}
 #+ATTR_LATEX: :options fontsize=\large
 #+begin_src agda :tangle op-involutive-on-the-nose.agda :prologue module op-involutive-on-the-nose where \nopen import Notation\n
record Semigroup : Set‚ÇÅ where
  constructor ùíÆ
  field
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    assoc ≥ : ‚àÄ {x y z} ‚Üí     (x ‚®æ y) ‚®æ z
                          ‚â°   x ‚®æ (y ‚®æ z)
    assocÀ° : ‚àÄ {x y z} ‚Üí      x ‚®æ (y ‚®æ z)
                          ‚â°  (x ‚®æ y) ‚®æ z

-- Notice:  assocÀ° ‚âà sym assoc ≥

smart : (C : Set) (_‚®æ_ : C ‚Üí C ‚Üí C)
       (assoc ≥ : ‚àÄ {x y z} ‚Üí  (x ‚®æ y) ‚®æ z
                            ‚â°  x ‚®æ (y ‚®æ z))
       ‚Üí  Semigroup
smart C _‚®æ_ asoc = ùíÆ C _‚®æ_ asoc (sym asoc)

-- The opposite of the opposite
-- is definitionally equal to the original

_Àò : Semigroup ‚Üí Semigroup
(ùíÆ car _‚®æ_ assoc ≥ assocÀ°) Àò
    =  ùíÆ car (Œª b a ‚Üí a ‚®æ b)  assocÀ° assoc ≥

ÀòÀò‚âàid : ‚àÄ {S} ‚Üí (S Àò) Àò ‚â° S
ÀòÀò‚âàid = refl
 #+end_src
#+latex: }}

#+latex: \vspace{-4cm}\begin{mybox}{On-the-nose Redundancy Design Pattern (Agda-Categories)}
Include redundant features if they allow certain common constructions to be
 definitionally equal, thereby requiring no overhead to use such an
 equality. Then, provide a smart constructor so users are not forced to produce
 the redundant features manually.
#+latex: \end{mybox}

 Incidentally, since this is not a library method, inconsistencies
 #+begin_margin :width "0.45\\textwidth"
 In particular, in the ~ùí≥~ and ~ùí≥Helper~ naming scheme: The ~NaturalIsomorphism~ type
 has ~NIHelper~ as its minimised version, and the type of [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/Monoidal/Symmetric.agda][symmetric monoidal
 categories]] is oddly called ~Symmetric'~ with its helper named ~Symmetric~.
 #+end_margin
 are bound to arise. Such issues could be reduced, if not avoided, if library
 methods could have been used instead of manually implementing design patterns.

 It is interesting to note that duality forming operators, such as ~_Àò~ above, are
 a design pattern themselves. How? In the setting of algebraic structures, one
 picks an operation to have its arguments flipped, then systematically ‚Äòflips‚Äô
 all proof obligations via a user-provided symmetry operator. We shall return to
 this as a library method in a future section.

 # Since names are given a low priority, the brading operation is simply called ~B~!
 # A symbol closer to the standard model, inverses ~_‚Åª¬π~, such as ~_Àò~ may have been
 # more suggestive.

 Another example of purposefully keeping redundant features is for the sake of
 efficiency; e.g., quoting RATH-Agda (section 15.13),
 #+latex: \emph{
 For division semi-allegories, even though right residuals, restricted
 residuals, and symmetric quotients all can be derived from left residuals, we
 still assume them all as primitive here, since this produces more readable
 goals, and also makes connecting to optimised implementations easier.
  #+latex: }
 For instance, the above semigroup type could have been augmented with an
 ordering if we view ~_‚®æ_~ as a meet-operation. Instead, we could lift such a
 derived operation as a primitive field, in case the user has a better
 implementation.

#+latex: \vspace{-5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Simulating Default Implementations with Smart Constructors)}}}
 #+ATTR_LATEX: :options fontsize=\large
  #+begin_src agda :tangle op-involutive-on-the-nose.agda
record Order (S : Semigroup) : Set‚ÇÅ where
  constructor ùí™
  open Semigroup S public
  field
    _‚äë_    : Carrier ‚Üí Carrier ‚Üí Set
    ‚äë-def  : ‚àÄ {x y} ‚Üí     (x ‚äë y)
                        ‚â°  (x ‚®æ y ‚â° x)

  {- Results about _‚®æ_ and _‚äë_ here ‚Ä¶ -}

defaultOrder : ‚àÄ S ‚Üí Order S
defaultOrder S = let open Semigroup S in
                 ùí™ (Œª x y ‚Üí  x ‚®æ y ‚â° x)
                    refl
 #+end_src
#+latex: }} \vspace{-1cm}

#+latex: \begin{mybox}{ Efficient Redundancy Design Pattern (RATH-Agda section 17.1)}
 To enable efficient implementations, replace derived operators with additional
 fields for them and for the equalities that would otherwise be used as their
 definitions. Then, provide instances of these fields as derived operators, so
 that in the absence of more efficient implementations, these default
 implementations can be used with negligible penalty over a development that
 defines these operators as derived in the first place.
#+latex: \end{mybox}

 # Also
 # which RATH-Agda does a number of times ---e.g., due to the converse
 # operator, not only are division operators are inter-definable but
 # symmetric-quotient congruence laws are derivable.

** Extensions
:PROPERTIES:
:CUSTOM_ID: Extensions
:END:

<<sec:examples:extensions>>
# +latex: \label{sec:examples:extensions}

   In our previous discussion, we needed to drop features from ~Monoid~ to get
   ~Semigroup~. However, excluding the unit-element from the monoid also required
   excluding the identity laws. More generally, all features reachable, via
   occurrence relationships, must be dropped when a particular feature is
   dropped. In some sense, a generated graph of features needs to be ‚Äúripped out‚Äù
   from the starting type, and the generated graph may be the whole type. As
   such, in general, we do not know if the resulting type even has any features.

   Instead of ‚Äòripping things out‚Äô, in an ideal world, it may be preferable to
   begin with a minimal interface then /extend/ it with features as
   necessary. E.g., begin with ~Semigroup~ then add orthogonal features until
   ~Monoid~ is reached. Extensions are also known as /subclassing/ or /inheritance/.


#+begin_src plantuml :file example_hierarchy.png :exports none
skinparam defaultTextAlignment center

[*] -> Empty
Empty -> Type
Type -down-> Pointed
Type -> Magma
Magma -> Semigroup
Pointed   -down-> Pointed_Semigroup
Semigroup -down-> Pointed_Semigroup
Pointed_Semigroup -down-> Left_Unital_Semigroup
Pointed_Semigroup -down-> Right_Unital_Semigroup
Left_Unital_Semigroup -down-> Monoid
Right_Unital_Semigroup -down-> Monoid

Type : Carrier
Pointed : Carrier, point
Magma : Carrier, binary_op
Semigroup : Carrier, binary_op, associativity

Pointed_Semigroup : Carrier, point, binary_op, associativity
Left_Unital_Semigroup : ‚ü™inherit above‚ü´, left_identity_law
Right_Unital_Semigroup : ‚ü™inherit above‚ü´, right_identity_law

Monoid : Carrier, point, binary_op, associativity, identity_laws

center footer  Possible hierarchy leading to Monoid
#+end_src

#+latex: \vspace{-3.5cm} $\,$ \hfill \hspace{.95\textwidth}
#+latex: \includegraphics[width=0.65\textwidth,height=\textheight,keepaspectratio]{images/example_hierarchy.png}
#+latex: \vspace{-4.5cm}

:NO_mermaid:
 #+BEGIN_SRC NOmermaid :file semigroup-to-monoid.png :theme default :background-color transparent  :tangle no :tangle no :exports results
graph LR                          %% A ‚ÄúL‚Äùeft to ‚ÄúR‚Äùight graph

Semigroup[<strong>Semigroup</strong><br>carrier <br> binary operation <br> associativity law ]
PointedSemigroup[<strong>PointedSemigroup</strong><br>carrier <br> binary operation <br> +<i>unit-element</i> <br> associativity law ]
LeftUnitalSemigroup[<strong>LeftUnitalSemigroup</strong><br>carrier <br> binary operation <br> unit-element <br> +<i>left-identity law</i> <br> associativity law ]
RightUnitalSemigroup[<strong>RightUnitalSemigroup</strong><br>carrier <br> binary operation <br> unit-element <br> +<i>right-identity law</i> <br> associativity law ]
Monoid[<strong>Monoid</strong><br>carrier <br> binary operation <br> unit-element <br> +<i>left-identity law <br> +right-identity law</i> <br> associativity law ]

Semigroup --> PointedSemigroup

PointedSemigroup --> LeftUnitalSemigroup
PointedSemigroup --> RightUnitalSemigroup

LeftUnitalSemigroup --> Monoid
RightUnitalSemigroup --> Monoid
 #+END_SRC

 #+RESULTS:
 [[file:images/semigroup-to-monoid.png]]
:End:

 The libraries mentioned thus far generally implement extensions in this way. By
 way of example, here is how monoids could be built directly from semigroups
 along a particular path in the above hierarchy.

 {{{code(Extending Semigroup to Obtain Monoid)}}}
 #+begin_src agda :tangle semigroups_to_monoids.agda :prologue "module semigroups_to_monoids where \nopen import Notation\n"
record Semigroup : Set‚ÇÅ where
  field
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    assoc  : ‚àÄ {x y z} ‚Üí  (x ‚®æ y) ‚®æ z  ‚â°  x ‚®æ (y ‚®æ z)

record PointedSemigroup : Set‚ÇÅ where
  field semigroup : Semigroup
  open  Semigroup semigroup public -- (‚òÖ)
  field Id : Carrier

record LeftUnitalSemigroup : Set‚ÇÅ where
  field pointedSemigroup : PointedSemigroup
  open  PointedSemigroup pointedSemigroup public -- (‚òÖ)
  field leftId : ‚àÄ {x} ‚Üí Id ‚®æ x ‚â° x

record Monoid : Set‚ÇÅ where
  field leftUnitalSemigroup : LeftUnitalSemigroup
  open LeftUnitalSemigroup leftUnitalSemigroup public -- (‚òÖ)
  field rightId : ‚àÄ {x} ‚Üí x ‚®æ Id ‚â° x

open Monoid  -- (‚òÖ, *)

neato : ‚àÄ {M} ‚Üí Carrier M ‚Üí Carrier M ‚Üí Carrier M
neato {M} = _‚®æ_ M -- (*); Possible due to all of the (‚òÖ) above
 #+end_src

#+latex: \vspace{-6cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Extensions are not flattened inheritance)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+begin_src agda :tangle semigroups_to_monoids.agda
woah : Monoid
woah = record
     { leftUnitalSemigroup
       = record { pointedSemigroup
                  = record { semigroup
                             = record
                               { Carrier = {!!}
                               ; _‚®æ_     = {!!}
                               ; assoc   = {!!}
                               } -- Nesting level 3
                           ; Id = {!!}
                           } -- Nesting level 2
                 ; leftId = {!!}
                 } -- Nesting level 1
       ; rightId = {!!}
       }  -- Nesting level 0
#+end_src
#+latex: }} \vspace{1cm}

 Notice how we accessed the binary operation ~_‚®æ_~ feature from ~Semigroup~ as if it
 were a native feature of ~Monoid~. Unfortunately, ~_‚®æ_~ is only /superficially
 native/ to ~Monoid~ ---any actual instance, such as src_emacs-lisp[:exports
 code]{woah} to the right, needs to define the binary operation in a ~Semigroup~
 instance first, which lives in a ~PointedSemigroup~ instance, which lives in a
 ~LeftUnitalSemigroup~ instance.

#+latex: \vspace{-1cm}\remark{
  It is interesting to note that diamond hierarchies cannot be trivially
  eliminated when providing fine-grained hierarchies. As such, we make no rash
  decisions regarding limiting them ---and completely forego the unreasonable
  possibility of forbidding them.
#+latex: }\vspace{0cm}

  This nesting scenario happens rather often, in one guise or another. The
  amount of syntactic noise required to produce a simple instantiation is
  unreasonable: /One should not be forced to work through the hierarchy if it
  provides no immediate benefit./
  # It is to be noted that this issue does not
  # generally apply to implementations of object-oriented class supporting
  # multiple interfaces.
  # or rephrasing the hierarchy to be horizontal and unrelated,
  # so each piece is a typeclass, and we then use multiple class constraints.
  #
  # What about OCaml, F#, F*?

  Even worse, pragmatically speaking, to access a field deep down in a nested
  structure results in overtly lengthy and verbose names; as shown below.
  Indeed, in the above example, the monoid operation lives at the top-most
  level, we would need to access all the intermediary levels to simply refer to
  it. Such verbose invocations would immediately give way to helper functions to
  refer to fields lower in the hierarchy; yet another opportunity for
  boilerplate to leak in.
{{{code(Extensions require deep ---‚Äòstaircase‚Äô--- projections )}}}
#+begin_src agda :tangle semigroups_to_monoids.agda
-- Without the (‚òÖ) ‚Äúpublic‚Äù declarations,
-- projections are difficult!
carrier : Monoid ‚Üí Set
carrier M = Semigroup.Carrier
              (PointedSemigroup.semigroup
                (LeftUnitalSemigroup.pointedSemigroup
                  (Monoid.leftUnitalSemigroup M)))
 #+end_src

# \remark {Projecting several levels down to get to \texttt{Carrier}}

# Instead of the above ‚Äòstaircase‚Äô, the following figure presents an alternative
# view of how extensions require deep projections.
#+latex: \vspace{-3.5cm} $\,$ \hfill \hspace{1.1\textwidth} { \maxsizebox{.3\textwidth}{\textheight}{
 #+begin_export latex
\begin{tikzpicture}
\coordinate (O) at (0,0);
\draw[fill=red!30] (O) circle (2.8);
\draw[fill=green!40] (O) circle (2);
\draw[fill=yellow!70] (O) circle (1.2);
\draw[fill=blue!45] (O) circle (0.4);

\draw[decoration={text along path,reverse path,text align={align=center},text={Carrier}},decorate] (0.5,-.6) arc (0:180:0.5);
\draw[decoration={text along path,reverse path,text align={align=center},text={Semigroup}},decorate] (0.5,0.2) arc (0:180:0.5);
\draw[decoration={text along path,reverse path,text align={align=center},text={Pointed Semigroup}},decorate] (1.3,0.1) arc (0:180:1.3);
\draw[decoration={text along path,reverse path,text align={align=center},text={Left Unital Semigroup}},decorate] (2.1,0.2) arc (0:180:2.1);
\draw[decoration={text along path,reverse path,text align={align=center},text={Monoid}},decorate] (2.9,0) arc (0:180:2.9);
\end{tikzpicture}
#+end_export
#+latex: }} \vspace{-0.5cm}

 #+latex: \begin{mybox}{Extension Design Pattern}
To extend a structure ~ùí≥~ by new features ~f‚ÇÄ, ‚Ä¶, f‚Çô~ which may mention features of
 ~ùí≥~, make a new structure ~ùí¥~ with fields for ~ùí≥, f‚ÇÄ, ‚Ä¶, f‚Çô~. Then publicly open ~ùí≥~ in
 this new structure =(‚òÖ)= so that the features of ~ùí≥~ are visible directly from ~ùí¥~ to
 all users ---see lines marked =(*)= above.
#+latex: \end{mybox}
#+latex: \vspace{-3.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Extension Design Pattern Prototype)}}}
 #+ATTR_LATEX: :options fontsize=\Large
 #+begin_src agda :tangle semigroups_to_monoids.agda
record ùí¥ : Set‚ÇÅ where
  field ùìç : ùí≥
  open  ùí≥ ùìç public -- (‚òÖ)
  field f‚ÇÄ : ‚ãØ
    ‚ãÆ
  field f‚Çô : ‚ãØ
#+end_src
#+latex: }} \vspace{0cm}

 While library designers may be content to build ~Monoid~ out of ~Semigroup~, users
 should not be forced to learn about how the hierarchy was built. Even worse,
 when the library designers decide to incorporate, say, ~RightUnitalSemigroup~
 instead of the left unital form, then all users' code would break.

 Instead, it would be preferable to have a ‚Äòflattened‚Äô presentation for the
 users that ‚Äúdoes not leak out implementation
 details‚Äù. @@latex:\iffalse\remark{We shall return to this in a future
 section.}\fi@@ That is, a ‚Äòflattened‚Äô hierarchy may be /seen/ as a single
 package, consisting of the fields throughout the hierarchy, possibly with
 default implementations, yet still be able to view the resulting package at
 base levels in the hierarchy ---c.f., section
 ref:sec:examples:redundancy. Another benefit of this approach is that it allows
 users to utilise the package without consideration of how the hierarchy was
 formed, thereby providing library designers with the freedom to alter it in the
 future.


 #+latex: \vspace{-7cm}\remark{
  A more common example from programming is that of providing monad instances in
  Haskell. Most often users want to avoid tedious case analysis or prefer a
  sequential-style approach to producing programs, so they want to furnish a
  type constructor with a monad instance in order to utilise Haskell's
  src_haskell[:exports code]{do}-notation.  Unfortunately, this requires an
  applicative instances, which in turn requires a functor instance. However,
  providing the return-and-bind interface for monads allows us to obtain functor
  and applicative instances. Consequently, many users simply provide local names
  for the return-and-bind interface then use that to provide the default
  implementations for the other interfaces. In this scenario, /the standard
  approach is side-stepped/ by manually carrying out a mechanical and tedious set
  of steps that not only wastes time but obscures the generic process and could
  be error-prone.
#+latex: }\vspace{6cm}

** Conclusion
:PROPERTIES:
:CUSTOM_ID: Examples-Conclusion
:END:

After ‚Äòlibrary spelunking‚Äô, we are now in a position to summarise the problems
encountered, when using existing modules systems, that need a solution.
From our learned lessons, we can then pinpoint a necessary feature of an
ideal module system for dependently-typed languages.

*** Lessons Learned
:PROPERTIES:
:CUSTOM_ID: Lessons-Learned
:END:

<<sec:DTL_design_patterns>>
# +latex: \label{sec:DTL_design_patterns}

   Systems tend to come with a pre-defined set of operations for built-in
   constructs; the user is left to utilise third-party pre-processing tools, for
   example, to provide extra-linguistic support for common repetitive scenarios
   they encounter. Let's consider two concrete examples.

   *Example (1).* A large number of proofs can be discharged by merely pattern
   matching on variables ---this works since the case analysis reduces the proof
   goal into a trivial reflexitivity obligation, for example. The number of
   cases can quickly grow thereby taking up space, which is unfortunate since
   the proof has very little to offer besides verifying the claim. In such
   cases, a pre-process, perhaps an ‚Äúeditor tactic‚Äù, could be utilised to
   produce the proof in an auxiliary file, and reference it in the current file.
   #+latex: \vspace{-1.5cm}\remark{
That sounds like a terrific idea! We do it in the next chapter ;-)
#+latex: }\vspace{1.5cm}

   *Example (2).* Perhaps more common is the renaming of package contents, by
   hand.  For example, when a notion of preorder is defined with a relation named
   ~_‚â§_~, one may rename it and all references to it by, say, ~_‚äë_~. Again, a
   pre-processor or editor-tactic could be utilised; yet many simply perform the
   re-write by hand.
   #+latex: \vspace{-0.5cm}\remark{
   ‚ÄúBy hand‚Äù is tedious, error prone, and obscures the generic rewriting method!
   #+latex: }\vspace{.5cm}

   It would be desirable to
   #+latex: \emph{
   allow packages to be treated as first-class concepts that could be acted
   upon, in order to avoid third-party tools that obscure generic operations and
   leave them out of reach for the powerful typechecker of a dependently typed
   system.
   #+latex: }
   Below is a summary of the design patterns discussed in this chapter, using
   monoids as the prototypical structure. Some patterns we did not cover, as
   they will be covered in future sections.

#+latex: \vspace{-2cm}\remark{
   There are many more design patterns in dependently-typed programming. Since
   grouping mechanisms are our topic, we have only presented those involving
   organising data.
#+latex: }\vspace{2cm}

 # #  COMMENT ** Summary of Some Design Patterns in Dependently-Typed Programming :ignore:
 #    :PROPERTIES:
 #    :CUSTOM_ID: design-patterns
 #    :END:
 # #
 # #+BEGIN_SRC mermaid  :file patterns.png :theme forest :background-color transparent

:NO_mermaid:
#+BEGIN_SRC NOmermaid :file patterns.png :theme forest :exports none :noeval
graph LR %% LR and TD are both also good!

%% A(<h1><br><hr> Carrier : Set <br> _‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier <br> Id : Carrier</h1>)
A(<h1><hr> carrier <br> binary operation <br> point <br> left-identity law <br> right-identity law <br> associativity law</h1>)
B(<h1>carrier <br> binary operation <br> point <br><hr> left-identity law <br> right-identity law <br> associativity law</h1>)
C(<h1>carrier <br><hr> binary operation <br> point <br> left-identity law <br> right-identity law <br> associativity law</h1>)

D{<h1><hr> <pre>Branch <br>Nil </pre></h1>}               %% Using verbatim environment
E{<h1>Variables <br><hr> <pre>Embed <br>Branch <br>Nil </pre></h1>} %% Using verbatim environment
F((<h1><hr> &ensp;carrier <br> &ensp;binary operation <br> &ensp;point</h1>))

A-. <h1>Predicate  &ensp;<br></h1> .->B
B-. <h1>Œ£ Padding  &ensp;<br></h1>.->A
A-. <h1>Typeclass  &ensp;<br></h1> .-> C
C-. <h1>Œ£ Padding &ensp;<br></h1> .-> A

A-. <h1>Closed Termtype  &ensp;<br></h1> .-> D
D-. <h1>Interpreter &ensp;<br></h1> .-> A
A-. <h1>Open Termtype &ensp;<br></h1> .-> E
E-. <h1>Interpreter  &ensp;<br></h1> .-> C
E-. <h1>Setoid &ensp;<br></h1> .-> A
A-. <h1>Signature &ensp;<br></h1> .-> F
E-- <h1>Instance  &ensp;<br></h1> --> F

A-. <h1>Renaming &ensp;<br></h1> .-> R
R-. <h1>Renaming &ensp;<br></h1> .-> A
R(<h1><hr> universe of discourse <br> composition <br> unit <br> left unital <br> right unital <br> parenthesis shift</h1>)

A-- <h1>Theorem Proving &ensp;<br></h1> -->A

E-- <h1>Simplifier  &ensp;<br></h1> -->E
E-- <h1>Metaprogramming  &ensp;<br></h1> -->E

UA> <h1>Universal <br> Algebra</h1> ]

A-. <h1>Œª Homomorphism &nbsp;<br> Œª Kernel &nbsp;<br> Œª Products &nbsp;<br> Œª FOL termtypes &nbsp;<br> Œª etc</h1> .-> UA
C-. <h1> Œª Products &nbsp;<br> Œª Substructure &nbsp;<br> Œª etc</h1> .-> UA
UA-. <h1>Œª Pushouts / Pullbacks &nbsp;<br> Œª Extensions / Exclusions &nbsp;<br> Œª Duality / Views &nbsp;<br> Œª etc</h1> .-> UA

subgraph  %% A subgraph environment places the legend in the top left, which is better than it being in the bottom somewhere.
Legend[<h1><center>Legend</center>0. Parameters occur above the waist line <br> 1. Fields occur below the waist line <br> 2. Dashed lines are design patterns</h1> ]
end
   #+END_SRC
:END:

#+LATEX_HEADER: \usepackage{placeins}
#+latex: \nomargins
#+begin_export latex
\begin{figure*}[h]
\centering
 \makebox[\textwidth]{\includegraphics[width=.9\paperwidth, height=.75\paperheight]{images/patterns.png}}
\caption{PL Research is about getting free stuff: From the left-most node, we can get a lot!}
\end{figure*}
#+end_export
# +latex: \FloatBarrier
# The FloatBarrier stops floats (figures are floats) from jumping over them. I
# will need to look into passing [tbh] options to figures from org mode further.
#+latex: \yesmargins

:Useful_remarks:
   #+latex: \noindent
   Remarks:
  #+latex: \vspace{-1em}
   0. It is important to note that the ~termtype~ constructions could also be
      co-inductive, thereby yielding possibly infinitely branching syntax-trees.

      - In the ‚Äúsimplify‚Äù pattern, one could use axioms as rewrite rules.

   1. It is more convenient to restrict a carrier or to form products along carriers using the typeclass version.

   2. As discussed earlier, the name /typeclass/ is justified not only by the fact
      that this is the shape used by typeclasses in Haskell and Coq, but also that
      instance search for such records is supported in Agda by using the ~instance~
      keyword.
:End:

*** One-Item Checklist for a Candidate Solution
:PROPERTIES:
:CUSTOM_ID: One-Item-Checklist-for-a-Candidate-Solution
:END:

   # WK: This section is actually good! ;-)

   An adequate module system for dependently-typed languages should make use of
   dependent-types as much as possible. As such, there is essentially one and
   only one primary goal for a module system to be considered reasonable for
   dependently-typed languages: /Needless distinctions should be eliminated as
   much as possible./

   The ‚Äúwrite once, instantiate many‚Äù attitude is well-promoted in functional
   communities predominately for /functions/, but we will take this approach to
   modules as well, beyond the features of, e.g., SML functors.
   With one package declaration, one should be able to mechanically
   derive data, record, typeclass, product, sum formulations, among many others.
   All operations on the generic package then should also apply to the particular
   package instantiations.

   This one goal for a reasonable solution has a number of important and difficult
   subgoals. The resulting system should be well-defined with a coherent semantic
   underpinning ---possibly being a conservative extension---; it should support
   the elementary uses of pedestrian module systems; the algorithms utilised need
   to be proven correct with a mechanical proof assistant, considerations for
   efficiency cannot be dismissed if the system is to be usable; the interface for
   modules should be as minimal as possible, and, finally, a large number of
   existing use-cases must be rendered tersely using the resulting system without
   jeopardising runtime performance in order to demonstrate its success.
   #
   # At least a convincing case must be made that overhead can be
   # ``compiled away''.

  :Hide:
   During the research stage of the thesis, some of the sub-goals may be altered
   radically, dismissed altogether, or new ones brought forth due to implementation
   considerations. However, the one main goal will remain unchanged as it is how
   we have chosen to measure the minimal adequacy for a module system for rich
   settings that include dependent-types.
  :End:

*** COMMENT Why (ASTs) syntax                                  :Maybe_Delete:
:PROPERTIES:
:CUSTOM_ID: COMMENT-Why-ASTs-syntax
:END:
      The archetype for records and termtypes ---algebraic data types--- are
      monoids. They describe untyped compositional structures, such as programs in
      dynamically type-checked language. In turn, their termtype is linked lists
      which reify a monoid value ---such as a program--- as a sequence of values
      ---i.e., a list of language instructions--- which ‚Äòevaluate‚Äô to the original
      value. The shift to syntax gives rise to evaluators, optimisers, and  constrained
      recursion-induction principles.
*** COMMENT Excerption
:PROPERTIES:
:CUSTOM_ID: COMMENT-Excerption
:END:

  # #+latex: \noindent
  # *Excerption*
  # #
  # #+latex: \noindent
   In order to produce reusable components, theories ---i.e., packages--- are formed
   from existing theories by adding only one new concept at a time. Such an approach
   reduces the possibility of missing a useful structure in the hierarchy, as well
   as provides tremendous generality ---operations can be rendered using the minimal
   interface required rather than one that is overly expressive. This is a common
   scheme when formalising mathematics citet:typeclasses_for_maths,coq_cat_experiences.

   Unfortunately, a common scenario is when one wants to /instantiate/ such a deeply
   nested theory ---as was the case in section ref:sec:examples:extensions for
   fine-grained hierarchy of monoids.
* nomargins                                                          :ignore:
#+latex: \nomargins
* Contributions of the Thesis

<<sec:research_problem_statement>>
# +latex: \label{sec:research_problem_statement}
#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

With the necessary background covered in Chapter
\ref{sec:packages_and_their_parts} and motivating examples discussed in Chapter
\ref{sec:examples_from_the_wild}, we are in a position to discuss the
contributions of this thesis in a technical fashion.  The first section
discusses the primary problem the thesis aims to address.  The second section
outlines the objectives of this thesis and discusses the methodology used to
achieve those objectives.  The third, and final, section discusses the outcomes
of the thesis effort.

Since ‚Äògrammars‚Äô and ‚Äòalgebraic datatypes‚Äô are just ùí≤ell-founded tress, we
abbreviate such terms to ‚Äòùí≤-types‚Äô. Technically, every inductive datatype is
expressible as a ùí≤-type ---a discussion we leave for Chapter
\ref{sec:Pi-Sigma-W}.


# +latex: \begin{fullwidth}
{{{localtoc}}}
# +latex: \end{fullwidth}


** Problem Statement

<<sec:PF:problem_statement>>
# +latex: \label{sec:PF:problem_statement}

Use of dependent types to express modularity was
first proposed by MacQueen\footcitet{dtls_give_modules}.
Nevertheless, first-class module systems for dependently-typed languages are currently poorly
/supported/. Modules ùí≥ consisting of functions symbols, properties, and derived
results are currently presented in the form ~Isùí≥~: A module parameterised by
function symbols and exposing derived results possibly with further,
uninstantiated, proof obligations ---that is, it is of the shape Œ† ∑Œ£, below,
having parameters $p·µ¢$ at the type level and fields $p_{w + i}$ at the body
level.  \[ Œ† ∑Œ£ \;=\; Œ†\, p‚ÇÅ : œÑ‚ÇÅ ‚Ä¢ Œ†\, p‚ÇÇ : œÑ‚ÇÇ ‚Ä¢ ‚ãØ ‚Ä¢ Œ†\, p_w : œÑ_w ‚Ä¢ Œ£\, p_{w +
1} : œÑ'_{w + 1} ‚Ä¢ ‚ãØ ‚Ä¢ Œ£\, f : œÑ'_n ‚Ä¢ body \] This is understandable: Function
symbols generally vary more often than proof obligations.  (This is discussed in
detail in Section ref:sec:examples:IsX and rendered in concrete Agda code in
Section ref:sec:problems.)  However, when users do not yet have the necessary
parameters =p·µ¢=, they need to use a curried (or /bundled/) form of the module and so
library developers also provide a module =ùí≥= which packs up the parameters as
necessary fields within the module; i.e., ùí≥ has the shape =Œ†‚Å∞Œ£= by ‚Äúpushing down‚Äù
the parameters into the record body.  Unfortunately, there is a whole spectrum
of modules $ùí≥_w$ that is missing: These are the module ùí≥ where only ùìå-many of
the original parameters are exposed with the remaining being packed-away into
the module body; i.e., having the shape Œ† ∑Œ£ for $0 ‚â§ w ‚â§ n$ ---in subsequent
chapters, we refer to ùìå as ‚Äúthe waist‚Äù of a package former.  It is tedious and
error-prone to form all the $ùí≥_w$ by hand; such ‚Äòunbundling‚Äô should be
mechanically achievable from the completely bundled form ~ùí≥~. A similar issue
happens when one wants to /describe a computation/ using module ùí≥, then its
function symbols need to have associated syntactic counterparts ---i.e., we want
to interpret ùí≥ as a ùí≤-type instead of a Œ†‚ÅøŒ£-type ---; the tedium is then
compounded if one considers the family $ùí≥_w$.  Finally, instead of combinations
of Œ†,Œ£,ùí≤, a user may need to treat a module ùí≥ as an arbitrary container
type\footcitet{DBLP:journals/jfp/AltenkirchGHMM15}; in which case, they will
likely have to create it by hand.

# Finally, if the user decides that a /derived/ definition should be /abstracted/ away
# as a parameter, let-clause or field.

#+latex: \begin{tcolorbox}[colframe=red!75!black]
This thesis aims to enhance the understanding of modules systems within
dependently-typed languages by developing an in-language framework for unifying
disparate presentations of what are essentially the same module.  Moreover, the
framework will be constructed with /practicality/ in mind so that the end-result
is not an unusable theoretical claim.
#+latex: \end{tcolorbox}

** Objectives and Methodology

To reach a framework for the modelling of module systems for DTLs,
this thesis sets a number of objectives which are described below.

*** *Objective 1: Modelling Module Systems*
     :PROPERTIES:
     :UNNUMBERED: t
     :END:

   #+latex: \vspace{1ex}

   The first objective is to actually develop a framework that models
   module systems ---grouping mechanisms--- within DTLs.
   The resulting framework should capture at least
   the expected features:
     1. Namespacing, or definitional extensions
        @@latex: \hfill@@ ---a combination of Œ†- and Œ£-types
     2. Opaque fields, or parameters
        @@latex: \hfill@@ ---Œ†-types
     3. Constructors, or uninterpreted identifiers
        @@latex: \hfill@@ ---ùí≤-types
   Moreover, the resulting framework should be /practical/ so as to be a
   usable experimentation-site for further research or immediate application
   ---at least, in DTLs. In this thesis, we present two /declarative/ approaches
   using meta-programming and =do=-notation.

*** *Objective 2: Support Unexpected Notions of Module*
     :PROPERTIES:
     :UNNUMBERED: t
     :END:
     #+latex: \vspace{1ex}

The second objective is to make the resulting framework /extensible/.  Users
should be able to form new
#+latex: exotic\FOOTNOTE{
‚ÄúExotic‚Äù in the sense that traditional module systems would not, or
could not, support such constructions. For instance, some systems allow users to
get the ‚Äúshared structure‚Äù of two modules ---e.g., for the purposes of finding a
common abstract interface between them--- and it does so considering /names/ of
symbols; i.e., an name-based intersection is formed. However, different contexts
necessitate names meaningful in that context and so it would be ideal to get
the shared structure by /considering/ a user-provided association of ‚Äúsame thing,
but different name‚Äù ---e.g., recall that a signature has ‚Äúsorts‚Äù whereas a graph
has ‚Äúvertices‚Äù, they are the ‚Äòsame thing, but have different names‚Äô.
#+latex: }
notions of grouping mechanisms /within/ a DTL rather than ‚Äòstepping outside‚Äô of it
and altering its interpreter ---which may be a code implementation or an
abstract rewrite-system.  Ideally, users would be able to formulate arbitrary
constructions from Universal Algebra and Category Theory.  For example, given a
theory ---a notion of grouping--- one would like to ‚Äòglue‚Äô two ‚Äòinstances‚Äô along
an ‚Äòidentified common interface‚Äô. More concretely, we may want to treat some
parameters as ‚Äòthe same‚Äô and others as ‚Äòdifferent‚Äô to obtain a new module that
has copies of some parameters but not others.  Moreover, users should be able to
mechanically produce the necessary morphisms to make this construction into a
pushout.  Likewise, we would expect products, unions, intersections, and
substructures of theories ---when possible, and then to be constructed by
users. In this thesis, we only want to provide a fixed set of meta-primitives
from which usual and (un)conventional notions of grouping may be defined.

*** *Objective 3: Provide a Semantics*
     :PROPERTIES:
     :UNNUMBERED: t
     :END:

    :PROPERTIES:
    :UNNUMBERED: t
    :END:

    #+latex: \vspace{1ex}

    The third objective is to provide a /concrete/ semantics for the resulting
    framework ---in contrast to the /abstract/ generalised signatures semantics
    outlined earlier in this chapter.  We propose to implement the framework in
    the dependently-typed functional programming language Agda, thereby
    automatically furnishing our syntactic constructs with semantics as Agda
    functions and types.  This has the pleasant side-effect of making the
    framework accessible to future researchers for experimentation.

** Contributions
  :PROPERTIES:
  :CUSTOM_ID: 1-5j
  :END:
<<sec:contributions>>
# +latex: \label{sec:contributions}

The fulfilment of the objectives of this thesis leads to the following
contributions.

1. The ability to model module systems /for/ DTLs /within/ DTLs
2. The ability to arbitrarily /extend/ such systems by users at a high-level
3. Demonstrate that there is an expressive yet minimal set of module
   meta-primitives which allow common module constructions to be defined
4. Demonstrate that relationships between modules can also be /mechanically/
   generated.
   - In particular, if module ‚Ñ¨ is obtained by applying a user-defined
     ‚Äòvariational‚Äô to module ùíú, then the user could also enrich the child module
     ‚Ñ¨ with morphisms that describe its relationships to the parent module ùíú.
   - E.g., if ‚Ñ¨ is an extension of ùíú, then we may have a ‚Äúforgetful mapping‚Äù
     that drops the new components; or if ‚Ñ¨ is a ‚Äòminimal‚Äô rendition of the
     theory ùíú, then we have a ‚Äúsmart constructor‚Äù that forms the rich ùíú by only
     asking the few ‚Ñ¨ components of the user.
5. Demonstrate that there is a /practical/ implementation of such a framework
6. Solve the unbundling problem: The ability to ‚Äòunbundle‚Äô module fields
   as if they were parameters ‚Äòon the fly‚Äô
   - I.e., to transform a type of the shape Œ† ∑Œ£ into $Œ†^{w+k}Œ£$, for $k ‚â• 0$,
     such that the resulting type is /as practical and as usable/ as the original
7. Bring algebraic data types ---i.e., /termtypes/ or /ùí≤-types/--- under the
   umbrella of grouping mechanisms: An ADT is just a context whose symbols
   target the ADT ‚Äòcarrier‚Äô and are not otherwise interpreted
   - In particular, both an ADT and a record can be obtained from
     a /single/ context declaration.
8. Show that common data-structures are /mechanically/ the (free) termtypes of
   common modules.
   - In particular, lists arise from modules modelling collections
     whereas nullables ---the =Maybe= monad--- arises from modules
     modelling pointed structures.
   - Moreover, such termtypes also have a /practical/ interface.
9. Finally, the resulting framework is /mostly type-theory agnostic/: The target
   setting is DTLs but we only assume the barebones as discussed in
   \ref{sec:language_agnostic}; if users drop parts of that theory, then /only/
   some parts of the framework will no longer apply.
   - For instance, in DTLs without a fixed-point functor the framework still
     ‚Äòapplies‚Äô, but can no longer be used to provide arbitrary algebraic data
     types from contexts. Instead, one could settle for the safer ùí≤-types, if
     possible.

* nomargins                                                          :ignore:
#+latex: \nomargins
* A Œ†-Œ£-ùí≤ View of Packaging Systems

<<sec:Pi-Sigma-W>>
# +latex: \label{sec:Pi-Sigma-W}
#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

#+latex: \def\LET{\,\mathsf{let}\,}
#+latex: \def\IN{\,\mathsf{in}\,}
#+latex: \def\CASE{\,\mathsf{case}\,}
#+latex: \def\OF{\,\mathsf{of}\,}
#+latex: \def\Type{\mathsf{Type}}
#+latex: \def\elim{\mathsf{elim}}
#+latex: \def\refl{\mathsf{refl}}
#+latex: \def\child{\mathsf{child}}
#+latex: \def\true{\mathsf{true}}
#+latex: \def\false{\mathsf{false}}
#+latex: \def\Fin{\mathsf{Fin}\,}
#+latex: \def\zero{\mathsf{zero}}
#+latex: \def\suc{\mathsf{suc}\,}

#+latex: \def\length{\mathsf{length}\,}
#+latex: \def\Term{\mathsf{Term}}


# +latex: \begin{tcolorbox}[title=Demonstrate the interdefinability of structuring mechanisms]
The thesis is that contexts serve as a unified notion of packaging.

As such, in this chapter, in section \ref{sec:module_interdefinability}, we
demonstrate three possible ways to define monoids in Agda and argue their
equivalence; thereby, showing that structuring mechanisms are in effect
accomplishing the same goal in different ways: They package data along with a
particular /usage interface/.  As such, it is not unreasonable to seek out a
unified notion of *package* ---namely, contexts. @@ignore: the aforementioned
generalised signatures.@@ After showing how the usual record formulation of
monoids is equivalent to a pure contextual one, in section
\ref{sec:contexts_promising} we verify that contexts are indeed promising by
discussing how other dependently-typed languages (DTLs) handle type
#+latex: abstraction\footcitet{modules:sharing}$^,$\footcitet{modules:manifest} ---namely,
contexts and signatures.  In particular, we compare the construction of a tiny
graph library in Coq with its alternative form in Agda. Unlike Coq, we want to
use the contexts for algebraic datatypes as well.  As such, we review ùí≤-types in
section \ref{sec:W_types}.  Finally, in section
\ref{sec:semantics_for_contexts}, we formalise our approach for contexts serving
as a generic packaging mechanism. The formalism is in dependent type theory,
whereas the next chapter provides a Lisp implementation and the chapter after
that shows an Agda implementation.


#+latex: \begin{fullwidth}
{{{localtoc}}}
#+latex: \end{fullwidth}


** Facets of Structuring Mechanisms
  <<sec:module_agda>>
 # +latex: \label{sec:module_agda}
  <<sec:module_interdefinability>>
 # +latex: \label{sec:module_interdefinability}

*** Intro                                                            :ignore:
    :PROPERTIES:
    :CUSTOM_ID: Intro
    :END:
  :Setup:
 {{{code( ??? )}}}
  #+begin_src haskell
open import Relation.Binary.PropositionalEquality
open ‚â°-Reasoning

-- Z-notation for sums
open import Level
open import Data.Product using (Œ£ ; proj‚ÇÅ ; proj‚ÇÇ ; _√ó_ ; _,_)
Œ£‚à∂‚Ä¢ : {a b : Level} (A : Set a) (B : A ‚Üí Set b) ‚Üí Set (a ‚äî b)
Œ£‚à∂‚Ä¢ = Œ£
infix -666 Œ£‚à∂‚Ä¢
syntax Œ£‚à∂‚Ä¢ A (Œª x ‚Üí B) = Œ£ x ‚à∂ A ‚Ä¢ B

open import Data.Nat
open import Data.Nat.Properties
  #+end_src
  :End:

#+begin_parallel

  In this section we provide a demonstration that with dependent-types we can
  show records, direct dependent types, and contexts ---which in Agda may be
  thought of as parameters to a module--- are interdefinable. Consequently, we
  observe that the structuring mechanisms provided by the current implementation
  of Agda ---and other DTLs--- have no real differences aside from those imposed by
  the language and how they are generally utilised. More importantly, this
  demonstration indicates our proposed direction of identifying notions of
  packages is on the right track.

  Our example will be implementing a monoidal interface in each format, then
  presenting /views/ between each format and that of the ~record~ format.
  Furthermore, we shall also construe each as a
  #+latex: typeclass,
  thereby demonstrating that typeclasses are, essentially, not only a selected
  record but also a selected /value/ of a dependent type ---incidentally this
  follows from the previous claim that records and direct dependent types are
  essentially the same.

  #+begin_export latex
% \begin{center}
\smartdiagram[descriptive diagram]{
  {Record, A $\Sigma$-type in \texttt{record} notation },
  {Typeclass,A ``$\Pi\, parameter \bullet \Sigma\, body$''-type in \texttt{record} notation },
  {Dependent Product, A $\Sigma$-type in $\Sigma$-notation},
  {Context / \\ Telescope, A $\Pi$-type in \texttt{module} notation},
  }
% \end{center}
  #+end_export
#+end_parallel

*** Three Ways to Define Monoids
    :PROPERTIES:
    :CUSTOM_ID: Three-Ways-to-Define-Monoids
    :END:

A *monoid* is a collection, say =Carrier=, along with an operation, say =_‚®æ_=, on it
and a chosen point, say =Id=, from that collection. *Monoids model composition:* We
have a bunch of things called =Carrier= ---such as programs or words---, we have a
way to ‚Äòmix‚Äô or ‚Äòcompose‚Äô two things =x= and =y= to get a third =x ‚®æ y= ---such as
forming a big program from smaller pieces or a story from words--- which has an
selected ‚Äòempty‚Äô thing that does not affect composition ---such as the
do-nothing program or the ‚Äòempty word‚Äô which does not add content to a story.
There are three /typical/ ways to formalise the type of monoids: (1) As a
src_agda[:exports code]{record} since a monoid is a bunch of things together;
(2) as a ‚Äòtypeclass‚Äô (parameterised record) since we want to /specialise/ the
carrier dynamically or to have instance search (which is an invaluable feature
in, for example, Haskell, which organises its libraries using typeclasses and
instance search); (3) as a raw unsugared src_agda[:exports code]{Œ£}-type since
we want to explicitly disallow the inherent src_agda[:exports
code]{module}-nature of Agda's src_agda[:exports code]{record}s.  A DTL allows
for redundancies like this so users can solve their problems in ways they see
best.

The type of monoids is formalised below as =Monoid-Record=; additionally, we have
the derived result: ~Id~-entity can be popped-in and out as desired.

 # Recall that the signature of a monoid consists of a type ~Carrier~ with a method
 # ~_‚®æ_~ that composes values and an ~Id~-entity value. With Agda's lack of type-proof
 # discrimination, i.e., its support for the Curry-Howard Correspondence, the
 # ‚Äúpropositions as types‚Äù interpretation, we can encode the signature as well as
 # the axioms of monoids to yield their theory presentation in the following two
 # ways. Additionally, we have the derived result: ~Id~-entity can be popped-in and
 # out as desired.

 {{{code(Monoids as Agda Records \hfill---The usual mathematical definition)}}}
 #+BEGIN_SRC haskell
record Monoid-Record : Set‚ÇÅ where
  infixl 5 _‚®æ_
  field
    -- Interface
    Carrier  : Set
    Id       : Carrier
    _‚®æ_      : Carrier ‚Üí Carrier ‚Üí Carrier

    -- Constraints
    lid   : ‚àÄ{x}    ‚Üí (Id ‚®æ x) ‚â° x
    rid   : ‚àÄ{x}    ‚Üí (x ‚®æ Id) ‚â° x
    assoc : ‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z  ‚â°  x ‚®æ (y ‚®æ z)

  -- derived result
  pop-Id-Rec : ‚àÄ x y  ‚Üí  x ‚®æ Id ‚®æ y  ‚â°  x ‚®æ y
  pop-Id-Rec x y = cong (_‚®æ y) rid

open Monoid-Record {{...}} using (pop-Id-Rec)
 #+END_SRC

# +latex: \begin{tcolorbox}[colframe=red!75!black, title=Instance Resolution]
*Instance Resolution:* The double curly-braces src_agda[:exports code]{{{...}}}
serve to indicate that the given argument is to be found by /instance
resolution/. For example, if we declare src_haskell[:exports code]{it : {{e ‚à∂ A}}
‚Üí B}, then src_emacs-lisp[:exports code]{it} is a src_haskell[:exports
code]{B}-value that is formed using an src_haskell[:exports code]{A}-value; but
which src_haskell[:exports code]{A}-value? Unlike a function which requires the
src_haskell[:exports code]{A}-value as input, src_emacs-lisp[:exports code]{it}
will ‚Äúlook up‚Äù an src_haskell[:exports code]{A}-value in the list of names that
are marked for look-up by the keyword src_agda[:exports code]{instance}.  If
multiple src_haskell[:exports code]{A}-values are marked for look-up, it is not
clear which one should be used; as such,
 #+latex: \emph{at most one}\FOOTNOTE{
 More accurately, there needs to be /a unique instance that solves local
constraints/. Continuing with src_emacs-lisp[:exports code]{it}, any call to
src_emacs-lisp[:exports code]{it} will occur in a context src_haskell[:exports
code]{Œì} that will include inferred types and so when an src_haskell[:exports
code]{A}-valued is looked-up it suffices to find a /unique/ value
src_emacs-lisp[:exports code]{e} such that src_haskell[:exports code]{Œì ‚ä¢ e :
A}. More concretely, suppose src_haskell[:exports code]{A =
‚Ñï √ó ‚Ñï, B = ‚Ñï} and src_agda[:exports code]{it {{(x , y)}} = x} and we declared
two ‚Ñïumbers for instance search, src_haskell[:exports code]{p = (0 , 10)} and
src_haskell[:exports code]{q = (1, 14)}.  Then in the call site
src_agda[:exports code]{go : it ‚â° 1; go = refl}, the use of
src_emacs-lisp[:exports code]{refl} means both sides of the equality must be
identical and so src_agda[:exports code]{it {{e}}} must have the
src_emacs-lisp[:exports code]{e} chosen to make the equality true, but only
src_emacs-lisp[:exports code]{q} does so and so it is chosen. However, if
instead we had defined src_haskell[:exports code]{p = (1 , 10)}, then both
src_emacs-lisp[:exports code]{p} and src_emacs-lisp[:exports code]{q} could be
used and so there is no local solution; prompting Agda to produce an error.
:More_neato:
#+begin_src agda
open import Data.Product

it : {{e : ‚Ñï √ó ‚Ñï}} ‚Üí ‚Ñï
it {{x , y}} = x

instance
  p q : ‚Ñï √ó ‚Ñï
  p = (0 , 10)
  -- p = (1 , 10) -- Using this breaks the resolution of ‚Äúgo‚Äù below.
  q = (1 , 14)

go : it ‚â° 1
go = refl

--------------------------------------------------------------------------------
-- Again, using records.

open import Data.Nat
open import Relation.Binary.PropositionalEquality

record R : Set‚ÇÅ where
  constructor MkR
  field c : ‚Ñï
  field bop : ‚Ñï ‚Üí ‚Ñï ‚Üí ‚Ñï

open R {{...}}

instance
  A = MkR 1 _*_
  B = MkR 0 _*_

_ : bop 1 2 ‚â° 2 -- Which record is used?
_ = refl
#+end_src
:End:
 #+latex: }
 value can be provided for lookup and this value is called ‚Äúthe declared
 =A=-instance‚Äù, whence the name ‚Äòinstance resolution‚Äô.  Recall that Agda records
 automatically come with an associated module, and so the =open= clause, above,
 makes the name {{{mbox(src_haskell[:exports code]{pop-Id-Rec : {{ùë¥ :
 Monoid-Record}} ‚Üí (x y : Monoid-Record.Carrier ùë¥) ‚Üí ‚Ä¶})}}}  accessible;
 in-particular, this name uses instance resolution: The derived result,
 =pop-Id-Rec=, can be invoked without having to mention a monoid, provided a
 unique =Monoid-Record= value is declared for instance search ---otherwise one
 must use named instances \footcitet{named_instances}.  We will return to
 actually declaring and using instances in the next section.

 #+latex: {\color{gray!80} \footnotesize
 Notice that Haskell's distinction of constructs results in distinct tools: It
 needs both a type-class checker and a type-checker.  The former is unnecessary
 if typeclasses were syntactic sugar for canonical record types, thereby having
 them as ordinary types.  Conveniently, the reduction of distinctions not only
 makes it easier to learn a language but also demands less tooling on the
 compiler implementers.
#+latex: }
 # Notice that the
 # carrier argument in the typeclasses approach, ‚Äústructure on a carrier‚Äù, is an
 # (undeclared) implicit argument to the ~pop-Id-tc~ operation.
# +latex: \end{tcolorbox}
#  @@hide:

 A value of =Monoid-Record= is essentially a tuple =record{Carrier = C; ‚Ä¶}=; so the
 carrier is /bundled at the value level/. If we to speak of ‚Äúmonoids with the
 specific carrier ùí≥‚Äù, we need to /bundle the carrier at the type level/.
 This is akin to finding the carrier ‚Äúdynamically, at runtime‚Äù versus
 finding it
 #+latex: ‚Äústatically, at typechecking time‚Äù. \FOOTNOTE{
  An accessible introduction to semantics and typeclasses, using a monoid of
  functions as the running example, can be found in:
  \fullcite{Elliott2016DenotationalDW}.
  #+latex: }
 # i.e., the difference between
 # ‚Äúa structure‚Äù and ‚Äúa structure on a particular carrier‚Äù.

 {{{code(Monoids as ‚ÄòTypeclasses‚Äô/‚ÄòGenerics‚Äô \hfill ---Parameterisation on the underlying set)}}}
 #+BEGIN_SRC haskell
record MonoidOn (Carrier : Set) : Set‚ÇÅ where
  infixl 5 _‚®æ_
  field
    Id    : Carrier
    _‚®æ_   : Carrier ‚Üí Carrier ‚Üí Carrier
    lid   : ‚àÄ{x} ‚Üí (Id ‚®æ x) ‚â° x
    rid   : ‚àÄ{x} ‚Üí (x ‚®æ Id) ‚â° x
    assoc : ‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)

  pop-Id-Tc : ‚àÄ x y ‚Üí  x ‚®æ Id ‚®æ y  ‚â°  x ‚®æ y
  pop-Id-Tc x y = cong (_‚®æ y) rid

open MonoidOn {{...}} using (pop-Id-Tc)
 #+END_SRC

 Alternatively, in a DTL we may encode the monoidal interface using dependent
 products *directly* rather than use the syntactic sugar of records. Recall that
 ~Œ£ a ‚à∂ A ‚Ä¢ B a~ denotes the type of pairs ~(a , b)~ where ~a ‚à∂ A~ and ~b ‚à∂ B a~
 ---i.e., a record consisting of two fields--- and it may be thought of as a
 constructive analogue to the classical set comprehension {{{newline}}}
 ~{x ‚à∂ A ‚ùô B x}~.

 {{{code(Monoids as Dependent Sums \hfill---Using none of Agda's built-in syntactic sugar)}}}
 # ATTR_LATEX: :options fontsize={\fontsize{10}{11}\selectfont}
 #+BEGIN_SRC haskell
-- Type alias
Monoid-Œ£  :  Set‚ÇÅ
Monoid-Œ£  =    Œ£ Carrier ‚à∂ Set
             ‚Ä¢ Œ£ Id ‚à∂ Carrier
             ‚Ä¢ Œ£ _‚®æ_ ‚à∂ (Carrier ‚Üí Carrier ‚Üí Carrier)
             ‚Ä¢ Œ£ lid ‚à∂ (‚àÄ{x} ‚Üí Id ‚®æ x ‚â° x)
             ‚Ä¢ Œ£ rid ‚à∂ (‚àÄ{x} ‚Üí x ‚®æ Id ‚â° x)
             ‚Ä¢ (‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z))

pop-Id-Œ£ : ‚àÄ {{M : Monoid-Œ£}}
               (let Id  = proj‚ÇÅ (proj‚ÇÇ M))
               (let _‚®æ_ = proj‚ÇÅ (proj‚ÇÇ (proj‚ÇÇ M)))
           ‚Üí  ‚àÄ (x y : proj‚ÇÅ M)  ‚Üí  (x ‚®æ Id) ‚®æ y  ‚â°  x ‚®æ y
pop-Id-Œ£ {{M}} x y = cong (_‚®æ y) (rid {x})
             where  _‚®æ_    = proj‚ÇÅ (proj‚ÇÇ (proj‚ÇÇ M))
                    rid    = proj‚ÇÅ (proj‚ÇÇ (proj‚ÇÇ (proj‚ÇÇ (proj‚ÇÇ M))))
 #+END_SRC

 Observe the lack of informational difference between the presentations, yet
 there is a /Utility Difference: Records give us the power to name our
 projections @@latex:\underline{\smash{directly}}@@ with possibly meaningful names./ Of course this could be
 achieved indirectly by declaring extra functions; e.g.,
 #+LaTeX: \def\mytitle{Agda}
 #+BEGIN_SRC haskell :tangle no
Carrier‚Çú : Monoid-Œ£ ‚Üí Set
Carrier‚Çú = proj‚ÇÅ
 #+END_SRC
 We will refrain from creating such boiler plate ---that is, /records allow us to
 omit such mechanical boilerplate./

 Of the renditions thus far, the ~Œ£~ rendering makes it clear that a monoid could
 have any subpart as a record with the rest being dependent upon said record.
 For example, if we had a
 #+latex: semigroup\FOOTNOTE{
 A /semigroup/ is like a monoid except it does not have the =Id= element.
 #+latex: }
 type, we could have declared a monoid to be a semigroup with additional pieces:
 | ~Monoid-Œ£ ¬†=¬† Œ£ S ‚à∂ Semigroup ‚Ä¢ Œ£ Id ‚à∂ Semigroup.Carrier S ‚Ä¢ ‚ãØ~ |

 # +latex: \begin{tcolorbox}[colframe=red!75!black]
 There are a large number of hyper-graphs indicating how monoidal interfaces
 could be built from their parts, we have only presented a stratified view for
 brevity. In particular, ~Monoid-Œ£~ is the extreme unbundled version, whereas
 ~Monoid-Record~ is the other extreme, and there is a large spectrum in between
 ---all of which are somehow
 #+latex: isomorphic\FOOTNOTE{
 For this reason ---namely that records are existential closures of a
 typeclasses--- typeclasses are also known as ‚Äúconstraints, or predicates, on
 types‚Äù.
 #+latex: };
 e.g., ~Monoid-Record ‚âÖ Œ£ C ‚à∂ Set ‚Ä¢ MonoidOn C~. Our envisioned system would be
 able to derive any such view at will\footcitet{casl_overview} and so programs
 may be written according to one view, but easily repurposed for other view with
 little human intervention.
# +latex: \end{tcolorbox}

*** Instances and Their Use
    :PROPERTIES:
    :CUSTOM_ID: Instances-and-Their-Use
    :END:

  :Irrelevant:
  Like a Java ~class~, within the ~record~ we may include derived results
  that are then available to all values, `instances', of the record type.
  Outside the ~record~, further properties may be added, though they now
  require an actual value, instance, to be given.
  :End:

  # Instances and their use are as follows.

  Instances of the monoid types are declared by providing implementations for
  the necessary fields. Moreover, as mentioned earlier, to support instance
  search, we place the declarations in an ~instance~ clause.

  {{{code(Instance Declarations)}}}
  #+BEGIN_SRC haskell
instance
   ‚Ñï-Rec : Monoid-Record
   ‚Ñï-Rec = record { Carrier = ‚Ñï ; Id = 0 ; _‚®æ_ = _+_
                  ; lid =  +-identityÀ° _  ; rid = +-identity ≥ _
                  ; assoc = +-assoc }

   ‚Ñï-Tc : MonoidOn ‚Ñï
   ‚Ñï-Tc = record { Id = 0; _‚®æ_ = _+_ ; lid = +-identityÀ° _
                 ; rid = +-identity ≥ _ ; assoc = +-assoc }

   ‚Ñï-Œ£ : Monoid-Œ£
   ‚Ñï-Œ£ = ‚Ñï , 0 , _+_ , +-identityÀ° _ , +-identity ≥ _ , +-assoc
  #+END_SRC

  Interestingly, notice that the grouping in ~‚Ñï-Œ£~ is just an unlabelled
  (dependent) product, and so when it is used below in ~pop-Id-Œ£~ we project to the
  desired components. Whereas in the ~Monoid-Record~ case we could have projected
  the carrier by ~Carrier M~, now we would write ~proj‚ÇÅ M~.

  {{{code(No Monoids Mentioned at Use Sites)}}}
  #+BEGIN_SRC haskell
‚Ñï-pop-0-Rec ‚Ñï-pop-0-Tc ‚Ñï-pop-0-Œ£ : (x y : ‚Ñï) ‚Üí x + 0 + y  ‚â°  x + y

‚Ñï-pop-0-Rec  = pop-Id-Rec
‚Ñï-pop-0-Tc   = pop-Id-Tc
‚Ñï-pop-0-Œ£    = pop-Id-Œ£
  #+END_SRC

  With a change in perspective, we could treat the =pop-0= implementations as a
  form of /polymorphism/: The result is independent of the particular packaging
  mechanism; record, typeclass, Œ£, it does not matter.

  :Irrelevant:
  This is nearly identical to the previous implementation and possibly
  simpler due to the lack of the ~record { ‚ãØ }~ clutter required of /labelled products/.
  However, said clutter could have been removed by providing
  a ~constructor~ declaration in the definition of ~Monoid-Record~
  but we have decided not to do so, to make the labelling clear
  and distinct from the unlabelled product presentations.
  :End:

  Finally, since we have already discussed the relationship between
  =Monoid-Record= and =MonoidOn=, let us exhibit views between the Œ£ form and the ~record~ form.
  #+LaTeX: \def\mytitle{Agda}
{{{code(Monoid-Record and Monoid-Œ£ \emph{represent} the same data)}}}
  #+BEGIN_SRC agda
{- Essentially moved from record{‚ãØ} to product listing -}
from : Monoid-Record ‚Üí Monoid-Œ£
from M  =  let open Monoid-Record M
           in Carrier , Id , _‚®æ_ , lid , rid , assoc

from-record-to-usual-type M  =  Carrier , Id , _‚®æ_ , lid , rid , assoc

{- Organise a tuple componenets as implementing named fields -}
to : Monoid-Œ£ ‚Üí Monoid-Record
to (c , id , op , lid , rid , assoc)  = record { Carrier = c
                                               ; Id      = id
                                               ; _‚®æ_     = op
                                               ; lid     = lid
                                               ; rid     = rid
                                               ; assoc   = assoc
                                               }
  #+END_SRC

  #                                                } -- Term construed by ‚ÄòAgsy‚Äô,
  #               -- Agda's mechanical proof search.

  Furthermore, by definition chasing, ~refl~-exivity, these operations are seen to be inverse of
  each other. Hence we have two faithful non-lossy protocols for reshaping our grouped data.

*** A Fourth Definition ---Contexts
    :PROPERTIES:
    :CUSTOM_ID: A-Fourth-Definition-Contexts
    :END:
 In our final presentation, we construe the grouping of the monoidal interface
 as a sequence of /variable ‚à∂ type/ declarations ---i.e., a [[gls:context][‚Äòcontext‚Äô]] or
 ‚Äòtelescope‚Äô. Since these are not top level items by themselves, in Agda, we
 take a purely syntactic route by positioning them in a ~module~ declaration as
 follows.

 {{{code(Monoids as Telescopes)}}}
 #+BEGIN_SRC haskell
module Monoid-Telescope-User
  (Carrier : Set)
  (Id      : Carrier)
  (_‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier)
  (lid     : ‚àÄ{x} ‚Üí Id ‚®æ x ‚â° x)
  (rid     : ‚àÄ{x} ‚Üí x ‚®æ Id ‚â° x)
  (assoc   : ‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z))
  where

  pop-Id-Tel : ‚àÄ(x y : Carrier)  ‚Üí  (x ‚®æ Id) ‚®æ y  ‚â°  x ‚®æ y
  pop-Id-Tel x y = cong (_‚®æ y) (rid {x})
 #+END_SRC

 # +latex: \begin{tcolorbox}[colframe=red!75!black, title=Squint and They're The Same]
 *‚ÄúSquint and They're The Same:‚Äù*
 Notice that this is nothing more than the named fields of ~Monoid-Record~ but
 #+latex: not\FOOTNOTE{
 Records let us put things in a bag and run around with them, whereas telescopes
amount to us running around with all of our things in our hands ---hoping we
don't drop (forget) any of them.
 #+latex: }
 bundled. Additionally, if we insert a Œ£ before each name we essentially regain
 the ~Monoid-Œ£~ formulation. It seems contexts, at least superficially, are a nice
 middle ground between the previous two formulations.  For instance, if we
 /syntactically/, visually, move the {{{mbox(~Carrier ‚à∂ Set~)}}} declaration one
 line above, the resulting setup looks eerily similar to the typeclass
 formulation of records.
# +latex: \end{tcolorbox}

 As promised earlier, we can regard the above telescope as a record:
 #+LaTeX: \def\mytitle{Agda}
 #+BEGIN_SRC haskell
  {- No more running around with things in our hands. -}
  {- Place the telescope parameters into a nice bag to hold on to. -}
  record-from-telescope : Monoid-Record
  record-from-telescope
    = record { Carrier = Carrier
             ; Id      = Id
             ; _‚®æ_     = _‚®æ_
             ; lid     = lid
             ; rid     = rid
             ; assoc   = assoc
             }
 #+END_SRC

 The structuring mechanism ~module~ is not a first class citizen in Agda.
 As such, to obtain the converse view, we work in a parameterised module.
 #+LaTeX: \def\mytitle{Agda}
 #+BEGIN_SRC haskell
module record-to-telescope (M : Monoid-Record) where

  -- Treat record type as if it were a parameterised module type,
  -- instantiated with M.
   open Monoid-Record M

  -- Actually using M as a telescope
  open Monoid-Telescope-User Carrier Id _‚®æ_ lid rid assoc
 #+END_SRC

 Notice that we just listed the components out ---rather reminiscent of the formulation
 ~Monoid-Œ£~. This observation only increases confidence in our thesis that there is no
 real distinctions of packaging mechanisms in DTLs.
 Similarity, instantiating the telescope approach to a natural number monoid
 is nothing more than listing the required components.
 #+LaTeX: \def\mytitle{Agda}
 #+BEGIN_SRC haskell
open Monoid-Telescope-User ‚Ñï 0 _+_ (+-identityÀ° _) (+-identity ≥ _) +-assoc
 #+END_SRC

 This instantiation is nearly the same as the definition of ~‚Ñï-Œ£~; with the primary
 syntactical difference being that this form had its arguments separated by
 spaces rather than commas!
 #+LaTeX: \def\mytitle{Agda}
 #+BEGIN_SRC haskell
‚Ñï-pop-Tel  : ‚àÄ(x y : ‚Ñï)  ‚Üí  x + 0 + y  ‚â°  x + y
‚Ñï-pop-Tel  =   pop-Id-Tel
 #+END_SRC

#  Notice how this presentation makes it explicitly clear why we cannot have multiple instances:
# There would be name clashes. Even if the data we used had distinct names, the derived result
# may utilise data having the same name thereby admitting name clashes elsewhere.
# ---This could be avoided in Agda by qualifying names and/or renaming.

 It is interesting to note that this presentation is akin to that of ~class~-es in
 C#/Java languages: The interface is declared in one place, monolithic-ly, as
 well as all derived operations there; if we want additional operations, we
 create another module that takes that given module as an argument in the same
 way we create a class that inherits from that given class.

 Demonstrating the interdefinablity of different notions of packaging cements
 our thesis that it is essentially /utility/ that distinguishes packages more than
 anything else ---just as =data= language's words (constructors) have their
 meanings determined by /utility/.  Consequently, explicit distinctions have lead
 to a duplication of work where the same structure is formalised using different
 notions of packaging. In chapter ref:sec:PF we will show how to avoid
 duplication by coding against a particular ‚Äòpackage former‚Äô rather than a
 particular variation thereof ---this is akin to a type former.
** Contexts are Promising
   :PROPERTIES:
   :CUSTOM_ID: DTLs-Today-a-pr√©cis
   :END:
   # @@latex:pr\'{e}cis@@ @@html: pr√©cis@@

   # DTLs Today, a pr√©cis

 #+latex: \label{sec:contexts_promising}

  The current implementation of the Agda
  #+latex: language\footcitet{agda_overview}$^,$\footcitet{agda_thesis}
  has a notion of second-class modules which may contain sub-modules along with
  declarations and definitions of first-class citizens. The intimate
  relationship between records and modules is perhaps best exemplified here
  since the current implementation provides a declaration to construe a record
  as if it were a module ---as demonstrated in the previous section. This
  observation is not specific to Agda, which is herein only used as a
  presentation language.  Indeed, other DTLs (dependently-typed languages)
  reassure our hypothesis; the existence of a unified notion of package:


  # This change in perspective allows
  # Agda records to act as /typeclasses/. However, Agda's current implementation
  # does not support sharing. In particular, a parameterised module is only
  # syntactic sugar such that each member of the module actually obtains a new
  # functional parameter; as such, a computationally expensive parameter provided
  # to a module invocation may be intended to be computed only once, but is
  # actually computed at each call site.

  - *The centrality of contexts*

     The *Beluga* language has the distinctive feature of direct support for
     first-class contexts\footcitet{beluga}. A term ~t(x)~ may have free variables and so
     whether it is well-formed, or what its type could be, depends on the types of
     its free variables, necessitating one to either declare them before hand or to
     write, in Beluga, ~[ x ‚à∂ T |- t(x) ]~ for example. As argued in
     the previous section, contexts are essentially dependent sums. In contrast to
     Beluga, *Isabelle* is a full-featured language and logical framework that also
     provides support for named contexts in the form of
     #+latex: ‚Äòlocales‚Äô\footcitet{locales}$^,$\footcitet{isabelle_locales};
     however, it is not a dependently-typed language.

  - *Signatures as an underlying formalism*

   *Twelf*\footcitet{twelf_site} is a logic programming language implementing
    Edinburgh's Logical
    #+latex: \newline  Framework\footcitet{lf_meta_mechanisation}$^,$\footcitet{lf_has_isabelle}$^,$\footcitet{lf_fast_proof_checking}
    and has been used to prove safety properties of ‚Äòreal languages‚Äô such as
    SML.  A notable practical module system\footcitet{lf_practical_modules} for Twelf
    has been implemented using signatures and signature morphisms.

  - *Packages (modules) have their own useful language*

    The current implementation of
    #+latex: {\textbf{Coq}}\footcitet{coq:sets}$^,$\footcitet{coq:type_decorations}$^,$\footcitet{coq:art}$^,$\footcitet{coq_cat_experiences}
    provides a ‚Äúcopy and paste‚Äù operation for modules using the src_coq[:exports
    code]{include} keyword. Consequently it provides a number of module
    combinators, such as ~<+~ which is the infix form of module
    inclusion\footcitet{coq_manual}. Since Coq module types are essentially
    contexts, the module type src_coq[:exports code]{X <+ Y <+ Z} is really the
    catenation of contexts, where later items may depend on former items. The
    #+latex: \textbf{Maude}\footcitet{maude}$^,$\footcitet{maude_module_algebra}
    framework contains a similar yet more comprehensive algebra of modules and
    how they work with Maude theories.

  - *Parameters of records are actually their fields*

    The *Arend* proof
    #+latex: assistant\footcitet{arend:webpage}$^,$\footcitet{arend:DBLP:journals/corr/abs-2004-14195}
    is based on intuitionistic logic, like Agda, but is otherwise intended
    for theorem proving in homotopy type theory\footcitet{hottbook}.
    Arend
    [[https://arend-lang.github.io/about/arend-features#anonymous-extensions][does not distinguish between record parameters and record fields]] (as such,
    fields can be /specialised/ dynamically; i.e., Œ† and Œª are essentially
    identified, but we will form a combinator ‚ÄòŒ†‚ÜíŒª‚Äô in Chapter
    \ref{sec:contexts}).  This is the exact insight that we arrived at,
    cite:DBLP:conf/gpce/Al-hassyCK19, independently [[https://arend-lang.github.io/2019/07/17/Arend-1.0.0-released.html][at around the same time that
    the first version of Arend was released.]]

    Arend provides a /built-in/ solution, whereas we show how such a solution to
    the unbundling problem can be formed as a reflection library in a DTL.
    Moreover, our target setting is for both proving /and/ programming.

    # As of 2020 April, Arend has no trusted core.
    # More concerns discussed here: https://leanprover-community.github.io/archive/stream/113488-general/topic/seminars.html

It is important to consider other languages so as to how see their communities
treat module systems and what uses cases they are interested in: /It is important
to draw wisdom from many different places; if you take it from only/ /one place,
it becomes rigid and stale\footcitet{ATLA}./ In the next section, we shall see a
glimpse of how the Coq community works with packages, and, to make the
discussion accessible, we shall provide Agda translations of Coq code.

*** COMMENT old intro

 <<sec:module_existing>>
#+latex: \label{sec:module_existing}
#+latex: \label{sec:module_existing}

 We want to implement solutions in a dependently typed language. Let us discuss
 which are active and their capabilities.

 To the best of our knowledge, as confirmed by Wikipedia
 citet:wiki_proof_assistants,wiki_proof_assistants_dependent, there are currently
 less than 15 /actively developed/ dependently-typed languages in-use /that are
 also used/ as proof-assistants ---which are interesting to us since we aim to
 mechanise all of our results: Algorithms as well as theorems.
 Below is a quick summary of our stance on the primary candidates.

#+caption: Primary reason a language is not used in-place of Agda
| Coq        | Tactics reinforce a fictitious divide between propositions and types     |
| Idris      | Records can be parameterised but not indexed                             |
| Lean       | Rapid development of Lean has left it backward incompatible and unstable |
| ATS        | Weak module system                                                       |
| F*, Beluga | The language is immature; it has little support                          |
# | Beluga     | Has two syntactic categories: Data and computation                       |

#+macro: fstar @@latex: F*@@ @@html: F*@@


  # The Common Algebraic Specification Language
  # citet:casl_overview,casl_user_manual,casl_reference_manual will also be
  # investigated with the aim of extracting, and generalising, useful module
  # combinators and their properties.
  # #
  # Casl in general: http://www.cofi.info
  # Casl tools: http://hets.dfki.de
  # Casl libraries: http://www.cofi.info/Libraries
  # #
  # Coq <+ sutff: #
  # See https://coq.inria.fr/distrib/V8.7.2/refman/gallina-ext.html#sec90

  :WK_maude:
  Maude is based on rewriting logic,
  which uses term rewrite rules in two roles:
  + as equations, for algebraic specification
  + as (labelled) transitions.

  In the resulting transition systems,
  a ``state'' is an equivalence class of value terms
  modulo the associated set of equations,
  and transitions are rewrites using the second class of rules.

  Theories (and functional modules fmod) can only
  contain equations.
  :End:

*** COMMENT Agda --‚ÄúHaskell on steroids‚Äù
    :PROPERTIES:
    :CUSTOM_ID: Agda-Haskell-on-steroids
    :END:
  Agda citet:agda_overview,agda_thesis is one of the more popular proof
  assistants around; possibly due to its syntactic inheritance from Haskell
  ---as is the case with Idris. Its Unicode mixfix lexemes permit somewhat
  faithful renditions of informal mathematics; e.g., calculational proofs can be
  encoded in seemingly informal style that they can be easily read by those
  unfamiliar with the system. It also allows traditional functional programming
  with the ability to ‚Äòescape under the hood‚Äô and write Haskell code. The
  language has not been designed solely with theorem proving in mind, as is the
  case for Coq, but rather has been designed with dependently-typed programming
  in mind citet:agda_web,agda_plf.

#+begin_edcomm org
:ed: WK

Wadler-Kokke-2018 is about theorem proving in theories of programming languages.
#+end_edcomm

  The current implementation of the Agda language has a notion of second-class
  modules which may contain sub-modules along with declarations and definitions
  of first-class citizens. The intimate relationship between records and modules
  is perhaps best exemplified here since the current implementation provides a
  declaration to construe a record as if it were a module. This change in
  perspective allows Agda records to act as Haskell typeclasses. However, the
  relationship with Haskell is only superficial: Agda's current implementation
  does not support sharing. In particular, a parameterised module is only
  syntactic sugar such that each member of the module actually obtains a new
  functional parameter; as such, a computationally expensive parameter provided
  to a module invocation may be intended to be computed only once, but is
  actually computed at each call site.

*** COMMENT Coq ---‚ÄúThe standard proof assistant‚Äù
    :PROPERTIES:
    :CUSTOM_ID: Coq-The-standard-proof-assistant
    :END:

  Coq citet:coq:art,coq:type_decorations,coq:sets,coq_cat_experiences is
  unquestionably one of, if not, the most popular proof assistant around. It has
  been used to produce mechanised proofs of the Four Colour Theorem
  citet:coq_four_colour, the Feit-Thompson Theorem citet:coq_feit, and an
  optimising compiler for the C language: CompCert
  citet:coq_compcert,compcert_paper.

  Unlike Agda, Coq supports tactics citet:tacticstype ---a brute force approach
  that renders (hundredfold) case analysis as child's play: Just refine your
  tactics till all the subgoals are achieved. Ultimately the cost of utilising
  tactics is that a tactical proof can only be understood with the aid of the
  system, and may otherwise be un-insightful and so failing to meet most of the
  purposes of proof citet:purposes_of_proof ---which may well be a large barrier
  for mathematicians who value insightful proofs.

  The current implementation of Coq provides the base features expected of any
  module system. A notable difference from Agda is that it allows to ‚Äúcopy and
  paste‚Äù contents of modules using the src_coq[:exports code]{include} keyword. Consequently it provides
  a number of module combinators, such as ~<+~ which is the infix form of module
  inclusion citet:coq_manual. Since Coq module types are essentially contexts, the
  module type src_coq[:exports code]{X <+ Y <+ Z} is really the catenation of contexts, where later items
  may depend on former items. The Maude citet:maude,maude_module_algebra framework
  contains a similar yet more comprehensive algebra of modules and how they work
  with Maude theories.

  As the oldest proof assistant, in a later section we shall compare and contrast
  its module system with Agda's to some depth.

*** COMMENT Idris ---‚ÄúAgda with tactics‚Äù
    :PROPERTIES:
    :CUSTOM_ID: Idris-Agda-with-tactics
    :END:
  Idris citet:idris_main is a general purpose, functional, programming language
  with dependent types. Alongside ATS, below, it is perhaps the only language in
  our list that can truthfully boast to being general purpose and to have
  dependent types. It supports both equational and tactic based proof styles,
  like Agda and Coq respectively; unlike these two however, Idris erases unused
  proof-terms automatically rather than forcing the user to declare this far in
  advance as is the case with Agda and Coq. The only (negligible) downside, for
  us, is that the use of tactics creates a sort of distinction between the
  activities of proving and programming, which is mostly fictitious.
  #
  # Can tactics in Idris be used for programming?
  # They can in Coq, but this is for good reasons strongly discouraged.

  :Irrelevant:
  Moreover, Idris compiles to C whereas Agda compiles to Haskell thereby opening
  the possibility to use GHC's many optimisations without too much translation
  from the source: In contrast, Idris programs must be first transformed to their
  imperative counterparts citet:idris_website,idris_tdd.
  :End:

  Intended to be a more accessible and practical version of Agda, Idris
  implements the base module system features and includes interesting new ones.
  Until [[https://agda.readthedocs.io/en/v2.6.0/language/generalization-of-declared-variables.html][recently]], in Agda, one would write ~module _ (x : ‚Ñï) where ‚ãØ~ to
  parameterise every declaration in the block $‚Äú‚ãØ‚Äù$ by the name ~x~; whereas in
  Idris, one writes ~parameters (x : ‚Ñï) ‚ãØ~ to obtain the [[http://docs.idris-lang.org/en/latest/tutorial/modules.html][same behaviour]] ---which
  Agda has since improved upon it via ‚Äògeneralisation‚Äô: A declaration's type gets
  only the variables it actually uses, not every declared parameter.

  # http://docs.idris-lang.org/en/latest/tutorial/modules.html

  Other than such pleasantries, Idris does not add anything of note. However, it
  does provide new constraints. As noted earlier, the current implementation of
  Idris attempts to erase implicits aggressively therefore providing speedup over
  Agda. In particular, Idris modules and records can be parameterised but not
  indexed ---a limitation not in Agda.

  Unlike Coq, Idris has been designed to ‚Äúemphasise general purpose programming
  rather than theorem proving‚Äù citet:idris_faq,idris_tdd. However, like Coq, Idris
  provides a Haskell-looking typeclasses mechanism; but unlike Coq, it allows
  named instances. In contrast to Agda's record-instances, typeclasses result in
  backtracking to resolve operator overloading thereby having a slower type
  checker.

  # http://docs.idris-lang.org/en/latest/tutorial/interfaces.html

  # https://github.com/idris-lang/Idris-dev/wiki/Egg-%234:-Agda-style-records-and-modules

*** COMMENT Lean ---‚ÄúProofs for metaprogramming‚Äù
    :PROPERTIES:
    :CUSTOM_ID: Lean-Proofs-for-metaprogramming
    :END:
  # Lean: lean_website,

  Lean citet:lean_system_desc,lean_formalizing_math is both a theorem prover and
  programming language; moreover it permits quotient types and so the
  usually-desired notion of extensional equality. It is primarily tactics-based,
  also permitting a ~calc~-ulational proof format not too dissimilar with the
  standard equational proof format utilised in Agda.

  # In our opinion, it is a nice language but we will remain with Agda since it
  # is a bit older, whence more stable, and it is also more syntactically pleasant.
  # citet:lean_website

  Lean is based on a version of the Calculus of Inductive Constructions, like
  Coq. It is heavily aimed at metaprogramming for formal verification, thereby
  bridging the gap between interactive and automated theorem proving.
  Unfortunately, inspecting the language shows that its rapid development is not
  backwards-compatible ---Lean 2 standard libraries have yet to be ported to Lean
  3---, and unlike, for example, Coq and Isabelle which are backed by other
  complete languages, Lean is backed by Lean, which is unfortunately too young to
  program various tactics, for example.

  :Other_remarks_on_Lean:
  The lean prover [[https://leanprover.github.io/introduction_to_lean/][tutorial]] is not even complete!

  It does not seem to be well docmented; only 1 file in the docs!
  It's been difficult finding anything superficially; I may need to install and try things out?
  :End:

*** COMMENT ATS ---‚ÄúDependent types for systems programming‚Äù
    :PROPERTIES:
    :CUSTOM_ID: ATS-Dependent-types-for-systems-programming
    :END:

  ATS, the Applied Type System citet:ats_website,ats_combining, is a language that
  combines programming and proving, but is aimed at unifying programming with
  formal specification. With the focus being more on programming than on proving.

  ATS is intended as an approach to practical programming with theorem proving.
  Its module system is largely influenced by that of Modula-3, providing what
  would today be considered the bare bones of a module system. Advocating a
  programmer-centric approach to program verification that syntactically
  intertwines programming and theorem proving, ATS is a more mature relative of
  Idris ---whereas Idris is Haskell-based, ATS is OCaml-based.

  # Unfortunately, ATS proofs are separate from implementation: One writes
  # a function /then/ writes a proof that it meets is specification.

  ATS is remarkable in that its performance is comparable to that of the C
  language, and it supports secure memory management by permitting type safe
  pointer arithmetic. In some regard, ATS is the fusions of OCaml, C, and
  dependent types. Its module system has less to offer than Coq's.

 # A (Not So Gentle) Introduction To Systems Programming In ATS
 # https://www.youtube.com/watch?v=zt0OQb1DBko

*** COMMENT {{{fstar}}} ---‚ÄúThe immature adult‚Äù
    :PROPERTIES:
    :CUSTOM_ID: fstar-The-immature-adult
    :END:
  The {{{fstar}}} citet:fstar_website language supports dependent types, refinement types,
  and a weakest precondition calculus. However it is primarily aimed at program
  verification rather than general proof. Even though this language is roughly
  nine years in the making, it is not mature ---one encounters great difficulty in
  doing anything past the initial language tutorial.
  # Language age ~ 9 years

  The module system of {{{fstar}}} is rather uninteresting, predominately acting
  as namespace management. It has very little to offer in comparison to Agda;
  e.g., within the last three years, it obtained a typeclass mechanism
  ---regardless, typeclasses can be simulated as dependent records.

  # The offical tutorial, https://rise4fun.com/fstar/tutorial,
  # gives only one syntactic item to deal with modules:
  # Module       m ::= module M tl1 ... tln ;; e [end]

  # http://complogic.cs.mcgill.ca/beluga/index.html
  #
*** COMMENT Beluga ---‚ÄúContext notation‚Äù :ignore:
    :PROPERTIES:
    :CUSTOM_ID: Beluga-Context-notation
    :END:

  The Beluga language has the distinctive feature of
  direct support for first-class contexts citet:beluga. A term ~t(x)~ may have free
  variables and so whether it is well-formed, or what its type could be, depends
  on the types of its free variables, necessitating one to either declare them
  before hand or to write, in Beluga, {{{newline}}} ~[ x ‚à∂ T |- t(x) ]~ for
  example. As argued in the previous section, contexts are essentially dependent
  sums.

  # As we have mentioned, and will reiterate a few times, contexts are
  # behaviourally indistinguishable from dependent sums.

  # Unlike the previously mentioned languages, Beluga provides a
  # dependently-typed language that supports specfiying formal systems in the
  # logical framework LF.

  # A displeasure of Beluga is that, while embracing the Curry-Howard Correspondence,
  # it insists on two syntactic categories: Data and computation.
  # This is similar to Coq's distinction of ~Prop~ and ~Type~.
  # Another issue is that to a large degree the terms one uses in their type
  # declarations are closed and so have an empty context therefore one sees
  # expressions of the form ~[ |- t ]~ since ~t~ is a closed term needing only the empty
  # context. At a first glance, this is only a minor aesthetic concern; yet after
  # inspection of the language's webpage, tutorials, and publication matter, it is
  # concerning that nearly all code makes use of empty contexts ---which are easily
  # spotted visually. The tremendous amount of empty contexts suggests that the language
  # is not actually making substantial use of the concept, or it is yet unclear what
  # pragmatic utility is provided by contexts, and, in either way,
  # they might as well be relegated to a less intrusive notation.
  # Finally, the language lacks any substantial standard libraries
  # thereby rendering it more as a proof of concept rather than a serious system
  # for considerable work.

  :Mizar_remarks:
  *Mizar*: Unlike the rest, it is based on (untyped) Tarski‚ÄìGrothendieck set theory
  which in some-sense has a ‚Äòhierarchy of sets‚Äô. Being based on set theory, it is non-constructive. It has a large library of formalised mathematics; like Coq.
  citet:mizar_website, mizar_overview, mizar_library.

  Like Idris, it provide a ‚Äòreservation‚Äô mechanism to name parameters for a block
  of code. Mizar ~environ~-ments are generally difficult to work with due to
  multiple namespaces for articles and vocabularies.
  There is otherwise nothing interesting to say regarding its module system.
  :End:

*** COMMENT Notable Mentions
    :PROPERTIES:
    :CUSTOM_ID: Notable-Mentions
    :END:
   The following are not actively being developed, as far we can tell from their
   websites or source repositories, but are interesting or have made useful
   contributions.

 + In contrast to Beluga, Isabelle is a full-featured language and logical
   framework that also provides support for named contexts in the form of
   ‚Äòlocales‚Äô citet:locales,isabelle_locales; unfortunately it is not a
   dependently-typed language ---though DTLs can be implemented in it.

 + Mizar, unlike the above, is based on (untyped) Tarski‚ÄìGrothendieck set theory
   which in some-sense has a hierarchy of sets. Like Coq, it has a large library of formalised mathematics
   citet:mizar_website,mizar_overview,mizar_library.

 + Developed in the early 1980s, Nuprl citet:prl_site is constructive with a
   refinement-style logic; besides being a mature language, it has been used to provide
   proofs of problems related to Girard's Paradox citet:girard_paradox.

 + PVS, Prototype Verification System citet:pvs_prover, differs from other DTLs
   in its support for subset types; however, the language seems to be unmaintained as of 2014.

 + Twelf citet:twelf_site is a logic programming language
   implementing Edinburgh's Logical \newline Framework
   citet:lf_meta_mechanisation,lf_has_isabelle,lf_fast_proof_checking
   and has been used to prove safety properties of ‚Äòreal languages‚Äô such as SML.
   A notable practical module system citet:lf_practical_modules for Twelf has been implemented using signatures and signature morphisms.

 + Matita citet:matita_main,matita_site is a Coq-like system that is much lighter citet:matita_is_coq_light;
   it is been used for the verification of a complexity-preserving C compiler.
   # Matita home page last updated 2017! *Eek!*
   # Twelf home page last updated 2015! *Eek!*

#+begin_edcomm org
:ed: WK

4.2.8: Isabelle and Mizar are certainly actively developed.
#+end_edcomm

 # *Matita*
 # last publication was 2012
 # website hasn't been updated since 2016
 # http://matita.cs.unibo.it/index.shtml

 # *NuPRL*
 # https://github.com/jonsterling/JonPRL
 # last touched 2-3 years ago!

 # *PVS*
 # not modified since 2014
 # http://pvs.csl.sri.com/

 # *Twelf* This is a logic programming language, similar to Prolog; it has been
 # used to formalise safety proofs for ‚Äòreal world‚Äô programming languages such
 # as Standard ML. Seems like that
 # Website hasn't been updated since 2009!
 # http://twelf.org/wiki/Main_Page

# https://github.com/jonsterling/JonPRL

*** COMMENT Closing                                                          :ignore:
    :PROPERTIES:
    :CUSTOM_ID: Closing
    :END:
Dependent types are mostly visible within the functional community, however this
is a matter of taste and culture as they can also be found in imperative
settings, citet:dtl_imperative, albeit less prominently.

:hide:
 On a closing note, lest the reader think  that dependent types are far
 from being incorporated into mainstream languages, we would like to
 point out that the ubiquitous JavaScript has been
 considered for the addition of dependent types! \cite{???}
 #
 # http://goto.ucsd.edu/~ravi/research/oopsla12-djs.pdf
 #
 # That paper is from 2012, are there any newer ones!?
:end:
*** Coq Modules as Generalised Signatures

[[Gls:module-systems][Module systems]] parameterise programs, proofs, and tactics over structures.  In
this section, we shall form a library of simple
#+latex: graphs\FOOTNOTE{
A *graph* models ‚Äúlines and dots on a page‚Äù; i.e., it is a tuple =(V, E, tgt, src)=
where sets =V= and =E= denote the dots (‚Äòvertices‚Äô) and lines (‚Äòedges‚Äô),
respectively, and the functions =src, tgt : E ‚Üí V= assign a ‚Äòsource‚Äô and a
‚Äòtarget‚Äô dot (vertex) to each line (edge); so we do not have any ‚Äúdangling
lines‚Äù: All lines on the page must be between drawn dots.  In a simple graph,
every edge is determine by its source and target points, so we can instead
present a graph as a /set/ =V= and a *dependent-type* =E : V √ó V ‚Üí Type= where =E x y=
denotes the collection of edges starting at =x= and ending at =y=. The code
fragments of this section use the second form, for brevity.
#+latex: }
to showcase how Coq's approach to packages is essentially in the same
#+latex: spirit\FOOTNOTE{
With this observation, it is only natural to wonder why Coq is not used as the
presentation language in-place of Agda. We could rationalise our choice with
technical attacks against Coq ---e.g., tactics are ‚Äòevil‚Äô since they render the
concept of ‚Äòproof‚Äô as secondary
\cite{purposes_of_proof,purposes_of_proof_detailed} --- but they would not
reflect reality: Coq is a delight to use, but Agda's community-adopted Unicode
support and our own experiences with it biased our choice.
#+latex: }
as the proposed definition of generalised signatures: A sequence of
name-type-definition tuples where the definition may be omitted. To make the Coq
accessible to readers, we will provide an Agda translation that only uses the
~record~ construct in Agda ---completely ignoring the ~data~ and ~module~ forms which
would otherwise be more natural in certain scenarios below--- in order to
demonstrate that /all packaging concepts essentially coincide in a DTL/.

    #+latex: \begin{tcolorbox}[colframe=red!75!black]
    Along the way, we refer to aspects of Agda that we found convenient and
    desirable that we chose it as a presentation language instead of Coq and
    other equally appropriate DTLs.
    #+latex: \end{tcolorbox}

   # Along the way, we shall flesh out our concerns regarding using Coq:
   # 1. Modules and their types are explicitly given their own language.
   #    - They have their own syntax.
   # 2. Tactics hide any insight in proofs, and decrease readability.

   # Agda packaging mechanisms will be given less attention, since they were
   # covered in previous sections.

*** A Brief Overview of Coq Modules, Part 1 :ignore:

    :Imports:
  #+BEGIN_SRC agda :tangle modules.agda
open import Relation.Nullary {- Decidablity! -}
open import Relation.Binary.PropositionalEquality
open import Data.Empty
open import Data.Sum
open import Data.Bool renaming (_‚â§_ to leb)
open import Data.Bool.Properties
--
--  f‚â§t : false ‚â§ true
--  b‚â§b : ‚àÄ {b} ‚Üí b ‚â§ b
#+END_SRC

#+BEGIN_SRC coq :tangle modules.v
Require Import Bool.
#+END_SRC

:End:

    In Coq, a ~Module Type~ contains the signature of the abstract structure to
    work from; it lists the ~Parameter~ and ~Axiom~ values we want to use, possibly
    along with notation declaration to make the syntax easier.  ( The naming in
    the following module, ~Graph~, is slightly inappropriate since connectedness
    is generally via paths not edges ---which are chosen for brevity. )

{{{code(Graphs ---Coq)}}}
  #+BEGIN_SRC coq :tangle modules.v
Module Type Graph.
  Parameter Vertex : Type.
  Parameter Edges : Vertex -> Vertex -> Prop.

  (* Obtain convenient syntactic sugar. *)
  Infix "<=" := Edges : order_scope.
  Open Scope order_scope.

  Axiom loops : forall e, e <= e.
  Parameter decidable : forall x y, {x <= y} + {not (x <= y)}.
  Parameter connected : forall x y, {x <= y} + {y <= x}.
End Graph.
#+END_SRC

 {{{code(Graphs ---Agda)}}}
#+BEGIN_SRC agda :tangle modules.agda
record Graph : Set‚ÇÅ where
  field
    Vertex    : Set
    _‚ü∂_       : Vertex ‚Üí Vertex ‚Üí Set
    loops     : ‚àÄ {e} ‚Üí e ‚ü∂ e
    decidable : ‚àÄ x y ‚Üí Dec (x ‚ü∂ y)
    connected : ‚àÄ x y ‚Üí (x ‚ü∂ y) ‚äé (y ‚ü∂ x)
#+END_SRC

Notice that due to Agda's support for mixfix Unicode lexemes, we are able to use
the evocative arrow notation ~_‚ü∂_~ for edges directly. In contrast, Coq uses ASCII
order notation /after/ the type of edges is declared. In contrast to Agda,
conventional Coq distinguishes between value parameters and proofs, thereby
using the keywords =Parameter= and =Axiom= to, essentially, accomplish the same
thing.

In Coq, to form an instance of the graph module type, we define a module that
satisfies the module type signature. The ~_<:_~ declaration requires us to have
definitions and theorems with the same names and types as those listed in the
module type's signature. In contrast, the Agda form below explicitly ties the
signature's named fields with their implementations, rather than inferring it.

#+latex: \begin{tcolorbox}[colframe=red!75!black, title=Birds' Eye View]
The following two snippets only serve to produce instances of graphs that can be
used in subsequent snippets, as such their details are mostly irrelevant.  They
are present here for the sake of completeness and we rely on the reader to
accept them for their overarching purpose ---namely, to demonstrate how Coq's
=Module Type='s are close in spirit to the previously discussed notion of
generalised signatures. For the curious reader, the next Coq snippet is
annotated with comments explaining the tactics.
#+latex: \end{tcolorbox}

#+begin_parallel

{{{code(Booleans are Graphs ---Coq)}}}
#+ATTR_LATEX: :options fontsize=\tiny
#+BEGIN_SRC coq :tangle modules.v
Module BoolGraph <: Graph.
  Definition Vertex := bool.
  Definition Edges  := fun x => fun y => leb x y.

  Infix "<=" := Edges : order_scope.
  Open Scope order_scope.

  Theorem loops: forall x : Vertex, x <= x.
    Proof.
    intros; unfold Edges, leb; destruct x; tauto.
    Qed.

  Theorem decidable: forall x y, {Edges x y} + {not (Edges x y)}.
    Proof.
      intros; unfold Edges, leb; destruct x, y.
      all: (right; discriminate) || (left; trivial).
  Qed.

  Theorem connected: forall x y, {Edges x y} + {Edges y x}.
    Proof.
      intros; unfold Edges, leb. destruct x, y.
      all: (right; trivial; fail) || left; trivial.
  Qed.
End BoolGraph.
#+END_SRC

:Details:
Let go through the proof of ~decidable~.
1. Œª-introduce the quantified variables ~x, y~ with ~intros~.
2. We rewrite the definition of ~Edges~ into the Boolean valued
   order on Booleans, then rewrite that definition as well.
3. We perform case analysis on ~x~ and on ~y~ with ~destruct~.
4. There are now a number of subgoals ---to find out which, one must interact
   with the system--- and so we use the ~all:~ tactic to provide a recipe to
   handle them.
   1. Try to prove the ~right~ part of the sum ~{x <= y} + {not (x <= y)}~;
   2. Otherwise, if we explicitly ~fail~, try to prove the ~left~ part.

In contrast, in Agda, we explicitly Œª-introduce the variables and immediately
perform case analysis; then use ~C-c C-a~ to have the cases automatically filled
it.
:End:

#+columnbreak:

{{{code(Booleans are Graphs ---Agda)}}}
#+ATTR_LATEX: :options fontsize=\tiny
#+BEGIN_SRC agda :tangle modules.agda
BoolGraph : Graph
BoolGraph = record
              { Vertex = Bool
              ; _‚ü∂_ = leb
              ; loops = b‚â§b
              -- I only did the case analysis, the rest was ‚Äúauto‚Äù.
              ; decidable = Œª{ true  true  ‚Üí yes b‚â§b
                             ; true  false ‚Üí no (Œª ())
                             ; false true  ‚Üí yes f‚â§t
                             ; false false ‚Üí yes b‚â§b }
              -- I only did the case analysis, the rest was ‚Äúauto‚Äù.
              ; connected = Œª{ true true   ‚Üí inj‚ÇÅ b‚â§b
                             ; true false  ‚Üí inj‚ÇÇ f‚â§t
                             ; false true  ‚Üí inj‚ÇÅ f‚â§t
                             ; false false ‚Üí inj‚ÇÅ b‚â§b }
              }
#+END_SRC

#+end_parallel

We are now in a position to write a ‚Äúmodule functor‚Äù: A module that takes some
~Module Type~ parameters and results in a module that is inferred from the
definitions and parameters in the new module; i.e., a parameterised module.
E.g., here is a module that defines a minimum function.

{{{code(Minimisation as a function on modules ---Coq)}}}
#+BEGIN_SRC coq :tangle modules.v
Module Min (G : Graph).
  Import G. (* I.e., open it so we can use names in unquantifed form. *)
  Definition min a b : Vertex := if (decidable a b) then a else b.
  Theorem case_analysis: forall P : Vertex -> Type, forall x y,
        (x <= y -> P x) -> (y <= x -> P y) -> P (min x y).
  Proof.
    intros. (* P, x, y, and hypothesises H‚ÇÄ, H‚ÇÅ now in scope*)
    (* Goal: P (min x y) *)
    unfold min. (* Rewrite ‚Äúmin‚Äù according to its definition. *)
    (* Goal: P (if decidable x y then x else y) *)
    destruct (decidable x y). (* Case on the result of decidable *)
    (* Subgoal 1: P x  ---along with new hypothesis H‚ÇÉ : x ‚â§ y *)
    tauto. (* i.e., modus ponens using H‚ÇÅ and H‚ÇÉ *)
    (* Subgoal 2: P y  ---along with new hypothesis H‚ÇÉ : ¬¨ x ‚â§ y *)
    destruct (connected x y).
    (* Subgoal 2.1: P y ---along with new hypothesis H‚ÇÑ : x ‚â§ y *)
    absurd (x <= y); assumption.
    (* Subgoal 2.2: P y ---along with new hypothesis H‚ÇÑ : y ‚â§ x *)
    tauto. (* i.e., modus ponens using H‚ÇÇ and H‚ÇÑ *)
  Qed.
End Min.
#+END_SRC

=Min= is a function-on-modules; the input type is a =Graph= value and the output
module's type is inferred to be:
# | =Sig Definition min : ‚ãØ. Parameter case_analysis: ‚ãØ. End= |
{{{code(Type of module ‚ÄòMin‚Äô)}}}
#+BEGIN_SRC coq :tangle modules.v
Module Type (G : Graph).
  Import G.
  Definition min a b : Vertex := if (decidable a b) then a else b.
  Parameter case_analysis: forall P : Vertex -> Type, forall x y,
        (x <= y -> P x) -> (y <= x -> P y) -> P (min x y).
End Min.
#+END_SRC
# See https://github.com/alhassy/CoqCheatSheet/blob/master/CheatSheet.org#coq-modules
# This is similar to JavaScript's approach.

# ocaml:
#
# Just as Œ†-types have values constructed with Œª, so too src_coq[:exports
# code]{Module Type}s have their values constructed with src_coq[:exports
# code]{sig ‚Ä¶ end} ---then one implements a module type œÑ using a phrase of the
# form src_coq[:exports code]{module x : œÑ = struct ‚Ä¶ end}.

In contrast, Agda has no notion of signature, and so the declaration below only
serves as a /namespacing/ mechanism that has a parameter over-which new programs
and proofs are abstracted ---the primary purpose of module systems mentioned
earlier. Notice that the Agda record below has /no/ fields.

{{{code(Minimisation as a function on modules ---Agda)}}}
#+BEGIN_SRC agda :tangle modules.agda
record Min (G : Graph) : Set where
  open Graph G

  min : Vertex ‚Üí Vertex ‚Üí Vertex
  min x y with decidable x y
  ...| yes _  = x
  ...| no  _  = y

  case-analysis : ‚àÄ {P : Vertex ‚Üí Set} {x y}
                ‚Üí (x ‚ü∂ y  ‚Üí  P x)
                ‚Üí (y ‚ü∂ x  ‚Üí  P y)
                ‚Üí P (min x y)
  case-analysis {P} {x} {y} H‚ÇÄ H‚ÇÅ with decidable x y | connected x y
  ... | yes x‚ü∂y | _          = H‚ÇÄ x‚ü∂y
  ... | no ¬¨x‚ü∂y | inj‚ÇÅ x‚ü∂y = ‚ä•-elim (¬¨x‚ü∂y x‚ü∂y)
  ... | no ¬¨x‚ü∂y | inj‚ÇÇ y‚ü∂x = H‚ÇÅ y‚ü∂x

open Min
#+END_SRC

Let's apply the so called module functor. The ~min~ function, as shown in the
comment below, now specialises to the carrier of the Boolean graph.
# {{{code(Applying a function on modules, part I ---Coq)}}}
{{{code(Applying module-to-module functions (part I) ---Coq)}}}
#+BEGIN_SRC coq :tangle modules.v
Module Conjunction := Min BoolGraph.
Export Conjunction.
Print min.
(*
min =
fun a b : BoolGraph.Vertex => if BoolGraph.decidable a b then a else b
     : BoolGraph.Vertex -> BoolGraph.Vertex -> BoolGraph.Vertex
 ,*)
#+END_SRC

In the Agda setting, we can prove the aforementioned observation: The module is
for namespacing /only/ and so it has no non-trivial implementations.
{{{code(Applying module-to-module functions (part I) ---Agda)}}}
#+BEGIN_SRC agda :tangle modules.agda
Conjunction = Min BoolGraph

uep : ‚àÄ (p q : Conjunction) ‚Üí p ‚â° q
uep record {} record {} = refl

{- ‚Äúmin I‚Äù is the specialisation of ‚Äúmin‚Äù to the Boolean graph -}
_ : Bool ‚Üí Bool ‚Üí Bool
_ = min I where I : Conjunction; I = record {}
#+END_SRC

Unlike the previous functor, which had its return type inferred, we may
explicitly declare a return type. E.g., the following functor is a ~Graph ‚Üí Graph~
function.
{{{code(A module-to-module function ---Coq)}}}
#+BEGIN_SRC coq :tangle modules.v
Module Dual (G : Graph) <: Graph.
  Definition Vertex := G.Vertex.
  Definition Edges  x y : Prop := G.Edges y x.
  Definition loops := G.loops.
  Infix "<=" := Edges : order_scope.
  Open Scope order_scope.
  Theorem decidable: forall x y, {x <= y} + {not (x <= y)}.
    Proof.
      unfold Edges. pose (H := G.decidable). auto.
  Qed.
  Theorem connected: forall x y, {Edges x y} + {Edges y x}.
    Proof.
      unfold Edges.  pose (H := G.connected). auto.
  Qed.
End Dual.
#+END_SRC
Agda makes it clearer that this is a module-to-module function.
{{{code(A module-to-module function ---Agda)}}}
#+BEGIN_SRC agda :tangle modules.agda
Dual : Graph ‚Üí Graph
Dual G = let open Graph G in record
           { Vertex    = Vertex
           ; _‚ü∂_       = Œª x y ‚Üí  y ‚ü∂ x
           ; loops     = loops
           ; decidable = Œª x y ‚Üí decidable y x
           ; connected = Œª x y ‚Üí connected y x
           }
#+END_SRC

An example use would be renaming ‚Äúmin ‚Ü¶ max‚Äù ---e.g., to obtain meets from
joins.
{{{code(Applying module-to-module functions (part II) ---Coq)}}}
#+BEGIN_SRC coq :tangle modules.v
Module Max (G : Graph).
  (* Module applications cannot be chained;
     intermediate modules must be named. *)
  Module DualG   := Dual G.
  Module Flipped := Min DualG.
  Import G.
  Definition max := Flipped.min.
  Definition max_case_analysis:
        forall P : Vertex -> Type, forall x y,
        (y <= x -> P x) -> (x <= y -> P y) -> P (max x y)
        := Flipped.case_analysis.
End Max.
#+END_SRC

{{{code(Applying module-to-module functions (part II) ---Agda)}}}
#+BEGIN_SRC agda :tangle modules.agda
record Max (G : Graph) : Set where
  open Graph G
  private
    Flipped = Min (Dual G)
    I : Flipped
    I = record {}

  max : Vertex ‚Üí Vertex ‚Üí Vertex
  max = min I

  max-case-analysis : ‚àÄ {P : Vertex ‚Üí Set} {x y}
                ‚Üí (y ‚ü∂ x  ‚Üí  P x)
                ‚Üí (x ‚ü∂ y  ‚Üí  P y)
                ‚Üí P (max x y)
  max-case-analysis = case-analysis I
  #+END_SRC

Here is a table summarising the two languages' features, along with JavaScript
as a position of reference.
#+caption: Signatures and structures in Coq, Agda, and JavaScript
|            |   | Signature     | Structure      |
|------------+---+---------------+----------------|
| Coq        |   | ‚âà module type | ‚âà module       |
| Agda       |   | ‚âà record type | ‚âà record value |
| JavaScript |   | ‚âà prototype   | ‚âà JSON object  |

It is perhaps seen most easily in the last entry in the table, that modules and
modules types are essentially the same thing: They are just partially defined
record types. Again there is a *difference in the usage intent*:

#+caption: Modules and module types only differ in intended utility
| Concept      | Intent                             |
|--------------+------------------------------------|
| Module types | Any name may be opaque, undefined. |
| Modules      | All names must be fully defined.   |

*** COMMENT A Brief Overview of Coq Modules, Part 2

  Coq modules are essentially Agda records ---which is unsurprising since our
  thesis states packaging containers are all essentially the same. In more
  detail, both notions coincide with that of a gls:signature ---a sequence of
  pairs of name-type declarations. Where Agda users would speak of a /record
  instance/, Coq users would speak of a /module implementation/. To make matters
  worse, Coq has a notion of records which are far weaker than Agda's; e.g., by
  default all record field names are globally exposed and records are
  non-recursive.

  Coq's module system extends that of OCaml; a notable divergence is that Coq
  permits parameterised module types ---i.e., parameterised record types, in
  Agda parlance. Such module types are also known as ‚Äòfunctors‚Äô by Coq and OCaml
  users; which are ‚Äúgenerative‚Äù: Invocations generate new datatypes. Perhaps an
  example will make this rather strange concept more apparent.

  #+begin_parallel
  {{{code(Example of Generative Functors)}}}
# (* Coq has generative modules: Each application produces a new datatype instance. *)
# Module Type Unit. End Unit. (* Empty signature *)
# Module TT <: Unit. End TT.  (* Empty structure *)
#+BEGIN_SRC coq :tangle generatives.v
Module Type Unit. End Unit.
Module TT <: Unit. End TT.

Module F (X : Unit).
  Inductive t : Type := MakeT.
End F.

Module A := F TT.
Module B := F TT.
Fail Check eq_refl : A.t = B.t.
#+END_SRC
# Print A.t.
# (* ‚áí Inductive t : Prop :=  MakeT : A.t *)

  {{{code(Corresponding Agda Code)}}}
#+begin_src agda :tangle generatives.agda :prologue open import Relation.Binary.PropositionalEquality
record Unit : Set where
tt : Unit; tt = record {}

module F (X : Unit) where
  data t : Set where MakeT : t

module A = F tt
module B = F tt

eq : A.t ‚â° B.t
eq = refl
  #+end_src
  #+end_parallel

  As seen, in Coq the inductive types are different yet in Agda they are the
  same. This is because Agda treats such parameterised records, or functors, as
  ‚Äòapplicative‚Äô: They can only be applied, like functions. Coq's modules
  Œ∑-expand and so aliasing does nothing, but functors do not Œ∑-reduce, and as
  such one cannot expect them to be applicative, and so are generative.
  :Details:
#+BEGIN_SRC coq :tangle generatives.v
Module Type Carrier. Parameter t : Type. End Carrier.
Module Nat <: Carrier. Definition t := nat. End Nat.

Module Type Morphism (X : Carrier) <: Carrier. Parameter t : Type. End Morphism.
Module Identity (X : Carrier) <: Morphism X. Definition t := X.t. End Identity.

Module Alias  (X : Carrier). Module M := X. End Alias.
Module AtNat  (F : Morphism). Module M := F Nat. End AtNat.

Module N := Alias Nat.
Print N.M.t.
(* N.M.t = Nat.t
     : Type

Modules Œ∑-expand and so aliasing does nothing.
 ,*)

Module O := AtNat Identity.
Print O.M.t.
(*
[ O.M.t : Type ] ; i.e., an opaque type

Type of functors do not Œ∑-reduce, and as such one cannot expect them to be applicative, and so are generative ^_^
*)
  #+END_SRC
:End:

  For simplicity, we may think of generative functor applications ~F X~ as
  actually ~F X t~ where ~t~ is an implicit tag such as textual position or clock
  time. From an object-oriented programming perspective, ~F X~ for a generative
  functor ~F~ is like the ~new~ keyword in Java/C#: A new instance is created which
  is distinct from all other instances even though the same class is utilised.
  So much for the esotericity of generative functors.

  Unlike Agda, which uses records to provide traditional record types, Haskell-like
  typeclasses, and even a module perspective of both, Coq utilises distinct
  mechanisms for typeclasses and canonical structures. In contrast, Agda allows
  named instances since all instances are named and can be provided where an
  implicit failed to be found. Moreover, Coq's approach demands greater familiarity
  with the unifer than Agda's approach.
  # Coq typeclasses are nearly the same as Haskell's.
  # https://softwarefoundations.cis.upenn.edu/qc-current/Typeclasses.html

  # Nifty slides: ‚ÄúWhy Applicative Functors Matter‚Äù
  # https://www.cs.ox.ac.uk/ralf.hinze/WG2.8/24/slides/derek.pdf
** ADTs as ùí≤-types

<<sec:W-types>>
# +latex: \label{sec:W-types}

#+latex: \label{sec:W_types}

Earlier in the chapter we demonstrated the interdefinability of various
structuring mechanisms; yet, there are  times when it would be prudent
to have the /syntax/ of a concept (such as monoid) in hand so as to, say,
generate terms of that type or to simplify them as follows.

{{{code(A syntax for ùïÑonoid terms)}}}
#+begin_src agda
-- ùïÑonoid terms over carrier C
data ùïÑ (C : Set) : Set where
  inj : C ‚Üí ùïÑ C
  Id : ùïÑ C
  _‚®æ_ : ùïÑ C ‚Üí ùïÑ C ‚Üí ùïÑ C

-- If x and y are in simplified form, then so is x ‚®æ‚Ä≤ y
_‚®æ‚Ä≤_ : {C : Set} ‚Üí ùïÑ C ‚Üí ùïÑ C ‚Üí ùïÑ C
Id ‚®æ‚Ä≤ y = y
x ‚®æ‚Ä≤ Id = x
x ‚®æ‚Ä≤ y  = x ‚®æ y

-- Discard as much Id‚Äôs as possible
simplify : {C : Set} ‚Üí ùïÑ C ‚Üí ùïÑ C
simplify (a ‚®æ b) = simplify a  ‚®æ‚Ä≤ simplify b
simplify it = it

popId : ‚àÄ {C} {x y  : ùïÑ C}   ‚Üí   simplify (x ‚®æ (Id ‚®æ y))  ‚â°  simplify (x ‚®æ y)
popId = refl
#+end_src

Records and typeclasses have a similar shape --- as quantifiers $ùí¨ x : A ‚Ä¢ B\,
x$ --- and if we want to interpret contexts as grammars, we should use a similar
shape as well. Discussing such a shape is the goal of this section.

*** When does ~data~ actually define a type?

Grammars, =data= declarations, /describe/ the /smallest/ language that has the
constructors as words. What if no such language exists?  Indeed, not all
grammars are ‚Äòsensible‚Äô in that they define a language.  For instance, ~One~ below
is a language of only *one word*, =MakeOne=; whereas =None= is a language with *no
words*, since to form a phrase =MakeNone n= first requires we form =n=, which leads
to infinite regress, and so there are no /finite/ words. Even worse, ~What~
describes no language at all ---which Agda barks as being /not strictly positive/.
  # An inductive type must live in a universe that already contains all the
  # types going into its definition, but if type ùëª requires the type ùëª ‚Üí ùëª in
  # its definition, then we have a size issue ---whenever $ùëª : \Type_‚Ñì$ we have
  # $(ùëª ‚Üí ùëª) : \Type_{‚Ñì + 1}$.  (footnote 1 hott !!!!)  While =N= and =No= could
  # be represented using pairs, as discussed earlier, ---=N= with /one/ pair,
  # =No= with one pair function and /no/ pairs--- the =Noo= language is worse
  # since it has no possible representation, using pairs or otherwise.

 # | covariant     | negative | input  |
 # | contravariant | positive | output |

{{{code( Describing Possibly Non-Existent Languages )}}}
#+begin_src agda
data One : Set where
  MakeOne : One

data None : Set where
  MakeNone : None ‚Üí None

data What : Set where
 MakeWhat : (What ‚Üí What) ‚Üí What
#+end_src

Recall that $\;(A ‚Üí B) \;=\; Œ† \,\_{} : A ‚Ä¢ B\;$ and, when $A$ is finite , $\;(A ‚Üí B)
\;‚âÖ\; \left(Œ† \,\_{} : A ‚Ä¢ B\right) \;‚âÖ\; B^{|A|}$.  As such, a function ~What ‚Üí What~,
above, is ~What~-many arguments, each of type ~What~. But how many arguments is that
exactly? We need to actually know the type ~What~, which is the type being
defined.  As such, the above ~data~ does not actually define any type.

*** ùí≤

How do we know whether a grammar describes a language that /actually exists/?
Suppose =T= is defined by $n$ constructors =C·µ¢ ‚à∂ œÑ·µ¢(T) ‚Üí T=, which may mention =T= in
their payload =œÑ·µ¢(T)=. Then we have a type operation =ùë≠ X = (Œ£ i ‚à∂ Fin n ‚Ä¢ œÑ·µ¢(X))=,
where =Fin n= is the type of natural numbers less than =n=. The type =T= describes a
language =X= that /contains/ all the constructors; i.e., ‚Äúit can distinguish the
constructors, along with their payloads‚Äù; i.e., there is a method =ùë≠ X ‚Üí X= that
shows how the descriptive constructors =ùë≠ X= can be viewed as values of =X=.  More
concretely, the type ~One~ above has one constructor =MakeOne= which takes an empty
tuple of arguments, denoted {{{mbox(=ùüô = { () }=)}}}, and so it has =ùë≠ X ‚âÖ ùüô= and so
=(ùë≠ X ‚Üí X) ‚âÖ (ùüô ‚Üí X) ‚âÖ X=; whence any non-empty collection =X= is described by ùë≠;
but the *smallest* such language is a singleton language with one element that we
call =MakeOne=. *ADTs describe the smallest languages generated by their
constructors*.

#+latex: \begin{tcolorbox}[colframe=red!75!black, title=Important Observation]
Recall that we earlier observed that Œ† and Œ£ could be thought of as way to
interpret a contextual judgement; so too a judgement $Œì ‚ä¢ t : œÑ$ could be
interpreted as a term $t : œÑ$ in the presence of the ADT described by some $ùë≠$
which is obtained by treating all (or a select set of) names of Œì as constructors.

#+latex: \vspace{1ex}
Indeed, ùí≤-types (introduced below) are essentially generalised signatures: =ùí≤ A B=
has =A= as ‚Äòfunction symbols‚Äô and each symbol =f ‚à∂ A= has ‚Äòargument type‚Äô =B f=.
ùí≤-types are not generalised signatures since they do not support optional
definitions; which is a minor technicality: If $t$ has the associated definition
=d=, then we may use ‚Äú =let t = d in ùí≤ ‚ãØ= ‚Äù and repeated =let= clauses solve the issue
of optional definitions.

# #+latex: \vspace{1ex}
# The generic situation of ‚Äòcontainers‚Äô is described in
# citet:DBLP:journals/jfp/AltenkirchGHMM15.
#+latex: \end{tcolorbox}
#

Notice that we have again encountered the problem of a syntax that is ‚Äútoo
powerful‚Äù for the concepts it denotes: We can declare grammars (ADTs) that do
not describe /any/ language. Since a grammar consists of a number of /disjoint/
(‚ÄúŒ£‚Äù) constructor clauses that take a /tuple/ (‚ÄúŒ†‚Äù) of arguments, it suffices to
consider when
#+latex: ‚Äúpolynomial‚Äù\FOOTNOTE{
Using exponential notation $Q^P = (P ‚Üí Q)$ along with subscript notation yields
$ùë≠\, X = Œ£_{a : A} X^{B\, a}$, which is the shape of a polynomial. These
notations and names are standard.
#+latex: }
descriptions @@latex: \newline@@ =ùë≠ X = (Œ£ a ‚à∂ A ‚Ä¢ Œ† b ‚à∂ B a ‚Ä¢ X)= actually
describe a language. That is, when is there a function $ùë≠\, X ‚Üí X$ and what is
the /smallest/ $X$ with such a function?  The values of $ùë≠\, X$ are pairs $(a, f)$
where $a : A$ and $f : B\, a ‚Üí X$; so we may take the collection of /only/ such
pairs to be the language described by ùë≠, and it is thus the smallest such
collection.  This language is called a *ùí≤-type*.

#+latex: \begin{tcolorbox}[colframe=red!75!black, title=Descriptions of Languages That Necessarily Exist]

=(ùí≤ a ‚à∂ A ‚Ä¢ B a)= is the type of well-founded trees
with node ‚Äúlabels from $A$‚Äù and each node having ‚Äú$B\, a$ many possible children
trees‚Äù.  That is, it is the (inductive) language/type whose /constructors/ are
indexed by elements $a : A$, each with arity $B\, a$.

# An element sup(r, s) of W x : A ‚Ä¢ B x is a tree with label r and subtrees s(b)
#   for b : B(r). The elements of W A B are therefore trees with branching degrees
#   (B a)_{a : A}.

{{{code(ùí≤-types in Agda)}}}
#+begin_src agda
-- The type of trees with B-branching degrees
data ùí≤ (A : Set) (B : A ‚Üí Set) : Set where
  sup : (a : A) ‚Üí (B a ‚Üí ùí≤ A B) ‚Üí ùí≤ A B
#+end_src

In particular, =ùí≤ ùíæ ‚à∂ Fin n ‚Ä¢ B ùíæ= is essentially the =data= declaration of =n=
constructors where the ùíæ-th constructor takes arguments of ‚Äòshape‚Äô =B ùíæ=.
#+latex: \newline
E.g., in Agda syntax, =‚Ñï ‚âÖ ùí≤ (Fin 2) Œª{zero ‚Üí Fin 0; (suc zero) ‚Üí Fin 1}=.
#+latex: \end{tcolorbox}

Categorically speaking, polynomial functors ---i.e., type formers of the shape =ùë≠
X = Œ£ a ‚à∂ A ‚Ä¢ Œ† b ‚à∂ B a ‚Ä¢ X=, ‚Äúsums of products‚Äù or a ‚Äúdisjoint union of possible
constructors and their arguments‚Äù--- have ‚Äúinitial algebras‚Äù named =ùëæ = (ùí≤ a ‚à∂ A
‚Ä¢ B a)=, which are the smallest languages described by ùë≠.  That is, ùí≤-types are
the initial algebras of polynomial functors; that is, =ùë≠= has an initial algebra
src_agda[:exports code]{sup : ùë≠ ùëæ ‚Üí ùëæ}.  Moreover, every strictly positive type
operator
#+latex: can\footcitet{Dybjer_1997}$^,$\footcitet{DBLP:conf/icalp/AbbottAG04}$^,$\footcitet{hottbook}$^,$\footcitet{emmenegger18:_w}
be expressed in the same shape as ùë≠ and so they all have an initial
algebra. Inductive families arise as indexed ùí≤-types which are initial algebras
for dependent polynomial functors, and Gambino et al\footcitet{Gambino_2004}
have shown them to be constructible from non-dependent ones in locally cartesian
closed categories. That is, indexed ùí≤-types can be obtained from ordinary
ùí≤-types.  See also
# Dybjer's
# [[https://www.sciencedirect.com/science/article/pii/S0304397596001454?via%3Dihub][‚ÄúRepresenting inductively defined sets by wellorderings in Martin-LoÃàf's type theory‚Äù]].
# See On Relating Indexed W-Types with Ordinary Ones by Christian Sattler

*** ùí≤-types generalise trees

To further understand ùí≤-types ---and to justify the name $\sup$!---, consider
the type =Rose A= of ‚Äúmulti-branching trees with leaves from $A$‚Äù. /ùí≤-types
generalise the idea of rose trees:/ Each list of children trees =xs ‚à∂ List (Rose
A)= can be
#+latex: equivalently\FOOTNOTE{
Since every functon =Fin n ‚Üí X= can be ‚Äòtabulated‚Äô as a =List X= value of
      length =n= @@latex: \newline@@ ---i.e., =(Œ£ xs ‚à∂ List A ‚Ä¢ length xs ‚â° n) ‚âÖ (Fin n ‚Üí A)=--- we have
      that =Rose' A ‚âÖ Rose A=.
#+latex: }
replaced by
a /tabulation/ =cs ‚à∂ Fin (length xs) ‚Üí Rose A= that tells the ùíæ-th child of =xs=.
That is, *ùí≤-types are trees with branching degrees $(B\, a)_{a : A}$.*
# The elimination rule for the W-type formalises induction over trees.

{{{code(Rose trees)}}}
#+begin_src agda
data Rose (A : Set) : Set where
  Node : (parent : A) (children : List (Rose A)) ‚Üí Rose A

example : Rose ‚Ñï
example = MkRose 0  (MkRose 1 (MkRose 3 [] ‚à∑ [])
                   ‚à∑ MkRose 2 (MkRose 4 [] ‚à∑ []) ‚à∑ [])
#+end_src
The =example= tree is shown diagrammatically below.
#+begin_src dot :file images/rose-example.png
digraph {0 -> 1;
            1 -> 3;
       0 -> 2;
            2 -> 4;
       rankdir=LR;  //Rank Direction Left to Right
       }
#+end_src

#+attr_latex: :width 5cm
#+RESULTS:
[[file:images/rose-example.png]]

We can easily recast the =Rose= type and the example as a ùí≤-type.  In particular,
notice that in the construction of =example'=, each node construction =sup (a, n) cs=
indicates that the label is =n= and the number of children the node has is =n=.
That is, the choice of using lists or vectors in the design of =Rose= is forced to
being (implicitly and essentially) vectors in the construction of =Rose'=.
#+begin_src agda
Rose' : Set ‚Üí Set
Rose' A = ùí≤ (A √ó ‚Ñï) Œª{ (a , ‚ôØchildren)  ‚Üí Fin ‚ôØchildren }

example' : Rose' ‚Ñï
example' = sup ((0 , 2))
             Œª { zero       ‚Üí sup (1 , 1) Œª {zero ‚Üí sup (3 , 0) Œª ()}
               ; (suc zero) ‚Üí sup (2 , 1) Œª {zero ‚Üí sup (4 , 0) Œª ()}}
#+end_src

Similar to rose trees, =ùí≤ a ‚à∂ Fin n ‚Ä¢ Fin 0= is an enumerated type having =n=
constants, such as the Booleans.  That is, if =B a= is empty for all =a=, then trees
in =ùí≤ a ‚à∂ A ‚Ä¢ B a= have no subtrees, and hence have ‚Äòheight‚Äô 0.

#+latex: \def\child{\mathsf{child}}
#+latex: \def\Fin{\mathsf{Fin}\,}
#+latex: \def\length{\mathsf{length}\,}

The /height/ of a tree, is an ordinal, and is defined to be the
#+latex: supremum\FOOTNOTE{
The supremum of the empty set of natural numbers is, by definition, 0.
\[\sup ‚àÖ = 0\]
Hence, if any (child) tree is empty, then its height is 0.
#+latex: }
---i.e., the least upper bound--- of the height of its elements: \[
\mathsf{height}\, (\sup\, a\, \mathsf{child}) \;=\; \sup_{i : B\, a} \,
\left(\mathsf{height}\, (\mathsf{child}\, i) + 1\right) \] This may be reason
why the only constructor of ùí≤-types is named =sup=.  Indeed, we may interpret $\;ùí≤
a : A ‚Ä¢ B\, a\;$ as the least upper bound of all languages (ordered by language
inclusion) that contain terms ‚Äú ~f(args)~ ‚Äù where $f : A$ is a ‚Äòfunction symbol‚Äô
and $args : B\, f$ is an ‚Äòappropriately-shaped argument‚Äô ---e.g., concrete terms
‚Äú ~f(t‚ÇÄ, t‚ÇÅ, ‚Ä¶, t‚Çô)~ ‚Äù are an instance of this idea, as witnessed by $\sup \, f \,
\child_f$ with $\child_f : \Fin (\length f) ‚Üí \Term$ defined by $\child_f(i) =
t·µ¢$.

In contrast, =ùí≤ a ‚à∂ A ‚Ä¢ Fin n= is a data type with =A=-many clauses that /each/ make =n=
recursive calls; this is an /empty type/ since every construction requires =n= many
existing constructions ---however, it is still a type, unlike =Noo= above.  That
#+latex: is\FOOTNOTE{
A ùí≤-type is empty precisely when it has no nullary constructor;
#+latex: see exercise 5.17 of \cite{hottbook}.
#+begin_center
      =¬¨(ùí≤ a : A ‚Ä¢ B a) ‚âÖ ¬¨ (Œ£ a : A ‚Ä¢ ¬¨ B a)=
#+end_center
#+latex: },
if =B a= is non-empty for all =a=, then =ùí≤ a ‚à∂ A ‚Ä¢ B a= is empty, since in
order to form an element =sup a c=, we need to have defined before-hand =c(b) ‚à∂ (ùí≤
a ‚à∂ A ‚Ä¢ B a)= for each one of the elements =b= of =B a=.

# Unlike generalised signatures which do not possess a singular
# semantics, Agda =data= declarations are pleasant way to write ùí≤-types.
** Œ†Œ£ùí≤ Semantics for Contexts
#+latex: \label{sec:semantics_for_contexts}

Parameterised Agda modules (and records) are contexts ---i.e., Coq modules---
that have all their parameters first then followed by only by named symbols that
must have term definitions.  These are a mixture of Œ† and Œ£ types: The
parameters are captured by a Œ† type and the defined named are captured by
Œ£-types as in ‚Äú =Œ† parameters ‚Ä¢ Œ£ body= ‚Äù.  (In general, since Coq modules allow
parameters to occur /after/ locally defined names, one could use ~let~-clauses to
mimic such an approach with Œ†-Œ£-types.) /Were/ it possible, dynamically
on-the-fly, to only request a subsegement of the parameters list then we have a
solution to the unbundling problem. Moreover, as we will show, contexts can also
be furnished with ùí≤ semantics to obtain a termtype for the structure being
defined ---this is one of our primary contributions.

*A quick recap of how Œ†, Œ£, ùí≤ serve programming: ‚ÄúŒ†‚Äù* Product types are the
essence of structured data ---all languages have some form of product type, such
as /record, class, struct, object, JSON object, hashmap/.  @@ignore: ( The unit
type is sometimes, confusingly, called /void/ to communicate that a value has /no
interesting information/ ---and /not/ that the type is void, empty! )@@ *‚ÄúŒ£‚Äù* Most
data structures involve alternatives, choice, which is expressed by sum types
---a value of a sum type is thus used (‚Äòeliminated‚Äô) by case analysis.
@@ignore: For instance, the nullary sum represents no choice and so has no
introductory forms: ‚ÄúThere is nothing to choose from, so there is no way to make
such an (impossible) choice.‚Äù  As such, if somehow we have an (impossible) value
of the empty type then any attempt to actually ‚Äúlook at it‚Äù (evaluation) would
‚Äúcause the program to abort‚Äù.@@ Perhaps the simplest example of a sum type is
the type of truth values: Acting depends on whether a particular condition is
$\true$ /or/ $\false$.  The eliminator (‚Äúhow to use the Boolean‚Äù) for the Booleans
is the familiar ~if‚Ä¶then‚Ä¶else~ construct.  More generally, sum types may be used
to define /finitely enumerated types/, the types whose values are of an explicitly
declared set and whose elimination form (‚Äúhow to use them‚Äù) is case analysis.
For instance, the cardinal directions ---~Up, Down, Left, Right~--- are an
enumerated type that may be useful in an system requiring navigation, whereas
the type ~Maybe œÑ ‚à∑= Just œÑ | Nothing~ models /pointers to values of type œÑ/. Notice
that ~Maybe œÑ~ is an enumerated type where /its values may hold values of œÑ/
---these are alternatives with a ‚Äòpayload‚Äô: Indeed, ~Maybe œÑ ¬†‚âÖ¬†œÑ + ùüô~.  *‚Äúùí≤‚Äù* Next,
one wonders, can we have an enumerated type whose values may involve other
values of the type being defined: Enter inductive types; which are captured by
ùí≤-types.

For brevity we will work with the polymorphic lambda calculus, ‚ÄòSystem F‚Äô, whose
terms are as follows ---assuming a given set of variable $\mathsf{Name}s$.
#+begin_export latex
\[\begin{array}{lcll}
\mathsf{Term} &::=& x & \text{(variable, an element of $\mathsf{Name}$)} \\
              & | & \lambda x ‚Ä¢ e & \text{(lambda abstraction)} \\
              & | & f\, e & \text{(application)} \\
              & | & Œ† x : A ‚Ä¢ B & \text{(dependent function type)} \\
              & | & \Type_i & \text{(\(i\)th universe; $i$ = 0, 1, 2, ...)} \\
\end{array}\]
#+end_export
We may then takes /types/ to be the terms that /describe/ other terms; as such,
there is one grammar for both Rather than two grammars.

Type constructions $T : \Type ‚Üí \Type$ give algebraic data types ---‚Äúinitial
algebras‚Äù--- $I$ satisfying $I ‚âÖ T(I)$ by the definition $I \;=\; Œ†\, X : \Type
‚Ä¢ (T\, X ‚Üí X) ‚Üí X$.  We use this idea to regain the other useful type formers;
e.g., for ùí≤-types we have $T\, X \;=\; Œ£\, a : A ‚Ä¢ (B\, a ‚Üí X)$ and so ùí≤-types
are encoded as $Œ† X : \Type ‚Ä¢ ((Œ£\, a : A ‚Ä¢ (B\, a ‚Üí X)) ‚Üí X))‚Üí X$, or
equivalently ---using Œ£-elimination--- as $Œ†\, X : \Type ‚Ä¢ (Œ†\, a : A ‚Ä¢ Œ£\, f :
B\, a ‚Üí X ‚Ä¢ X) ‚Üí X$.

| Type            | Encoding                                                |
|-----------------+---------------------------------------------------------|
| ùüò               | $Œ†\, X : \Type ‚Ä¢ X$                                     |
| ùüô               | $Œ†\, X : \Type ‚Ä¢ (X ‚Üí X)$                               |
| $A ‚Üí B$         | $Œ†\, \_{} : A ‚Ä¢ B$                                      |
| $A √ó B$         | $Œ†\, i : \Fin 2 ‚Ä¢ Œª\{0 ‚Üí A, 1 ‚Üí B\}\, i$                |
| $Œ£\, x : A ‚Ä¢ B$ | $Œ†\, X : \Type ‚Ä¢ (Œ†\, x : A ‚Ä¢ Œ†\, y : B ‚Ä¢ X) ‚Üí X$       |
| $ùí≤\, x : A ‚Ä¢ B$ | $Œ†\, X : \Type ‚Ä¢ (Œ†\, x : A ‚Ä¢ Œ†\, f : (B ‚Üí X) ‚Ä¢ X) ‚Üí X$ |

Recall that our contexts are left-growing lists of variables annotated with
their types. We use left-growing instead of the more common right-growing lists
since we are working with /dependent/ contexts: In the context $\;x : A; Œì\;$ we
expect the name $x$ to be available in the rest of the context Œì.
#+begin_export latex
\[\begin{array}{lcll}
\Gamma         &::=& . & \text{(empty context)} \\
               & | & x : A, Œì & \text{(context extension)} \\
\end{array}\]
#+end_export
We shall use the same notation --- viz $x‚ÇÄ, x‚ÇÅ, ‚Ä¶, x‚Çô$ and $\cdot$ --- to denote
lists and make use of a number of common list operations, including the
following.
#+begin_export latex
\def\foldr{\mathsf{foldr1}\,}
\def\any{\mathsf{any}\,}
\def\List{\mathsf{List}\,}
\[\begin{array}{lcl}
   \foldr &:& ‚àÄ \{œÑ\} (\_{}\!‚äï\!\_{} : œÑ ‚Üí œÑ ‚Üí œÑ) ‚Üí \List œÑ ‚Üí œÑ
\\ \foldr \_{}\!\oplus\!\_{} \, (x,\cdot)  &=& x
\\ \foldr \_{}\oplus\!\!\_{} \, (x,xs)  &= &x ‚äï \left(\foldr \_{}\!\oplus\!\_{} \, xs\right)
\\
\\ \any &:& ‚àÄ \{œÑ\} (p : œÑ ‚Üí ùîπ) ‚Üí \List œÑ ‚Üí ùîπ
\\ \any p \, \cdot &=& \false
\\ \any p \, (x, xs) &=& p\,x \;‚à®\; \any p \, xs
\end{array}\]
#+end_export

We can then define a number of semantics functions on contexts.
#+latex: \def\IF#1#2#3{\mathsf{if}\; #1\; \mathsf{then}\; #2 \;\mathsf{else}\; #3}
#+begin_export latex
\[\begin{array}{lcl}
Œ†‚ü¶\_{}‚üß &:& \mathsf{Context} ‚Üí \mathsf{Term} \\
Œ†‚ü¶\cdot‚üß & = & ùüô \\
Œ†‚ü¶x : A, Œì‚üß & = & Œ†\, x : A ‚Ä¢ Œ†‚ü¶Œì‚üß
\end{array}\]
#+end_export
For instance, @@latex:{\footnotesize@@ src_agda[:exports code]{Œ†‚ü¶ Carrier :
Type, point : Carrier ‚üß ¬†=¬† Œ† Carrier : Type ‚Ä¢ Œ† point : Carrier ‚Ä¢
ùüô};@@latex:}@@ the right-hand side is the uninteresting function sending its
input to the only element of ùüô.  We will find practical uses for this operation
in conjunction with the others.

Of course any proper Œ†-/term/ can be converted to a context:
#+begin_export latex
\[\begin{array}{lcl}
Œì‚ü¶\_{}‚üß &:& \mathsf{Term} ‚Üí \mathsf{Context}
\\ Œì‚ü¶Œ†\, x : A ‚Ä¢ B‚üß &=& x : A, Œì‚ü¶B‚üß
\\ Œì‚ü¶t‚üß &=& \cdot
\end{array}\]
#+end_export
By structural induction, one can verify $Œì\left‚ü¶\, Œ†‚ü¶c‚üß\, \right‚üß \;=\; c$ ---but we do
not, in general, have an isomorphism.

The next semantics function is hardly more complicated.
#+begin_export latex
\[\begin{array}{lcl}
Œ£‚ü¶\_{}‚üß &:& \mathsf{Context} ‚Üí \mathsf{Term} \\
Œ£‚ü¶\cdot‚üß & = & ùüô \\
Œ£‚ü¶x : A, Œì‚üß & = & Œ£\, x : A ‚Ä¢ Œ£‚ü¶Œì‚üß \\
\end{array}\]
#+end_export
For instance, @@latex:{\footnotesize@@ src_agda[:exports code]{Œ£ ‚ü¶Carrier :
Type, point : Carrier ‚üß ¬†=¬† Œ£ Carrier : Type ‚Ä¢ Œ£ point : Carrier ‚Ä¢ ùüô}; @@latex:}@@
the right-hand side is essentially a record type but lacking any syntactic
sugar.  This is the usual /record semantics/ of contexts.

The next semantics function is perhaps the most complicated.  Given a context Œì
and an elected type name œÑ, this operation keeps only the names of Œì that ‚Äòhit‚Äô
œÑ ---i.e., they have types being functions targeting œÑ--- then it ‚Äòd‚Äôrops that
h‚Äòead‚Äô ---c.f., ~dead~ below--- from the resulting types in the context /and/
produces a ‚Äòhole‚Äô for any recursive call; finally, the resulting types are
summed as well as the holes.
#+begin_export latex
\[\begin{array}{lcl}
ùí≤‚ü¶\_{}‚üß &:& \mathsf{Context} ‚Üí \mathsf{Name} ‚Üí \mathsf{Term} \\
ùí≤‚ü¶Œì‚üß \, œÑ & = & \mathsf{if}\; \any \; (\_{}\mathsf{hits}\, œÑ)\; Œì \\
          &    & \mathsf{then}\; ùí≤\; (\mathsf{foldr1}\, +\, (\mathsf{dead}\, œÑ\, Œì)) \; (\mathsf{foldr1}\, \triangledown\, (\mathsf{holes}\, œÑ\, Œì)) \\
          &    & \mathsf{else}\; ùüò
\end{array}\]
#+end_export
It is important that we use $\foldr$ and not $\mathsf{foldr}$ since we do not
want to append a any type for the recursive base case (empty list) ---otherwise,
our ADTs would all have ‚Äòone more‚Äô new constructor.  The ‚Äò+‚Äô is the sum
construction on types, whereas ‚Äò$\triangledown$‚Äô is the sum selection operator
---i.e., sum eliminator \footcitet{cats:programming_with_bananas}.  For
instance, @@latex:{\footnotesize@@ src_agda[:exports code]{ùí≤ ‚ü¶Carrier : Type,
point : Carrier ‚üß Carrier ¬†=¬† ùí≤ ùüô (Œª _ ‚Üí \Fin 0)}; @@latex:}@@ the right-hand
side is essentially a src_agda[:exports code]{data} declaration with one (‚Äòùüô‚Äô)
nullary (‚Äò$\Fin 0$‚Äô) constructor. This semantics, as far as we know, is novel.

The helper functions required to define $ùí≤‚ü¶\_{}‚üß$ include the standard textual
substitution of terms, the subterm relation ‚Äò‚äÜ‚Äô, and ‚Äò$x‚ôØt$‚Äô for the operation
of the number of times a name $x$ occurs in a term $t$. The two unmentioned
operations below are the incidence relation ‚Äò$\lhd$‚Äô and the context subtraction
operation ‚Äò-‚Äô.
#+begin_export latex
\[\begin{array}{lcl}
\_{}\lhd\_{} &:& \mathsf{Name} √ó \mathsf{Term} ‚Üí \mathsf{Context} ‚Üí ùîπ
\\   x : A \;\lhd\; Œì &=& \text{‚Äútyping $x : A$ draws from context Œì‚Äù}
\\ x : A \;\lhd\; \cdot &=& \false
\\ x : A \;\lhd\; (y : B, Œì) &=& x = y \;‚à®\; y ‚äÜ A \;‚à®\; x:A \,\lhd\, Œì
\\
\\  \_{}-\_{}  &:& \mathsf{Context} ‚Üí \mathsf{Context}  ‚Üí \mathsf{Context}
\\ \cdot \;-\; Œì‚Ä≤ &=& \cdot
\\ (x : A, Œì) \;-\; Œì‚Ä≤ &=& \IF{x:A \,\lhd\, Œì‚Ä≤}{Œì \,-\, (x:A, Œì‚Ä≤)}{x:A, (Œì - Œì‚Ä≤)}
\\
\\ \_{}\mathsf{hits}\_{} &:& \mathsf{Term} ‚Üí \mathsf{Name} ‚Üí ùîπ
\\ x \,\mathsf{hits}\, y &=& (x = y) \qquad\text{(Variable case)}
\\ (Œ† x : A ‚Ä¢ B) \,\mathsf{hits}\, y &=& B \,\mathsf{hits}\, y \qquad\text{(Œ†-type)}
\\ t \,\mathsf{hits}\, y &=& \false \qquad\text{(All other cases)}
\\
\\ \mathsf{dead} &:& \mathsf{Name} ‚Üí \mathsf{Context}  ‚Üí \mathsf{List}\, \mathsf{Term}
\\ \mathsf{dead}\, A\, \cdot &=& \cdot
\\ \mathsf{dead}\, A\, (y : B, Œì) &=& \mathsf{if}\; B \,\mathsf{hits}\, A
\\                             & & \mathsf{then}\; Œ£‚ü¶\mathsf{init}\, Œì‚ü¶B‚üß‚üß[A ‚âî ùüô], \mathsf{dead}\, A\, Œì
\\                             & & \mathsf{else}\; \mathsf{dead}\, A\, Œì \;-\; y : B
\\
\\ \mathsf{holes} &:& \mathsf{Name} ‚Üí \mathsf{Context} ‚Üí \mathsf{List}\, \mathsf{Term}
\\ \mathsf{holes}\, A\, \cdot &=& \Fin 0
\\ \mathsf{holes}\, A\, (y : B, Œì) &=& \IF{B \,\mathsf{hits}\, A}{ \Fin (A ‚ôØ B - 1), \mathsf{holes}\, A\, Œì}{\mathsf{holes}\, A\, (Œì \;-\; y : B)}
\end{array}\]
#+end_export

Rather than prove any correctness of these generic operations, we will, in
Chapter \ref{sec:contexts}, mechanise them in Agda.  The mechanisation is a
non-trivial contribution since it is the ‚Äúreal-world details‚Äù where things
become rather involved. For instance, unlike our supposed setup above, in Agda
terms have a much larger syntax and so a number of combinators must be developed
along the way ---including, manipulation of De Bruijn indices.  Moreover, the
resulting Agda setup is pragmatic since it uses monadic src_haskell[:exports
code]{do}-notation to achieve a simple concrete syntax for contexts and, unlike
the above setup, it is a library and not a ‚Äòproof-of-concept‚Äô development from
scratch.  ‚ÄúIn theory, it's doable; actually doing it is another matter!‚Äù

Finally, there is a family of useful semantics combinators built on top of
$Œ†‚ü¶\_{}‚üß$. For any semantics function $ùí¨‚ü¶\_{}‚üß : \mathsf{Context} ‚Üí
\mathsf{Term}$, we have the family ‚ÄúŒ† ∑ùí¨‚Äù for each /waist/ $w : ‚Ñï$.
#+begin_export latex
\[\begin{array}{lcl}
Œ† ∑ùí¨‚ü¶\_{}‚üß &:& \mathsf{Context} ‚Üí \mathsf{Term} \\
Œ†‚Å∞ùí¨‚ü¶ Œì ‚üß &=& ùí¨‚ü¶ Œì ‚üß \\
Œ†^{w + 1}ùí¨‚ü¶ \cdot ‚üß &=& ùí¨‚ü¶ \cdot ‚üß \\
Œ†^{w + 1}ùí¨‚ü¶x : A, Œì‚üß &=& Œ†\, x : A ‚Ä¢ Œ†^w ùí¨ ‚ü¶Œì‚üß
\end{array}\]
#+end_export

For instance, the single context src_agda[:exports code]{Carrier : Type, Tree :
Type, leaf : Carrier ‚Üí Tree, branch : Tree ‚Üí Tree ‚Üí Tree} can be used to obtain
a parameterised record and a paramterised datatype ---/both being different
useful ways to view the same context/.  follows.  {{{code(Œ†¬πŒ£ ‚âà Typeclass)}}}
#+begin_src agda
  Œ†¬πŒ£ ‚ü¶ Carrier : Type, Tree : Type, leaf : Carrier ‚Üí Tree
        , branch : Tree ‚Üí Tree ‚Üí Tree ‚üß
=
  Œ† Carrier : Type ‚Ä¢ Œ£ Tree : Type ‚Ä¢ Œ£ leaf : Carrier ‚Üí Tree
        ‚Ä¢ Œ£ branch : Tree ‚Üí Tree ‚Üí Tree ‚Ä¢ ùüô
‚âà
  record CollectionOn (Carrier : Set) : Set‚ÇÅ where
      field
        collection : Set -- ‚ÄòTree‚Äô above
        singleton  : Carrier ‚Üí collection -- ‚Äòleaf‚Äô above
        merge      : collection ‚Üí collection ‚Üí collection -- ‚Äòbranch‚Äô above
                      #+end_src
{{{code(Œ†¬πùí≤ ‚âà Termtypes)}}}
#+begin_src agda
  Œ†¬πùí≤ ‚ü¶ Carrier : Type, Tree : Type, leaf : Carrier ‚Üí Tree
         , branch : Tree ‚Üí Tree ‚Üí Tree ‚üß Tree
=
  Œ† Carrier : Type ‚Ä¢ ùí≤ (Carrier + ùüô √ó ùüô) (Œª{inl _ ‚Üí Fin 0, inr _ ‚Üí Fin 2})
‚âà
  data TreeOn (Carrier : Set) : Set where
      leaf   : Carrier ‚Üí TreeOn Carrier
      branch : TreeOn Carrier ‚Üí TreeOn Carrier ‚Üí TreeOn Carrier
#+end_src

\noindent As the examples show sometimes after restructuring a context it can be
useful to perform a /renaming/ operation.  The current implementation of Agda does
not allow for the declaration of freshly named entities and so we relegate this
aspect to the Emacs Lisp prototype of Chapter \ref{sec:PF}.  The prototype is
able to perform such renaming and /remember/ the
#+latex: relationship\footcitet{purposes_of_proof_detailed}$^,$\footcitet{purposes_of_proof}
to the original datatype by augmenting the resulting src_agda[:exports
code]{record} with coercions ---‚Äòforgetful operations‚Äô--- to the original,
parent, context.  Consequently, the prototype ---even though it is useful by
itself--- acts as a guide for features that would be ideal to implement in a DTL
capable of supporting them as a library.

Finally, the ‚Äúdo-it-yourself‚Äù in the title of the thesis is that the resulting
Agda library of Chapter \ref{sec:contexts} is designed around $Œ†‚ü¶\_{}‚üß$ and
$Œ£‚ü¶\_{}‚üß$ but users would use any other, possibly personal, semantics operation
$ùí¨‚ü¶\_{}‚üß$.

* yesmargins                                                 :ignore:
#+latex: \yesmargins
* The ~PackageFormer~ Prototype

<<sec:PF>>
# +latex: \label{sec:PF}

<<sec:module_meta_primitives_as_library_methods>>
# +latex: \label{sec:module_meta_primitives_as_library_methods}

<<sec:metaprogramming_module_meta_primitives>>
# +latex: \label{sec:metaprogramming_module_meta_primitives}

#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

# The Second Choice: =PackageFormer=

:LOG:

Progress towards issue #28, namely points i and iii; not yet item ii.

Most of the suggestions of issue #29 have been adopted, including the reduction
of bold. Issue #29 may be ready to be closed. (Sorry for not engaging too much
on the github issue thread!)

Regarding issue #31, section 4.1 has been reduced: The paragraph ‚ÄúWhy textual
transformations?‚Äù has been discarded. It may reappear in a terser form in an
introduction to reflection, as a new section 5.1 ---perhaps similarly for issues
#32 and #34.  For now, issue #31 may be ready to be closed.

Issue #33 not yet addressed.

Advice of issue #35 followed fully (‚Ä¢ÃÄ·¥ó‚Ä¢ÃÅ)Ÿà

Have also progressed toward issue #30. There are likely other places in the
thesis where this is a concern, so the issue should continue to remain open.
:END:

** Intro                                                             :ignore:

# TODO Removing the red box that appears in "minted" when using unicode :ignore:
# Src: https://tex.stackexchange.com/questions/343494/minted-red-box-around-greek-characters
#
#+LATEX: \makeatletter
#+LATEX: \AtBeginEnvironment{minted}{\dontdofcolorbox}
#+LATEX: \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
#+LATEX: \makeatother

#+macro: fold
#+macro: end-fold

#+macro: fold $1
#+macro: end-fold $1

#+macro: goal |‚Üí$1‚Üê|

 #+latex: \def\Id{\mathsf{Id}}
 #+latex_header: \def\KIND{\,:\!\mathsf{kind}\,}
 #+latex_header: \def\WAIST{\,:\!\mathsf{waist}\,}
 #+latex_header: \def\LEVEL{\,:\!\mathsf{level}\,}

 #+latex: \def\IF{\,\mathsf{if}\,}
 #+latex: \def\THEN{\,\mathsf{then}\,}
 #+latex: \def\ELSE{\,\mathsf{else}\,}


   # I'm trying to do things with one language, in a DTL, and about being first-class.
   # What I currently have is to approximate what it could look like.
   #
   # I'm not actually generating any external code.
   # It's all in the same language.

# reference the extensbility part from ‚Äúlessons learned‚Äù, ergo meta-primitives
# and the need for metaprogramming from current-aproaches? [translate·µ¢]
#
#

# Utility of a protottype?

# \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]
#+latex: \remark{
For the interested reader, the full implementation is presented \emph{literately} as a
discussion at \url{https://alhassy.github.io/next-700-module-systems/prototype/package-former.html}.
We will not be discussing any Lisp code in particular.
#+latex: } \vspace{-0.9cm}
# \end{tcolorbox}

From the lessons learned from spelunking in a few libraries, we concluded that
metaprogramming is a reasonable road on the journey toward first-class modules
in DTLs.  As such, we begin by forming an ‚Äòeditor extension‚Äô to Agda with an eye
toward a small number of @@latex: ‚Äòmeta-primitives‚Äô\footnote{Section 6.3
contains an example-driven approach}@@ for forming combinators on modules.  The
extension is written in Lisp, an excellent language for rapid prototyping.  The
purpose of writing the editor extension is not only to show that the
‚Äòflattening‚Äô of value terms and module terms is @@latex:
feasible\footnote{Indeed, the MathScheme \cite{mathscheme} prototype already
shows this.};@@ but to also show that ubiquitous packaging combinators can be
@@latex: generated\footnote{Just as the primitive of a programming language
permit arbitrarily complex programs to be written.}@@ from a small
#+latex: number\footnote{Dreyer \cite{modules:design_issues} provides a through summary of the main issue in module system design.}
of primitives.  The resulting tool resolves many of the issues discussed in
section ref:sec:examples_from_the_wild.

This chapter is organised as follows.  Firstly, the use of Lisp is explained.
Then, an example
#+latex: demonstration\footnote{Our approach is reminiscent of Deriving Via \cite{deriving_via}.}
of the utilities of the prototype is given. Afterwards is an overview of the
combinators that we have constructed using the prototype and we showcase a few
of them to solve problems observed in Chapter
\ref{sec:examples_from_the_wild}. The prototype's fundamental unit is the
generalised signature of Chapter \ref{sec:packages_and_their_parts}, with the
ambient generalised type theory being MLTT (see Chapter
\ref{sec:packages_and_their_parts}); but we will not discuss how the combinators
can be assigned semantics as morphisms in an appropriate category of
signatures. Instead, we will reach for an Agda-based semantics in the next
chapter.

:ignore:
*MA: TODO: ???*
Quick summary of subsections covered.
- ref:sec:PF_why_editor_extension  ‚áí why Emacs and Lisp
- ref:sec:PF_scrap_repetition ‚áí discuss how the PF editor extension works
  + In this section we discuss how =PackageFormer= works and
  + provide a ‚Äòreal-world‚Äô use case, along with a discussion.

     \noindent These manually written ‚àº25 lines elaborate into the ‚àº100 lines of raw,
   legitimate, Agda syntax below ---line breaks are denoted by the symbol ‚Äò‚Ü™‚Äô
   rather than inserted manually, since all subsequent code snippets in this
   section are *entirely generated* by =PackageFormer=.  The result is nearly a *400%
   increase in size*; that is, our fictitious code will save us a lot of repetition.

:End:

#+latex: \vspace{-0.1cm}
{{{localtoc}}}

#+latex: \vspace{-6cm}\remark{
The core of this chapter shows how some of the problems of Chapter
\ref{sec:examples_from_the_wild}, /Examples from the wild/, can be solved using
~PackageFormer~.
#+latex: }

#+latex: \vspace{2cm}\remark{
A ~20 minute lecture on =PackageFormer=, given at Athens SPLASH 2019, may be
viewed at https://youtu.be/xLHgN0dOZ6E.
#+latex: }\clearpage

** Why an editor extension?
   # Why Lisp is reasonable?
<<sec:PF_why_editor_extension>>
# +latex: \label{sec:PF_why_editor_extension}

The prototype[fn:54] /rewrites/ Agda phrases from an extended Agda syntax to
legitimate existing syntax; it is written as an Emacs editor extension to Emacs'
Agda interface, using Lisp citet:10.5555/229872.
#+latex: \remark{\textbf{Why Emacs?}}
Since Agda code is predominately written in Emacs, a practical and pragmatic
editor extension would need to be in Agda's de-facto
#+latex: IDE\footnote{\textbf{IDE}: Interactive Development Environment}, Emacs.
Moreover, Agda development involves the manipulation of Agda source code by
Emacs Lisp ---for example, for case splitting and term refinement tactics--- and
so it is natural to extend these ideas.  Nonetheless, at a first glance, it is
humorous[fn:7] that a module extension for a statically dependently-typed
language is written in a dynamically type checked language.  However, /a lack of
static types means some design decisions can be deferred as much as possible./

#+latex: \remark{\textbf{Why an editor extension?} Because we quickly needed a \emph{convenient} prototype to actually ‚Äúfigure out the problem‚Äù.}
Unless a language provides an extension mechanism, one is forced to either alter
the language's compiler or to use a preprocessing tool ---both have drawbacks.
The @@latex: former\footnote{Instead of ‚Äúhacking in‚Äù a new feature, one could
instead carefully research, design, and implement a new feature.}@@ is
/dangerous/; e.g., altering the grammar of a language requires non-trivial
propagated changes throughout its codebase, but even worse, it could lead to
existing language features to suddenly break due to incompatibility with the
added features. The latter is @@latex: \emph{tiresome}\footnote{Unless one uses
a sufficiently flexible IDE that allows the seemless integration of
preprocessing tools; which is exactly what we have done with Emacs.}@@: It can
be a nuisance to remember always invoke a preprocessor before compilation or
type-checking, and it becomes extra baggage to future users of the codebase
---i.e., a further addition to the toolchain that requires regular maintenance
in order to be kept up to date with the core language.  A middle-road between
the two is not always possible.  However, if the language's community subscribes
to /one/ IDE, then a reasonable approach
#+begin_margin :width "0.45\\textwidth"
#+latex_header: \usepackage{rotating}
#+latex_header: \usepackage{tikz} \usetikzlibrary{positioning} \usetikzlibrary{arrows, arrows.meta}
[[https://www.cs.virginia.edu/~evans/cs655/readings/steele.pdf][‚ÄúGrowing a Language‚Äù]]; Difficulty for user setup vs difficulty for implementation
# +resize:
#+begin_export latex
\vspace{1cm}
{\LARGE \maxsizebox{1.3\textwidth}{\textheight}{
% Spectrum template from: https://tex.stackexchange.com/a/84998/69371
\def\TWO#1#2{$\substack{\displaystyle \text{#1} \\ \displaystyle \text{#2}}$}
\begin{tikzpicture}[node distance=5cm]
  \node(origin) at (-150,0){};
  % nodes on horizontal and vertical
  \node(freedom)[above=of origin]{Smooth Usability};
  \node(authority)[below=of origin]{Intrusive Usage};
  \node(equality)[left=of origin]{\TWO{Wholesale}{Reimplemention}};
  \node(inequality)[right=of origin]{\TWO{Localised}{Addition}};
  % nodes on diagonals
  \node(socdemo)[above left=2cm of origin]{\TWO{Altering}{the compiler}};
  \node(classlib)[above right=2cm of origin]{\TWO{Libraries}{(Lisp Macros)}};
  \node(facism)[below right=2cm of origin]{\TWO{Preprocessor}{tool}};
  \node(facism)[below left=2cm of origin]{\TWO{Incompatible changes}{to concrete syntax}};
  %
  \node[right=1cm of origin]{\rotatebox{45}{\TWO{\color{red!70}\texttt{Package}}{\color{red!70}\texttt{Former}}}};
  % connect horizontal and vertical nodes
  \draw[>=open triangle 60, thick, <->](equality)--(inequality);
  \draw[>=open triangle 60, thick, <->](freedom)--(authority);
\end{tikzpicture}}}
\vspace{-12em}
#+end_export
#+end_margin
to extending a language would be to /plug-in/ the necessary preprocessing ---to
transform the extended language into the pure core language--- in a saliently
/silent/ fashion such that users need not invoke it manually.

The usual workflow of an Agda user involves writing some code (types and terms
alike), then asking for Agda to typecheck it. The typechecking operation is done
quite frequently. Thus, one way for our prototype to fit in well to this
workflow is to extend the emacs hook that triggers Agda's typechecking to also
invoke our prototype.

The prototype implementation works via string manipulations. Although we have no
formal proof of this, the manipulations all seem quite straightforward, and none
seem to be overly time-consuming.  While we can't be assured that these are
linear in the size of the code, in practice, it seems like this is the case. To
guard against bugs potentially introduced through this untyped ‚Äúwild
manipulation‚Äù phase, Agda typechecks everything that the prototype generates,
thus ensuring eventual soundness.

Unlike Agda itself, which rewrites user code, such as when doing case-split, and
will occasionally produce incorrect code, we eschew that. Instead, our prototype
produces auxilliary files that contain Agda code, which are then imported into
user code. The necessary import clauses, to the auxiliary files, are
automatically inserted when not present.  One benefit of this approach is that
library users do not need to know about the extended language, as what is
imported is pure Agda, albeit with the extended language features appearing in
special comments.

# --------------------------------------------------------------------------------
#
# Moreover, the prototype goes to great lengths to ‚Äòfit‚Äô into the usual workflow
# of an Agda user.  In particular, after the initial setup, the prototype is
# implicitly invoked whenver users perform Agda's usual typechecking in Emacs.
# Since the prototype is mostly string manipulation, its presence is barely
# noticable, and its results are then checked by Agda itself.  In addition, to
# mitigate the burden of increasing the toolchain, the silent preprocessing would
# not transform user code/ but instead /produce auxiliary files/ containing core
# language code which are then /imported/ by user code ---furthermore, such import
# clauses could be automatically inserted when necessary.  The benefit here is
# that /library users/ need not know about the extended language features; since all
# files are in the core language with extended language feature appearing in
# special comments.
# #+latex: {Details can be found in section \ref{sec:PF_scrap_repetition}.}
# #
# the Prototype is a preprocessor. It is just integrated into the IDE, itself a
# preprocessor, in such a way that it does not feel like it. It is not a "manual
# command-line preprocessor", that is true.
#
:How_does_it_work:
#+begin_export latex
\vspace{-3.5cm}
$\,$ \hfill \hspace{.95\textwidth}
{\large \maxsizebox{.55\textwidth}{\textheight}{
\smartdiagram[priority descriptive diagram]{
  User writes Agda with ‚Äò700-syntax‚Äô,
  User loads the file (which creates actual Agda for the 700-syntax),
  Result is pure (type-checkable) Agda}}}

\remark{\textbf{How does it work?} All stages transpire in \emph{one} user-written file}
\vspace{-1.5cm}
#+end_export
:End:

*Why Lisp?* Emacs is extensible using @@latex:Elisp\footnote{Emacs Lisp is a
combination of a large porition of Common Lisp and a editor language supporting,
e.g., buffers, text elements, windows, fonts.}@@ wherein literally every key may
be remapped and existing utilities could easily be altered /without/ having to
recompile Emacs.  In some sense, Emacs is a Lisp interpreter and state
machine. This means, we can hook our editor extension /seamlessly into the
existing Agda interface/ and even provide tooltips, among other @@latex:
features\footnote{E.g., since Emacs is a self-documenting editor, whenever a
user of our tool wishes to see the documentation of a module combinator that
they have written, or to read its Lisp elaboration, they merely need to invoke
Emacs' help system ---e.g., \texttt{C-h o} or \texttt{M-x describe-symbol}.}@@,
to quickly see what our extended Agda syntax transpiles into.

:Silly_slightlyInteresting_Stuff:
*Why textual transformations?* Metaprogramming is notoriously difficult to work
with in typed settings, which mostly provide an opaque ~Term~ type thereby
essentially resolving to working with untyped syntax trees. For instance,
consider the Lisp term
#+latex: \begin{center}
src_emacs-lisp[:exports code]{(--map (+ it 2) '(1 2 3))}
#+latex: \end{center}
which may be written in Haskell as
#+latex: \begin{center}
src_haskell[:exports code]{map (Œª it ‚Üí it + 2) [1, 2, 3]}
#+latex: \end{center}
What is the type of src_emacs-lisp[:exports code]{--map}? It expects a list
after a functional expression whose bound variable is named
src_emacs-lisp[:exports code]{it}.  Anaphoric macros like
src_emacs-lisp[:exports code]{--map} are thus not typeable as functions, but
could be thought of as *new quantifiers*, implicitly binding the variable
src_emacs-lisp[:exports code]{it} in the first argument ---in Haskell, one sees
#+latex: \begin{center}
src_haskell[:exports code]{map (Œª it ‚Üí ‚ãØ) xs = [‚ãØ | it ‚Üê xs]}
#+latex: \end{center}
thereby cementing src_haskell[:exports code]{map} as a form of variable binder.
Thus, rather than work with abstract syntax terms for Agda, which requires
non-trivial design decisions, we instead resolve to /rewrite/ Agda phrases from an
extended Agda syntax to legitimate existing syntax.
:End:

Finally, Lisp uses a rather small number of constructs, such as macros and
lambda, which themselves are used to build ‚Äòprimitives‚Äô, such as
src_emacs-lisp[:exports code]{defun} for defining top-level functions
citet:10.5555/1816935.  Knowing this about Lisp encourages us to emulate this
expressive parsimony.
#
# Finally, Lisp has a minimal number of built-in constructs which serve to define
# the usual host of expected language conveniences. That is, it provides an
# orthogonal set of ‚Äòmeta-primitives‚Äô from which one may construct the
# ‚Äòprimitives‚Äô used in day-to-day activities. E.g., with macro and lambda
# meta-primitives, one obtains the src_emacs-lisp[:exports code]{defun} primitive
# for defining top-level functions.  With Lisp as the implementing language, we
# were *implicitly encouraged* to seek meta-primitives for making modules.
#
** Aim: /Scrap the Repetition/
  :PROPERTIES:
  :CUSTOM_ID: Aim---Scrap-the-Repetition-
  :END:

<<sec:PF_scrap_repetition>>
# +latex: \label{sec:PF_scrap_repetition}

# README: C-c C-v C-t  ‚áí  M-Sets.agda
# Then open and load it with PF  ‚áí  M-Sets-generated.agda

Programming Language research is summarised, in essence, by the question: /If ùí≥
is written manually, what information ùí¥ can be derived for free?/ Perhaps the
most popular instance is /type inference/: From the syntactic structure of an
expression, its type can be derived. From a context, the src_haskell[:exports
code]{PackageFormer}@@latex: \remark{With the extension, Agda's usual
\texttt{C-c C-l} command parses special comments containing fictitious Agda
declarations, produces an auxiliary Agda file which it ensures is imported in
the current file, then control is passed to the usual Agda typechecking
mechanism.}@@ editor extension can generate the many common design patterns
discussed earlier in section ref:sec:DTL_design_patterns; such as unbundled
variations of any number wherein fields are exposed as parameters at the type
level, term types for syntactic manipulation, arbitrary renaming, extracting
signatures, and forming homomorphism types. In this section we discuss how
=PackageFormer= works and provide a ‚Äòreal-world‚Äô use case, along with a
discussion.

:PF_usage_details_DELETE:
The =PackageFormer= tool is an Emacs editor extension written in Lisp that is
integrated seemlessly into the Agda Emacs interface: Whenver a user loads a file
~X.agda~ for interactive typechecking, with the usual Agda keybinding ~C-c C-l~,
~PackageFormer~ performs the following steps:
1. Parse any comments ~{-700 ‚ãØ -}~ containing fictitious Agda code,
2. Produce legitimate Agda code for the ‚Äò700-comments‚Äô into a file ~X_generated.agda~,
3. Add to ~X.agda~ a call to import ~X_generated.agda~, if need be; and, finally,
4. Actually perform the expected typechecking.
   - For every 700-comment declaration ~‚Ñí = ‚Ñõ~ in the source file, the name ~‚Ñí~
     obtains a tooltip which mentions its specification ~‚Ñõ~ and the resulting
     legitimate Agda code. This feature is indispensable as it lets one generate
     grouping mechanisms and quickly ensure that they are what one intends them
     to be.
:END:

# Here is an example of contents in a 700-comment.
Below is example code that can occur in the specially recognised comments.
The first eight lines,
starting at line [[(msetDecl)]], are essentially an Agda src_agda[:exports
code]{record} declaration but the src_agda[:exports code]{field} qualifier is
absent. The declaration is intended to name an abstract context, a sequence of
‚Äúname ‚à∂ type‚Äù pairs as discussed at length in chapter
ref:sec:packages_and_their_parts, but we use the name =PackageFormer= instead of
‚Äòcontext, signature, telescope‚Äô, nor ‚Äòtheory‚Äô since those names have existing
biased connotations ---besides, the new name is more ‚Äòprogrammer friendly‚Äô.

:Header:
#+BEGIN_Src haskell :tangle M-Set.agda
-- Run the following commands:
-- M-x load-file ENTER agda-next-700-module-systems.el
-- M-x agda-next-700-module-systems-mode

module M-Set where
import Relation.Binary.PropositionalEquality as ‚â°; open ‚â° using (_‚â°_)
#+END_SRC
:End:
{{{code(M-Sets are sets ‚ÄòScalar‚Äô acting ‚Äò\_{}¬∑\_{}‚Äô on semigroups ‚ÄòVector‚Äô )}}}
#+attr_latex: :options xleftmargin=6pt
#+BEGIN_SRC haskell -n -r :tangle M-Set.agda :prologue {-700 :epilogue -}
PackageFormer M-Set : Set‚ÇÅ where (ref:msetDecl)
   Scalar  : Set
   Vector  : Set
   _¬∑_     : Scalar ‚Üí Vector ‚Üí Vector
   ùüô       : Scalar
   _√ó_     : Scalar ‚Üí Scalar ‚Üí Scalar
   leftId  : {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã
   assoc   : {a b : Scalar} {ùìã : Vector} ‚Üí   (a √ó b) ¬∑ ùìã
                                           ‚â°  a ¬∑ (b ¬∑ ùìã)
#+END_SRC

# \vspace{-1cm}
{{{code(Different Ways to Organise (‚Äúinterpret‚Äù / ‚Äúuse‚Äù) M-Sets)}}}
#+attr_latex: :options xleftmargin=6pt
#+BEGIN_SRC haskell -n 9 -r :tangle M-Set.agda :prologue {-700 :epilogue -}
Semantics  = M-Set ‚ü¥ record (ref:msetSemantics)
Semanticsùíü = Semantics ‚ü¥ rename (Œª x ‚Üí (concat x "ùíü"))
Semantics‚ÇÉ =  Semantics :waist 3

Left-M-Set  = M-Set ‚ü¥ record  (ref:msetLeftSet)
Right-M-Set = Left-M-Set ‚ü¥ flipping "_¬∑_" :renaming "leftId to rightId"

ScalarSyntax = M-Set ‚ü¥ primed ‚ü¥ data "Scalar'" (ref:msetTermtype)
Signature    = M-Set ‚ü¥ record ‚ü¥ signature
Sorts        = M-Set ‚ü¥ record ‚ü¥ sorts

ùí±-one-carrier   = renaming "Scalar to Carrier; Vector to Carrier"  (ref:msetNewVariationals)
ùí±-compositional = renaming "_√ó_ to _‚®æ_; _¬∑_ to _‚®æ_"
ùí±-monoidal      = one-carrier ‚ü¥ compositional ‚ü¥ record

LeftUnitalSemigroup = M-Set ‚ü¥ monoidal
Semigroup           = M-Set ‚ü¥ keeping "assoc" ‚ü¥ monoidal
Magma               = M-Set ‚ü¥ keeping "_√ó_" ‚ü¥ monoidal
#+END_Src

#+begin_export latex
\vspace{-8.5cm}
\remark{Now to actually use this context ...}

\vspace{0.5cm}
\remark{M-Sets as records, possibly with renaming or parameters.}
\remark{\centering ‚ãÜ ‚ãÜ ‚ãÜ}

\vspace{0.4cm}
\remark{Duality;
we might want to change the order of the action, say, to write \texttt{evalAt x f}
instead of \texttt{run f x} ---using the program-input interpretation of M-Sets
above.}
\remark{\centering ‚ãÜ ‚ãÜ ‚ãÜ}

\vspace{1cm}
\remark{Keeping only the ‚Äòsyntactic interface‚Äô, say, for serialisation or automation.}
\remark{\centering ‚ãÜ ‚ãÜ ‚ãÜ}

\vspace{0.5cm}
\remark{Collapsing different features to obtain the notion of ‚Äúmonoid‚Äù.}
\remark{\centering ‚ãÜ ‚ãÜ ‚ãÜ}

\vspace{0.8cm}
\remark{Obtaining parts of the monoid hierarchy (see chapter \ref{sec:examples_from_the_wild}) from M-Sets}

\vspace{0.8cm}
#+end_export

\noindent These
#+begin_margin :width "0.45\\textwidth"
In the code block, the names have been chosen to stay relatively close to the
real-world examples presented in chapter ref:sec:examples_from_the_wild. The
name *M-Set* comes from /monoid acting on a set/; in our example,
src_haskell[:exports code]{Scalar} values may act on src_haskell[:exports
code]{Vector} values to produce new src_haskell[:exports code]{Scalar}
values. The programmer may very well appreciate this example if the names
src_haskell[:exports code]{Scalar, ùüô, _√ó_, Vector, _¬∑_} were chosen to be
src_agda[:exports code]{Program, do-nothing, _‚®æ_, Input, run}.  With this new
naming, src_haskell[:exports code]{leftId} says /running the empty program on any
input, leaves the input unchanged/, whereas src_haskell[:exports code]{assoc}
says /to run a sequence of programs on an input, the input must be threaded
through the programs/.  Whence, *M-Sets abstract program execution*.
#+end_margin
manually written ‚àº25 lines elaborate into the ‚àº100 lines of raw,
legitimate, Agda syntax below ---line breaks are denoted by the symbol ‚Äò‚Ü™‚Äô
rather than inserted manually, since all subsequent code snippets in this
section are *entirely generated* by =PackageFormer=.  The result is nearly a *400%
increase in size*; that is, our fictitious code will save us a lot of repetition.

Let's discuss what's actually going on here.

# Line [[(msetDecl)]] ::
The first line declares the context of src_haskell[:exports code]{M-Set}s using
traditional Agda syntax ‚Äú src_agda[:exports code]{record M-Set : Set‚ÇÅ where} ‚Äù
except the we use the word \newline ~PackageFormer~ to avoid confusion with the
existing record concept, but[fn:57] we also /omit/ the need for a
src_agda[:exports code]{field} keyword and /forbid/ the existence of parameters.
Such abstract contexts have no concrete form in Agda and so no code is
generated; the second snippet above[fn:56] shows sample declarations that result
in legitimate Agda.
# are further samples of code that could be in the special comments.

=PackageFormer= module combinators are called <<</variationals/>>>
#+latex: \label{</variationals/>} since they
provide a variation on an existing grouping mechanism. The syntax ~p ‚ü¥ ùìã‚ÇÅ ‚ü¥ ‚ãØ ‚ü¥
ùìã‚Çô~ is tantamount to explicit forward function application ~ùìã‚Çô (ùìã‚Çô‚Çã‚ÇÅ (‚ãØ (ùìã‚ÇÅ p)))~.
With this understanding, we can explain the different ways to organise M-sets.

# +latex: \clearpage
# The next page shows, first, the elaboration of lines 9-11 and, in the second
# snippet, the elaborations of lines 12-14.

#+latex: \remark{
The waist is the number of parameters exposed; recall $Œ† ∑Œ£$ from Chapter
\ref{sec:research_problem_statement}.
#+latex: } \vspace{0cm}
In line [[(msetSemantics)]], the src_emacs-lisp[:exports code]{record} variational
  is invoked to transform the abstract context src_haskell[:exports code]{M-Set}
  into a valid Agda record declaration, with the key word src_agda[:exports
  code]{field} inserted as necessary. Later, its first 3 fields are lifted as
  parameters using the meta-primitive src_emacs-lisp[:exports code]{:waist}.

#+latex: \begin{fullwidth}
  {{{code(Elaboration of lines 9-11 \hfill Record / decorated renaming / typeclass forms)}}}
  #+INCLUDE: "M-Set-generated.agda" src agda :lines "20-50"
#+latex: \end{fullwidth}

  Notice how src_haskell[:exports code]{Semanticsùíü} was /built from/ a concrete
  context, namely the src_haskell[:exports code]{Semantics} record.  As such,
  every instance of src_haskell[:exports code]{Semanticsùíü} can be transformed as
  an instance of src_haskell[:exports code]{Semantics}:
  This view[fn:59] @@latex: \ignore{---see Section
  ref:sec:module_theory---}@@ is automatically generated and named
  src_haskell[:exports code]{toSemantics} above, by default. Likewise,
  src_haskell[:exports code]{Right-M-Set} was derived from src_haskell[:exports
  code]{Left-M-Set} and so we have automatically have a view
  src_haskell[:exports code]{Right-M-Set ‚Üí Left-M-Set}.

  *‚ÄúArbitrary functions act on modules‚Äù:* When only one variational is applied to
  a context, the one and only sequencing operator ‚Äò‚ü¥‚Äô may be omitted. As such,
  the ùíüecorated =Semanticsùíü= is defined as ~Semantics rename f~, where =f= is the
  decoration function.  In this form, one is tempted to believe
  #+latex: \begin{center}
  # src_haskell[:exports code]{ _rename_ : PackageFormer} \\
  # src_haskell[:exports code]{¬†¬†¬†¬†¬†¬†¬†¬†‚Üí (Name ‚Üí Name) } \\
  # src_haskell[:exports code]{¬†¬†¬†¬†¬†¬†¬†¬†‚Üí PackageFormer }
  src_haskell[:exports code]{ _rename_ : PackageFormer ‚Üí (Name ‚Üí Name) ‚Üí PackageFormer }
  #+latex: \end{center}
#+latex: \vspace{-1cm}\remark{
  That is, we have a binary operation in which functions may act on modules
  ---this is yet a new feature that Agda cannot perform.
#+latex: }

#+latex: \vspace{-2cm}\remark{
More accurately, the ‚Äò‚ü¥‚Äô-based mini-language for variationals is realised as a
Lisp macro and so, in general, the right side of a declaration in 700-comments
is interpreted as valid Lisp modulo this mini-language: =PackageFormer= names and
variationals are variables in the Emacs environment ---for declaration purposes,
and to avoid touching Emacs specific utilities, variationals
src_emacs-lisp[:exports code]{f} are actually named src_emacs-lisp[:exports
code]{ùí±-f}. One may quickly obtain the documentation of a variational
src_emacs-lisp[:exports code]{f} with \newline src_haskell[:exports code]{C-h o
RET ùí±-f} to see how it works.
#+latex: }\vspace{1cm}
#
Likewise, line [[(msetLeftSet)]], mentions another combinator
# +latex: \vspace{-1em}
#+begin_center
src_haskell[:exports code]{_flipping_ : PackageFormer ‚Üí Name ‚Üí PackageFormer}
#+end_center
# +latex: \vspace{1ex}
  All combinators are demonstrated in this section and their usefulness is
  dicussed in the nextion section. For example, in contrast to the above ‚Äòtype‚Äô,
  the src_emacs-lisp[:exports code]{flipping} combinator also takes an /optional
  keyword argument/ src_emacs-lisp[:exports code]{:renaming}, which simply
  renames the given pair.  The notation of keyword arguments is inherited from
  Lisp.

#+latex: \vspace{1cm}\begin{fullwidth}
  {{{code(Elaboration of lines 13-14 \hfill Duality: Sets can act on semigroups from the left or the right)}}}
  #+INCLUDE: "M-Set-generated.agda" src agda :lines "51-73"
#+latex: \end{fullwidth}\vspace{1cm}

# +latex: \remark{ ‚ãÜ ‚ãÜ ‚ãÜ }

Next, in line [[(msetTermtype)]], we view a context as such a
@@latex:termtype\remark{An algebraic data type is a tagged union of symbols,
terms, and so is one type ---see section \ref{sec:W-types}.}@@ by declaring
one sort of the context to act as the termtype (carrier) and then keep only the function
symbols that target it ---this is the *core idea* that is used when we operate
on Agda src_haskell[:exports code]{Term}s in the next chapter.
#+latex: \remark{
Recall from Chapter ref:sec:packages_and_their_parts, symbols that target
src_haskell[:exports code]{Set} are considered sorts and if we keep only the
symbols targeting a sort, we have a signature.  By allowing symbols to be of
type src_haskell[:exports code]{Set}, we actually have *generalised contexts*.
#+latex: }

{{{code(\hspace{-0.7cm}Elaboration of lines 16-18 \hfill Termtypes and lawless presentations)}}}
#+INCLUDE: "M-Set-generated.agda" src agda :lines "74-94"

#+latex: \vspace{-4cm} \remark{
The priming decoration in ~ScalarSyntax~ is needed so that the names ~ùüô, _√ó_~ do not
pollute the global name space.
#+latex: }\vspace{3.1cm}

Finally, starting with line [[(msetNewVariationals)]], declarations start with ‚Äú
src_haskell[:exports code]{ùí±-} ‚Äù to indicate that a new variation /combinator/ is
to be formed, rather than a new /grouping/ mechanism. For instance, the
user-defined src_emacs-lisp[:exports code]{one-carrier} variational identifies
both the src_haskell[:exports code]{Scalar} and src_haskell[:exports
code]{Vector} sorts, whereas src_emacs-lisp[:exports code]{compositional}
identifies the binary operations; then, finally, src_emacs-lisp[:exports
code]{monoidal} performs both of those operations and also produces a concrete
Agda src_agda[:exports code]{record} formulation. Below, in the final code
snippet of this section, are the elaborations of using these new new
user-defined variationals.

# +latex: \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,fonttitle=\bfseries,colbacktitle=red!85!black]
#+latex: \vspace{-3cm}\remark{
  User defined variationals are applied as if they were built-ins.
#+latex: }\vspace{3cm}
#  ---interestingly, only src_emacs-lisp[:exports code]{:waist} and
# src_haskell[:exports code]{_‚ü¥_} are built-in meta-primitives, the other
# primitives discussed thus far build upon less than 5 meta-primitives.
# +latex: \end{tcolorbox}

#+latex: \begin{fullwidth}
#+latex: \vspace{-2em}
  {{{code(Elaboration of lines 24-26 \hfill Conflating features gives familiar structures)}}}
  #+INCLUDE: "M-Set-generated.agda" src agda :lines "95-"
#+latex: \end{fullwidth}
#+latex: \newpage

#+latex: \vspace{1ex}
As shown in the figure below, the source file is furnished with tooltips
displaying the special comment that a name is associated with, as well as the
full elaboration into legitimate Agda syntax. In addition, the above generated
elaborations also document the special comment that produced them.  Moreover,
since the editor extension results in valid code in an auxiliary file, future
users of a library need not use the =PackageFormer= extension at all ---thus we
essentially have a static *editor tactic* similar to Agda's (Emacs interface)
proof finder.

:Constraints:

1. The type of a PackageFormer is ~Set ‚Ñì~ where ~‚Ñì~ is the empty string
   or a parenthesised expression of type ~Level~.
   - Subscript levels are supported.

2. The ~where~ keyword appears on the same line as the ~PackageFormer~ key-phrase.

3. The name of the PackageFormer should not contain ~PackageFormer~ as a sub-identifier.

4. Each element of a PackageFormer spans only /one/ physical line.

There are many useful features outlined in the proposal, such as default
implementations, that we hope to include in the future. For now, we just want
something that works, is decently documented, and can be useful.
:End:

#+latex: \vspace{2cm}\remark{
Hovering to show details. Notice special syntax has default colouring: Red for
\textsf{PackageFormer} delimiters, yellow for elements, and green for
variationals.
#+latex: } \vspace{-3cm}
#+attr_latex: :width 200px
[[file:./papers/gpce19-mousing-over-large.png]]

** Practicality
<<sec:PF:practicality>>
# +latex: \label{sec:PF:practicality}

#+latex_header: \usepackage{smartdiagram}

*** Intro                                                            :ignore:

 # If the previous section is unclear regarding the aims and uses of this prototype,
 # please consult the pre-print [[../papers/gpce19_a_language_feature_to_unbundle_data_at_will.pdf][A Language Feature to Unbundle Data at Will]]
 # or [[https://alhassy.github.io/next-700-module-systems/][the next 700 module systems proposal]].

 #+latex: \vspace{-0.5em}
 Herein we demonstrate how to use this system from the perspective of /library
 designers/.  That is to say, we will demonstrate how common desirable features
 encountered ‚Äúin the wild‚Äù ---chapter ref:sec:examples_from_the_wild--- can be
 used with our system.  The exposition here follows section 2 citet:tpc,
 reiterating many the ideas therein.  These features are *not built-in* but
 instead are constructed from a small set of primitives, shown below, just as a
 small core set of language features give way to complex software programs.
 Moreover, users may combine the primitives ---using Lisp--- to *extend* the
 system to produce grouping mechanisms for any desired purpose.
 #+latex: \vspace{+0.5em}

 # #+latex: \vspace{-3cm} \remark{
 #   This table has the *five primitives* from which all variationals are borne,
 #   followed by two others that are useful for extending the system by making
 #   your own grouping mechanisms and operations on them.  Using these requires a
 #   small amount of Lisp.
 # #+latex: }\vspace{2cm}

 #+latex: \vspace{-0.415cm}\begin{fullwidth}
    #+latex: \begin{tcolorbox}[title = \TABLE{Metaprogramming Meta-primitives for Making Modules}, colback=red!5!white, colframe=red!75!black]{\footnotesize
   # +name: tbl:meta-primitives
   # +caption: Metaprogramming Meta-primitives for Making Modules
   | *Name*            | *Description*                                                          |
   |-----------------+----------------------------------------------------------------------|
   | ~:waist~          | Consider the first /N/ elements as, possibly ill-formed, parameters.   |
   | ~:kind~           | Valid Agda grouping mechanisms: ~record, data, module~.                |
   | ~:level~          | The Agda level of a PackageFormer.                                   |
   | ~:alter-elements~ | Apply a ~List Element ‚Üí List Element~ function over a PackageFormer.   |
   | ~‚ü¥~               | Compose two variational clauses in left-to-right sequence.           |
   |-----------------+----------------------------------------------------------------------|
   | ~map~             | Map a ~Element ‚Üí Element~ function over a PackageFormer.               |
   | ~generated~       | Keep the sub-PackageFormer whose elements satisfy a given predicate. |
   |-----------------+----------------------------------------------------------------------|
  #+latex: }\end{tcolorbox} \vspace{0.5cm}
 #+latex: \end{fullwidth}

 @@comment: This section demonstrates the power and expressivity of the
 meta-primitives by showcasing a series of ubiquitous combinators /which may be
 defined using the meta-primitives and Lisp/.  In particular, *this section
 showcases a core kernel of context combinators* and the section afterwards goes
 into the detail of how to *extend the system to build ---presumably--- any
 desired operations on any notion of grouping mechanism*.  @@

 The few constructs demonstrated in this section not only create new grouping
 mechanisms from old ones, but also create morphsisms from the new, child,
 presentations to the old parent presentations.  @@comment: Maps between
 grouping mechanisms are sometimes called /views/. @@ For example, a theory extended by new declarations
 comes equipped with a map that forgets the new declarations to obtain an
 instance of the original theory.  Such morphisms are tedious to write out, and
 our system provides them for free. The user can implement such features using
 our 5 primitives ---but we have implemented a few to show that the primitives
 are deserving of their name, as shown below.

 #+latex: \vspace{-5cm}\remark{ %\begin{tcolorbox}[title = Do-it-yourself Extendability, colback=red!5!white, colframe=red!75!black]
 *Do-it-yourself Extendability:*
 In order to make the editor extension immediately useful, and to substantiate
 the claim that *common module combinators can be defined using the system*, we
 have implemented a few notable ones, as described in the table below. The
 implementations, in the user manual, are discussed along with the associated
 Lisp code and use cases.
 #+latex: }\vspace{5cm} %\end{tcolorbox}


 :Header:
 #+BEGIN_SRC agda
module package-former-user-manual-i where
import Relation.Binary.PropositionalEquality as ‚â°; open ‚â° using (_‚â°_)

-- Run the following commands:
-- M-x load-file ENTER agda-next-700-module-systems.el
-- M-x agda-next-700-module-systems-mode
 #+END_SRC
 :End:

 # As such, some of the definitions of combinators are biased or have some
 # shortcomings: Our goal is to show the meta-primitives allow for such
 # definitions, and to provide examples (mostly in the second part of the user
 # manual) for users to build what they want.

 #+latex: \begin{fullwidth}
  #+latex: \begin{tcolorbox}[title = \TABLE{Summary of Sample Variationals Provided With The System}, colback=red!5!white, colframe=red!75!black]{\footnotesize
 #+latex: \label{tbl:variationals-summary}
 # +caption: Summary of Sample Variationals Provided With The System
     | *Name*            | *Description*                                                          |
     |----------------------+--------------------------------------------------------------------------|
     | ~record~               | Reify a PackageFormer as a valid /Agda record/                             |
     | ~data~                 | Reify a PackageFormer as a valid Agda algebraic data type, ùí≤-type        |
     |----------------------+--------------------------------------------------------------------------|
     | ~extended-by~          | Extend a PackageFormer by a string-‚Äú;‚Äù-list of declaration               |
     | ~union~                | Union two PackageFormers into a new one, maintaining relationships       |
     | ~flipping~             | Dualise a binary operation or predicate                                  |
     | ~unbundling~           | Consider the first /N/ elements, which may have definitions, as parameters |
     |----------------------+--------------------------------------------------------------------------|
     | ~open~                 | Reify a given PackageFormer as a parameterised /Agda module/ declaration   |
     | ~opening~              | Open a record as a module exposing only the given names                  |
     | ~open-with-decoration~ | Open a record, exposing all elements, with a given decoration            |
     |----------------------+--------------------------------------------------------------------------|
     | ~keeping~              | Largest well-formed PackageFormer consisting of a given list of elements |
     | ~sorts~                | Keep only the types declared in a grouping mechanism                     |
     | ~signature~            | Keep only the elements that target a sort, drop all else                 |
     |----------------------+--------------------------------------------------------------------------|
     | ~rename~               | Apply a ~Name ‚Üí Name~ function to the elements of a PackageFormer          |
     | ~renaming~             | Rename elements using a list of ‚Äúto‚Äù-separated pairs                     |
     | ~decorated~            | Append all element names by a given string                               |
     | ~codecorated~          | Prepend all element names by a given string                              |
     | ~primed~               | Prime all element names                                                  |
     | ~subscripted·µ¢~         | Append all element names by subscript ~i ‚à∂ 0..9~                           |
     |----------------------+--------------------------------------------------------------------------|
     | ~hom~                  | Formulate the notion of homomorphism of parent PackageFormer algebras    |
     |----------------------+--------------------------------------------------------------------------|
  #+latex: }\end{tcolorbox}
 #+latex: \end{fullwidth}

#+latex: \vspace{0.5cm} \remark{
Any variational ~ùìã~ that takes an argument of type ~œÑ~ can be thought of as a *binary
packaged-valued operator*,
#+begin_center
src_haskell[:exports code]{_ùìã_ : PackageFormer} \newline
src_haskell[:exports code]{¬†‚Üí œÑ} \newline
src_haskell[:exports code]{¬†¬†¬†‚Üí PackageFormer}
#+end_center
With this perspective, the /sequencing variational
combinator/ ‚Äò‚ü¥‚Äô is essentially forward function composition/application.  Details
can be found on the associated webpage; whereas the next chapter provides an
Agda function-based semantics.
#+latex: } \vspace{-0.5cm}

\noindent =PackageFormer= packages are an *implementation of the idea* of packages
fleshed out in Chapter ref:sec:packages_and_their_parts.  Tersely put, a
=PackageFormer= package is essentially a pair of tags ---alterable by
src_emacs-lisp[:exports code]{:waist} to determine the height delimiting
parameters from fields, and by src_emacs-lisp[:exports code]{:kind} to determine
a possible legitimate Agda representation that lives in a universe dictated by
src_emacs-lisp[:exports code]{:level}--- as well as a list of declarations
(elements) that can be manipulated with src_emacs-lisp[:exports
code]{:alter-elements}.

The remainder of this section is an exposition of notable /user-defined/
combinators ---i.e., those which can be constructed using the system's
primitives and a small amount of Lisp.  Along the way, for each example, we show
both the terse specfication using =PackageFormer= and its elaboration into pure
typecheckable Agda.  In particular, since packages are essentially a list of
declarations ---see Chapter ref:sec:packages_and_their_parts--- we begin in
section ref:sec:PF:extension with the src_emacs-lisp[:exports code]{extended-by}
combinator which ‚Äúgrows a package‚Äù.  Then, in section
ref:sec:PF:practicality:postulating, we show how /Agda users/ can *quickly*, with a
/tiny/ amount of Lisp[fn:9] knowledge, make useful variationals to abbreviate
commonly occurring situations, such as a method to adjoin named operation
properties to a a package.  After looking at a src_emacs-lisp[:exports
code]{renaming} combinator, in section ref:sec:PF:practicality:renaming, and its
properties that make it resonable; we show the Lisp code, in section
ref:sec:PF:practicality:pushout required for a pushout construction on packages.
Of note is how Lisp's keyword argument feature allows the /verbose/ 5-argument
pushout operation to be *used* /easily/ as a 2-argument operation, with other
arguments optional.  This construction is shown to generalise set union
(disjoint and otherwise) and provide support for granular hierarchies thereby
solving the so-called ‚Äòdiamond problem‚Äô.  Afterword, in section
ref:sec:PF:duality, we turn to another example of /formalising common patterns/
---see Chapter ref:sec:examples_from_the_wild--- by showing how the idea of
duality, not much used in simpler type systems, is used to mechanically produce
new packages from old ones.  Then, in section
ref:sec:PF:extracting_little_theories, we show how the interface segregation
principle can be /applied after the fact/. Finally, we close in section
ref:sec:PF:hundreds-of-theories with a measure of the systems immediate
practicality.

*** Extension
<<sec:PF:extension>>
# +latex: \label{sec:PF:extension}

#+latex: \remark{\noindent
 One may use the call @@latex: \hbox{\scriptsize@@ src_emacs-lisp[:exports code]{P = Q extended-by R
 :adjoin-retract nil} @@latex:}@@ to extend src_emacs-lisp[:exports code]{Q} by declaration
 src_emacs-lisp[:exports code]{R} but avoid having a view (coercion)
 src_emacs-lisp[:exports code]{P ‚Üí Q}. Of course, src_emacs-lisp[:exports
 code]{extended-by} is /user-defined/ and we have simply chosen to adjoint retract
 views by default; the online documentation shows how users can define their own
 variationals.
#+latex: }
    The simplest operation on packages is when one package is included,
    verbatim, in another.  Concretely, consider src_haskell[:exports
    code]{Monoid} ---which consists of a number of /parameters/ and
    the derived result src_haskell[:exports code]{ùïÄ-unique}---
    and src_haskell[:exports code]{CommutativeMonoid‚ÇÄ} below.

 {{{code( Manually Repeating the entirety of ‚ÄòMonoid‚Äô within ‚ÄòCommutativeMonoid‚ÇÄ‚Äô )}}}
 #+BEGIN_SRC agda
PackageFormer Monoid : Set‚ÇÅ where
   Carrier : Set
   _¬∑_     : Carrier ‚Üí Carrier ‚Üí Carrier
   assoc   : {x y z : Carrier} ‚Üí (x ¬∑ y) ¬∑ z  ‚â°  x ¬∑ (y ¬∑ z)
   ùïÄ       : Carrier
   leftId  : {x : Carrier} ‚Üí ùïÄ ¬∑ x  ‚â° x
   rightId : {x : Carrier} ‚Üí x ¬∑ ùïÄ  ‚â° x
   ùïÄ-unique : ‚àÄ {e} (lid : ‚àÄ {x} ‚Üí e ¬∑ x ‚â° x) (rid : ‚àÄ {x} ‚Üí x ¬∑ e ‚â° x) ‚Üí e ‚â° ùïÄ
   ùïÄ-unique lid rid = ‚â°.trans (‚â°.sym leftId) rid

PackageFormer CommutativeMonoid‚ÇÄ : Set‚ÇÅ where
   Carrier : Set
   _¬∑_     : Carrier ‚Üí Carrier ‚Üí Carrier
   assoc   : {x y z : Carrier} ‚Üí (x ¬∑ y) ¬∑ z  ‚â°  x ¬∑ (y ¬∑ z)
   ùïÄ       : Carrier
   leftId  : {x : Carrier} ‚Üí  ùïÄ ¬∑ x  ‚â° x
   rightId : {x : Carrier} ‚Üí  x ¬∑ ùïÄ  ‚â° x
   comm    : {x y : Carrier} ‚Üí  x ¬∑ y  ‚â°  y ¬∑ x
   ùïÄ-unique : ‚àÄ {e} (lid : ‚àÄ {x} ‚Üí e ¬∑ x ‚â° x) (rid : ‚àÄ {x} ‚Üí x ¬∑ e ‚â° x) ‚Üí e ‚â° ùïÄ
   ùïÄ-unique lid rid = ‚â°.trans (‚â°.sym leftId) rid
 #+END_SRC

#+latex: \vspace{-3cm}\remark{
So much repetition for an additional axiom! Eek!
#+latex: }\vspace{2cm}

 #+latex: \begin{fullwidth}
 #+latex: \vspace{-3cm}\noindent
 As expected, the only difference is that src_haskell[:exports
 code]{CommutativeMonoid‚ÇÄ} adds a src_emacs-lisp[:exports code]{comm}utatity
 axiom.  Thus, given src_haskell[:exports code]{Monoid}, it would be *more
 economical* to define:

 #+latex: \vspace{1ex}
 {{{code( Economically declaring only the new additions to ‚ÄòMonoid‚Äô )}}}
 #+BEGIN_SRC agda
CommutativeMonoid = Monoid extended-by "comm : {x y : Carrier} ‚Üí  x ¬∑ y  ‚â°  y ¬∑ x"
 #+END_SRC
#+latex: \end{fullwidth}

#+latex: \remark{
 As discussed in the previous section, mouse-hovering over the left-hand-side of
 this declaration gives a tooltip showing the resulting elaboration, which is
 identical to src_haskell[:exports code]{CommutativeMonoid‚ÇÄ} above ---followed
 by forgetful operation.  The tooltip shows the /expanded/ version of the theory,
 which is *what we want to specify but not what we want to enter manually*.
#+latex: } \noindent
 As discussed in section ref:sec:examples:extensions, to obtain this
 specification of \newline src_haskell[:exports code]{CommutativeMonoid} in the current
 implementation of Agda, one would likely declare a record with two fields
 ---one being a src_haskell[:exports code]{Monoid} and the other being the
 commutativity constraint--- however, this _only_ gives the appearance of the
 above specification for consumers; those who produce instances of
 src_haskell[:exports code]{CommutativeMonoid} are then _forced_ to know the
 particular hierarchy and must provide a src_haskell[:exports code]{Monoid}
 value first. It is a happy coincidence that our system alleviates such an
 issue; i.e., we have *flattened extensions*.

:Already_done_in_tour:
 Alternatively, we may reify the new syntactical items as concrete Agda
 supported src_agda[:exports code]{record}s as follows.
 {{{code( Every ‚ÄòCommutativeMonoid‚Äô is automatically viewable as a ‚ÄòMonoid‚Äô )}}}
 #+BEGIN_SRC agda
{-700
MonoidR            = Monoid ‚ü¥ record
CommutativeMonoidR = MonoidR extended-by "comm : {x y : Carrier} ‚Üí  x ¬∑ y  ‚â°  y ¬∑ x" ‚ü¥ record
-}

neato : CommutativeMonoidR ‚Üí MonoidR
neato = CommutativeMonoidR.toMonoidR
 #+END_SRC

 #+latex: \begin{tcolorbox}[title = Transport, colback=red!5!white, colframe=red!75!black]
 It is important to notice that the /derived/ result src_haskell[:exports
 code]{ùïÄ-unique}, while proven in the setting of src_haskell[:exports
 code]{Monoid}, is not only available via the morphism src_haskell[:exports
 code]{toMonoidR} but is also available directly since it is also a member of
 src_haskell[:exports code]{CommutativeMonoidR}.
 #+latex: \tcblower
 One may use the call src_emacs-lisp[:exports code]{P = Q extended-by R
 :adjoin-retract nil} to extend src_emacs-lisp[:exports code]{Q} by declaration
 src_emacs-lisp[:exports code]{R} but avoid having a view (coercion)
 src_emacs-lisp[:exports code]{P ‚Üí Q}. Of course, src_emacs-lisp[:exports
 code]{extended-by} is /user-defined/ and we have simply chosen to adjoint retract
 views by default; the online documentation shows how users can define their own
 variationals.
 #+latex: \end{tcolorbox}
:End:

*** Defining a Concept Only Once
    :PROPERTIES:
    :CUSTOM_ID: Defining-a-Concept-Only-Once
    :END:
<<sec:PF:practicality:postulating>>
# +latex: \label{sec:PF:practicality:postulating}

#+latex: \remark{
The definition below uses functional methods and
should not be inaccessible to Agda programmers.
#+latex: } \remark{\centering ‚ãÜ ‚ãÜ ‚ãÜ} \remark{
Method call src_emacs-lisp[:exports code]{(s-replace old new s)}
replaces all occurrences of string src_emacs-lisp[:exports code]{old} by
src_emacs-lisp[:exports code]{new} in the given string src_emacs-lisp[:exports
code]{s}.
#+latex: } \remark{\centering ‚ãÜ ‚ãÜ ‚ãÜ} \remark{
src_emacs-lisp[:exports code]{(pcase e (x‚ÇÄ y‚ÇÄ) ‚Ä¶ (x‚Çô y‚Çô))}
pattern matches on src_emacs-lisp[:exports code]{e} and performs the first
src_emacs-lisp[:exports code]{y·µ¢} if src_emacs-lisp[:exports code]{e = x·µ¢},
otherwise it returns src_emacs-lisp[:exports code]{nil}.
#+latex: } \vspace{-1cm}

    From a library-designer's perspective, our definition of \newline
    src_haskell[:exports code]{CommutativeMonoid} has the commutativity property
    ‚Äòhard coded‚Äô into it.  If we wish to speak of commutative magmas ---types
    with a single commutative operation--- we need to hard-code the property
    once again.  If, at a later time, we wish to move from having arguments be
    implicit to being explicit then we need to track down every hard-coded
    instance of the property then alter them ---having them in-sync then becomes
    an issue.
    Instead, as shown below, the system lets us ‚Äòbuild upon‚Äô the src_emacs-lisp[:exports
    code]{extended-by} combinator: We make an associative list of names and
    properties, then string-replace the meta-names /op, op', rel/ with the
    provided user names.

#+latex: \vspace{-2.2cm}\begin{fullwidth}
 {{{code( Writing definitions \textbf{only once} with the ‚Äòpostulating‚Äô variational )}}}
 #+BEGIN_SRC emacs-lisp  :tangle "variationals.tmp" :noweb-ref ùí±-user-man-pt-1 :noweb yes
(ùí± postulating bop prop (using bop) (adjoin-retract t)
 = "Adjoin a property PROP for a given binary operation BOP.

   PROP may be a string: associative, commutative, idempotent, etc.
   Some properties require another operator or a relation; which may
   be provided via USING.

   ADJOIN-RETRACT is the optional name of the resulting retract morphism.
   Provide nil if you do not want the morphism adjoined."
   extended-by
    (s-replace "op" bop (s-replace "rel" using (s-replace "op'" using
     (pcase prop
      ("associative"   "assoc : ‚àÄ x y z ‚Üí op (op x y) z ‚â° op x (op y z)")
      ("commutative"   "comm  : ‚àÄ x y   ‚Üí op x y ‚â° op y x")
      ("idempotent"    "idemp : ‚àÄ x     ‚Üí op x x ‚â° x")
      ("left-unit"     "unitÀ° : ‚àÄ x y z ‚Üí op e x ‚â° e")
      ("right-unit"    "unit ≥ : ‚àÄ x y z ‚Üí op x e ‚â° e")
      ("absorptive"    "absorp  : ‚àÄ x y  ‚Üí op x (op' x y) ‚â° x")
      ("reflexive"     "refl    : ‚àÄ x y  ‚Üí rel x x")
      ("transitive"    "trans   : ‚àÄ x y z ‚Üí rel x y ‚Üí rel y z ‚Üí rel x z")
      ("antisymmetric" "antisym : ‚àÄ x y ‚Üí rel x y ‚Üí rel y x ‚Üí x ‚â° z")
      ("congruence"    "cong    : ‚àÄ x x' y y' ‚Üí rel x x' ‚Üí rel y y' ‚Üí rel (op x x') (op y y')")
      (_ (error "ùí±-postulating does not know the property ‚Äú%s‚Äù" prop))
      )))) :adjoin-retract 'adjoin-retract)
 #+END_SRC
#+latex: \end{fullwidth}

:How_It_Works:
 #+latex: \begin{tcolorbox}[title = Lisp Syntax, colback=red!5!white, colframe=red!75!black]
 The syntax of variational declarations was discussed in the previous section;
 one has access to the entirety of Emacs Lisp when forming such definitions.  In
 particular, notice that their is a /documentation string/ for the variational
 src_emacs-lisp[:exports code]{postulating} so that when a user mouse-hovers
 over any occurrence of it within an Agda file, the documentation string appears
 as a tooltip. The first line declares the variational src_emacs-lisp[:exports
 code]{postulating} to take two explicit arguments src_emacs-lisp[:exports
 code]{bop, prop} followed by two optional arguments src_C[:exports
 code]{:using, :adjoin-retract} that have default values src_emacs-lisp[:exports
 code]{bop, t}.
 #+latex: \tcblower
 This variational simply looks up the requested property src_emacs-lisp[:exports
 code]{prop} in its local (hard coded) database, rewrites the /prototypical/ name
 /op/ with the given src_emacs-lisp[:exports code]{bop}, then extends the given
 package with this property by calling on the src_emacs-lisp[:exports
 code]{extended-by} variational.
 In Lisp, call sites for optional keyword arguments require a
 prefix colon; e.g., the last line of the above definition invokes
 src_emacs-lisp[:exports code]{extended-by} and simply propagates the
 request to either adjoin, or not, a retract to the parent package.
 #+latex: \end{tcolorbox}
:END:

 # +latex: \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]  # +latex: \end{tcolorbox}
 As such, we have a formal approach to the idea that *each piece of mathematical
 knowledge should be formalised only once* citet:DBLP:conf/aisc/GrabowskiS10.  We
 can extend this database of properties as needed with relative ease. Here is an
 example use along with its elaboration.

 {{{code( Example Use )}}}
 #+BEGIN_SRC agda
PackageFormer Magma : Set‚ÇÅ where
  Carrier : Set
  _¬∑_      : Carrier ‚Üí Carrier ‚Üí Carrier

RawRelationalMagma = Magma extended-by "_‚âà_ : Carrier ‚Üí Carrier ‚Üí Set" ‚ü¥ record

RelationalMagma    = RawRelationalMagma postulating "_¬∑_" "congruence" :using "_‚âà_" ‚ü¥ record
 #+END_SRC
 {{{code( Associated Elaboration )}}}
 #+BEGIN_SRC haskell :remark these-are-just-results-from-previous-blocks :tangle no
record RawRelationalMagma : Set‚ÇÅ where
    field Carrier       : Set
    field op        : Carrier ‚Üí Carrier ‚Üí Carrier
    toType      : let View X = X in View Type ; toType = record {Carrier = Carrier}
    field _‚âà_       : Carrier ‚Üí Carrier ‚Üí Set
    toMagma     : let View X = X in View Magma ;    toMagma = record {Carrier = Carrier;op = op}

record RelationalMagma : Set‚ÇÅ where
    field Carrier       : Set
    field op        : Carrier ‚Üí Carrier ‚Üí Carrier
    toType      : let View X = X in View Type ; toType = record {Carrier = Carrier}
    field _‚âà_       : Carrier ‚Üí Carrier ‚Üí Set
    toMagma     : let View X = X in View Magma ;    toMagma = record {Carrier = Carrier;op = op}
    field cong      : ‚àÄ x x' y y' ‚Üí _‚âà_ x x' ‚Üí _‚âà_ y y' ‚Üí _‚âà_ (op x x') (op y y')
    toRawRelationalMagma        : let View X = X in View RawRelationalMagma ;   toRawRelationalMagma = record {Carrier = Carrier;op = op;_‚âà_ = _‚âà_}
 #+END_SRC

#+latex: \vspace{-5cm}\remark{
 The src_haskell[:exports code]{let View X = X in View ‚ãØ} clauses are a part
 of the user implementation of src_emacs-lisp[:exports code]{extended-by}; they
 are used as markers to indicate that a declaration is a /view/ and so should not
 be an element of the current view constructed by a call to src_emacs-lisp[:exports
 code]{extended-by}.
#+latex: }\vspace{5cm}

#+latex: \begin{fullwidth}

 In conjunction with src_emacs-lisp[:exports code]{postulating},
 the src_emacs-lisp[:exports code]{extended-by} variational makes it
 *tremendously easy to build fine-grained hierarchies* since at any stage in the
 hierarchy we have views to parent stages (unless requested otherwise) /and/ the
 hierarchy structure is /hidden/ from end-users.
 That is to say, ignoring the views, the above initial declaration
 of src_haskell[:exports code]{CommutativeMonoid‚ÇÄ} is identical to
 the src_haskell[:exports code]{CommutativeMonoid} package obtained by
 using variationals, as follows.
 #+latex: \vspace{1cm}

 {{{code(Building fine-grained hierarchies with ease)}}}
#+BEGIN_SRC agda
PackageFormer Empty : Set1 where {- No elements -}
Type                = Empty               extended-by "Carrier : Set"
Magma               = Type                extended-by "_¬∑_ : Carrier ‚Üí Carrier ‚Üí Carrier"
Semigroup           = Magma               postulating "_¬∑_" "associative"
LeftUnitalSemigroup = Semigroup           postulating "_¬∑_" "left-unit"  :using "ùïÄ"
Monoid              = LeftUnitalSemigroup postulating "_¬∑_" "right-unit" :using "ùïÄ"
CommutativeMonoid   = Monoid              postulating "_¬∑_" "commutative"
#+END_SRC

#+latex: \vspace{1ex} \noindent
Of course, one can continue to build packages in a monolithic fashion, as shown
below.

  {{{code()}}}
#+BEGIN_SRC agda
Group = Monoid extended-by "_‚Åª¬π : Carrier ‚Üí Carrier; left‚Åª¬π : ‚àÄ {x} ‚Üí (x ‚Åª¬π) ¬∑ x ‚â° ùïÄ; right‚Åª¬π : ‚àÄ {x} ‚Üí x ¬∑ (x ‚Åª¬π) ‚â° ùïÄ" ‚ü¥ record
#+END_SRC

#+latex: \vspace{1ex} \noindent
After discussing renaming, we return to discuss the loss of relationships when
we augment ~Group~ with a commutativity axiom ---commutative groups are
commutative monoids!

#+latex: \end{fullwidth}

*** Renaming
    :PROPERTIES:
    :CUSTOM_ID: PF-Renaming
    :END:

<<sec:PF:practicality:renaming>>
# +latex: \label{sec:PF:practicality:renaming}

 #+latex: \remark{
    An Abealian monoid is /both/ a commutative monoid and also, simply, a monoid.
    The above declaration freely maintains these relationships: The resulting
    record comes with a new projection src_haskell[:exports
    code]{toCommutativeMonoid}, and still has the /inherited/ projection
    src_haskell[:exports code]{toMonoid}.
#+latex: } \vspace{-1cm}

    From an end-user perspective, our src_haskell[:exports
    code]{CommutativeMonoid} has one flaw: Such monoids are frequently written
    /additively/ rather than multiplicatively. Such a change can be rendered
    conveniently:
 {{{code( Renaming Example )}}}
 #+BEGIN_SRC agda
AbealianMonoid = CommutativeMonoid renaming "_¬∑_ to _+_"
 #+END_SRC

    There are a few reasonable properties that a renaming construction should
    support. Let us briefly look at the (operational) properties of
    src_emacs-lisp[:exports code]{renaming}.

**** Relationship to Parent Packages :ignore:

#+latex: \newline

    *Relationship to Parent Packages.* Dual to src_emacs-lisp[:exports
    code]{extended-by} which can construct (retract) views /to parent/ modules
    mechanically, src_emacs-lisp[:exports code]{renaming} constructs (coretract)
    views /from parent/ packages.
#+latex: \vspace{-1cm}\remark{
    That is, it has an optional argument src_emacs-lisp[:exports
    code]{:adjoin-coretract} which can be provided with src_emacs-lisp[:exports
    code]{t} to use a default name or provided with a string to use a desired
    name for the inverse part of a projection, src_haskell[:exports
    code]{fromMagma} below.
#+latex: }\vspace{1cm}

    {{{code(Adjoining coretracts ---views from parent packages)}}}
 #+BEGIN_SRC agda
Sequential = Magma renaming "op to _‚®æ_" :adjoin-coretract t
 #+END_SRC

#+latex: \vspace{-1.6cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(\texttt{Sequential} elaboration)}}}
 #+ATTR_LATEX: :options fontsize=\small
 #+BEGIN_SRC haskell :remark these-are-just-results-from-previous-blocks :tangle no
record Sequential : Set‚ÇÅ where
    field Carrier : Set
    field _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier

    toType : let View X = X in View Type
    toType = record {Carrier = Carrier}

    toMagma : let View X = X in View Magma
    toMagma = record {Carrier = Carrier;op = _‚®æ_}

    fromMagma : let View X = X in Magma ‚Üí View Sequential
    fromMagma = Œª g227742 ‚Üí record {Carrier = Magma.Carrier g227742;_‚®æ_ = Magma.op g227742}
 #+END_SRC
#+latex: }}

#+latex: \vspace{-0.4cm}\remark{
 This user implementation of src_emacs-lisp[:exports code]{renaming} avoid name
 clashes for Œª-arguments by using /gensyms/ ---generated symbolic names, ‚Äúfresh
 variable names‚Äù.
#+latex: }

**** Commutativity :ignore:

#+latex: \vspace{-2cm}

*Commutativity.* Since src_emacs-lisp[:exports code]{renaming} and
   src_emacs-lisp[:exports code]{postulating} both adjoin retract morphisms, by
   default, we are led to wonder about the result of performing these
   operations in sequence ‚Äòon the fly‚Äô, rather than naming each
   application. Since src_emacs-lisp[:exports code]{P renaming X ‚ü¥ postulating
   Y} comes with a retract src_haskell[:exports code]{toP} via the
   src_emacs-lisp[:exports code]{renaming} and another, distinctly defined,
   src_haskell[:exports code]{toP} via src_emacs-lisp[:exports
   code]{postulating}, we have that the operations commute if /only/ the first
   permits the creation of a @@latex: retract\footnote{@@
For instance, we may define idempotent magmas with
#+latex: \vspace{1ex}\newline
src_emacs-lisp[:exports code]{¬†¬†¬†renaming "_¬∑_ to _‚äî_"}
#+latex: \newline\mbox{
src_emacs-lisp[:exports code]{‚ü¥ postulating "_‚äî_" "idempotent"}
#+latex: }\newline
src_emacs-lisp[:exports code]{:adjoin-retract nil}
#+latex: \vspace{1ex}\newline
or, equivalently (up to reordering of constituents), with
#+latex: \vspace{1ex}\newline
src_emacs-lisp[:exports code]{postulating "_‚äî_" "idempotent" ‚ü¥ renaming "_¬∑_ to _‚äî_"¬†¬†¬†¬† :adjoin-retract nil}
#+latex: }. % \vspace{-0.5cm}
# %\vspace{-2cm}\remark{
#   and still end up with the same elaboration, up to order of constituents.

#+latex: \vspace{1ex}
  It is important to realise that the renaming and postulating combinators are
  /user-defined/, and could have been defined without adjoining a retract by
  default; consequently, we would have *unconditional commutativity of these
  combinators*. The user can make these alternative combinators as follows:

#+latex: \vspace{0.5cm} \begin{fullwidth}
  {{{code(Alternative ‚Äòrenaming‚Äô and ‚Äòpostulating‚Äô ---with an example use)}}}
#+BEGIN_SRC agda
ùí±-renaming' by = renaming 'by :adjoin-retract nil
ùí±-postulating' p bop (using) = postulating 'p 'bop :using 'using :adjoin-retract nil

IdempotentMagma = Magma postulating' "_‚äî_" "idempotent" ‚ü¥ renaming' "_¬∑_ to _‚äî_"
#+END_SRC
#+latex: \end{fullwidth}

# Super neat stuff!

**** Simultaneous Textual Substitution & Involution; self-inverse                            :ignore:

#+latex: \vspace{0em}\remark{
src_haskell[:exports code]{TwoR} is just src_haskell[:exports code]{Two} but as
an Agda src_agda[:exports code]{record}, so it typechecks.
#+latex: } \vspace{-1cm}

Finally, as expected, simultaneous renaming works too, and renaming is an
invertible operation ---e.g., below src_haskell[:exports code]{Magma ≥ ≥} is
identical to src_haskell[:exports code]{Magma}.

#+latex: \vspace{-0.6cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Simultaneous textual substitution example)}}}
 #+ATTR_LATEX: :options fontsize=\small
#+BEGIN_SRC agda
PackageFormer Two : Set‚ÇÅ where
  Carrier : Set
  ùüò       : Carrier
  ùüô       : Carrier

TwoR = Two record ‚ü¥ renaming' "ùüò to ùüô; ùüô to ùüò"
#+END_SRC
#+latex: }}

# Self Inverse
#+latex: \vspace{-2cm}
{{{code(\hspace{-2ex}({\footnotesize Recall \texttt{renaming'} performs renaming but does not adjoin retract views.}))}}}
#+BEGIN_SRC agda
Magma ≥  = Magma  renaming' "_¬∑_  to op"
Magma ≥ ≥ = Magma ≥ renaming' "op   to _¬∑_"
#+END_SRC

**** Do-it-yourself :ignore:

<<sec:PF:practicality:renaming:rename>>
# +latex: \label{sec:PF:practicality:renaming:rename}

#+latex: \begin{fullwidth}
*Do-it-yourself.*
Finally, to demonstrate the accessibility of the system, we show how a generic
renaming operation can be defined swiftly using the primitives mentioned listed
in the first table of this section.  Instead of src_emacs-lisp[:exports
code]{renaming} elements /one at a time/, suppose we want to be able to uniformly
src_emacs-lisp[:exports code]{rename} all elements in a package. That is, given a
function src_emacs-lisp[:exports code]{f} on strings, we want to map over the
name component of each element in the package. This is easily done with the
following declaration.

#+latex: \vspace{1ex}
{{{code(Tersely forming a new variational)}}}
#+begin_src emacs-lisp
ùí±-rename f = map (Œª element ‚Üí (map-name (Œª nom ‚Üí (funcall f nom))) element)
#+end_src
#+latex: \end{fullwidth}

# \noindent Perhaps the main point of the above definition that may be unexpected
# to the Agda programmer is that Lisp function calls are of the form
# src_emacs-lisp[:exports code]{(function arg‚ÇÄ arg‚ÇÅ ... arg‚Çô)}.

#+latex: \vspace{-0.5em}

*** Unions/Pushouts (and intersections)
    :PROPERTIES:
    :CUSTOM_ID: Union
    :END:

<<sec:PF:practicality:pushout>>
# +latex: \label{sec:PF:practicality:pushout}

#+latex: \vspace{-0.5em}

But even with these features, using src_haskell[:exports code]{Group} from above, we would find ourselves writing:
# But even with these features, we may find ourselves writing:
 {{{code()}}}
 #+BEGIN_SRC agda
CommutativeGroup‚ÇÄ = Group extended-by "comm : {x y : Carrier} ‚Üí  x ¬∑ y  ‚â°  y ¬∑ x" ‚ü¥ record
#+END_SRC

#+latex: \noindent
 This is *problematic*: We lose the /relationship/ that every commutative group is a
 commutative monoid.  This is not an issue of erroneous hierarchical design:
 From src_haskell[:exports code]{Monoid}, we could orthogonally add a
 commutativity property or inverse operation; src_haskell[:exports
 code]{CommutativeGroup‚ÇÄ} then closes this diamond-loop by adding both
 features, as shown in the figure to the right.  The simplest way to share
 structure is to union two presentations:

 #+latex_header: \usepackage{my-tikz-cats}
 #+begin_export latex
\vspace{-7cm}\remark{\centerline{Given green, require red}}

$\,$ \hfill \hspace{.95\textwidth}
{\large \maxsizebox{.6\textwidth}{\textheight}{
  \begin{tikzpicture}
    \setlength{\unit}{3cm}
\def\arrowthickness{thick}
\def\nodethickness{thick}
\def\textoffset{0cm}

\mknode{CM}{x = 1, y = 1, given color, text =  \footnotesize Commutative \\ Monoid}
\mknode{MUO}{x = 3, y = 1, given color, text =  \footnotesize Monoid with \\ inverse \\ operation}
\mknode{M}{x = 2, y = 0, given color, text = Monoid}
\mknode{G}{x = 2, y = 2, required color, text = Group}

% Given green,
\mkline[bend left]{left = M}{bot = CM, given color}
\mkline[bend right]{right = M}{bot = MUO, given color}
% Require red,
\mkline[bend left]{top = CM}{left = G, required color}
\mkline[bend right]{top = MUO}{right = G, required color}
\end{tikzpicture}}} \vspace{0cm}
 #+end_export

 {{{code(Unions of packages)}}}
 #+BEGIN_SRC agda
CommutativeGroup = Group union CommutativeMonoid ‚ü¥ record
 #+END_SRC

 \noindent The resulting record, src_haskell[:exports code]{CommutativeMonoidR},
 comes with three[fn:60] derived fields ---src_haskell[:exports code]{toMonoidR,
 toGroupR, toCommutativeMonoidR}--- that retain the results relationships with
 its hierarchical construction.  This approach ‚Äúworks‚Äù to build a sizeable
 library, say of the order of 500 concepts, in a fairly economical way
 citet:tpc. The union operation is an instance of a /pushout/ operation, which
 consists of 5 arguments ---three objects and two morphisms--- which may be
 included into the src_emacs-lisp[:exports code]{union} operation as optional
 keyword arguments.  The more general notion of pushout is required if we were
 to combine[fn:61] src_haskell[:exports code]{Group} with src_haskell[:exports
 code]{AbealianMonoid}, which have non-identical syntactic copies of
 src_haskell[:exports code]{Monoid}.

 #+latex: \remark{\textbf{What is a pushout?}}
 #+latex: \vspace{-0.2em}
 The pushout of morphisms $f : Z ‚Üí X$ and $g : Z ‚Üí Y$ is, essentially, the
 disjoint sum of contexts $X$ and $Y$ where embedded elements are considered
 ‚Äòindistinguishable‚Äô when they share the same origin in $Z$ via the ‚Äòpaths‚Äô $f$
 and $g$ ---the pushout generalises the notion of /least upper bound/ as shown in
 the figure to the right, by treating each ‚Äò‚Üí‚Äô as a ‚Äò‚â§‚Äô.  Unfortunately, the
 resulting ‚Äòindistinguishable‚Äô elements $f(z) ‚âà g(z)$ are *actually
 distinguishable*: They may be the /f/-name or the /g/-name and a choice must be made
 as to which name is preferred since users actually want to refer to them later
 on.  Hence, to be useful for library construction, the pushout construction
 actually requires at least another input function that provides canonical names
 to the supposedly ‚Äòindistinguishable‚Äô elements. Hence, 6 inputs are actually
 needed for forming a /usable/ pushout object.

  #+begin_export latex
\vspace{-5cm}
$\,$ \hfill \hspace{.95\textwidth}
{\large \maxsizebox{.6\textwidth}{\textheight}{
\begin{tikzpicture}
\setlength{\unit}{3cm}
\def\arrowthickness{thick}
\def\nodethickness{thick}
\def\textoffset{0cm}

\mknode{X}{x = 1, y = 1, given color, text = $X$}
\mknode{Y}{x = 3, y = 1, given color, text = $Y$}
\mknode{Z}{x = 2, y = 0, given color, text = $Z$}
\mknode{P}{x = 2, y = 2, required color, text = $P$}
\mknode{PP}{x = 2, y = 3, candidate color, text = $P'$}

% Given green,
\mkline[bend left]{left = Z}{bot = X, given color}
\mkline[bend right]{right = Z}{bot = Y, given color}
% Require red,
\mkline[bend left]{top = X}{left = P, required color}
\mkline[bend right]{top = Y}{right = P, required color}
% such that for any candidate cyan,
\mkline[bend left]{top = X, dx = -0.2cm}{left = PP, candidate color}
\mkline[bend right]{top = Y, dx = +0.2cm}{right = PP, candidate color}
% there is a unique umber
\mkline{top = P}{bot = PP,  dashed, unique color}
\end{tikzpicture}}}

\remark{Given green, require red, such that every candidate cyan has a unique umber}
\vspace{-3.5cm}
  #+end_export

 #+latex: \vspace{-0.2em}
 At first, a pushout construction needs 5 inputs, to be practical it further
 needs a function for canonical names for a total of 6 inputs. However, a
 pushout of $f : Z ‚Üí X$ and $g : Z ‚Üí Y$ is intended to be the ‚Äòsmallest object
 $P$ that contains a copy of $X$ and of $Y$ sharing the common substructure
 $X$‚Äô, and as such it outputs two functions $\mathsf{inj‚ÇÅ} : X ‚Üí P,\,
 \mathsf{inj‚ÇÇ} : Y ‚Üí P$ that inject the names of $X$ and $Y$ into $P$.  If we
 realise $P$ as a record ---a type of models--- then the embedding functions are
 /reversed/, to obtain projections $P ‚Üí X$ and $P ‚Üí Y$: If we have a model of $P$,
 then we can forget some structure and rename via $f$ and $g$ to obtain models
 of $X$ and $Y$.  For the resulting construction to be useful, these names could
 be automated such as $\mathsf{toX} : P ‚Üí X$ and $\mathsf{toY} : P ‚Üí Y$ but such
 a naming scheme does not scale ---but we shall use it for default names. As
 such, we need two more inputs to the pushout construction so the names of the
 resulting output functions can be used later on.  /Hence, a practical choice of
 pushout needs 8 inputs!/

 #+latex: \remark{\textbf{By changing perspective, we halve the number of inputs to the pushout construction!}} \vspace{-0.9cm}

 Since a ~PackageFormer~ is essentially just a /signature/ ---a collection of typed
 names---, we can make a ‚Äòpartial choice of pushout‚Äô to reduce the number of
 arguments from 6 to 4 by letting the typed-names object $Z$ be ‚Äòinferred‚Äô and
 encoding the canonical names function into the operations $f$ and $g$.  The
 input functions $f, g$ are necessarily /signature morphisms/ ---mappings of names
 that preserve types--- and so are simply lists associating names of $Z$ to
 names of $X$ and $Y$. If we instead consider $f' : Z' ‚Üê X$ and $g' : Z' ‚Üê Y$,
 in the /opposite direction/, then we may reconstruct a pushout by setting $Z$ to
 be common image of $f', g'$, and set $f, g$ to be inclusions.  In-particular,
 the full identity of $Z'$ is not necessarily relevant for the pushout
 reconstruction and so it may be omitted. Moreover, the issue of canonical names
 is resolved: @@latex:\emph{@@If $x ‚àà X$ is intended to be identified with $y ‚àà
 Y$ such that the resulting element has $z$ as the chosen canonical name, then
 we simply require $f'\, x = z = g' \, y$.@@latex:}@@
 # An example is shown below in Figure ref:fig:pushout-example.

#+latex: \vspace{-4cm}\remark{
 That is, /this particular user implementation/ realises
 @@latex: \vspace{-0.5em}\begin{center}\hbox{@@
 src_emacs-lisp[:exports code]{X‚ÇÅ union X‚ÇÇ :renaming‚ÇÅ f' :renaming‚ÇÇ g'}
 @@latex: }\end{center}\vspace{-1em}@@
 as the pushout of the inclusions
#+begin_center
 src_haskell[:exports code]{f' X‚ÇÅ ‚à© g' X‚ÇÇ ‚Ü™ X·µ¢}
#+end_center
 where the source is the set-wise intersection of /names/.  Moreover, when either
 src_emacs-lisp[:exports code]{renaming·µ¢} is omitted, it defaults to the
 identity function.
#+latex: } \vspace{3cm}

#+latex: \remark{
In Lisp, optional keyword arguments are passed with the syntax
src_emacs-lisp[:exports code]{:arg val}.
#+latex: } \remark{\centerline{‚ãÜ ‚ãÜ ‚ãÜ}}
#+latex: \remark{
Invoke src_emacs-lisp[:exports code]{union} with
#+latex: \mbox{
src_emacs-lisp[:exports code]{:adjoin-retract·µ¢ "new-function-name"}
#+latex: }
to use a new name, or src_emacs-lisp[:exports code]{nil} instead of a string to
omit the retract ---as was done for src_emacs-lisp[:exports code]{extended-by}
earlier.
#+latex: }

 Incidentally, using the reversed directions of $f, g$ via $f', g'$, we can
 infer the shared structure $Z$ and the canonical name function. Likewise, by
 using $\mathsf{toChild} : P ‚Üí \mathsf{Child}$ default-naming scheme, we may
 omit the names of the retract functions. If we wish to rename these retracts or
 simply omit them altogether, we make them /optional/ arguments.

#+latex: \remark{\centerline{‚ãÜ ‚ãÜ ‚ãÜ}}
#+latex: \remark{Whew, a worked-out example!}
Before we show the implementation of src_emacs-lisp[:exports code]{union}, let
us showcase an example that mentions all arguments, optional and otherwise
---i.e., test-driven development.  Besides the elaboration The *commutative*
diagram, to the right, /informally/ carries out the src_emacs-lisp[:exports
code]{union} construction that results in the elaborated code below.

#+latex: \remark{
The user manual contains full details and an implementation of
intersection, pullback, as well.
#+latex: } \vspace{-0.5cm}
 {{{code(Bimagmas: Two magmas sharing the same carrier)}}}
 #+BEGIN_SRC agda
BiMagma = Magma union Magma :renaming‚ÇÅ "op to _+_" :renaming‚ÇÇ "op to _√ó_"  :adjoin-retract‚ÇÅ "left" :adjoin-retract‚ÇÇ "right"
  #+END_SRC
 {{{code(Elaboration)}}}
 #+BEGIN_SRC haskell :remark these-are-just-results-from-previous-blocks :tangle no
record BiMagma : Set‚ÇÅ where
    field Carrier : Set
    field _+_     : Carrier ‚Üí Carrier ‚Üí Carrier

    toType : let View X = X in View Type
    toType = record {Carrier = Carrier}

    field _√ó_     : Carrier ‚Üí Carrier ‚Üí Carrier

    left : let View X = X in View Magma
    left = record {Carrier = Carrier;op = _+_}

    right : let View X = X in View Magma
    right = record {Carrier = Carrier;op = _√ó_}
 #+END_SRC
#+begin_export latex
\vspace{-7cm}
\remark{\begin{center}Given green, yield yellow, require red, form fuchsia\end{center}}
\vspace{1ex}

$\,$ \hfill \hspace{.95\textwidth}
{\large \maxsizebox{.6\textwidth}{\textheight}{
\begin{tikzpicture}
\setlength{\unit}{4cm}
\def\arrowthickness{thick}
\def\nodethickness{thick}
\def\textoffset{0cm}

\mknode{Add}{x = 1, y = 1, color = green!40!orange, text = \texttt{Carrier \\  \_{}+\_{}}}
\mknode{Mul}{x = 3, y = 1, color = green!40!orange, text = \texttt{Carrier \\  $\_{}\times\_{}$}}
\mknode{Car}{x = 2, y = 0, color = green!40!orange, text = \texttt{Carrier}}
\mknode{Two}{x = 2, y = 2, required color,
  text =  \fbox{BiMagma} \\[0.3ex] \texttt{Carrier \\[-0.2ex]  \_{}+\_{} \\[-0.2ex]  \_{}$\times$\_{}}}
\mknode{Mag}{x = 2, y = 1, given color, text = \fbox{Magma} \\[0.8ex] \texttt{Carrier \\ op}}

% Given green,
\mkline[bend right]{left = Mag}{right = Add, given color, label = $\substack{\texttt{:renaming$_1$} \\ \\ \\}$, location = above}
\mkline[bend left]{right = Mag}{left = Mul, given color, label = $\substack{\texttt{:renaming$_2$} \\ \\ \\}$, location = above}

\mkline[bend left]{left = Car}{bot = Add, label = inclusion, sloped, location = below, color = green!40!orange}
\mkline[bend right]{right = Car}{bot = Mul, label = inclusion, sloped, location = below, color = green!40!orange}

% Require red,
\mkline[bend left]{top = Add}{left = Two, required color, label = inclusion, sloped, location = above}
\mkline[bend right]{top = Mul}{right = Two, required color, label = inclusion, sloped, location = above}
\mkline[bend right]{bot = Two, dx = -0.2cm}{top = Mag, dx = -0.1cm, color = pink!40!purple, label = \texttt{left}, location = left}
\mkline[bend left]{bot = Two, dx = +0.2cm}{top = Mag, dx = +0.1cm, color = pink!40!purple, label = \texttt{right}, location = right}
\end{tikzpicture}}} \vspace{0.5cm}
#+end_export

 *Idempotence.* The main reason that the construction is named ‚Äòunion‚Äô instead of
 ‚Äòpushout‚Äô is that, modulo adjoined retracts, it is idempotent.  For example,
 src_emacs-lisp[:exports code]{Magma union Magma ‚âà Magma} ---this is essentially
 the previous bi-magma example /but/ we are not distinguishing (via
 src_emacs-lisp[:exports code]{:renaming·µ¢}) the two instances of
 src_haskell[:exports code]{Magma}.

#+latex: \vspace{-3cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(\texttt{MagmaAgain = Magma union Magma})}}}
 #+ATTR_LATEX: :options fontsize=\small
 #+BEGIN_SRC agda
record MagmaAgain : Set‚ÇÅ where
    field Carrier : Set
    field op      : Carrier ‚Üí Carrier ‚Üí Carrier

    toType : let View X = X in View Type
    toType = record {Carrier = Carrier}

    toMagma : let View X = X in View Magma
    toMagma = record {Carrier = Carrier;op = op}
 #+END_SRC
#+latex: }} \vspace{3cm}

*Disjointness.* On the other extreme, distinguishing all the names of one of the
input objects, we have disjoint sums.  In contrast to the above bi-magma, in the
example below, we are not distinguishing the two instances of
src_haskell[:exports code]{Magma} ‚Äòon the fly‚Äô via src_emacs-lisp[:exports
code]{:renaming·µ¢} but instead making them disjoint beforehand using
src_emacs-lisp[:exports code]{primed} ---which is specified informally as
#+latex: \quad
src_emacs-lisp[:exports code]{p primed  ‚âà  p :renaming (Œª name ‚Üí name ++ "'")}.
{{{code()}}}
 #+BEGIN_SRC agda
Magma'    = Magma primed  ‚ü¥ record
SumMagmas = Magma union Magma' :adjoin-retract‚ÇÅ nil ‚ü¥ record
 #+END_SRC

#+latex: \vspace{-5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Elaboration)}}}
 #+ATTR_LATEX: :options fontsize=\small
 #+BEGIN_SRC haskell :remark these-are-just-results-from-previous-blocks :tangle no
record SumMagmas : Set‚ÇÅ where
    field Carrier  : Set
    field op       : Carrier ‚Üí Carrier ‚Üí Carrier

    toType         : let View X = X in View Type
    toType = record {Carrier = Carrier}

    field Carrier' : Set
    field op'      : Carrier' ‚Üí Carrier' ‚Üí Carrier'

    toType' : let View X = X in View Type
    toType' = record {Carrier = Carrier'}

    toMagma : let View X = X in View Magma
    toMagma = record {Carrier = Carrier';op = op'}

    toMagma' : let View X = X in View Magma'
    toMagma' = record {Carrier' = Carrier';op' = op'}
 #+END_SRC
#+latex: }} \vspace{-0.5cm}

# After a remark on implementation, we discuss how the user-defined
# src_emacs-lisp[:exports code]{union} variational can be used to solve the
# diamond problem posed at the start of this section, then we conclude with an
# example algebraic hierarhcy /declared tersely, and succiently,/ by using
# src_emacs-lisp[:exports code]{union}.
#

**** An Implementation of src_C[:exports code]{union} :ignore:

 Before returning to the diamond problem, we show an implementation not so that
 the reader can see some cleverness ---not that we even expect the reader to
 understand it--- but instead to showcase that a sufficiently complicated
 combinator, which is /not built-in/, can be defined without much difficulty.

#  \noindent
#  The reader is not meant to understand the (abridged) definition provided below, however we
#  present a few implementation remarks and wish to emphasise that this definition
#  is *not built in*, and so the user could have, for example, provided a faster
#  implementation by omitting checks for name clashes.
#
#+latex: \vspace{-0.15cm}
#+latex: \hspace{-1.8em}\begin{minipage}{13.245cm} \maxsizebox{!}{0.6\textheight}{
 {{{code( (Abridged) Pushout combinator with 4 optional arguments)}}}
 #+ATTR_LATEX: :options fontsize=\footnotesize
 #+begin_src emacs-lisp
(ùí± union pf (renaming‚ÇÅ "") (renaming‚ÇÇ "") (adjoin-retract‚ÇÅ t) (adjoin-retract‚ÇÇ t)

 = "Union the elements of the parent PackageFormer with those of
    the provided PF symbolic name, then adorn the result with two views:
    One to the parent and one to the provided PF.

    If an identifer is shared but has different types, then crash.

    ADJOIN-RETRACT·µ¢, for i : 1..2, are the optional names of the resulting
    views. Provide NIL if you do not want the morphisms adjoined."
   :alter-elements (Œª es ‚Üí
     (let* ((p (symbol-name 'pf))
            (es‚ÇÅ (alter-elements es renaming renaming‚ÇÅ :adjoin-retract nil))
            (es‚ÇÇ (alter-elements ($ùëíùëôùëíùëöùëíùëõùë°ùë†-ùëúùëì p) renaming renaming‚ÇÇ
                                 :adjoin-retract nil))
            (es' (-concat es‚ÇÅ es‚ÇÇ))
            (name-clashes (loop for n in (find-duplicates (mapcar #'element-name es'))
                                for e = (--filter (equal n (element-name it)) es')
                                unless (--all-p (equal (car e) it) e)
                                collect e))
            (er‚ÇÅ (if (equal t adjoin-retract‚ÇÅ) (format "to%s" $ùëùùëéùëüùëíùëõùë°)
                   adjoin-retract‚ÇÅ))
            (er‚ÇÇ (if (equal t adjoin-retract‚ÇÇ) (format "to%s" p)
                   adjoin-retract‚ÇÇ)))

       (if name-clashes
            (-let [debug-on-error nil]
              (error "%s = %s union %s \n\n\t\t ‚û© Error:
                      Elements ‚Äú%s‚Äù conflict!\n\n\t\t\t%s"
                      $ùëõùëéùëöùëí $ùëùùëéùëüùëíùëõùë° p (element-name (caar name-clashes))
                      (s-join "\n\t\t\t" (mapcar #'show-element (car name-clashes))))))

   ;; return value
   (-concat es'
            (and adjoin-retract‚ÇÅ (not er‚ÇÅ) (list (element-retract $ùëùùëéùëüùëíùëõùë° es :new es‚ÇÅ :name adjoin-retract‚ÇÅ)))
            (and adjoin-retract‚ÇÇ (not er‚ÇÇ) (list (element-retract p ($ùëíùëôùëíùëöùëíùëõùë°ùë†-ùëúùëì p) :new es‚ÇÇ :name adjoin-retract‚ÇÇ)))))))
 #+end_src
 #+latex: }\end{minipage}
#       ;; Error on name clashes; unabridged version has a mechanism to ‚Äúfix conflicts‚Äù
#       ;; The unabridged version accounts for name clashes on retracts as well.

#+latex: \vspace{-8cm}\remark{
Indeed, the core of the construction lies in the first 12 lines of
the src_emacs-lisp[:exports code]{let*} clause; the rest are extra
bells-and-whistles ---which could have been omitted, by the user, for a faster
implementation.
#+latex: }

#+latex: \vspace{3cm}\remark{
The unabridged definition, on the =PackageFormer= webpage, has more
features. In particular, it accepts additional keyword toggles that dictate
how it should behave when name clashes occur; e.g., whether it should
halt and report the name clash or whether it should silently perform a name
change, according to another provided argument. The additional flexibility
is useful for rapid experimentation.
#+latex: }\vspace{3cm}

#  1. Since the systems allows optional keyword arguments, the first line declares
#     only a context name, src_emacs-lisp[:exports code]{pf}, is mandatory and the
#     remaining arguments to a pushout are ‚Äòinferred‚Äô unless provided.
#  2. The second line documents this new user-defined variational; the
#     documentation string is attached as a tooltip to all instances of the phrase
#     src_emacs-lisp[:exports code]{union}.
#  3. Given src_emacs-lisp[:exports code]{f, g} as src_emacs-lisp[:exports code]{renaming·µ¢}, we apply the renaming variational on the elements of
#     the implicit context (to this variational) and to the given context src_emacs-lisp[:exports code]{pf}
#     to obtain two new element lists src_emacs-lisp[:exports code]{e·µ¢}.
#  4. We then adjoin retract elements src_emacs-lisp[:exports code]{er·µ¢}.
#  5. Finally, we check for name clashes and handle them appropriately.
#

#+latex: \vspace{1ex}

**** Support for Diamond Hierarchies

#+latex: \begin{fullwidth}
 A common scenario is extending a structure, say src_haskell[:exports
 code]{Magma}, into orthogonal directions, such as by making its operation
 associative or idempotent, then closing the resulting diamond by combining
 them, to obtain a semilattice. However, the orthogonal extensions may involve
 different names and so the resulting semilattice presentation can only be
 formed via pushout; below are three ways to form it.

 #+latex: \vspace{0.5cm}
 {{{code(Three ways to get to SemiLattice)}}}
 #+BEGIN_SRC agda
Semigroup          = Magma postulating "_¬∑_" "associative"
IdempotentMagma    = Magma renaming "_¬∑_ to _‚äî_" ‚ü¥ postulating "_‚äî_" "idempotent"  :adjoin-retract nil

‚äî-SemiLattice     = Semigroup union IdempotentMagma :renaming‚ÇÅ "_¬∑_ to _‚äî_"
¬∑-SemiLattice     = Semigroup union IdempotentMagma :renaming‚ÇÇ "_‚äî_ to _¬∑_"
‚Üë-SemiLattice     = Semigroup union IdempotentMagma :renaming‚ÇÅ "_¬∑_ to _‚Üë_" :renaming‚ÇÇ "_‚äî_ to _‚Üë_"
 #+END_SRC
#+latex: \end{fullwidth}
**** Application: Granular (Modular) Hierarchy for Rings
 We will close with the classic example of forming a ring structure by combining
 two monoidal structures.  This example also serves to further showcase how
 using src_emacs-lisp[:exports code]{postulating} can make for more granular,
 modular, developments.

 {{{code()}}}
 #+BEGIN_SRC agda
Additive           = Magma renaming "_¬∑_ to _+_" ‚ü¥ postulating "_+_" "commutative"  :adjoin-retract nil ‚ü¥ record

Multiplicative     = Magma renaming "_¬∑_ to _√ó_" :adjoin-retract nil ‚ü¥ record

AddMult            = Additive union Multiplicative ‚ü¥ record

AlmostNearSemiRing = AddMult ‚ü¥ postulating "_√ó_" "distributiveÀ°" :using "_+_" ‚ü¥ record
 #+END_SRC

#+latex: \vspace{-6cm} $\,$ \hfill \hspace{.9\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Elaboration)}}}
 #+ATTR_LATEX: :options fontsize=\small
 #+BEGIN_SRC haskell :remark these-are-just-results-from-previous-blocks :tangle no
record AlmostNearSemiRing : Set‚ÇÅ where
    field Carrier : Set
    field _+_     : Carrier ‚Üí Carrier ‚Üí Carrier

    toType : let View X = X in View Type
    toType = record {Carrier = Carrier}

    toMagma : let View X = X in View Magma
    toMagma = record {Carrier = Carrier;op = _+_}

    field comm       : ‚àÄ x y   ‚Üí _+_ x y ‚â° _+_ y x
    field _√ó_        : Carrier ‚Üí Carrier ‚Üí Carrier

    toAdditive : let View X = X in View Additive
    toAdditive = record {Carrier = Carrier;_+_ = _+_;comm = comm}

    toMultiplicative : let View X = X in View Multiplicative
    toMultiplicative = record {Carrier = Carrier;_√ó_ = _√ó_}

    field distÀ°      : ‚àÄ x y z ‚Üí _√ó_ x (_+_ y z) ‚â° _+_ (_√ó_ x y) (_√ó_ x z)
 #+END_SRC
#+latex: }} \vspace{-1cm}

\noindent
This example, as well as mitigating diamond problems, show that the
implementation outlined is reasonably well-behaved.

*** COMMENT ùëµùë∂ Pullbacks
 Following the reasoning for pushouts, we implement pullbacks in the same way with the same optional arguments.
 Here's an example use:
 {{{code()}}}
 #+BEGIN_SRC agda
{-700
Just-Carrier    = Additive intersect Multiplicative
Magma-yet-again = Additive intersect Multiplicative :renaming‚ÇÅ "_+_ to op" :renaming‚ÇÇ "_√ó_ to op"
-}
 #+END_SRC
 Moreover the absorptive law $X ‚à© (X ‚à™ Z) = X$ also holds for these operations:
 {{{newline}}}
 ~Additive intersect AddMult~ is just ~Additive~, when we ignore all adjoined retracts.

*** Duality
    :PROPERTIES:
    :CUSTOM_ID: Duality
    :END:

<<sec:PF:duality>>
# +latex: \label{sec:PF:duality}

#+latex: \remark{
The *dual*, or opposite, of a binary operation src_agda[:exports code]{_¬∑_ : X ‚Üí Y ‚Üí
 Z} is the operation src_agda[:exports code]{_¬∑·µí·µñ_ : Y ‚Üí X ‚Üí Z} defined by
 src_agda[:exports code]{x ¬∑·µí·µñ y = y ¬∑ x}.
#+latex: } \vspace{-1cm}

 Maps between grouping mechanisms are sometimes called /views/, which are
 essentially an internalisation of the /variationals/ in our system.  A useful
 view is that of capturing the heuristic of /dual concepts/, e.g., by changing the
 order of arguments in an operation. Classically in Agda, duality is /utilised/ as
 follows:

 1. Define a /parameterised/ module src_haskell[:exports code]{R _¬∑_} for the
    desired ideas *on* the operation src_haskell[:exports code]{_¬∑_}.

   #+latex: \vspace{-1.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.5\textwidth}{\textheight}{
   {{{code(Example)}}}
   #+ATTR_LATEX: :options fontsize=\small
    #+begin_src agda
module R (_¬∑_ : X ‚Üí Y ‚Üí Z) where
    ¬∑-isLeftId : X ‚Üí Set
    ¬∑-isLeftId e = ‚àÄ {x} ‚Üí e ¬∑ x ‚â° x
    #+end_src
    #+latex: }}

 2. Define a shallow (parameterised) module src_haskell[:exports code]{R·µí·µñ _¬∑_}
    that essentially only opens src_haskell[:exports code]{R _¬∑·µí·µñ_} and renames
    the concepts in src_haskell[:exports code]{R} with dual names.

   #+latex: \vspace{-1.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.5\textwidth}{\textheight}{
   {{{code(Continuing...)}}}
   #+ATTR_LATEX: :options fontsize=\small
    #+begin_src agda
module R·µí·µñ (_¬∑_ : X ‚Üí Y ‚Üí Z) where
    public open R _¬∑_
           renaming (¬∑-isLeftId to ¬∑-isRightId)
    #+end_src
    #+latex: }}

    # +latex: \begin{tcolorbox}[title = The Ubiquity of Duality, colback=red!5!white, colframe=red!75!black]
#+latex: \remark{
\textbf{The ubiquity of duality!}
#+latex: } \noindent
 The RATH-Agda citet:RATH library performs essentially this approach, for example
 for obtaining src_haskell[:exports code]{UpperBounds} from src_haskell[:exports
 code]{LowerBounds} in the context of an ordered set.  Moreover, since category
 theory can serve as a foundational system of reasoning (logic) and
 implementation (programming), the idea of duality immediately applies to
 produce ‚Äútwo for one‚Äù theorems and programs.
 # +latex: \end{tcolorbox}

 #+latex: \remark{
Admittedly, RATH-Agda's names are well-chosen; e.g., src_emacs-lisp[:exports
 code]{value}, src_emacs-lisp[:exports code]{bound·µ¢}, src_emacs-lisp[:exports
 code]{universal} to denote a src_emacs-lisp[:exports code]{value} that is a
 lower/upper src_emacs-lisp[:exports code]{bound} of two given elements,
 satisfying a least upper bound or greatest lower bound src_emacs-lisp[:exports
 code]{universal} property.
#+latex: } \vspace{0cm}
 Unfortunately, this means that any record definitions in src_haskell[:exports
 code]{R} must have their field names be sufficiently generic to play /both/ roles
 of the original and the dual concept.  However, well-chosen names come at an
 upfront cost: One must take care to provide sufficiently generic names and
 account for duality at the outset, irrespective of whether one /currently/ cares
 about the dual or not; otherwise when the dual is later formalised, then the
 names of the original concept must be refactored throughout a library and its
 users.  This is not the case using =PackageFormer=.

 Consider the following heterogeneous algebra ---which is essentially the main
 example of section ref:sec:PF_scrap_repetition but missing the associativity
 field.

#+latex: \begin{fullwidth}\vspace{-0.2cm}
 {{{code(Left unital actions)}}}
 #+BEGIN_SRC agda
PackageFormer LeftUnitalAction : Set‚ÇÅ where
  Scalar : Set
  Vector : Set
  _¬∑_     : Scalar ‚Üí Vector ‚Üí Vector
  ùüô       : Scalar
  leftId  : {x : Vector} ‚Üí ùüô ¬∑ x ‚â° x

-- Let's reify this as a valid Agda record declaration
LeftUnitalActionR  = LeftUnitalAction ‚ü¥ record
 #+END_SRC

#+latex: \noindent \vspace{.5em}
Informally, one now ‚Äòdefines‚Äô a right unital action by duality,
 flipping the binary operation and renaming src_agda[:exports code]{leftId} to
 be src_agda[:exports code]{rightId}. Such informal parlance is in-fact nearly
 formally, as the following:

 #+latex: \vspace{.5em}
 {{{code(Right unital actions ---mechanically by duality)}}}
 #+BEGIN_SRC agda
RightUnitalActionR = LeftUnitalActionR flipping "_¬∑_" :renaming "leftId to rightId" ‚ü¥ record
 #+END_SRC
#+latex: \end{fullwidth}

#+latex: \begin{fullwidth}
\noindent Of course the resulting representation is semantically identical to
 the previous one, and so it is furnished with a $\mathsf{to}Parent$ mapping:

  #+latex: \vspace{.5em}
 {{{code()}}}
 #+BEGIN_SRC agda
forget : RightUnitalActionR ‚Üí LeftUnitalActionR
forget = RightUnitalActionR.toLeftUnitalActionR
 #+END_SRC

 \noindent
 Likewise, for the RATH-Agda library's example from above, to define semi-lattice structures by duality:
 #+latex: \vspace{1ex}
 {{{code(\texttt{import Data.Product as P})}}}
 #+BEGIN_SRC agda
PackageFormer JoinSemiLattice : Set‚ÇÅ where
  Carrier : Set
  _‚äë_     : Carrier ‚Üí Carrier ‚Üí Set

  refl    : ‚àÄ {x}     ‚Üí x ‚äë x
  trans   : ‚àÄ {x y z} ‚Üí x ‚äë y ‚Üí y ‚äë z ‚Üí x ‚äë z
  antisym : ‚àÄ {x y}   ‚Üí x ‚äë y ‚Üí y ‚äë x ‚Üí x ‚â° y

  _‚äî_     : Carrier ‚Üí Carrier ‚Üí Carrier
  ‚äî-lub   : ‚àÄ {x y z} ‚Üí x ‚äë z ‚Üí y ‚äë z ‚Üí (x ‚äî y) ‚äë z
  ‚äî-lubÀò  : ‚àÄ {x y z} ‚Üí (x ‚äî y) ‚äë z  ‚Üí  x ‚äë z  P.√ó  y ‚äë z

JoinSemiLatticeR = JoinSemiLattice record
MeetSemiLatticeR = JoinSemiLatticeR flipping "_‚äë_" :renaming "_‚äî_ to _‚äì_; ‚äî-lub to ‚äì-glb"
 #+END_SRC
 #+latex: \vspace{1ex}
 \noindent
 In this example, besides the map from meet semi-lattices to join semi-lattices,
 the types of the dualised names, such as src_agda[:exports code]{‚äì-glb}, are
 what one would expect were the definition written out explicitly:
 #+latex: \vspace{1ex}
 {{{code(Checking the types of the duals)}}}
 #+BEGIN_SRC agda
module woah (M : MeetSemiLatticeR) where
  open MeetSemiLatticeR M

  lub_dual_type : ‚àÄ {x y z} ‚Üí z ‚äë x ‚Üí z ‚äë y ‚Üí z ‚äë (x ‚äì y)
  lub_dual_type = ‚äì-glb

  trans_dual_type : let _‚äí_ = Œª x y ‚Üí y ‚äë x
                    in ‚àÄ {x y z} ‚Üí x ‚äí y ‚Üí y ‚äí z ‚Üí x ‚äí z
  trans_dual_type = trans
 #+END_SRC

#+latex: \end{fullwidth}
#+latex: \vspace{-1em}

*** Extracting Little Theories
    :PROPERTIES:
    :CUSTOM_ID: Extracting-Little-Theories
    :END:

#+latex: \vspace{-0.5em}

<<sec:PF:extracting_little_theories>>
# +latex: \label{sec:PF:extracting_little_theories}

 The src_emacs-lisp[:exports code]{extended-by} variational allows Agda users to
 easily employ the /tiny theories/ citet:little_theories approach to library
 design: New structures are built from old ones by augmenting one concept at a
 time ---as shown below--- then one uses mixins such as src_emacs-lisp[:exports
 code]{union} to obtain a complex structure.  This approach lets us write a
 program, or proof, in a context that only provides what is /necessary/ for that
 program-proof and nothing more.  In this way, we obtain /maximal generality/ for
 re-use!  This approach can be construed as /the interface segregation
 principle/ citet:old-design-patterns-solid,design_patterns_head_first: /No client
 should be forced to depend on methods it does not use./

#+latex: \vspace{-0.2cm}
#+latex: \hspace{-1.8em}\begin{minipage}{13.3cm} \maxsizebox{!}{0.1\textheight}{
 {{{code(Tiny Theories Example)}}}
 #+ATTR_LATEX: :options fontsize=\footnotesize
 #+BEGIN_SRC agda :tangle no
PackageFormer Empty : Set‚ÇÅ where {- No elements -}
Type  = Empty extended-by "Carrier : Set"
Magma = Type  extended-by "_¬∑_ : Carrier ‚Üí Carrier ‚Üí Carrier"
CommutativeMagma = Magma extended-by "comm : {x y : Carrier} ‚Üí  x ¬∑ y  ‚â°  y ¬∑ x"
 #+END_SRC
#+latex: }\end{minipage}

 However, life is messy and sometimes one may hurriedly create a structure, then
 later realise that they are being forced to depend on unused methods.  Rather
 than throw a =not implemented= exception or leave them undefined, we may use the
 src_emacs-lisp[:exports code]{keeping} variational to *extract the smallest
 well-formed sub-PackageFormer that mentions a given list of identifiers*.  For
 example, suppose we quickly formed ~Monoid~ *monolithicaly* as presented at the
 start of section ref:sec:PF:extension, but later wished to utilise other
 substrata. This is easily achieved with the following declarations.

 #+latex: \vspace{1ex}
 {{{code(Extracting Substrata from a Monolithic Construction)}}}
 #+BEGIN_SRC agda
Empty'        = Monoid keeping ""
Type'         = Monoid keeping "Carrier"
Magma'        = Monoid keeping "_¬∑_"
Semigroup'    = Monoid keeping "assoc"
PointedMagma' = Monoid keeping "ùïÄ; _¬∑_"
                -- This is just ‚Äú keeping: Carrier; _¬∑_; ùïÄ ‚Äù
 #+END_SRC

  #+latex: \vspace{1ex}
 \noindent Even better, we may go about deriving results ---such as theorems or
 algorithms--- in familiar settings, such as ~Monoid~, only to realise that they
 are written in *settings more expressive than necessary*. Such an observation
 no longer need to be found by inspection, instead it may be derived
 mechanically.

  #+latex: \vspace{1ex}
 {{{code(Specialising a result from an expressive setting to the
 \textbf{minimal} necessary setting)}}}
 #+BEGIN_SRC agda
LeftUnitalMagma = Monoid keeping "ùïÄ-unique" ‚ü¥ record
 #+END_SRC

  #+latex: \vspace{1ex}
 \noindent This expands to the following theory, minimal enough to derive
 src_haskell[:exports code]{ùïÄ-unique}.
 #+latex: \vspace{1cm}\begin{fullwidth}
 #+latex: \vspace{1ex}
 {{{code(Elaboration)}}}
 #+BEGIN_SRC haskell :remark these-are-just-results-from-previous-blocks :tangle no :tangle no
record LeftUnitalMagma : Set‚ÇÅ where

   field
     Carrier : Set
     _¬∑_     : Carrier ‚Üí Carrier ‚Üí Carrier
     ùïÄ       : Carrier
     leftId  : {x : Carrier} ‚Üí ùïÄ ¬∑ x  ‚â° x

   ùïÄ-unique     : ‚àÄ {e} (lid : ‚àÄ {x} ‚Üí e ¬∑ x ‚â° x) (rid : ‚àÄ {x} ‚Üí x ¬∑ e ‚â° x) ‚Üí e ‚â° ùïÄ
   ùïÄ-unique lid rid = ‚â°.trans (‚â°.sym leftId) rid
 #+END_SRC
#+latex: \end{fullwidth}

 #+latex: \vspace{1ex}
 \noindent Surprisingly, in some sense, src_emacs-lisp[:exports code]{keeping}
 let's us apply the interface segregation principle, or ‚Äòlittle theories‚Äô, *after
 the fact* ---this is also known as /[[https://en.wikipedia.org/wiki/Reverse_mathematics][reverse mathematics]]/.

*** 200+ theories ---one line for each
    :PROPERTIES:
    :CUSTOM_ID: hundreds-of-theories
    :END:


<<sec:PF:hundreds-of-theories>>
# +latex: \label{sec:PF:hundreds-of-theories}

#+latex: \remark{
‚Üª /People should enter terse, readable, specifications that expand into useful,
typecheckable, code that may be dauntingly larger in textual size./ ‚Ü∫
#+latex: } \vspace{-1cm}

    In order to demonstrate the *immediate practicality* of the ideas embodied by
    src_haskell[:exports code]{PackageFormer}, we have implemented a list of
    mathematical concepts from universal algebra ---which is useful to computer
    science in the setting of specifications.  The list of structures is adapted
    from the source of a MathScheme library, which in turn was inspired by web
    lists of [[http://math.chapman.edu/~jipsen/structures/doku.php][Peter Jipsen]], [[http://home.utah.edu/~nahaj/logic/structures/][John Halleck]], and many others from Wikipedia and nLab
    citet:tpc,mathscheme. Totalling over 200 theories which elaborate into nearly
    1500 lines of typechecked Agda, this demonstrates that our systems works;
    the *over 80% source savings* speak for themselves.

     #+latex: \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]
     The 200+ one line specifications and their ~1500 lines of elaborated
     typechecked Agda can be found on src_haskell[:exports
     code]{PackageFormer}'s webpage.
     #+latex: \vspace{-1em}
     | https://alhassy.github.io/next-700-module-systems |
     #+latex: \tcblower
       If anything, this elaboration demonstrates our tool as a useful
       engineering result.  The main novelty being the ability for library users
       to extend the collection of operations on packages, modules, and then
       have it immediately applicable to Agda, an *executable* programming
       language.
     #+latex: \end{tcolorbox}

# +latex: \begin{tcolorbox}[title = Extensiblity, colback=red!5!white, colframe=red!75!black]
#+latex: \vspace{-3cm} \remark{
Unlike other systems, src_haskell[:exports code]{PackageFormer} does not come
with a static set of module operators ---it grows dynamically, possibly by you,
the user.
#+latex: } \vspace{2cm}
# +latex: \end{tcolorbox}

#+latex: \remark{
  MathScheme's design hierarchy raised certain semantic concerns that we think
  are out-of-place, but we chose to leave them as is ---e.g., one would think
  that a ‚Äúpartially ordered magma‚Äù would consist of a set, an order relation,
  and a binary operation that is monotonic in both arguments; however,
  ~PartiallyOrderedMagma~ instead comes with a single monotonicity axiom which is
  only equivalent to the two monotonicity claims in the setting of a monoidal
  operation.
#+latex: }
  Since the resulting *expanded code is typechecked* by Agda, we encountered a
  number of places where non-trivial assumptions accidentally got-by the
  MathScheme team.  For example, in a number of places, an arbitrary binary
  operation occurred multiple times leading to ambiguous terms, since no
  associativity was declared.  Even if there was an implicit associativity
  criterion, one would then expect multiple copies of such structures, one
  axiomatisation for each parenthesisation.  Nonetheless, we are grateful for
  the source file provided by the MathScheme team.
  # Indeed, monotonicity in the second argument cannot be proven from the given
  # law for the operation ‚Äúx ‚ü™ y = x‚Äù when ‚â§ is taken to be ‚âà, and we have 2 points.

** COMMENT ‚ü®No‚ü© Things learned from making a protottype?
     * Perhaps show the minimal code needed to get PF working; <= 300 lines?
     * Much more Lisp for implementing common grouping mechanisms; e.g., pushouts.
** COMMENT ‚ü®No‚ü© How usable is it?
** COMMENT ‚ü®No‚ü© What exotic notions of grouping mechanisms can be coded-up? Utilit!?
** COMMENT ‚ü®No‚ü© [Disadvantages of PackageFormer?
** COMMENT ‚ü®No‚ü© Two
 Design patterns for theories become library methods! An interesting side-effect
 of having meta-primitives for packages is that traditional patterns for theories
 ‚Äîe.g., homomorphisms, syntax, interpretation functions‚Äî can now be codified as
 general re-usable methods.

** COMMENT ‚ü®No‚ü© One

 Think of a language that does not support currying and you need to have a
 function of 10 arguments that needs to support accepting any number of arguments
 less than 10, say for partial application. In such languages, one must utilise
 the builder design pattern, or quickly copy-paste the function 10 times,
 altering it slightly each time. In general, if such a function definition
 requires N lines and M forms of the function are needed, then nearly N √ó M lines
 of code are written manually.

** COMMENT ‚ü®No‚ü© Semantics

*** Intro :ignore:

 Herein we demonstrate how with a little bit of Lisp, one may create any
 desired form of grouping mechanism as well as operation between groupings.

 # We also give an overview of the semantics of variationals where we use the
 # context-like syntax, section ref:lost ref:grammar_DTL, ~‚ü®k; ‚Ñì; q‚ÇÄ n‚ÇÄ ‚à∂ œÑ‚ÇÄ [‚âî d‚ÇÄ], ‚Ä¶, q‚ÇÄ
 # n‚Çñ ‚à∂ œÑ‚Çñ ‚âî [‚âî d‚Çñ]‚ü©~ for the =PackageFormer= context with names ~n·µ¢~ of type ~œÑ·µ¢~ with
 # optional definition ~d·µ¢~ and optional qualifier ~q·µ¢~, such as =field= or =private= or
 # ~parameter~; and ~k~ is the ‚Äòkind‚Äô of grouping construct supported ---namely,
 # ~PackageFormer, record, data,~ and ~module~--- and =‚Ñì= is the universe level that the
 # context inhabits. Let us write =x ‚üø y= to indicate that /x reduces to y/.

Rather than present the implementation, we shall present an abstract interpreter
----a relation ‚Äò‚üø‚Äô that specifies how terms ‚Äòreduce‚Äô.
To present the rules for this relation, we will use an abbreviated form of
contexts ---which is not valid concrete syntax.
{{{code(Linear Abbreviation for PackageFormer Contexts)}}}
#+BEGIN_SRC agda
  Name  = ‚ü®k; ‚Ñì; q·µ¢ Œ∑·µ¢ : œÑ·µ¢ ‚âî Œ¥·µ¢‚ü©·µ¢
‚âà
  k Name : Set ‚Ñì where

     q‚ÇÄ Œ∑‚ÇÄ : œÑ‚ÇÄ
        Œ∑‚ÇÄ = Œ¥‚ÇÄ

     ‚ãÆ

     q‚Çñ Œ∑‚Çñ : œÑ‚Çñ
        Œ∑‚Çñ = Œ¥‚Çñ
#+END_SRC
A =PackageFormer= context is simply two tags, a ‚Äòkind‚Äô ~k~ and a level ~‚Ñì~, along with
a list of ‚Äòelements‚Äô which consist of components ~qualifier q·µ¢, name Œ∑·µ¢, type œÑ·µ¢,
equations~ definitions =Œ¥·µ¢=---the first and last are optional.
:ElementInterface:
Elements have the following interface, where ‚Ñ∞ denotes a component name:

| ~(make-element ùìÜ ùìÉ ùìâ ‚ÑØ)~      | An ~element~ value is formed                                |
| ~(element-‚Ñ∞ e)~               | Project component ‚Ñ∞ from element ~e~                        |
| ~(map-‚Ñ∞ f e)~                 | Return a copy of ~e~ with component ‚Ñ∞ updated by function ~f~ |
| ~(element-replace old new e)~ | Replace all string occurances of ~old~ by ~new~ in element ~e~  |

# #
| You can always see the documentation of an item with ~C-h o~ |
:End:
:List_String_methods:
     | ~(list x‚ÇÄ ‚Ä¶ x‚Çô)~            | Form a list of elements ~x·µ¢~.                    |
     | ~(car xs)~                  | Obtain first element of list ~xs~.               |
     | ~(cdr xs)~                  | Obtain all but first element of ~xs~.            |
     | ~(cons x xs)~               | Form a new list with car ~x~ and cdr ~xs~.         |
     | ~(mapcar (Œª it ‚Üí ‚ãØit‚ãØ) xs)~ | Map the given function on ~xs.~                  |
     | ~(--map (‚ãØit‚ãØ) xs)~         | Map the /implicit/ function ~(Œª it ‚Üí ‚ãØit‚ãØ)~ on ~xs~. |
     | ~(-cons* x‚ÇÄ ‚Ä¶ x‚Çô xs)~       | ~(cons x‚ÇÄ (cons x‚ÇÅ (‚ãØ (cons x‚Çô xs))))~.          |

   + *Strings*

     | ~(concat s‚ÇÄ ‚Ä¶ s‚Çô)~      | Concatenate strings ~s·µ¢~.                                                 |
     | ~(s-replace old new s)~ | Replace all string occurrences of ~old~ by ~new~ in string ~e~.               |
     | ~(rename-mixfix f op)~  | Rename string ~op~ according to function ~f~ by ‚Äòleaping over‚Äô underscores. |
     |                       | E.g., ~f, op = (Œª x ‚Üí (concat x "'")), _‚äï_  ‚áí _‚äï'_~.                        |
:End:

# # We will provide rules for declaration syntax, ‚Ä¶?

*** Declaration Rules
<<rules:declaration>>
#+latex: \label{rules:declaration}

    Begin extensible, the system allows user definable variationals which can
    then be applied create new contexts.  For instance, the simplest user
    definable variational, the empty one, could be defined and used as follows.
{{{code(User-defined variational and application thereof)}}}
 #+BEGIN_SRC agda
{-700
-- Variational with empty right hand side.
ùí±-identity =

-- Using it to form a new context
MonoidP‚Å±·µà = MonoidP identity
-}
         #+END_SRC

    The prefix ~ùí±-~ signals to the Elisp meta-program that this particular
    equation is intended to be a variational and should be /loaded into Emacs/ as
    such. Indeed, you may view the documentation and /elaborated/ Lisp of this
    definition using ~C-h o RET ùí±-identity~.

    The prefix ~ùí±-~ only occurs at the definition site, the call site omits it.
    Why? We have augmented the Emacs system with a new functional definition,
    and the ùí±- serves as a namespace delimiter.

  Loading the meta-program using Agda's usual ~C-c C-l~ lets us hover over
  ~MonoidP‚Å±·µà~ to see its elaboration is precisely that of ~MonoidP~.

  /Moreover/, to be useful, all variationals have tooltips showing their
  user-defined documentation.  If we hover over ~identity~, we are informed that
  it is undocumented.  User documentation is optional and may appear immediately
  following the ~=~, as follows.
{{{code(Documented User-defined Variational)}}}
 #+BEGIN_SRC agda
{-700
ùí±-Id = "This is the do-nothing variational"
-}
         #+END_SRC

Operationally, we substitute equals-for-equals.
{{{code(No Variational Clauses Needed)}}}
         #+BEGIN_SRC agda
{-700
-- No variational clauses needed
MonoidP‚Å∞  = MonoidP
-}
         #+END_SRC

 We may also augment a variational with positional and (optional) keyword
 arguments that have default values.  The keyword arguments along with their
 default value, /if any/, are enclosed in parenthesis.
 {{{code(User-defined Variational with Arguments)}}}
 #+BEGIN_SRC agda
{-700
ùí±-test positional (keyword 3) another = "I have two mandatory arguments and one keyword argument"

Monoid-test = MonoidP ‚ü¥ test "positional arg‚ÇÅ" "positional arg‚ÇÇ" :keyword 25
-}
 #+END_SRC

We are not doing anything with the arguments here; we shall return to this in
later subsections.

In summary, declarations provide an alias and one may substitute equals for
equals; however, only variational declarations support arguments.
$$\frac{\text{\texttt{l = r} is declared}}{l ‚üø r}$$
# This applies to both PF declarations and ùí± declarations.

$$\frac{\text{\texttt{ùí±-l a = r} is declared}}{p \,‚ü¥\, l\, e ‚üø p \,‚ü¥\, r[a ‚âî e]}$$
# Declared variationals may have any number of arguments.

Ideally variational definition would be rendered in Agda code;
we will return to this issue in Section ref:sec:contexts.

*Declaration Well-definedness Provisos*: A declaration ~l = r~ must satisfy:
1. The name ~l~ is a string of consecutive symbols, if this is a context
   declaration; otherwise, ~l~ must be of the form ~ùí±-ll a‚ÇÄ ‚Ä¶ a‚Çô~ to designate it as
   a variational declaration with arguments ~a·µ¢~ which in turn are either atomic
   names or pairs ~(n d)~ consisting of an atomic name along with a default value.

2. The expression ~r~ may mention any arguments to ~l~ ---if ~l~ is a variational---
   and may mention the constant ~$ùëõùëéùëöùëí~ which is the string representation of the
   name ~l~ ---if ~l~ is a context declaration.
   - This is necessary to produce term types, section ref:rules:data.

   :more_on_$name:

 Notice that ~$ùëõùëéùëöùëí~ is a special variable that refers to the newly defined PackageFormer's name.
 - It is written using ~\Mi~ with Agda input; e.g., ~\Min~ gives ~ùëõ~.
 - The ‚Äò$‚Äô is intended to further mark the special nature of this variable.

   :End:

**** COMMENT More Information about arguments

#+latex: \noindent
In the concrete syntax, e.g., ~ùí±-l x (y d) z = r~ declares the variational ~l~ to
have positional arguments ~x~ followed by ~z~, then followed by the optional keyword
argument ~:y~ with default value ~d~.

Argument come before the ~=~ in a variational's definition and
the may be used as if they were constants on the right-hand side.

    + Invocation of variationals has positional arguments first then named arguments afterwards.
      One supplies a named argument in the form ~:argument-name the-value~ ---this is Lisp-inspired syntax.

      Consequently, order is irrelevant for named arguments.

      - Supplying ~:key value~ pairs where the ~key~ is not a named argument of
        the variational yields a error message indicating the allowable keys.

*** Composition Rule

Variationals ~ùìã·µ¢~ may be sequentially applied to a context ~p~ by writing ~p ‚ü¥ ùìã‚ÇÅ ‚ü¥
ùìã‚ÇÇ ‚ü¥ ‚ãØ ‚ü¥ ùìã‚Çô~, which ‚Äòthreads‚Äô the context ~p~ through each of the variationals
---that is, we have forward function application ~ùìã‚Çô (‚ãØ (ùìã‚ÇÅ p))~.


$$\frac{p \,‚ü¥\, v ‚üø q  \qquad q \,‚ü¥\, w ‚üø q}{ (p \,‚ü¥\, v) \,‚ü¥\, w ‚üø q}$$

- In the concrete syntax, parenthesis ~(,)~ are not allowed: ‚ü¥ is
  left-associative.
# - As this rule show, ‚ü¥ is forward function application.

:Naming:
- Of course, users may name a composition:
  #+BEGIN_SRC agda
{-700
ùí±-ùìã  = ‚Ä¶
ùí±-ùìå = ‚ãØ
ùí±-the-composition = "The composition of ùìã and ùìå"  ùìã ‚ü¥ ùìå

-- Later:
new = old ‚ü¥ the-composition
-}
#+END_SRC
The optional documentation string is attached to the right-side's name
in tooltips.
:End:

#+begin_edcomm org
:ed: MA
Do we /need/ congruence rules for ‚Äò‚ü¥‚Äô?
#+end_edcomm

*** Empty Variational Rule

   A nullary composition of variationals ~ùìã·µ¢~ applied to a context ~p~ does not
   alter ~p~; i.e., when ~n = 0~ in ~p ‚ü¥ ùìã‚ÇÅ ‚ü¥ ‚ãØ ‚ü¥ ùìã‚Çô~ we have ~p ‚ü¥~ which is the same as
   ~p~. Using ~Id~ from section ref:rules:declaration, we may characterise the identity
   variational as follows.

# #
$$\frac{}{p \,‚ü¥\, \Id ‚üø p}$$

In the concrete syntax, $\Id$ is simply whitespace; whence we have the following
optimisation laws.
  | ~p ‚ü¥ ‚âà p~             |
  | ~p ‚ü¥ ùìã ‚âà p ùìã ‚ü¥ ‚âà p ùìã~ |

In particular, /single variational application/ may be written with or without the
use of ~‚ü¥~. Moreover, any variational ~ùìã~ that takes an argument of type ~œÑ~ can be
thought of as a *binary context-value operator*,
| ~_ùìã_ : PackageFormer ‚Üí œÑ ‚Üí PackageFormer~ |

*** @@latex:$\KIND, \WAIST,$ and $\LEVEL$@@ Rules

The meta-primitive ~:kind~ declares the tag of a context.  If the tag is
~PackageFormer~ then we have an abstract context that will not directly elaborate
into Agda code; otherwise if the tag is ~record, data, module~ ---constructs
supported by Agda--- then we have the following elaboration, where ~q‚±º~ is the
first[fn:10] non-~parameter~ qualifier.
{{{code(Kind-Waist Elaboration)}}}
#+BEGIN_SRC agda
    Name = ‚ü®k; ‚Ñì; q·µ¢ Œ∑·µ¢ : œÑ·µ¢ ‚âî Œ¥·µ¢‚ü©·µ¢
‚üø
    k Name (Œ∑‚ÇÄ : œÑ‚ÇÄ ‚âî Œ¥‚ÇÄ) ‚ãØ (Œ∑‚±º‚Çã‚ÇÅ : œÑ‚±º‚Çã‚ÇÅ ‚âî Œ¥‚±º‚Çã‚ÇÅ) : Set ‚Ñì where
      q‚±º Œ∑‚±º : œÑ‚±º
         Œ∑‚±º = Œ¥‚±º

      q‚±º‚Çä‚ÇÅ Œ∑‚±º‚Çä‚ÇÅ : œÑ‚±º‚Çä‚ÇÅ
           Œ∑‚±º‚Çä‚ÇÅ = Œ¥‚±º‚Çä‚ÇÅ

      ‚ãÆ

      q‚Çñ Œ∑‚Çñ : œÑ‚Çñ
         Œ∑‚Çñ = Œ¥‚Çñ
#+END_SRC

Notice that unless the first ~j~-many elements have *no definitions*, the resulting
elaboration will result in invalid Agda.  Rather than impose a particular way to
handle definitional extensions, it is left to the variational designer to handle
this ---e.g., by performing /‚Äòdefinitional erasure‚Äô/ or dropping those particular
elements.

$$\frac{}{‚ü®k; ‚Ñì; q·µ¢\, n·µ¢ ‚à∂ œÑ·µ¢ ‚âî d·µ¢‚ü©·µ¢ \,‚ü¥\, \KIND k' ‚üø ‚ü®k'; ‚Ñì; q·µ¢\, n·µ¢ ‚à∂ œÑ·µ¢ ‚âî d·µ¢‚ü©·µ¢}$$

We then quickly have /kind-fusion/: ~p ‚ü¥ :kind k‚ÇÅ ‚ü¥ :kind k‚ÇÇ ‚âà p ‚ü¥ :kind k‚ÇÇ~.

For instance, =Empty= below is an abstract context and so has no form using
existing Agda syntax, whereas ~Empty ≥~ elaborates to a valid Agda phrase.
{{{code(Example $\KIND$ Application)}}}
#+BEGIN_SRC agda
PackageFormer Empty : Set where

Empty ≥ = Empty ‚ü¥ :kind record
{-
record Empty : Set where    -- Equivalently
-}
#+END_SRC

If a =PackageFormer= has some elements, like ~Type~ below, then this approach
crashes.
{{{code($\KIND$ application is not enough)}}}
#+BEGIN_SRC agda
PackageFormer Type : Set‚ÇÅ where
  Carrier : Set

-- Type ≥ = Type :kind record
{-
record Type ≥ : Set‚ÇÅ where    -- Equivalently
   Carrier : Set             -- Invalid Agda phrase
-}
#+END_SRC

#+latex: \noindent
We thus need a way to alter all elements ---e.g., by changing their qualifiers
to be ~field~ or ~parameter~. Enter the $\WAIST$ rule:
$$\frac{q'·µ¢ = \IF i ‚â§ w \THEN \mathsf{parameter} \ELSE q·µ¢}{‚ü®k; ‚Ñì; q·µ¢\; n·µ¢ ‚à∂ œÑ·µ¢ ‚âî d·µ¢‚ü©·µ¢
\WAIST w ‚üø ‚ü®k; ‚Ñì; q'·µ¢\; n·µ¢ ‚à∂ œÑ·µ¢ ‚âî d·µ¢‚ü©·µ¢}$$

{{{code(Example $\WAIST$ Application)}}}
#+BEGIN_SRC agda
Type ≥ = Type ≥ :kind record :waist 1
{-
record Type (Carrier : Set) : Set‚ÇÅ where    -- Equivalently
-}
#+END_SRC

However, the level of ~Type ≥~ is unnecessarily large: ~Set~ suffices in-place of
~Set‚ÇÅ~. The level could have been inferred by inspecting the elements of ~Type ≥~,
however, we took the conservative option of leaving it to the reader to alter a
level by providing either ~inc~ or ~dec~ to increment it or decrement it ---our
abstract interpreter will be more generic: Any function ~f~ on levels is
acceptable.

$$\frac{f : \mathsf{Level} ‚Üí \mathsf{Level}} {‚ü®k;‚Ñì; q·µ¢\, n·µ¢ ‚à∂ œÑ·µ¢ ‚âî d·µ¢‚ü©·µ¢ \LEVEL f ‚üø ‚ü®k;\, f\, ‚Ñì; q·µ¢\, n·µ¢ ‚à∂ œÑ·µ¢ ‚âî d·µ¢‚ü©·µ¢}$$

{{{code(Example $\LEVEL$ Application)}}}
#+BEGIN_SRC agda
Type ≥' = Type ≥ :kind record :waist 1 :level dec
{-
record Type (Carrier : Set) : Set where    -- Equivalently
-}
#+END_SRC

*** COMMENT typeclass
#+BEGIN_SRC agda
-- Example variational with arguments
ùí±-typelcass height (level 'dec) = record ‚ü¥ :waist height :level level

-- Example use
M-Set‚ÇÉ = M-Set typeclass 3 :level 'inc
#+END_SRC

      0. Above we introduced the named arguments ~height~ and ~level~.
      1. The first is positional, and the second is a keyword argument
         with /default/ value being a decrement value.
      2. We then passed the /argument/ ~level~ to the /meta-primitive/ ~:level~.

*** Altering Elements ---Map Rule

# $$\frac{}{p :alter-elements f ‚üø ???}$$

The final meta-primitive is =:alter-elements=; it is the ‚Äòhammer‚Äô that
accomplishes most of the work, it takes an arbitrary function ~List Element ‚Üí
List Element~ which it then applies to the context to obtain a new, possibly
ill-formed, context. As such, the rule for it is rather unhelpful.

#+latex: \def\ALTERELEMENTS{\,:\!\mathsf{alter\!-\!elements}\,}
$$\frac{ f : \mathsf{List\, Element} ‚Üí \mathsf{List\, Element}}{‚ü®k; ‚Ñì; es‚ü©
\ALTERELEMENTS f ‚üø ‚ü®k; ‚Ñì; f\, es‚ü©}$$

Instead, using ~:alter-elements~, we can define a ‚Äòsafe‚Äô traversal variational,
*map*, and provide a rule for it.
#+latex: \def\NAME{\mathsf{name}\,}
#+latex: \def\MAP{\,\mathsf{map}\,}
$$\frac{ e'·µ¢ = f(e·µ¢)[\NAME e‚±º ‚âî \NAME (f e‚±º)]‚±º}{‚ü®k; ‚Ñì; e·µ¢‚ü©·µ¢ \MAP f ‚üø ‚ü®k; ‚Ñì; e'·µ¢‚ü©·µ¢}$$

#+latex: \noindent
That is, the function ~f~ is applied to all elements of a context, while
propagating all new name changes to subsequent elements.

For practicality, ~map~ actually takes some optional arguments; such as
~:adjoin-retract~ and ~:adjoin-coretract~ to mechanically produce views ---record
translations--- ~record {old-name·µ¢ = new-name·µ¢}~ and ~record {new-name·µ¢ =
old-name·µ¢}~ respectively. For example, ~q = p map f :adjoin-retract "go"~ produces
a new context with a new element ~go : q ‚Üí p~ which implements the ‚Äòold names‚Äô of
~p~ using the symbols of ~q~. Whether such translations are meaningful depends on ~f~.

:More:
For practicality, ~map~ actually takes three optional arguments:
~:support-mixfix-names~ so that name changes ‚Äòjump over underscores‚Äô ~f(_‚äï_) = _(f
‚äï)_~, ~:adjoin-retract~ and ~:adjoin-coretract~ to mechanically produce views
---record translations--- ~record {old-name·µ¢ = new-name·µ¢}~ and ~record {new-name·µ¢ =
old-name·µ¢}~ respectively.
:End:

{{{code(Corollaries of Map)}}}
#+BEGIN_SRC agda
ùí±-rename f = map (Œª e ‚Üí (map-name (Œª n ‚Üí (funcall f n)) e))

ùí±-decorated by = rename (Œª name ‚Üí (concat name by))
ùí±-co-decorated by = rename (Œª name ‚Üí (concat by name))
ùí±-primed = decorated "'"
ùí±-subscripted‚ÇÄ = decorated "‚ÇÄ"
-- ‚ãÆ
ùí±-subscripted‚Çâ = decorated "‚Çâ"
#+END_SRC
Since decoration is invertible, we could have adjoined both a retract and
‚Äòco-retract‚Äô, as follows.
{{{code(Decoration is invertible)}}}
#+BEGIN_SRC agda
ùí±-decorated' by = map (Œª e ‚Üí (map-name (Œª n ‚Üí (concat n by)) e)) :adjoin-coretract "decorate"
#+END_SRC


*** TODO COMMENT Other items  to incorporate

    # ‚û± If an argument is not supplied or its value is unacceptable, the cute
    # error-reporting mechanism is activated ---as is the case with other
    # pertinent aspects of loading such declarations.

 :ùí±-map:
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(eval-and-compile
(ùí± map elements (support-mixfix-names nil) (adjoin-retract nil) (adjoin-coretract nil)
   = "Apply function ELEMENTS that acts on PackageFormer elements,
      then propogate all new name changes to subsequent elements.

      There is minimal support for mixfix names, but it may be
      ignored by setting SUPPORT-MIXFIX-NAMES to be nil.

      When ADJOIN-RETRACT is non-nil, we adjoin a ‚Äúrecord {old·µ¢ = name·µ¢}‚Äù
      view morphism; i.e., record translation.

      Clauses ‚Äúf = f‚Äù are considered to occur only in views, record translations,
      and so only the RHS occurance is updated to a new name.
      C.f. the definition of element-retract.
      "
     :alter-elements (lambda (es)

    (let* ((es'    (mapcar elements es))
           (names  (mapcar #'element-name es))
           (names' (mapcar #'element-name es')))

      ;; Replace all occurances of old names with corresponding new ones.
      (loop for old in names
            for new in names'
            do (setq es' (--map (element-replace old new it :support-mixfix-names support-mixfix-names :avoid-altering-names (equal new (element-name it))) es')))
            ;; E.g., With ‚Äúelements = Œª x ‚Ü¶ x'‚Äù, a name ‚Äúop‚Äù goes to ‚Äúop'‚Äù, such a name-change should propogate everywhere including in old names ‚Äúop-some-property‚Äù,
            ;; to obtain ‚Äúop'-some-property‚Äù, but we should not propogate it to the newely named element ‚Äúop'‚Äù thereby accidentally obtaining ‚Äúop''‚Äù.

     ;; return value
     (-concat es' (when adjoin-retract (list (element-retract $ùëùùëéùëüùëíùëõùë° es :new es' :name adjoin-retract)))
                  (when adjoin-coretract (list (element-retract $ùëùùëéùëüùëíùëõùë° es' :new es :name adjoin-coretract :contravariant t)))))))
)
 #+END_EXAMPLE
:End:

2. To provide minimal accommodation for mixfix names, we simply remove the
    Agda argument indicator ‚Äò_‚Äô when performing rewrites.

    E.g., Agda let's you
    declare a name such as ~_‚äï_~ and use it without mentioning the underscore
    as in ~x ‚äï y~ and so the rename ~_‚äï_ ‚Ü¶ _‚äï'_~ would have no effect since ~_‚äï_~
    does not occur as a substring in ~x ‚äï y~, whence the need to ignore the underscores.

3. We would expect it to be common to prefix and suffix symbols, so let's make
  variationals for these patterns.
  # :ùí±-map_corrolaries:
   #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± decorated by
  = "Rename all elements by suffixing string BY to them."
     rename (Œª name ‚Üí (concat name by)))

(ùí± co-decorated by
  = "Rename all elements by prefixing string BY to them."
     rename (Œª name ‚Üí (concat by name)))

(ùí± primed
  = "All elements are renamed with a postfix prime."
    decorated "'")
 #+END_EXAMPLE
  # :End:

 Likewise, for the casing approach, let's make a ‚Äúto list‚Äù.
 For now, such lists are necessarily enclosed in double-quotes.

4. reify-to-list
   - Given a string of ‚Äú;‚Äù-separated items consisting of ‚Äúto‚Äù-separated pairs,
     interpret it as a Lisp function where ‚Äúto‚Äù-pairs denote mapping clauses.

   - E.g., ‚Äúx‚ÇÄ to y‚ÇÄ; ‚Ä¶; x‚Çô to y‚Çô‚Äù becomes the function sending value x·µ¢ to y·µ¢,
     and behaves as the identity function otherwise unless OTHERWISE is provided,
     in which case it acts as a fallback.

   - Concretely:
     #+BEGIN_EXAMPLE emacs-lisp :tangle no
        (reify-to-list "1 to x; 2 to y; p to q")
      ‚âà (Œª arg ‚Üí (pcase arg ("1" "x") ("2" "y") ("p" "q") (otherwise otherwise)))
     #+END_EXAMPLE

   - ‚ü¶"x‚ÇÄ to y‚ÇÄ; ‚Ä¶; x‚Çñ to y‚Çñ"‚üß = Œª e ‚Üí if (‚àÉ i ‚Ä¢ e ‚âà x·µ¢) then y·µ¢ else e

   :reify-to-list:
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
;; Neato: (reify-to-list "x‚ÇÄ; ‚ãØ; x‚Çô" nil) ‚áí (Œª x ‚Ü¶ If ‚àÉ i ‚Ä¢ x ‚âà x·µ¢ then "" else nil)
;; KEY is a function applied to the input argument /before/ casing on LHS ‚Ü¶ RHS names.
;; INVERSE means to interpret clauses ‚Äúx to y‚Äù as mappings ‚Äúy ‚Ü¶ x‚Äù.
   (cl-defun reify-to-list (str &key (otherwise 'otherwise) (key #'identity) inverse)
   "Transform ‚Äúto list‚Äù STR with default OTHERWISE into a Lisp function.
<<docs('reify-to-list)>>
#+latex: \label{docs('reify-to-list)}"
   (let (clauses)
     (thread-last str
       (s-split ";")
       (--map (s-split " to " it))
       (--map (list (s-trim (car it)) (s-trim (or (cadr it) "")))) ;; accomodate empty str.
       (funcall (Œª cs ‚Üí (if inverse (--map (-rotate 1 it) cs) cs)))
       (-cons* 'pcase `(,key arg))
       (setq clauses))
     `(lambda (arg) ,(append clauses `((otherwise ,otherwise))))))

;; (reify-to-list "a to b; c to d" :inverse t) ;; neato!
#+end_example
:End:
   #+begin_example agda

(ùí± renaming by  (adjoin-retract nil) (adjoin-coretract nil)
= "Rename elements using BY, a ‚Äú;‚Äù-separated string of ‚Äúto‚Äù-separated pairs.

      Unlike ‚Äòrename‚Äô, this variational permits simultaneous renaming.
      Moreover, when the to-list is 1-to-1, we have a constructible bijection
      via ADJOIN-CORETRACT.

      When ADJOIN-RETRACT is non-nil, we adjoin a ‚Äúrecord {old·µ¢ = name·µ¢}‚Äù
      view morphism; i.e., record translation.
      Likewise for ADJOIN-CORETRACT results in the inverse morphism,
      ‚Äúrecord {name·µ¢ = old·µ¢}‚Äù.
"
 #+END_EXAMPLE

   :Implementation_remark:
The renaming function is decomposed into
an injective function followed by a possibly non-injective function.
E.g., to rename with =a to b'; b to a; c to c'= we cannot treat this as a function
and apply it everywhere since, say, a pair ~(a, b)~ will be renamed to
~(b', b')~ since we traverse the string to perform the renaming, since we cannot
simply walk along the syntax tree since PackageFormer uses strings, not ASTs.
:End:

    #+BEGIN_EXAMPLE emacs-lisp :tangle no
(ùí± renaming by (adjoin-retract t) (adjoin-coretract nil)
  = "Rename elements using BY, a ‚Äú;‚Äù-separated string of ‚Äúto‚Äù-separated pairs.

      There is minimal support for mixfix names, which may be ignored
      by setting SUPPORT-MIXFIX-NAMES to be nil.

      When ADJOIN-RETRACT is non-nil, we adjoin a ‚Äúrecord {old·µ¢ = name·µ¢}‚Äù
      view morphism; i.e., record translation.
      Likewise for ADJOIN-CORETRACT results in the inverse morphism,
      ‚Äúrecord {name·µ¢ = old·µ¢}‚Äù.
"
  map (Œª e ‚Üí (map-name (Œª n ‚Üí (funcall (reify-to-list by) n)) e))
         :adjoin-retract adjoin-retract
         :adjoin-coretract adjoin-coretract
         )
 #+END_EXAMPLE

5. It is common in Agda to provide ‚Äúto‚Äù-lists, so we've provide a variant that
   supports those instead of forcing users to produce functions explicitly.

6.  We may also prefer writing ~subscripted·µ¢~ rather than ~decorated "·µ¢"~.
   With a bit of Lisp meta-programming, we can generate these variationals.

   Here are some example uses.
    #+BEGIN_EXAMPLE agda
{-700
-- MR‚ÇÅ‚ÇÇ   = M-Set-Record decorated "‚ÇÅ" ‚ü¥ decorated "‚ÇÇ" :adjoin-retract nil
the-MR = M-Set-Record co-decorated "the-"
-- MR‚ÇÉ‚ÇÑ   = M-Set-Record subscripted‚ÇÉ ‚ü¥ subscripted‚ÇÑ :adjoin-retract nil
MR‚Çú‚Çí   = M-Set-Record renaming "Scalar to S; Vector to V; ¬∑ to nice"
NearMonoid = M-Set-Record renaming "Scalar to Carrier; Vector to Carrier; ¬∑ to √ó"
-}
#+END_EXAMPLE

  Some observations are in order:

   1. Example ~M‚ÇÅ‚ÇÇ~ demonstrates that composition, ‚ü¥, is sequential from left to right.
     That is, ‚Äú‚ü¥‚Äù is just forwards composition: We thread the given PackageFormer
     through the variationals ~v·µ¢~ in order. Operationally:

    | Pf v‚ÇÄ ‚ü¥ ‚ãØ ‚ü¥ v‚Çô ‚âà ((Pf v‚ÇÄ) v‚ÇÅ) ‚ãØ) v‚Çô |
    | Pf ‚ü¥ v  ‚âà  Pf v ‚ü¥  ‚âà  Pf v          |

    Note: In the concrete syntax, parenthesisation is not permitted.

   2. Notice that the ~NearMonoid~ example demonstrates multiplicity of
      PackageFormer elements is irrelevant.  That is, elements are algebraically
      a free monoid with the axiom ~xs ‚äï ys ‚äï xs ‚âà xs ‚äï ys~.

      1. *Notice that we wanted Agda-style renaming via ~to~-lists, so we simply code
         that up!*
          This is so cool: We can just extend the system with whatever pattern we prefer!
          No more bending to the will of language designers! More power to the user!

          For example, we can codify the previous ~NearMonoid~ scheme into a top-level
            pattern.
            #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
      (defun is-sort (element)
        "Check whether the target of ELEMENT‚Äôs type is ‚ÄòSet‚Äô."
        (s-contains? "Set" (target (element-type element))))
        ;; Method ‚Äòtarget‚Äô is defined in the next subsection, on ADTs.

      (ùí± single-sorted with-sort
        = "Replace all nullary sorts with the provided WITH-SORT string
           as the name of the new single sort, the universe of discourse."
          map (Œª e ‚Üí (if (is-sort e) (map-name (Œª _ ‚Üí with-sort) e) e)))
       #+END_EXAMPLE

          Then the previous PackageFormer can be obtained with: Note that the
            following differs from ~NearMonoid~ since it has two binary operations: Our
            new variational one alters the number and name of sorts, not other
            elements.
           #+BEGIN_EXAMPLE agda
      {-700
      NearMonoid¬π = M-Set-Record single-sorted "Carrier"
      -}
       #+END_EXAMPLE
            #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
      record NearMonoid¬π : Set‚ÇÅ where
         field Carrier        : Set
         field _¬∑_        : Carrier ‚Üí Carrier ‚Üí Carrier
         field ùüô      : Carrier
         field _√ó_        : Carrier ‚Üí Carrier ‚Üí Carrier
         field leftId     : {ùìã : Carrier}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã
         field assoc      : {a b : Carrier} {ùìã : Carrier} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã)
       #+END_EXAMPLE

7. *Exercise:* Write a variational ~remove-sorts~ that strips out all sorts from a
   PackageFormer.  If elements depend on sorts, as they normally do, then one
   must remove them as well; ignore this for now, and we shall return to
   subgenerated PackageFormers later on.

0. Consult these tables as necessary and look at an [[https://alhassy.github.io/ElispCheatSheet/][Elisp Cheat Sheet]], if need be.

--------------------------------------------------------------------------------

   1. When we have two occurrences of a structure, we may want one of them to be
    decorated say with a prime so as to disambiguate them easily rather than
    have to qualify all of their components.



   2. The ~:key value~ pairs have legitimate Lisp for the ~value~ positions.

       The basics of list processing, such as maps/filters/folds, with Lisp suffice for a rich
       inventory of possible configurations. Moreover, the functional nature of such higher-order
       functions ought to be familiar to any Agda coder [[https://www.phrases.org.uk/meanings/worth-ones-salt.html][worth their salt]].

       Here's a terse tutorial rendered as an [[https://alhassy.github.io/ElispCheatSheet/][Elisp Cheat Sheet]].

   3. One would expect catenating a prime to the mixfix name ~_√ó_~ would yield ~_√ó_'~ but above
       it yielded ~_√ó'_~. Indeed, the former would yield confusing expressions of the form
       ~1 √ó 2 '~ whereas the latter permits ~1 √ó' 2~. It is with this pragmatic usage that
       ~rename-mixfix~ performs a rewrite to a name by jumping over the Agda mixfix marker, ~_~,
       if it occurs at the start or end of a name.

       As an additional example, the name
       ~_‚âà_‚à∂_~, under the above scheme, would have rewritten to ~_‚âà_‚à∂'_~ thereby
       allowing terms such as ~x ‚âà y ‚à∂ A  ‚Üí  f x ‚âà f y ‚à∂' B~ ---a elegant way to
       express that, say, ~f~ is a setoid homomorphism.
       If the prime scheme were instead a prepend, we would have obtained the name
       ~_'‚âà_‚à∂_~.

    # Notice that the generated code is commented out: The current type of the package
    # is not an admissible construct in Agda.

    # Moreover, if we try to instantiate this package further, say as in    ~M' = M-Set'-attempt record~

    Notice that
    we have fields such as ~ùüô' : Scalar~
    whose type is a free variable: ~Scalar~ no longer refers to any field.
    As such, the above code is ill-typed.
    The solution then is to /propagate/ any changes a name has down to its siblings.
    We will return to this later in the form of a ~map~ variational.

**** COMMENT primer
     :PROPERTIES:
     :CUSTOM_ID: COMMENT-primer
     :END:
    Indeed, /propagating the name changes:/
 #+BEGIN_EXAMPLE agda
{-lisp
(ùí± primer = :alter-elements (lambda (es)
   (let* ((esnew es)
         ;; Let's try to accomodate for names with underscores
         (names_ (--map (element-name it) es))
         (names  (--map (s-replace "_" "" it) names_))
         (oldies (append names names_)))

     (loop for old in oldies
           for new in (--map (rename-mixfix (Œª n ‚Üí (concat n "'")) it) oldies)
           do
           (setq esnew (--map (element-replace old new it) esnew)))

     ;; return value
     esnew)))
-}
 #+END_EXAMPLE

 Then, for example:
 #+BEGIN_EXAMPLE agda
{-700
MR' = M-Set record ‚ü¥ primer
-}
         #+END_EXAMPLE

         #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record MR' : Set‚ÇÅ where
   field Scalar'        : Set
   field Vector'        : Set
   field _¬∑'_       : Scalar' ‚Üí Vector' ‚Üí Vector'
   field ùüô'     : Scalar'
   field _√ó'_       : Scalar' ‚Üí Scalar' ‚Üí Scalar'
   field leftId'        : {ùìã : Vector'}  ‚Üí  ùüô' ¬∑' ùìã  ‚â°  ùìã
   field assoc'     : {a b : Scalar'} {ùìã : Vector'} ‚Üí (a √ó' b) ¬∑' ùìã  ‚â°  a ¬∑' (b ¬∑' ùìã)
 #+END_EXAMPLE

 :maybe_not:
    Since 700-declarations must be single lines, we are forced to have something like
    the following ---which you are not expected to understand, but it serves as a nice
    comparison and motivation for the alternative approach below.
 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
{-700

ùí±-primed‚Çó‚Çë‚Çú = :alter-elements (lambda (fs) (-as-> (-unzip (--zip-with `(,other  ,(format "let %s = %s in " (get-name it) (get-name other))) fs (--map (map-name (concat name "'") it) fs))) yup (--zip-with (map-type (concat (s-join "" it) type) other) (-inits (cadr yup)) (car yup))))

MonoidR'   =  MonoidP record ‚ü¥ primed‚Çó‚Çë‚Çú
-}

record MonoidR' : Set‚ÇÅ where
  field
    Carrier' : Set
    _‚®æ'_ : let Carrier = Carrier' in Carrier ‚Üí Carrier ‚Üí Carrier
    Id' : let Carrier = Carrier' in let _‚®æ_ = _‚®æ'_ in Carrier
    assoc' : let Carrier = Carrier' in let _‚®æ_ = _‚®æ'_ in let Id = Id' in ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId' : let Carrier = Carrier' in let _‚®æ_ = _‚®æ'_ in let Id = Id' in let assoc = assoc' in ‚àÄ {x : Carrier} ‚Üí Id ‚®æ x ‚â° x
    rightId' : let Carrier = Carrier' in let _‚®æ_ = _‚®æ'_ in let Id = Id' in let assoc = assoc' in let leftId = leftId' in ‚àÄ {x : Carrier} ‚Üí x ‚®æ Id ‚â° x

 #+END_EXAMPLE
 :End:


--------------------------------------------------------------------------------

     | /We may apply  variationals even to concrete Agda packaging constructs!/ |


    Since the ~record~ and ~primed~ configurations are ‚Äòdisjoint‚Äô, they commute
    with respect to composition. The reader may want to confirm the following identifications:
 #+BEGIN_EXAMPLE agda :tangle no
      M-Set-Record'
   ‚âà  M-Set record ‚ü¥ primed-attempt
   ‚âà  M-Set primed-attempt ‚ü¥ record
   ‚âà  M-Set' record
   ‚âà  M-Set-Record primed-attempt
 #+END_EXAMPLE

 It is important to remember that these primed perspectives do /not/ typecheck in Agda due to the free-variable
 issue mentioned earlier. We are only demonstrating composition, ~‚ü¥~, in this section; in a later section we
 fix-up ~primed~.


--------------------------------------------------------------------------------

{{{code()}}}
#+BEGIN_SRC emacs-lisp :tangle "variationals.tmp" :noweb-ref ùí±-user-man-pt-1 :noweb yes
(defun find-duplicates (list)
"Return a list that contains each element from LIST that occurs more than once.

Source: https://emacs.stackexchange.com/a/31449/10352"
  (--> list
       (-group-by #'identity it)
       (-filter (lambda (ele) (> (length ele) 2)) it)
       (mapcar #'car it)))
#+END_SRC

{{{code()}}}
#+BEGIN_SRC emacs-lisp :tangle "variationals.tmp" :noweb-ref ùí±-user-man-pt-1 :noweb yes
(cl-defmacro alter-elements (elements variational &body rest)
  "Alter ELEMENTS using a given VARIATIONAL along with its arguments, REST.

   The result is a list of elements.

   This is essentially ‚Äú:alter-elements‚Äù but with the ability to work on the elements
   of **any** PackageFormer by using ‚Äú($ùëíùëôùëíùëöùëíùëõùë°ùë†-ùëúùëì pf)‚Äù.

   This method is only well-defined within the RHS of a variational, or instantiation, declaration.
   E.g., use it to alter elements in an ‚Äú:alter-elements‚Äù clause using a predefined variational;
   see ùí±-union and ùí±-intersect for sample uses.
  "
  `(funcall (cdr (assoc :alter-elements (,(ùí±- variational) ,@rest))) ,elements))
#+END_SRC


--------------------------------------------------------------------------------

+ =(element-retract p es es') ‚üø toP : p ‚âî (e·µ¢ ‚âî e·µ¢')·µ¢=
  - In Agda syntax, this produces the term ~toL = record {old·µ¢ = new·µ¢}·µ¢~.
  - es' is optional, defaulting to es.
  - Other optional arguments include a new name for the view, instead of ~toP~,
    ‚Äòto the parent‚Äô, and whether we want the view to be contravariant ---~e·µ¢' ‚âî
    e·µ¢~ instead.
  - This is a user defined function; it actually declares ~toP : let View X = X
    in View P~ so that the phrase ~View~ can be searched for in other uses.
    * As a user, you are welcome to define your own schemes.


{{{code()}}}
#+BEGIN_SRC emacs-lisp :tangle "variationals.tmp" :noweb-ref ùí±-user-man-pt-1 :noweb yes
(ùí± extended-by ds (adjoin-retract t)
   = "Extend a given presentation by a list of ;-separated declarations.

      The resuling presentation has a ‚ÄútoX‚Äù retract method,
      where ‚ÄòX‚Äô is the parent presentation. To avoid this,
      set ADJOIN-RETRACT to be nil. To provide a preferred name for
      the morphism, then set ADJOIN-RETRACT to the desired string.
     "
     :alter-elements (Œª es ‚Üí (-concat es (parse-elements (mapcar #'s-trim (s-split ";" ds))) (when adjoin-retract (list (element-retract $ùëùùëéùëüùëíùëõùë° es :name adjoin-retract))))))
)
     #+END_SRC


+ Simple exercise: Play with this setup to observe that ~extended-by~ is an idempotent operation.


--------------------------------------------------------------------------------

*** COMMENT User Manual Header
    :PROPERTIES:
    :CUSTOM_ID: User-Manual-Header
    :END:
 {{{goal(A literate programming approach to a user manual.)}}}

    In order for our manual's examples to be up-to-date, we will take a literate approach
    to producing them. Namely, the Agda code here is ‚Äòtangled‚Äô from this prose into an Agda
    file which can then be checked by an Agda process. Whence, this file is the de-facto source.

    Let's start-off with a usual Agda header:
 #+BEGIN_EXAMPLE agda
{- This loads the PackageFormer metaprogram; press C-x C-e after the closing ‚Äú)‚Äù below.                 -}
{- (progn (load-file "~/.emacs.d/agda-next-700-module-systems.el") (agda-next-700-module-systems-mode)) -}

module package-former where

open import package-former-generated
open import Level
open import Data.Bool
open import Data.List using (List; _‚à∑_; []; foldr)
import Relation.Binary.PropositionalEquality as ‚â°; open ‚â° using (_‚â°_)

{- Let's ensure content of User Manual part I actually type checkes -}
{- Feel free to comment this line out. -}
import package-former-user-manual-i
 #+END_EXAMPLE
 #
 # Strip away the 700 annotations with:
 # (progn (700-bare-bones) (find-file "Testing_Bare.agda"))

 To make the resulting Agda file somewhat self-contained, in case anyone wishes to read that
 or load it into Agda and play with it, let's add a blurb.
 #+BEGIN_EXAMPLE agda
{-
0. There are a number of common use-cases.
1. We can handle all of them & more, since we're extensible.
  - Mention the Lean & Coq, as well as the Agda, repeated fragments.
2. The resulting setup is pragmatic: It is unobtrusive in the
   traditional Agda coding style in that it happens in the background.
3. It fills a particular need; the desire to avoid repetitious code.
-}
 #+END_EXAMPLE

 Before getting to the meat of things, it is important to note that comments
 begun with ~{-~ /and/ followed by a space are treated as usual Agda comments,
 whereas those /without/ a following space such as ~{-700~ and ~{-lisp~ are picked-up
 by our meta-program.

 For example, having no space between ‚Äú{-‚Äù and ‚Äúlisp‚Äù would cause the following block to be executed
 as a Lisp form.
 #+BEGIN_EXAMPLE agda
{- lisp
(message-box "Hello")
(message-box "World")
-}
 #+END_EXAMPLE

 Alternatively, here is the PackageFormer for M-Sets from the introduction.
 It is a useful example since it is multi-sorted.
 #+BEGIN_EXAMPLE agda
{-700
PackageFormer M-Set : Set‚ÇÅ where
   Scalar  : Set
   Vector  : Set
   _¬∑_     : Scalar ‚Üí Vector ‚Üí Vector
   ùüô       : Scalar
   _√ó_     : Scalar ‚Üí Scalar ‚Üí Scalar
   leftId  : {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã
   assoc   : {a b : Scalar} {ùìã : Vector} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã)
-}
 #+END_EXAMPLE
 Let us also introduce a slightly more syntactically-involved example:
 *A PackageFormer with equations.* The equations, /depending on our perspective,/
 ---i.e., the variational invoked--- may be thought of as:
 + Derived elements; e.g., in a record, they are a definitional extension
   and for an ADT, they are methods defined on the constructors.
 + Coherence constraints; e.g., in a record, we may interpret an equation ~ùìÅ = ùìá~
   as an additional axiom ~‚àÄ {‚ãØ} ‚Üí ‚Ñì ‚â° ùìá~ ---e.g., when a user may supply an efficient definition
   of ~ùìÅ~ but is constrained to have a particular behaviour ~ùìá~.
 + Rewrite rules; e.g., in an ADT, an equation may simply act as an alias and is to be used
   in rewriting the remainder of the ADT declaration.
 + Ignored components; e.g., in a record, we may ignore the equations altogether
   and lift the associated names into being fields ---e.g., ~_‚âà_~ would usually be lifted into
   a field and its stringent implementation via ~_‚â°_~ is used as a motivating or simplifying factor.

 #+BEGIN_EXAMPLE agda
{-700
PackageFormer MonoidP : Set‚ÇÅ where

    -- A few declarations
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    Id      : Carrier
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)

    -- We have a setoid-like structure; with a default implementation
    _‚âà_   : Carrier ‚Üí Carrier ‚Üí Set
    _‚âà_   = _‚â°_
    ‚®æ-cong : ‚àÄ {x y x' y'} ‚Üí x ‚âà x' ‚Üí  y ‚âà y' ‚Üí (x ‚®æ y) ‚âà (x' ‚®æ y')
    ‚®æ-cong = Œª{ ‚â°.refl ‚â°.refl ‚Üí ‚â°.refl}

    -- For now only one item in a declaration;
    -- namely ‚ÄúLid‚Äù & ‚ÄúRid‚Äù cannot be declared in one line.
    Lid : Carrier ‚Üí Carrier
    Lid x = Id ‚®æ x
    Rid : Carrier ‚Üí Carrier
    Rid x = x ‚®æ Id

    -- Agda permits pure, non-pattern-matching, equations between ‚Äúfields‚Äù in a record.
    concat : List Carrier ‚Üí Carrier
    concat = foldr _‚®æ_ Id

    -- More declarations
    leftId  : ‚àÄ {x : Carrier} ‚Üí (Id ‚®æ x) ‚âà x
    rightId : ‚àÄ {x : Carrier} ‚Üí Rid x ‚âà x

    -- Since there are no more pure declarations, ‚Äúfields‚Äù, subsequent equations
    -- may use pattern matching.

    Id¬≤ : (Id ‚®æ Id) ‚âà Id
    Id¬≤ = rightId

    concat‚Çö : List Carrier ‚Üí Carrier
    concat‚Çö []       = Id
    concat‚Çö (x ‚à∑ xs) = x ‚®æ concat‚Çö xs
-}
 #+END_EXAMPLE

 Notice that there is no particular segregation of declarations and equations.
 Simply: A declaration may /optionally/ have an associated equation; however
 once an equation uses pattern matching then all subsequent declarations must also
 have equations ---this is a constraint of the current Agda implementation---;
 as such, the equation for ~‚®æ-cong~ uses Agda's pattern-matching-Œª.

 :not_yet_implemented:
 TODO: implement support for literate blocks

 The ~{-700 ‚ãØ -}~ approach may be acceptable to those writing ~.agda~ files,
 but those who write ~.lagda~ files may find themselves often having
 ~\begin{code} {-700 ‚ãØ -} \end{code}~ which is rather clunky.
 Instead, they may simply write ~\begin{700} ‚ãØ \end{700}~ and similarly for ~lisp~.

 | Henceforth, we omit the comment delimiters. |

 For example, here is our earlier PackageFormer of ~M-Set~'s declared in full.
 ,#+BEGIN_EXAMPLE agda :tangle no
 PackageFormer M-Set : Set‚ÇÅ where
    Scalar  : Set
    Vector  : Set
    _¬∑_     : Scalar ‚Üí Vector ‚Üí Vector
    ùüô       : Scalar
    _√ó_     : Scalar ‚Üí Scalar ‚Üí Scalar
    leftId  : {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã
    assoc   : {a b : Scalar} {ùìã : Vector} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã)
 #+END_EXAMPLE
 :end:

*** COMMENT ‚á® Errors
    :PROPERTIES:
    :CUSTOM_ID: --Errors
    :END:
    :PROPERTIES:

    :END:
   Even though this is a prototype, we wish it to be useful to ourselves and to others
   ---especially those who take a quick glance, think they got it, and try things out only to not have them work
   immediately. As such, we have implemented a cute little error-reporting system.
   | If you try to load, ~C-c C-l~, but your 700-syntax is wrong, you get an immediate error explaining why ‚ô•‚Äø‚ô• |

   For example, suppose we accidentally wrote ~tester~ instead of ~test~, which we defined
   at the end of the previous section, as in the following.
   ( The space before ~700~ is so that this crashing block is not in effect. )
 #+BEGIN_EXAMPLE agda
{-   700
ùí±-whoops  = tester 1 2 :keyword 3
-}
 #+END_EXAMPLE
   When we try to load our Agda file the Agda process is interrupted and we are warned:
 #+BEGIN_EXAMPLE text :tangle no
700: Did you mistype a variational‚Äôs name: ‚Äútester‚Äù is not defined.

    ‚á®	whoops = tester 1 2 :keyword 3
    ‚á®	Use the PackageFormer menu to see which variationals are defined.
 #+END_EXAMPLE
   The 700 system informs us of our fault in ‚Äúquotes‚Äù, suggests a solution,
   and points to the offending declaration hierarchy.

   The ‚Äúquotes‚Äù help, in this case, when there are multiple variationals being
   invoked in a clause.

   Of course, we do not attempt to cover all possible errors ---e.g., wrong number
   of arguments or division by zero--- instead relying on Emacs Lisp's native
   error mechanism.
** TODO COMMENT ‚ü®No‚ü© An Example in Extensibility
*** TODO Records and equational support
**** Records and Meta-Primitives ~:kind~ & ~:alter-elements~
     :PROPERTIES:
     :CUSTOM_ID: Records-and-Meta-Primitives---kind------alter-elements-
     :END:
     Let's begin with the simplest thing: Realising these fictitious
     ‚ÄòPackageFormers‚Äô as records.

     An Agda ‚Äòrecord‚Äô is just a PackageFormer where the qualifier ~PackageFormer~
     has been replaced with ~record~ and each element is qualified by Agda keyword
     ~field~.  We may declare this particular configuration using the
     meta-primitives ~:kind~ and ~:alter-elements~, as follows.
  #+BEGIN_EXAMPLE agda
{-700
ùí±-record‚ÇÄ = :kind record :alter-elements (Œª es ‚Üí (--map (map-qualifier (Œª _ ‚Üí "field") it) es))
-}
  #+END_EXAMPLE

     *Huh?* The ~:kind~ part was already explained, the ~:alter-elements~ is the
     powerhouse of our system.  It takes a function with argument being the list
     of PackageFormer elements, ~es~, then we perform a functorial list map where
     each element is implicitly referred to as ~it~.  Then the map function is to
     alter the qualifier of an element by replacing it with the string ~"field"~.
     In Agda syntax this corresponds to: ~Œª es ‚Üí map (Œª it ‚Üí (map-qualifier (Œª _ ‚Üí
     "field") it)) es~.  \\
     Notice that the Agda form and Lisp form are only one outer parenthesis off
     from each other ---Lisp is easy!

     | /The ~:key value~ syntax is inspired from Lisp/ |

     Unsurprisingly, we have elected to name this grouping mechanism configuration as ~ùí±-record~.
     Let's try it out.
  #+BEGIN_example agda
{-700
M-Set-Record = M-Set record‚ÇÄ
-}
  #+END_EXAMPLE

     The system picks this up, looks up ~M-Set~ which was defined in the first section earlier,
     looks up the variational ~record~, then runs that configuration to generate:
  #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
{- M-Set-Record = M-Set record‚ÇÄ -}
record M-Set-Record : Set‚ÇÅ where
   field Scalar     : Set
   field Vector     : Set
   field _¬∑_        : Scalar ‚Üí Vector ‚Üí Vector
   field ùüô      : Scalar
   field _√ó_        : Scalar ‚Üí Scalar ‚Üí Scalar
   field leftId     : {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã
   field assoc      : {a b : Scalar} {ùìã : Vector} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã)
  #+END_example

    Nothing too remarkable; the keyword ~field~ has been inserted and the rewrite ~PackageFormer ‚Ü¶ record~
    has been performed. The above is the /exact/ generated result of the system ---the comment indicates
    the source of this generated code.

**** Equation Accommodating Record Variational
     :PROPERTIES:
     :CUSTOM_ID: Equation-Accommodating-Record-Variational
     :END:

    Since record formation is a variational that is likely to be used often, it is sensible to document it
    ---which in turn is attached to all occurences of the variational name via tooltips.
    Moreover, let's strengthen it to accomodate PackageFormers with equations.
  #+BEGIN_EXAMPLE agda
{-lisp
(ùí± record‚ÇÅ (discard-equations nil)
 = "Reify a variational as an Agda ‚Äúrecord‚Äù.
    Elements with equations are construed as
    derivatives of fields  ---the elements
    without any equations--- by default, unless
    DISCARD-EQUATIONS is provided with a non-nil value.
   "
  :kind record
  :alter-elements
    (Œª es ‚Üí
      (thread-last es
      ;; Keep or drop eqns depending on ‚Äúdiscard-equations‚Äù
      (--map
        (if discard-equations
            (map-equations (Œª _ ‚Üí nil) it)
            it))
      ;; Unless there's equations, mark elements as fields.
      (--map (map-qualifier
        (Œª _ ‚Üí (unless (element-equations it)
               "field")) it)))))
-}
  #+END_EXAMPLE

     Unlike ~ùí±-identity~ from a previous section, we have decided to split this definition into multiple
     lines by enclosing it in ~{-lisp ‚ãØ -~}~. Such blocks may contain arbitrary Lisp to be executed and so
     all contents must be Lisp forms ---notice the ~ùí±-‚ãØ~ from ~700~-blocks has been *exchanged* for
     a parenthesised (~ùí± ‚ãØ)~ within ~lisp~-blocks.

     Let's try this out.

     First, using only the default value ---which doesn't discard equations.
  #+BEGIN_EXAMPLE agda
{-700
Monoid-Record-derived = MonoidP record‚ÇÅ
-}
  #+END_EXAMPLE
  #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record Monoid-Record-derived : Set‚ÇÅ where
    field Carrier       : Set
    field _‚®æ_       : Carrier ‚Üí Carrier ‚Üí Carrier
    field Id        : Carrier
    field assoc     : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    _‚âà_     : Carrier ‚Üí Carrier ‚Üí Set ; _‚âà_   = _‚â°_
    ‚®æ-cong      : ‚àÄ {x y x' y'} ‚Üí x ‚âà x' ‚Üí  y ‚âà y' ‚Üí (x ‚®æ y) ‚âà (x' ‚®æ y') ;  ‚®æ-cong = Œª{ ‚â°.refl ‚â°.refl ‚Üí ‚â°.refl}
    Lid     : Carrier ‚Üí Carrier ;   Lid x = Id ‚®æ x
    Rid     : Carrier ‚Üí Carrier ;   Rid x = x ‚®æ Id
    concat      : List Carrier ‚Üí Carrier ;  concat = foldr _‚®æ_ Id
    field leftId        : ‚àÄ {x : Carrier} ‚Üí (Id ‚®æ x) ‚âà x
    field rightId       : ‚àÄ {x : Carrier} ‚Üí Rid x ‚âà x
    Id¬≤     : (Id ‚®æ Id) ‚âà Id ;  Id¬≤ = rightId
    concat‚Çö     : List Carrier ‚Üí Carrier ;  concat‚Çö []       = Id ; concat‚Çö (x ‚à∑ xs) = x ‚®æ concat‚Çö xs
  #+END_EXAMPLE
     Second, discarding equations and lifting all elements into ~field~-s.
  #+BEGIN_EXAMPLE agda
{-700
Monoid-Record-field = MonoidP record‚ÇÅ :discard-equations t
-}
  #+END_EXAMPLE
  #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record Monoid-Record-cons : Set‚ÇÅ where
    field Carrier       : Set
    field _‚®æ_       : Carrier ‚Üí Carrier ‚Üí Carrier
    field Id        : Carrier
    field assoc     : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    field _‚âà_       : Carrier ‚Üí Carrier ‚Üí Set
    field ‚®æ-cong        : ‚àÄ {x y x' y'} ‚Üí x ‚âà x' ‚Üí  y ‚âà y' ‚Üí (x ‚®æ y) ‚âà (x' ‚®æ y')
    field Lid       : Carrier ‚Üí Carrier
    field Rid       : Carrier ‚Üí Carrier
    field concat        : List Carrier ‚Üí Carrier
    field leftId        : ‚àÄ {x : Carrier} ‚Üí (Id ‚®æ x) ‚âà x
    field rightId       : ‚àÄ {x : Carrier} ‚Üí Rid x ‚âà x
    field Id¬≤       : (Id ‚®æ Id) ‚âà Id
    field concat‚Çö       : List Carrier ‚Üí Carrier
  #+END_EXAMPLE

  Let's also codify the converse operation of marking a grouping mechanism abstract to avoid elaboration.
  #+BEGIN_EXAMPLE emacs-lisp emacs-lisp :tangle "variationals.tmp" :noweb-ref std-ùí±-lib :noweb yes
(ùí± PackageFormer = "Mark a grouping mechanism as abstract, so that it is NOT elaborated into concrete Agda." :kind PackageFormer)
  #+END_EXAMPLE

**** A Coherent Equation Accommodating Record Variational
     :PROPERTIES:
     :CUSTOM_ID: A-Coherent-Equation-Accommodating-Record-Variational
     :END:

     Yet another option to handling equations is to drop the names that have
     equations associated with them. To tackle such a scenario
     requires the remaining elements to be well-defined and so requires ‚Äúthe largest sub-PackageFormer‚Äù.

     Coherent relationships are just graphs in disguise, so let's abstract away the details and solve
     a graph-theoretic problem. In ~{-lisp ‚ãØ -}~ blocks we may have arbitrary Emacs Lisp code and so include
     the following ---which has a large number of shortcomings, but the aim is a simple demonstration of Lisp
     code for the Agda user, not to be robust Lisp code. The name, <<<graph-map>>>
#+latex: \label{<graph-map>}, may not be ideal but it seems good enough, for now.
  #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb-ref std-ùí±-lib :noweb yes
;; p ‚âà symptom; f ‚âà medicine; adj ‚âà neighbouring dependency
;;
(cl-defun graph-map (p f adj xs &optional keep-only-marked)
  "Map the nodes XS satisfying P by F along adjacency ADJ.
<<docs('graph-map)>>
#+latex: \label{docs('graph-map)}"
  (let* (;; Using -map instead of -filter since nodes may become
         ;; sickly later on, position matters.
         (sickly (-map p xs))
         ;; Obtain the items that are currently ‚Äòsickly‚Äô.
         (get-sickly (lambda ()
                       (--filter it (--zip-with (when it other) sickly xs))))
         ;; infected x  ‚â° x has a sickly neighbour
         (infected (Œª x ‚Üí (--any (funcall adj x it) (funcall get-sickly)))))

     ;; Propogate sickness.
     (loop for _ in xs
           do (loop for x in xs
                    for i from 0
                    do (when (funcall infected x) (setf (nth i sickly) t))))

     ;; Apply medication to sickly elements only.
     (--filter it (--map (if (-contains-p (funcall get-sickly) it)
                (funcall f it)
                (unless keep-only-marked it))
            xs))))
  #+END_EXAMPLE

  Here's how this works ---the following is what the incantation
  above ~<<docs('graph-map)>>~ refers to, and the reader may ignore all ~<<‚Ä¶>>
#+latex: \label{docs('graph-map)>>~ refers to, and the reader may ignore all ~<<‚Ä¶}~
  as they are a backend ‚Äòliterate programming‚Äô utility.

  #+name: graph-map
  - F is performed on nodes satisfying P,
    all neighbours are then considered to satisfy P
    and the process repeats recursively.

  -  E.g., nodes exhibiting symptoms P are given medicine F,
    and their sickness spreads to their neighbours who in turn
    become ill thereby requiring medication, and the process continues.

  - ADJ is a binary relation denoting adjacency.
    + (adj x y)  ‚âà  ‚Äúx depends on, or is a neighbour, of y.‚Äù

  - For example, a graph of 10 nodes, with an edge between multiples;
    where nodes 3, 4, 5 are initally ill.

    #+BEGIN_EXAMPLE emacs-lisp :tangle no
   (graph-map (Œª x ‚Üí (-contains-p '(3 4 5) x))
              (Œª x ‚Üí (format "medicated-%s" x))
              (Œª x y ‚Üí (zerop (mod x y)))
              '(1 2 3 4 5 6 7 8 9 10))
  ‚áí
    (1 2 medicated-3 medicated-4 medicated-5 medicated-6 7
       medicated-8 medicated-9 medicated-10)
    #+END_EXAMPLE

  Testing this graph-theoretic solution for our setting shows it to be a reasonable fit.
  #+BEGIN_EXAMPLE emacs-lisp :tangle no
;; Example: Dropping the implementations of the first 2 items.
(setq i -1)
(graph-map (Œª _ ‚Üí (incf i) (< i 2))
           (Œª x ‚Üí (map-equations (Œª _ ‚Üí nil) x))
           ;; x depends on y  ‚â°  x mentions y in its type or equations.
           (Œª x y ‚Üí (s-contains? (s-replace "_" " " (element-name y)) (s-join " " (cons (element-type x) (element-equations x)))))
           (parse-elements '("A : Set" "_‚âà_ : A ‚Üí A ‚Üí Set" "_‚âà_ = _‚â°_" "easy : ‚àÄ {x} ‚Üí x ‚âà x" "easy = refl"
                             "another : ‚àÄ {x} ‚Üí Set" "another = easy" "by : Set‚ÇÅ" "by = Set"))))
‚áí
  A       : Set
  eq      : A ‚Üí A ‚Üí Set    ;; implementation dropped
  easy    : ‚àÄ {x} ‚Üí x ‚âà x  ;; ditto, since it depends on ‚âà's implementation
  another : ‚àÄ {x} ‚Üí Set    ;; ditto, since it depends on easy's implementation
  by      : Set‚ÇÅ
  by      = Set‚ÇÅ
  #+END_EXAMPLE

  Let's introduce a dedicated form for ~element~ values:
  #+name: --graph-map
  - Mark elements in a given list, and recursively mark all those that depend on
    them.  Return the list of elements with the marked ones being altered.

  - MARK and ALTER are expressions mentioning IT, a value of ELEMENTS,
    and so are implicit functional expressions.

  - Only the MARKED elements are kept.
  #+BEGIN_EXAMPLE emacs-lisp  :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(cl-defmacro --graph-map (mark alter elements &optional (keep-only-marked t))
  "Recursively ALTER and MARK elements and their dependents.
<<docs('--graph-map)>>
#+latex: \label{docs('--graph-map)}"
  `(graph-map (Œª it ‚Üí ,mark)
              (Œª it ‚Üí ,alter)
              ;; x depends on y  ‚â°  x mentions y, with all or no undescores,
              ;;                    in its type or equations.
              (Œª x y ‚Üí
                 (or (s-contains? (s-replace "_" " " (element-name x))
                                  (s-join " " (cons (element-type y)
                                                    (element-equations y))))
                     (s-contains? (element-name x)
                                  (s-join " " (cons (element-type y)
                                                    (element-equations y))))))
              ,elements ,keep-only-marked))
  #+END_EXAMPLE

  Now the previous example may be invoked as:
  #+BEGIN_EXAMPLE emacs-lisp :tangle no
(setq i -1)
(--graph-map (progn (incf i) (< i 3))
             (map-equations (Œª _ ‚Üí nil) it)
             (parse-elements '("A : Set" "_‚âà_ : A ‚Üí A ‚Üí Set" "_‚âà_ = _‚â°_"
                               "easy : ‚àÄ {x} ‚Üí x ‚âà x" "easy = refl"
                               "another : ‚àÄ {x} ‚Üí Set" "another = easy" "by : Set‚ÇÅ" "by = Set"))))
  #+END_EXAMPLE

  With these pieces in hand, let's form
  #+BEGIN_EXAMPLE  emacs-lisp  :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± record (discard-equations nil) (and-names nil)
 = "Reify a variational as an Agda ‚Äúrecord‚Äù.

    By default, elements with equations are construed as
    derivatives of fields  ---the elements
    without any equations.

    ‚á® DISCARD-EQUATIONS is nil by default.
      If provided with a non-nil value, equations are dropped indiscriminately.

    ‚á® AND-NAMES is nil by default and only takes
      effect when DISCARD-EQUATIONS is active.
      If provided with a non-nil value, names with
      equations are dropped altogether; but some may be kept
      if they are needed for some fields to be well-defined.
   "
  :kind record
  :alter-elements
    (Œª es ‚Üí
      (thread-last es

      (funcall (Œª es' ‚Üí (if (not discard-equations) es'
               (--map (map-equations (-const nil) (map-qualifier (-const (when (element-equations it) 'eqns)) it)) es'))))

      (funcall (Œª es' ‚Üí (if (not and-names) es'
        (--graph-map (not (equal 'eqns (element-qualifier it))) it es'))))

      ;; Unless there's equations, mark elements as fields.
      (--map (map-qualifier
        (Œª _ ‚Üí (unless (element-equations it)
               "field")) it)))))
  #+END_EXAMPLE
  :old:
    :alter-elements
      (Œª es ‚Üí (thread-last es
                ;; Keep or drop eqns depending on ‚Äúdiscard-equationals‚Äù.
                (--filter (if and-names (not (element-equations it)) it))
                (--map (if discard-equations (map-equations (-const nil) it) it))
                ;; Unless there's equations, mark all remaining elements as fields.
                (--graph-map t (map-qualifier (-const (unless (element-equations it) "field")) it)))))
  :end:
  We can obtain the previous variationals ~rcord·µ¢~ as well as new presentations.
  #+BEGIN_EXAMPLE agda
{-700
Monoid-Record-derived-again  = MonoidP record
Monoid-Record-derived-again2 = MonoidP record :and-names t
Monoid-Record-field-again    = MonoidP record :discard-equations t
Monoid-Record-no-equationals = MonoidP record :discard-equations t :and-names t
-}
  #+END_EXAMPLE
  The last form yields:
  #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record Monoid-Record-no-equationals : Set‚ÇÅ where
    field Carrier       : Set
    field _‚®æ_       : Carrier ‚Üí Carrier ‚Üí Carrier
    field Id        : Carrier
    field assoc     : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
  #+END_EXAMPLE

*** COMMENT Typeclasses ---Parameterised Records--- and Meta-Primitives ~:waist~ & ~:level~
    :PROPERTIES:
    :CUSTOM_ID: Typeclasses----Parameterised-Records----and-Meta-Primitives---waist------level-
    :END:

     We mentioned the <<<‚Äúwaist‚Äù>>>
#+latex: \label{<‚Äúwaist‚Äù>} before, but what is it exactly?
     I propose that the difference between ‚Äòfield‚Äô and ‚Äòparameter‚Äô
     is an illusion ---as is that of ‚Äòinput‚Äô and ‚Äòoutput‚Äô when one
     considers relations rather than deterministic functions.

     For example, let's alter the previous variation declaration to
     lift the waist up 2 positions.
 #+BEGIN_example agda
{-700
ùí±-typeclass-attempt = record ‚ü¥ :waist 2
-}
         #+END_EXAMPLE

    Notice we have avoided repeating the definition of the ~record~ variational from
    earlier by making use of composition. More on it later, but it suffices to say
    that above we could replace ~record ‚ü¥~ with the exact text of ~ùí±-record = ‚ãØ~ right-hand-side
    and all would continue work.

    Trying this out, below, one notices that the first two elements of the PackageFormer have been lifted
    into being parameters, while the rest have been construed as fields.
        #+BEGIN_EXAMPLE agda
{-700
M-Set-TypeClass = M-Set typeclass-attempt
-}
                    #+END_EXAMPLE
                    #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record M-Set-TypeClass (Scalar : Set) (Vector : Set) : Set‚ÇÅ where
   field _¬∑_        : Scalar ‚Üí Vector ‚Üí Vector
   field ùüô      : Scalar
   field _√ó_        : Scalar ‚Üí Scalar ‚Üí Scalar
   field leftId     : {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã
   field assoc      : {a b : Scalar} {ùìã : Vector} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã)
 #+END_example

    While this typechecks according to Agda standards, it is not ideal to human
    standards since the level of the resulting package is larger than necessary.
    The meta-primitive ~:level~ allows us to ~inc~-rement or ~dec~-crement the
    current level of a PackageFormer, so we may instead define:
 #+BEGIN_example agda
{-700
ùí±-typeclass‚ÇÇ = record ‚ü¥ :waist 2 :level dec
MonoidT‚ÇÇ      = MonoidP typeclass‚ÇÇ
-}
         #+END_EXAMPLE

         #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record MonoidT‚ÇÇ (Carrier : Set) (_‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier) : Set where
    field Id        : Carrier
    field assoc     : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    field leftId        : ‚àÄ {x : Carrier} ‚Üí Id ‚®æ x ‚â° x
    field rightId       : ‚àÄ {x : Carrier} ‚Üí x ‚®æ Id ‚â° x
         #+END_EXAMPLE

   # Unlike records, typeclasses scream to have an argument: The height of the waist.
   # Variationals may have arguments and we will cover this issue in a later subsection
   # in preference to continuing our purview of the meta-primitives.

   For fun, here are a few more to play with:
 #+BEGIN_EXAMPLE agda
{-700
MonoidT‚ÇÉ         = MonoidP record ‚ü¥ :waist 3 :level dec
-- MonoidT‚ÇÉ-again   = MonoidP ‚ü¥ record ‚ü¥ unbundling 3
M-Set-Typeclass‚ÇÇ = M-Set record ‚ü¥ typeclass‚ÇÇ
-}
 #+END_EXAMPLE

 In particular, the last example suggest that our composition is idempotent, but this is clearly not the case.
 Indeed, here's a pretty alternative to the meta-primitive ~:waist~ that is not ‚ü¥-idempotent
 but is in-fact a homomorphism: ~unbundling n ‚ü¥ unbundling m ‚âà unbundling (n + m)~.
 #+BEGIN_EXAMPLE lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± unbundling n
 = "Make the first N elements as parameters to the PackageFormer.

    Any elements in above the waist line have their equations dropped.
    As such, unbundling is not invertible.
   "
   :waist n
   :alter-elements (Œª es ‚Üí
     (-let [i 0]
       (--graph-map (progn (incf i) (<= i n))
                    (map-equations (-const nil) it)
                    es))))
 #+END_EXAMPLE
 ( The graph-map operation was defined in the previous section. )

 Incidentally, this solves the problem of lifting the waist to include elements with equations.
 #+BEGIN_EXAMPLE agda
{-700
-- Ill-formed in Agda: A defintion is not a parameter!
MonoidP-Typeclass‚ÇÖ = MonoidP :waist 5
-}
     #+END_EXAMPLE

     #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
{- Kind ‚ÄúPackageFormer‚Äù does not correspond  to a concrete Agda type.
{- MonoidP-Typeclass‚ÇÖ = MonoidP :waist 5 -}
PackageFormer MonoidP-Typeclass‚ÇÖ (Carrier : Set) (_‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier) (Id : Carrier) (assoc : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)) (_‚âà_ : Carrier ‚Üí Carrier ‚Üí Set ; _‚âà_ = _‚â°_) : Set‚ÇÅ where
    ‚®æ-cong      : ‚àÄ {x y x' y'} ‚Üí x ‚âà x' ‚Üí  y ‚âà y' ‚Üí (x ‚®æ y) ‚âà (x' ‚®æ y') ;  ‚®æ-cong = Œª{ ‚â°.refl ‚â°.refl ‚Üí ‚â°.refl}
    Lid     : Carrier ‚Üí Carrier ;   Lid x = Id ‚®æ x
    Rid     : Carrier ‚Üí Carrier ;   Rid x = x ‚®æ Id
    concat      : List Carrier ‚Üí Carrier ;  concat = foldr _‚®æ_ Id
    leftId      : ‚àÄ {x : Carrier} ‚Üí (Id ‚®æ x) ‚âà x
    rightId     : ‚àÄ {x : Carrier} ‚Üí Rid x ‚âà x
    Id¬≤     : (Id ‚®æ Id) ‚âà Id ;  Id¬≤ = rightId
    concat‚Çö     : List Carrier ‚Üí Carrier ;  concat‚Çö []       = Id ; concat‚Çö (x ‚à∑ xs) = x ‚®æ concat‚Çö xs -}
 #+END_EXAMPLE

 #+BEGIN_EXAMPLE agda
{-700
MonoidT‚ÇÖ = MonoidP ‚ü¥ unbundling 5 ‚ü¥ record
-}
     #+END_EXAMPLE
     #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record MonoidT‚ÇÖ (Carrier : Set) (_‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier) (Id : Carrier) (assoc : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)) (_‚âà_ : Carrier ‚Üí Carrier ‚Üí Set) : Set‚ÇÅ where
    field ‚®æ-cong        : ‚àÄ {x y x' y'} ‚Üí x ‚âà x' ‚Üí  y ‚âà y' ‚Üí (x ‚®æ y) ‚âà (x' ‚®æ y')
    field Lid       : Carrier ‚Üí Carrier
    field Rid       : Carrier ‚Üí Carrier
    field concat        : List Carrier ‚Üí Carrier
    field leftId        : ‚àÄ {x : Carrier} ‚Üí (Id ‚®æ x) ‚âà x
    field rightId       : ‚àÄ {x : Carrier} ‚Üí Rid x ‚âà x
    field Id¬≤       : (Id ‚®æ Id) ‚âà Id
    field concat‚Çö       : List Carrier ‚Üí Carrier
 #+END_EXAMPLE

  :smile:

*** COMMENT Forming Syntax and the Special ~$ùëõùëéùëöùëí~ Variable
    :PROPERTIES:
    :CUSTOM_ID: Forming-Syntax-and-the-Special---ùëõùëéùëöùëí--Variable
    :END:

<<rules:data>>
#+latex: \label{rules:data}

   |  /Records provide a semantics, what if we want the syntax?/ |

 Since ~data~ declarations consist of constructors, whose target type necessarily
 begins with the name of the ~data~-type being defined, let's only keep those fields and drop the rest.
 To do so, we use the helper function ~target~ which takes a declaration ~name : type0 ‚Üí ‚ãØ ‚Üí typeN~ and yields ~typeN~.

 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(defun target (thing)
  "Return final type mentioned in THING, a string declaration.

Given a type-name ‚Äò[name :] œÑ‚ÇÄ ‚Üí ‚ãØ ‚Üí œÑ‚Çô‚Äô, yield ‚ÄòœÑ‚Çô‚Äô;
the ‚Äòname‚Äô porition is irrelevant."
  (car (-take-last 1 (s-split "‚Üí" thing))))
 #+END_EXAMPLE

 With this in hand, a ~data~ presentation requires a designated ~carrier~ which is used to
 keep only those elements that target it. Finally, as data constructor must target the
 type being defined, we alter the filtered elements by changing every instance of the
 carrier name with the name of the newly defined PackageFormer ---which we may access
 using the special identifier ~$ùëõùëéùëöùëí~. In a ~lisp~ block, we formalise this algorithm as follows.
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± data carrier
  = "Reify as an Agda ‚Äúdata‚Äù type.

     Only elements targeting CARRIER are kept.
    "
    :kind  data
    :level dec
    :alter-elements (lambda (es)
      (thread-last es
        (--filter (s-contains? carrier (target (element-type it))))
        (--map (map-type (Œª œÑ ‚Üí (s-replace carrier $ùëõùëéùëöùëí œÑ)) it)))))
 #+END_EXAMPLE

 For example:
 #+BEGIN_EXAMPLE agda
{-   700
ScalarTerm = M-Set data "Scalar"
-}
 #+END_EXAMPLE
 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
data ScalarTerm : Set where
   ùüô        : ScalarTerm
   _√ó_      : ScalarTerm ‚Üí ScalarTerm ‚Üí ScalarTerm
 #+END_EXAMPLE

 Again:
 The meta-primitive ~:alter-elements~ is instructed to map over those
 elements ~e~ that contain the ~carrier~ in their ~target~ type
 by replacing the given ~carrier~ with the newly-minted ~$ùëõùëéùëöùëí~ of
 the grouping mechanism being constructed. Those that do not
 contain the given ~carrier~ in their target type are filtered out.

*** COMMENT TODO: another adt example
    :PROPERTIES:
    :CUSTOM_ID: COMMENT-TODO--another-adt-example
    :END:
    :PROPERTIES:

    :END:
 *Important*: Notice that, in the second example above,
 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
{- ScalarSyntax = M-Set primer ‚ü¥ data :carrier "Scalar'" -}
data ScalarSyntax : Set where
   ùüô' : ScalarSyntax
   _√ó'_ : ScalarSyntax ‚Üí ScalarSyntax ‚Üí ScalarSyntax
 #+END_example
 the name of the carrier is ~Scalar'~ since we changed the
 PackageFormer to prime all elements, including the ~Scalar~, element.
 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks  :tangle no
{- No = M-Set primer ‚ü¥ data :carrier "Scalar" -}
data No : Set where
   ùüô' : No'
   _√ó'_ : No' ‚Üí No' ‚Üí No'

{- Crashes since type No' is not defined! -}
 #+END_EXAMPLE

 mention these:

    + [ ] Interpretation functions from termtypes to recordtypes ---which give terms meaning.
          - [ ] With an environment argument for open termtypes.
    + [ ] Staged terms and partial evaluators

*** COMMENT Subpackages with ~generated, sorts, signature~
    :PROPERTIES:
    :CUSTOM_ID: Subpackages-with--generated--sorts--signature-
    :END:

     A common grouping operation is to zoom-in to the minimal well-formed
     package that contains only certain specified elements. For example,
     in our ~M-Set~ grouping, we may want to keep only ~ùüô~ but to be well-defined
     we are forced to also keep the elements on which it depends ---namely, ~Scalar~.

     In particular, the following naive approach only works if the elements are
     independent of one another ---which is rarely the case for Agda users.
 #+BEGIN_EXAMPLE emacs-lisp  :tangle no
;; cute, but too brutish.
(ùí± generated by = :alter-elements (lambda (es) (-filter by es)))
 #+END_EXAMPLE

     The coherent scheme is straightforward to implement.
     For clarity, rather than efficiency,
     the algorithm below forms a list ~yeses~ of the elements that should be kept
     then traverses the elements list, adding all elements needed to ensure that list
     is coherent. Moreover, for generality, we consider a predicate rather than an explicit
     listing of items to be retained.
 #+BEGIN_EXAMPLE  emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± generated by
  = "Keep the largest well-formed PackageFormer whose elements satisfy BY.

     BY is a predicate on elements.
    "
    :alter-elements (Œª es ‚Üí (--graph-map (funcall by it) it es)))

 #+END_EXAMPLE
 :OLD:
 #+BEGIN_EXAMPLE  emacs-lisp :tangle no
(ùí± generated by
  = "Keep the largest well-formed PackageFormer whose elements satisfy BY.

     BY is a predicate on elements.
    "
    :alter-elements  (lambda (fs)
      (let* ( (yeses (--map (funcall by it) fs))
              (get-yeses (lambda () (--filter it (--zip-with (if it other) yeses fs))))
              (in-yeses (lambda (e)
                          (--any
                           (s-contains? (s-replace "_" " " (element-name e)) (element-type it))
                           (funcall get-yeses)))))

        (loop for _ in fs do
              (loop for f in fs
                    for i from 0
                    do ;; when f in yess, set f to be yes.
                    (when (funcall in-yeses f) (setf (nth i yeses) t))))

        (funcall get-yeses))))
 #+END_EXAMPLE
 :END:

 Here's an immediate application: Obtaining the types declared in a grouping mechanism.
 #+BEGIN_EXAMPLE emacs-lisp  :tangle  "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± sorts
 = "Obtaining the types declared in a grouping mechanism.

   For now, only base types; i.e., items targeting ‚ÄúSet‚Äù.
   "
   generated (Œª e ‚Üí (s-contains? "Set" (target (element-type e)))))
 #+END_EXAMPLE
 #+BEGIN_EXAMPLE agda
{-700
M-Set-Sorts = M-Set record ‚ü¥ sorts
-}
     #+END_EXAMPLE
     #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record M-Set-Sorts : Set‚ÇÅ where
   field Scalar     : Set
   field Vector     : Set
 #+END_EXAMPLE

 We can even obtain a sub-signature wholesale:
 #+BEGIN_EXAMPLE agda
{-700
MonoidSignature = M-Set-Record generated (Œª e ‚Üí (and (s-contains? "Scalar" (element-type e)) (not (s-contains? "Vector" (element-type e)))))
-}
     #+END_EXAMPLE
     #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record MonoidSignature : Set‚ÇÅ where
   field Scalar     : Set
   field ùüô      : Scalar
   field _√ó_        : Scalar ‚Üí Scalar ‚Üí Scalar
 #+END_EXAMPLE

 This pattern of having a lawless grouping seems sufficiently desirable that we may
 codify it.
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(defun targets-a-sort (element)
  "Check whether the given ELEMENT targets a sort.

The sorts considered refer to those of the *current* PacakgeFormer."
  (--any (s-contains? it (target (element-type element)))
         (-map #'element-name (-filter #'is-sort $ùëíùëôùëíùëöùëíùëõùë°ùë†))))

(ùí± signature
  = "Keep only the elements that target a sort, drop all else."
    generated (Œª e ‚Üí (targets-a-sort e)))
 #+END_EXAMPLE

 Here's an example.
 #+BEGIN_EXAMPLE agda
{-700
MonSig = M-Set-Record signature
-}
     #+END_EXAMPLE

     #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
record MonSig : Set‚ÇÅ where
   field Scalar     : Set
   field Vector     : Set
   field _¬∑_        : Scalar ‚Üí Vector ‚Üí Vector
   field ùüô      : Scalar
   field _√ó_        : Scalar ‚Üí Scalar ‚Üí Scalar
 #+END_EXAMPLE

    Neato! Those were some nifty applications!

    For practicality, let's also introduce a more concrete syntax
    analogous to that of ~renaming~:
    # Magma = Monoid generated (Œª e ‚Üí (equal "__¬∑__" (element-name e)))
 #+BEGIN_EXAMPLE emacs-lisp  :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± keeping those
  = "Keep THOSE elements, a ‚Äú;‚Äù-separated string of proper names,
    along with the elements that ensure THOSE is well-defined.
 "
    generated (reify-to-list those :otherwise nil :key #'element-name))
 #+END_EXAMPLE

*** COMMENT Shallow Renaming with Agda's ~open ‚ãØ public ‚ãØ renaming ‚ãØ~
    :PROPERTIES:
    :CUSTOM_ID: Shallow-Renaming-with-Agda-s--open---public---renaming---
    :END:
     The previous approach to renaming altered field names literally which is not
     desirable when one only wants to refer to field names of multiple instances
     of the same record ---e.g., when forming homomorphisms.

     A common pattern in Agda is then to open the record and perform the desired
     shallow renames. This pattern is so common that the standard library is [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.Structures.html#2757][littered]]
     with instances of it.
     We can codify the pattern as a method rather than as a
     manual technique.

     Let's go from zero to one-hundred ---again: There's a Lisp Cheat Sheet that should
     have been consulted at one point.

     Zero: A module where the elements are all parameters.
 #+BEGIN_EXAMPLE agda
{-700
ùí±-empty-module = :kind module :level none :waist 999
Neato = M-Set empty-module
-}

{- A module where the elements are all parameters -}
open Neato using ()
 #+END_EXAMPLE

 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
module Neato (Scalar : Set) (Vector : Set) (_¬∑_ : Scalar ‚Üí Vector ‚Üí Vector) (ùüô : Scalar) (_√ó_ : Scalar ‚Üí Scalar ‚Üí Scalar) (leftId : {ùìã : Vector} ‚Üí ùüô ¬∑ ùìã ‚â° ùìã) (assoc : ‚àÄ {a b ùìã} ‚Üí (a √ó b) ¬∑ ùìã ‚â° a ¬∑ (b ¬∑ ùìã)) where
 #+END_EXAMPLE

    One-hundred: A one-parameter module where elements may be renamed.
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± open with (avoid-mixfix-renaming nil)
  =
    "Reify a given PackageFormer as a *parameterised* Agda ‚Äúmodule‚Äù declaration.

     WITH is a renaming, string to string, function that is applied to the parent record that will
     be opened and reexported as a module.

     AVOID-MIXFIX-RENAMING is optional; by default renaming ‚Äújumps over‚Äù underscores,
     but providing a non-nil value for this argument leaves underscores alone.
     It is a matter of having, say, default ‚Äú_‚äï‚Çô_‚Äù versus ‚Äú_‚äï_‚Çô‚Äù.

     The resulting module has a parameter, whose name is irrelevant but is
     of the form ‚ÄúArgùíπùíπùíπùíπ‚Äù for some digits ùíπ in order to minimise clash with
     any user-defined names.

     Besides the addition of a new parameter, all element qualifiers are discarded.
    "
    :kind module
    :level none
    :waist 1
    :alter-elements  (lambda (fs)
      (let ((kind "{! !}") (‚Ñõ (format "Ar%s" (gensym))))
        (cons (make-element :name ‚Ñõ :type $ùëùùëéùëüùëíùëõùë°)
          (--map (let ((name (if avoid-mixfix-renaming (with (element-name it)) (rename-mixfix with (element-name it)))))
            (make-element :name name
                          :type (format "let open %s %s in %s" $ùëùùëéùëüùëíùëõùë° ‚Ñõ (element-type it))
                          :equations (list (format "%s = %s.%s %s" name $ùëùùëéùëüùëíùëõùë° (element-name it) ‚Ñõ)))) fs)))))
 #+END_EXAMPLE

   Notice that we do not need any ~open ‚ãØ public~ since all elements are top-level.
   We are not making using of Agda's renaming facility. An example may clarify this observation.
   #+BEGIN_EXAMPLE agda
{-700
M-Set-R = M-Set record
M-Set-R‚ÇÅ = M-Set-R ‚ü¥ open (Œª x ‚Üí (concat x "‚ÇÅ"))
-}
 #+END_EXAMPLE

 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
module M-Set-R‚ÇÅ (Arg6926 : M-Set-R) where
   Scalar‚ÇÅ      : let open M-Set-R Arg6926 in Set ; Scalar‚ÇÅ = M-Set-R.Scalar Arg6926
   Vector‚ÇÅ      : let open M-Set-R Arg6926 in Set ; Vector‚ÇÅ = M-Set-R.Vector Arg6926
   _¬∑‚ÇÅ_     : let open M-Set-R Arg6926 in Scalar ‚Üí Vector ‚Üí Vector ;    _¬∑‚ÇÅ_ = M-Set-R._¬∑_ Arg6926
   ùüô‚ÇÅ       : let open M-Set-R Arg6926 in Scalar ;  ùüô‚ÇÅ = M-Set-R.ùüô Arg6926
   _√ó‚ÇÅ_     : let open M-Set-R Arg6926 in Scalar ‚Üí Scalar ‚Üí Scalar ;    _√ó‚ÇÅ_ = M-Set-R._√ó_ Arg6926
   leftId‚ÇÅ      : let open M-Set-R Arg6926 in {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã ;    leftId‚ÇÅ = M-Set-R.leftId Arg6926
   assoc‚ÇÅ       : let open M-Set-R Arg6926 in ‚àÄ {a b ùìã} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã) ; assoc‚ÇÅ = M-Set-R.assoc Arg6926
   #+END_EXAMPLE

   In-case you've skipped over the above source documentation for ~open~, it's time to read it.

   Notice that a module opening depends on a record, whence the first declaration of ~M-Set-R~.

   #+begin_center
    These kind of open-renamings are so common that the tedium
    is actually acceptable by most users ---it shouldn't be
    and now it no longer has to be that way.
   #+end_center

   It is common in Agda to provide ‚Äúto‚Äù-lists, so let's provide a variant that supports those
   instead of forcing users to produce functions explicitly.
   #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± opening with
  = "Open a record as a module exposing only the names mentioned in WITH.

    WITH is a string of ‚Äú;‚Äù-separated items consisting of ‚Äúto‚Äù-separated pairs.
    "
    open (Œª x ‚Üí (funcall (reify-to-list with :otherwise "_") x)) :avoid-mixfix-renaming t)

    ;; Alternatively, we could have used ‚Äòtrash‚Äô names,
    ;; something like (format "%s" (gensym)), instead of "_".
   #+END_EXAMPLE

     #+BEGIN_EXAMPLE agda
{-700
M-Set-R-SV = M-Set-R opening "Scalar to S; Vector to V"
-}
     #+END_EXAMPLE
 This opens the ~M-Set-R~ record *exposing only* ~S~ and ~V~ ---the rest are ignored using Agda's ~_~ mechanism.
     #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
module M-Set-R-SV (Arg6933 : M-Set-R) where
   S        : let open M-Set-R Arg6933 in Set ; S = M-Set-R.Scalar Arg6933
   V        : let open M-Set-R Arg6933 in Set ; V = M-Set-R.Vector Arg6933
   _        : let open M-Set-R Arg6933 in Scalar ‚Üí Vector ‚Üí Vector ;    _ = M-Set-R._¬∑_ Arg6933
   _        : let open M-Set-R Arg6933 in Scalar ;  _ = M-Set-R.ùüô Arg6933
   _        : let open M-Set-R Arg6933 in Scalar ‚Üí Scalar ‚Üí Scalar ;    _ = M-Set-R._√ó_ Arg6933
   _        : let open M-Set-R Arg6933 in {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã ;    _ = M-Set-R.leftId Arg6933
   _        : let open M-Set-R Arg6933 in ‚àÄ {a b ùìã} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã) ; _ = M-Set-R.assoc Arg6933
 #+END_EXAMPLE

 After simplifying the ~let~-expressions, this module definition is equivalent to the following
 ---the types of which may be seen with Agda's ~C-c C-o~ call.
 #+BEGIN_EXAMPLE agda :tangle no
module M-Set-R-SV (Arg : M-Set-R) where
  S : (Arg : M-Set-R) ‚Üí Set ; S = M-Set-R.Scalar Arg
  V : (Arg : M-Set-R) ‚Üí Set ; V = M-Set-R.Vector Arg
 #+END_EXAMPLE

 Let's provide an even more common feature: Opening records with a decoration.
 For example, when we have two algebraic structures, we might want the first to be subscripted with ‚ÇÅ
 and the second with ‚ÇÇ ---this is different than ~subscripted·µ¢~ from above, which produces a /new/ record
 rather than opening it with renames.
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± open-with-decoration ddd
  = "Open a record, exposing all elements, with decoration DDD.

    DDD is a string.
   "
   open (Œª x ‚Üí (concat x ddd)))
 #+END_EXAMPLE

 Here's an example.
 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks
{-700
M-Set-R' = M-Set-R open-with-decoration "'"
-}
                           #+END_EXAMPLE

                           #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks  :tangle no
module M-Set-R' (Arg6938 : M-Set-R) where
   Scalar'      : let open M-Set-R Arg6938 in Set ; Scalar' = M-Set-R.Scalar Arg6938
   Vector'      : let open M-Set-R Arg6938 in Set ; Vector' = M-Set-R.Vector Arg6938
   _¬∑'_     : let open M-Set-R Arg6938 in Scalar ‚Üí Vector ‚Üí Vector ;    _¬∑'_ = M-Set-R._¬∑_ Arg6938
   ùüô'       : let open M-Set-R Arg6938 in Scalar ;  ùüô' = M-Set-R.ùüô Arg6938
   _√ó'_     : let open M-Set-R Arg6938 in Scalar ‚Üí Scalar ‚Üí Scalar ;    _√ó'_ = M-Set-R._√ó_ Arg6938
   leftId'      : let open M-Set-R Arg6938 in {ùìã : Vector}  ‚Üí  ùüô ¬∑ ùìã  ‚â°  ùìã ;    leftId' = M-Set-R.leftId Arg6938
   assoc'       : let open M-Set-R Arg6938 in ‚àÄ {a b ùìã} ‚Üí (a √ó b) ¬∑ ùìã  ‚â°  a ¬∑ (b ¬∑ ùìã) ; assoc' = M-Set-R.assoc Arg6938
 #+END_EXAMPLE

   Neato petito :smile:

 #+begin_center
 It is important to observe that ‚Äòopenings‚Äô are lossy:
 They lose the types of the declarations and so cannot be used further to construct
 new pacaking mechanisms. They are a terminal construction.
 #+end_center

   In the next section, we make use of such openings to actually produce
   homomorphism constructions.

 #  For now, let's show how /functions are PackageFormers./

*** COMMENT Automatically deriving homomorphism definitions ‚ô•‚Äø‚ô•
    :PROPERTIES:
    :CUSTOM_ID: Automatically-deriving-homomorphism-definitions
    :END:

     The definition of ‚Äústructure preservation‚Äù is, nearly always, mechanical to
     formulate and that's just what we shall do to avoid having to write it out
     by hand ever again ---which the [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.Morphism.html#586][current approach]] in the Agda standard library.

     :Illuminating_yet_overkill_to-subscript_defn:
 #+BEGIN_EXAMPLE emacs-lisp  :tangle no
(defun to-subscript (n)
  "Subscript numbers ùìÉ have hex-codes #x208ùìÉ,
   we realise the codes as characters to obtain the subscripts.

   This is preferable to casing:
  (pcase i (0 ‚Äú‚ÇÄ‚Äù) (1 ‚Äú‚ÇÅ‚Äù) (2 ‚Äú‚ÇÇ‚Äù) ‚ãØ)

  When ‚Äòn‚Äô ‚àâ 0..9 an error message halts execution.
  "

  (when (or (< n 0) (> n 9))
    (error "to-subscript: n must be in 0..9"))

  (thread-last
    (format "#x208%s" n)
    (read-from-string)
    car
    (format "%c")))
 #+END_EXAMPLE
     :End:

     The idea is not too complicated:
     1. Suppose you have an operation ~_¬∑_ : Scalar ‚Üí Vector ‚Üí Vector~.
     2. Suppose you have a numbering of the sorts; e.g., ~sort‚ÇÅ = Scalar, sort‚ÇÇ = Vector~.
     3. Form functions ~map·µ¢ : sort·µ¢ ‚Üí sort·µ¢'~
     4. Include implicit arguments in the type: ~{x‚ÇÅ : Scalar} ‚Üí {x‚ÇÇ : Vector} ‚Üí Vector~.
     5. The target type ~Vector = sort‚ÇÇ~ means we need to apply ~map‚ÇÇ~ to the expression
        formed from the operation's name along with the arguments.
        - The left hand side is thus ~map‚ÇÇ (_¬∑_ x‚ÇÅ x‚ÇÇ)~.
     6. For the right hand side, we use the target-space's name, say ~_¬∑'_~,
        along with ~map·µ¢~ applied to ~x·µ¢~ for each ~i~ mentioned in the type.

     7. The result:
        ~pres-¬∑ : {x‚ÇÅ : Scalar} ‚Üí {x‚ÇÇ : Vector} ‚Üí   map‚ÇÇ (_¬∑_ x‚ÇÅ x‚ÇÇ)   ‚â°   _¬∑'_ (map‚ÇÅ x‚ÇÅ) (map‚ÇÇ x‚ÇÇ)~.
       :RoughIdea:
     ‚áí  _¬∑_ : sort‚ÇÅ ‚Üí sort‚ÇÇ ‚Üí sort‚ÇÇ
     ‚áí pres-¬∑ : {x‚ÇÅ : sort‚ÇÅ} {x‚ÇÇ : sort‚ÇÇ}
          ‚Üí   form source expression:  x‚ÇÅ ¬∑ x‚ÇÇ
            ‚áí form target expression: map‚ÇÅ x‚ÇÇ ¬∑' map‚ÇÇ x‚ÇÇ
            ‚áí equate them using target sort's map:  map‚ÇÇ (x‚ÇÅ ¬∑ x‚ÇÇ) ‚â° map‚ÇÅ x‚ÇÇ ¬∑' map‚ÇÇ x‚ÇÇ
     :End:

     First, we need a helper that forms the preservation formulae.
     For example:
 #+BEGIN_EXAMPLE emacs-lisp  :tangle no
(show-element (homify (make-element :name "_¬∑_" :type "Scalar ‚Üí Vector ‚Üí Vector")
                      '( ("Scalar" . 4) ("Vector" . 1))))
‚áí
  pres-¬∑ : {x‚ÇÑ : Scalar} ‚Üí {x‚ÇÅ : Vector}
         ‚Üí map‚ÇÅ (_¬∑_ x‚ÇÑ x‚ÇÅ)   ‚â°   _¬∑'_ (map‚ÇÑ x‚ÇÑ) (map‚ÇÅ x‚ÇÅ)
 #+END_EXAMPLE

     With this as a specification, in a ~lisp~ block:
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(defun homify (element sort)
  "Given a typed name, produce the associating ‚Äúpreservation‚Äù formula.

E.g.,
  _¬∑_    : Scalar ‚Üí Vector ‚Üí Vector
  pres-¬∑ : {x‚ÇÅ : Scalar} ‚Üí {x‚ÇÇ : Vector} ‚Üí map‚ÇÇ (x‚ÇÅ ¬∑ x‚ÇÇ) = map‚ÇÅ x‚ÇÅ ¬∑' map‚ÇÇ x‚ÇÇ


Type œÑ gets variable x·µ¢ provided (i, œÑ) ‚àà SORT;
likewise we think of map·µ¢ : œÑ ‚Üí œÑ'.
Notice that the target name is primed, ‚Äú¬∑'‚Äù

ELEMENT is the typed-name and SORT is the alist of numbered sorts."
  (letf* ((sorts     (mapcar #'car sort))
          (index     (Œª it ‚Üí (to-subscript (cdr (assoc it sort)))))

          (tn‚Üí       (s-split " ‚Üí " (element-type element)))
          (arg-count (1- (length tn‚Üí)))

          (all-indicies  (mapcar index
                                 (--filter (member (s-trim it) sorts) tn‚Üí)))
          (indicies  (-drop-last 1 all-indicies))
          (tgt-idx   (car (-take-last 1 all-indicies)))

          (op        (element-name element))
          (args      (--map (concat "x" it) indicies))
          (lhs       (format "map%s (%s %s)" tgt-idx op (s-join " " args)))

          (op'       (rename-mixfix (lambda (n) (concat n "'")) op))
          (map-args  (--map (format "(map%s x%s)" it it) indicies))
          (rhs       (format "%s %s" op' (s-join " " map-args)))

          (target    (format "  %s   ‚â°   %s" lhs rhs)))

    ;; Change the target type.
    (setq tn‚Üí (--map (when (assoc it sort)
                       (format "{x%s : %s}" (funcall index it) it)) tn‚Üí))
    (setf (nth arg-count tn‚Üí) target)

    ;; Stick it all together, with an updated name.
    (make-element
     :name (format "pres-%s" (s-replace "_" "" (element-name element)))
     :type (s-join " ‚Üí " tn‚Üí))))
 #+END_EXAMPLE

     Then, we form the variational as follows ---also in a ~lisp~ block.
 #+BEGIN_EXAMPLE emacs-lisp :tangle "variationals.tmp" :noweb yes :noweb-ref std-ùí±-lib
(ùí± hom
  = "Formulate the notion of homomorphism of $ùëùùëéùëüùëíùëõùë° algebras.

     ‚û© $ùëùùëéùëüùëíùëõùë° must be an existing record type used in the resulting formulation.
    "
    record ‚ü¥
    :waist 2
    :alter-elements (lambda (es)

      (let (maps eqns sorts (ùíÆùìáùí∏ "Example") (ùíØ‚Ñäùìâ "Tgt"))

        ;; Construct the map·µ¢ : sort·µ¢ ‚Üí sort·µ¢'; keeping track of (sort . i) pairs.
        (loop for e in es
              for i from 1
         do
           (when (is-sort e)
             (push (cons (element-name e) i) sorts)
             (push (make-element
                      :qualifier "field"
                      :name (format "map%s" (to-subscript i))
                      :type (format "%s ‚Üí %s'" (element-name e) (element-name e)))
                   maps))

            (when (and (targets-a-sort e) (not (is-sort e)))
              (push (homify e sorts) eqns)))

      ;; Ensure we have a source and target space as elements.
      (-cons*
       (make-element :qualifier "field" :name ùíÆùìáùí∏ :type $ùëùùëéùëüùëíùëõùë°)
       (make-element :qualifier "field" :name ùíØ‚Ñäùìâ :type $ùëùùëéùëüùëíùëõùë°)
       (--map
        (map-type (Œª œÑ ‚Üí (format "let open %s %s; open %s' %s in %s"
                                 $ùëùùëéùëüùëíùëõùë° ùíÆùìáùí∏ $ùëùùëéùëüùëíùëõùë° ùíØ‚Ñäùìâ œÑ))
                  (map-qualifier (Œª _ ‚Üí "field") it))
        (reverse (-concat eqns maps)))))))
 #+END_EXAMPLE

     Here are two examples. *Note* that the latter allows us to /rename/ the ~map·µ¢~ as we
     wish ---which may be preferable to extending the variational to accommodate for new
     names.

 #+BEGIN_EXAMPLE agda
{-700
Algebra  = M-Set record
Algebra' = Algebra open-with-decoration "'"
Hom  = Algebra hom
Hom¬≤ = Algebra hom ‚ü¥ renaming "map‚ÇÅ to scalar; pres-ùüô to unity" :adjoin-retract nil
-}

_ : {Example Tgt : Algebra} ‚Üí Hom¬≤ Example Tgt ‚Üí Algebra.Scalar Example ‚Üí Algebra.Scalar Tgt
_ = Hom¬≤.scalar
 #+END_EXAMPLE

 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks :tangle no
{- Hom  = Algebra hom -}
record Hom (Example : Algebra) (Tgt : Algebra) : Set‚ÇÅ where
   field map‚ÇÅ       : let open Algebra Example; open Algebra' Tgt in Scalar ‚Üí Scalar'
   field map‚ÇÇ       : let open Algebra Example; open Algebra' Tgt in Vector ‚Üí Vector'
   field pres-¬∑     : let open Algebra Example; open Algebra' Tgt in {x‚ÇÅ : Scalar} ‚Üí {x‚ÇÇ : Vector} ‚Üí   map‚ÇÇ (_¬∑_ x‚ÇÅ x‚ÇÇ)   ‚â°   _¬∑'_ (map‚ÇÅ x‚ÇÅ) (map‚ÇÇ x‚ÇÇ)
   field pres-ùüô     : let open Algebra Example; open Algebra' Tgt in   map‚ÇÅ (ùüô )   ‚â°   ùüô'
   field pres-√ó     : let open Algebra Example; open Algebra' Tgt in {x‚ÇÅ : Scalar} ‚Üí {x‚ÇÅ : Scalar} ‚Üí   map‚ÇÅ (_√ó_ x‚ÇÅ x‚ÇÅ)   ‚â°   _√ó'_ (map‚ÇÅ x‚ÇÅ) (map‚ÇÅ x‚ÇÅ)


{- Hom¬≤ = Algebra hom ‚ü¥ renaming "map‚ÇÅ to scalar; pres-ùüô to unity" -}
record Hom¬≤ (Example : Algebra) (Tgt : Algebra) : Set‚ÇÅ where
   field scalar     : let open Algebra Example; open Algebra' Tgt in Scalar ‚Üí Scalar'
   field map‚ÇÇ       : let open Algebra Example; open Algebra' Tgt in Vector ‚Üí Vector'
   field pres-¬∑     : let open Algebra Example; open Algebra' Tgt in {x‚ÇÅ : Scalar} ‚Üí {x‚ÇÇ : Vector} ‚Üí   map‚ÇÇ (_¬∑_ x‚ÇÅ x‚ÇÇ)   ‚â°   _¬∑'_ (scalar x‚ÇÅ) (map‚ÇÇ x‚ÇÇ)
   field unity      : let open Algebra Example; open Algebra' Tgt in   scalar (ùüô )   ‚â°   ùüô'
   field pres-√ó     : let open Algebra Example; open Algebra' Tgt in {x‚ÇÅ : Scalar} ‚Üí {x‚ÇÅ : Scalar} ‚Üí   scalar (_√ó_ x‚ÇÅ x‚ÇÅ)   ‚â°   _√ó'_ (scalar x‚ÇÅ) (scalar x‚ÇÅ)
 #+END_EXAMPLE

   This is so cool ^_^

   We leave it to the reader to derive other constructs from a theory presentation.
   Examples can be found in these [[https://alhassy.github.io/next-700-module-systems/papers/JC_Program_Generation_Talk_IFIP.pdf][Metaprogramming Agda]] slides:
   Homomorphism equality, application to carrier elements, isomorphisms,
   isomorphisms where only one direction needs to preserve the structure
   and an automatically derivable proof that the other direction is also
   structure preserving, endomorphism and automorphism types, kernels,
   product & sum & other categorical types.

   + Challenge ::
       Design a scheme to produce simple Cartesian products from a given theory.

     1. The only variable to this problem is an arbitrary record, say it is ~M~.

        For this exercise to be tractable, assume ~M~ consists of declarations
        of sort symbols, function symbols, and nullary (non-implication) equations
        which may have implicit arguments.

     2. Ensure you understood the definition of the homomorphism scheme above.
     3. Mimic the homomorphism scheme to produce a typed ~Prod~ where ~Prod A‚ÇÄ A‚ÇÅ~
        consists of a ~M~ value, say ~P~, and two homomorphisms ~Hom P A·µ¢~.
     4. Write a Lisp code that produces a function ~MakeProduct : (A‚ÇÄ A‚ÇÅ : M) ‚Üí Prod A‚ÇÄ A‚ÇÅ~.

        - The projection morphisms are straightforward.
        - Every /n/-ary function ~f~ could be defined by ~f‚Çö = zip‚Çô f‚ÇÄ f‚ÇÅ~.
        - Every equation ~e~ could be defined by ~e‚Çö = cong‚ÇÇ _,_ e‚ÇÄ e‚ÇÅ~.

     5. If you have actually attempted this, then go on to include the remaining
        artefacts to make the construction an actual categorical product.

*** COMMENT Currying for Datatypes
    :PROPERTIES:
    :CUSTOM_ID: COMMENT-Currying-for-Datatypes
    :END:
    :PROPERTIES:

    :END:

    :Lisp_code_that_generates_the_code_for_this_subsection:
 #+BEGIN_EXAMPLE emacs-lisp :var monoid = monoid :exports both :results replace :wrap "example haskell :remark these-are-just-results-from-previous-blocks"
(let* ((variationals nil) (instantiations-remaining nil)
       (vs (pf--load-variationals (s-join "\n" '(
      "ùí±-identity = "
      "ùí±-record  = :kind record :waist-strings (\"field\")"
      "ùí±-whoops  = :kind recorder :waist-strings (\"field\")"
      "ùí±-typeclass-attempt  = :kind record :waist-strings (\"field\") :waist 2"
      "ùí±-typeclass‚ÇÇ  = :kind record :waist-strings (\"field\") :waist 2 :level dec"
      "ùí±-primed-record = :kind record :waist-strings (\"field\") :alter-elements (Œª f ‚Üí (map-name (concat name \"'\") f))"
      "ùí±-primed = :alter-elements (Œª f ‚Üí (map-name (concat name \"'\") f))"
      "ùí±-typeclass height level = :kind record :waist-strings (\"field\") :waist height :level level"
; TODO:   ; "ùí±-renamed with = :alter-elements (Œª e ‚Üí (map-name (funcall with name) e))"
      "ùí±-data-with carrier = :kind data :level dec :alter-elements (Œª f ‚Üí (if (s-contains? carrier (target (get-type f))) (map-type (s-replace carrier $ùëõùëéùëöùëí type) f) \"\"))"
      ))))
       (pf (load-package-former (second (get-children "PackageFormer" monoid)))))

  (--map (load-instance-declaration it)
    '(

      ; TODO: "M-Set-PF = M-Set identity :waist 2" ;; nope.

      ; "Monoid-Record = Monoid record"
      ; "Monoid-Classical = Monoid typeclass :height (1) :level (dec)"
       "MonoidOp = Monoid typeclass :height (2) :level (dec)"
      ; "M-Set-Record = M-Set whoops"
      ; "M-Set-Typeclass = M-Set typeclass-attempt"
      ; "M-Set-Typeclass‚ÇÇ = M-Set typeclass‚ÇÇ"
      ; "M-Set-Record' = M-Set primed-record"
      ; "M-Set' = M-Set primed"
      ; "M-Set-Record' = M-Set-Record primed"
      ; "M-Set-Record' = M-Set-Record record ‚ü¥ primed"
      ; "M-Set-Typeclass‚ÇÉ = M-Set-Record typeclass :height (3) :level (dec) :comment (why hello there)"

      ; TODO: "M-Set‚ÇÅ = M-Set renamed :with ((Œª x ‚Üí x))"

      ; "ScalarSyntax = M-Set data-with :carrier (\"Scalar\")"
      ))

  (reify-instances)
)
 #+END_EXAMPLE

 #+RESULTS:

 :End:

 Suppose you're a Haskell programmer and want to have multiple monoid instances for the Booleans.
 You may make isomorphic copies of the Booleans, say ~And~ and ~Any~, and implement the desired instance
 for each. What about if you want a Monoid instance but insist only that the unit be ~false~, what do you do then?

 With this prototype, you expose the carrier and the operation in the first case, and expose the identity in the second case.
 Moreover, you only write the definition of monoid once, leading to our motto:
 #+BEGIN_CENTER
 /Write once, derive many!/
 #+END_CENTER

 Here's a formalisation of monoids:
 #+NAME: monoid
 #+BEGIN_EXAMPLE agda :results replace :wrap "example haskell :remark these-are-just-results-from-previous-blocks"
PackageFormer Monoid : Set‚ÇÅ where
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    Id      : Carrier
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId  : ‚àÄ {x : Carrier} ‚Üí Id ‚®æ x ‚â° x
    rightId : ‚àÄ {x : Carrier} ‚Üí x ‚®æ Id ‚â° x
 #+END_EXAMPLE
 :Hide:
 #+RESULTS: monoid
 #+BEGIN_example haskell :remark these-are-just-results-from-previous-blocks
PackageFormer Monoid : Set‚ÇÅ where
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    Id      : Carrier
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId  : ‚àÄ {x : Carrier} ‚Üí Id ‚®æ x ‚â° x
    rightId : ‚àÄ {x : Carrier} ‚Üí x ‚®æ Id ‚â° x
 #+END_example
 :End:

 We regain the Haskell-style typeclass definition with the following declaration:
 #+BEGIN_EXAMPLE agda
 Monoid-Classical = Monoid typeclass :height (1) :level (dec)
 #+END_EXAMPLE
 Loading the script, with ~C-c C-l~ as usual, produces a generated file that elaborate this definition as follows:
 #+BEGIN_EXAMPLE haskell :remark these-are-just-results-from-previous-blocks
record Monoid-Classical (Carrier : Set) : Set where
  field
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    Id      : Carrier
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId  : ‚àÄ {x : Carrier} ‚Üí Id ‚®æ x ‚â° x
    rightId : ‚àÄ {x : Carrier} ‚Üí x ‚®æ Id ‚â° x
 #+END_EXAMPLE
 Notice that a name ~Carrier~ has been lifted to being a parameter instead of a field.
 This is the result of the ~:height~ argument to the ~typeclass~ variational defined
 in the previous subsection.

 :TODO_FIXME:
 We could use the letter ~m~ in-place of ~Carrier~, as is done in Haskell, as follows.
 #+BEGIN_EXAMPLE agda
 Monoid-m = Monoid typeclass renaming (Carrier to m)
 #+END_EXAMPLE
 Which propagates ~Carrier = m~ into the fields. The propagation is necessary
 if we were, for example, to rename ~_‚®æ_ to _‚äï_~ ---otherwise we would need to parse
 mixfix applications of this operator, as in ~assoc~!
 #+BEGIN_EXAMPLE agda
record Monoid-m (m : Set) : Set where
  field
    _‚®æ_     : let Carrier = m in m ‚Üí m ‚Üí m
    Id      : let Carrier = m in m
    assoc   : let Carrier = m in ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId  : let Carrier = m in ‚àÄ {x : let Carrier = m in m} ‚Üí Id ‚®æ x ‚â° x
    rightId : let Carrier = m in ‚àÄ {x : let Carrier = m in m} ‚Üí x ‚®æ Id ‚â° x
 #+END_EXAMPLE
 :END:

 Since Agda supports ‚Äònamed instances‚Äô, the Haskeller's first problem is solved. However, we demonstrate
 an alternative solution that will allow us to solve the second problem in a fashion that current Agda
 can only awkwardly approximate.

 For example, with the current setup, we may go about requesting multiple monoid instances for the Booleans:
 #+BEGIN_EXAMPLE agda
open Monoid-Classical using () renaming (_‚®æ_ to Op)

yuck-one :  (X Y : Classical ùîπ)
     ‚Üí  Op X  ‚â° _‚àß_  ‚Üí  Op Y  ‚â° _‚à®_
     ‚Üí  Set
yuck-one = ???
 #+END_EXAMPLE

 The following declaration lets us ‚Äòuncurry‚Äô the first ~N = 2~ elements
 from the field-position to the parameter-position.
 #+BEGIN_EXAMPLE agda
MonoidOp = Monoid typeclass :height (2) :level (dec)
 #+END_EXAMPLE

 This then yields:
 #+BEGIN_example haskell :remark these-are-just-results-from-previous-blocks
record MonoidOp (Carrier : Set) (_‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier) : Set where
  field
    Id      : Carrier
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId  : ‚àÄ {x : Carrier} ‚Üí Id ‚®æ x ‚â° x
    rightId : ‚àÄ {x : Carrier} ‚Üí x ‚®æ Id ‚â° x
 #+END_example

 Which let's us solve the first problem elegantly as so:
 #+BEGIN_EXAMPLE agda
first-problem : MonoidOp ùîπ _‚àß_  ‚Üí  MonoidOp ùîπ _‚à®_  ‚Üí Set
first-problem = ???
 #+END_EXAMPLE

 Neato ^_^ Short and sweet.

 Now for the second problem. Rather than forming a new data-type,
 we hoist up the ~Id~-entity field as a parameter.
 | ~TODO: Write this section~ |

 #+BEGIN_EXAMPLE agda
 MonoidId = Monoid record exposing (Carrier; Id)
 #+END_EXAMPLE
 Which results in:
 #+BEGIN_EXAMPLE agda
record MonoidId (Carrier : Set) (Id : Carrier) : Set where
  field
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId  : ‚àÄ {x : Carrier} ‚Üí Id ‚®æ x ‚â° x
    rightId : ‚àÄ {x : Carrier} ‚Üí x ‚®æ Id ‚â° x
 #+END_EXAMPLE

 Resulting in the solution type:
 #+BEGIN_EXAMPLE agda
second-problem-okay : (X Y : MonoidId ùîπ false) ‚Üí Set
second-problem-okay = ???
 #+END_EXAMPLE
 However, this too can get tedious if we wish to only consider monoids
 with unit ~false~. In that case, we /treat/ the fields as if they where
 manifest fields and instantiate them to form a new type.
 #+BEGIN_EXAMPLE agda
{-700 Monoid-false = Monoid record with (Carrier to ùîπ; Id to false) -}

record Monoid-false : Set where
  field
    _‚®æ_     : ùîπ ‚Üí ùîπ ‚Üí ùîπ
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftfalse  : ‚àÄ {x : ùîπ} ‚Üí false ‚®æ x ‚â° x
    rightfalse : ‚àÄ {x : ùîπ} ‚Üí x ‚®æ false ‚â° x

second-problem-better : (X Y : Monoid-false) ‚Üí Set
second-problem-better = ???
 #+END_EXAMPLE

 The full source of this discussion is as follows.
 {{{fold(CaseStudy.agda)}}}
 #+INCLUDE: "CaseStudy.agda" example agda
 {{{end-fold}}}

*** COMMENT Syntax
    :PROPERTIES:
    :CUSTOM_ID: Syntax
    :END:

 # {{{goal(Superficial glance at the system's syntax.)}}}

 The prototype works by translating fictitious 700-syntax into legitimate Agda;
 as follows:
 #+BEGIN_SRC agda :tangle no
...agda code here...
{-700
       ...700-syntactical items here...
-}
...more agda code...
 #+END_SRC
 Since the first section provides an example source fragment with both 700-comments as well
 as instantiations, we shall only enclose 700-syntax in 700-comments when it is surrounded
 by other Agda code, and otherwise leave it free standing.

 /We will provide full source listings at the end of discussions that only display fragments!/

  <<<700-syntax>>>
#+latex: \label{<700-syntax>} is defined informally as follows:
 #+BEGIN_EXAMPLE text
‚ü™700-syntax‚ü´    ::=  ‚ü™PackageFormer‚ü´ | ‚ü™Instantiation‚ü´ | ‚ü™Agda‚ü´

‚ü™PackageFormer‚ü´ ::= PackageFormer ‚ü™Identifier‚ü´ : Set (‚ü™level‚ü´) where
               ‚ü™newline-with-indentation‚ü´ ‚ü™Element‚ü´*

‚ü™Element‚ü´       ::=  ‚ü™Identifier‚ü´ : ‚ü™Any-Agda-Type‚ü´

‚ü™Instantiation‚ü´ ::= ‚ü™Identifier‚ü´ = ‚ü™Identifier‚ü´ ‚ü™VariationalClause‚ü´

‚ü™VariationalClause‚ü´ ::= [‚ü™Identifier‚ü´] (:key (value))* (‚ü¥ ‚ü™VariationalClause‚ü´)*
 #+END_EXAMPLE

 :Old:
 #+BEGIN_EXAMPLE text
{- Only listing the currently implemented -}
‚ü™Variation‚ü´     ::= typeclass | data | record
‚ü™VOp‚ü´           ::=   renaming ‚ü™ToList‚ü´
            | unbundling ‚ü™‚Ñï‚ü´
            | exposing (‚ü™Semicolon-seperated-list-of-Identifiers‚ü´)
            | with     ‚ü™ToList‚ü´

‚ü™ToList‚ü´ ::= (‚ü™Identifier‚ÇÄ‚ü´ to ‚ü™Identifier‚ÇÄ‚ü´; ‚ãØ; ‚ü™Identifier‚Çô‚ü´ to ‚ü™Identifier‚Çô‚ü´) {- for any n : ‚Ñï -}
 #+END_EXAMPLE
 :End:

 + One derives many presentations of a grouping mechanism by what we call ‚Äòvariational clauses‚Äô.
   - In a 700-comment, one declares ‚Äòvariational‚Äô such as
      | ~ùí±-typeclass height = :kind record :level dec :waist-strings ("field") :waist height~   |

      These are functions whose names begin with ~ùí±-~, they may have arguments on the left-hand-side,
      and their right hand side may invoke any of the 5 meta-primitives
      ~kind, waist, waist-strings, level, alter-elements~ with any mixture of
      arguments and concrete values.

      # - These is limited Agda syntax support; in doubt, Lisp syntax is used.

      - To invoke a variational in an instantiation clause, arguments are not positional
        but instead are passed by name ---e.g., ~:key value~.

 #   Note that package formation has been liberated from the backend and brought to the user
 #   via our 5 meta-primitives: preamble, kind, waist, waist-strings, level, alter-elements.

 + Example uses of the variational clauses could be seen in the ~package-former.agda~ listing in the first section above.
** Contributions: From Theory to Practice

=PackageFormer= implements the ideas of Chapters ref:sec:packages_and_their_parts,
ref:sec:examples_from_the_wild and \ref{sec:Pi-Sigma-W}.  As such, as an editor
extension, it is mostly *language agnostic* and could be altered to work with
other languages such as Coq, @@ignore: citet:coq_implementing_modules@@ Idris
citet:idris_tdd, and even Haskell citet:DBLP:conf/haskell/LindleyM13.  The
=PackageFormer= implementation has the following useful properties.

1. Expressive & extendable specification language for the library developer.
   - Our meta-primitives give way to the ubiquitous module combinators of
     the table on \pageref{tbl:variationals-summary}.
   - E.g., from a theory we can derive its homomorphism type, signature, its
     termtype, etc; we generate useful constructions inspired from universal
     algebra and seen in the wild ---see Chapter ref:sec:examples_from_the_wild.
   - An example of the freedom allotted by the extensible nature of the system
     is that combinators defined by library developers can, say, utilise
     auto-generated names when names are irrelevant, use ‚Äòclever‚Äô default names,
     and allow end-users to supply desirable names on demand using Lisps'
     keyword argument feature ---see section ref:sec:PF:practicality:pushout.

2. Unobtrusive and a tremendously simple interface to the end user.
   - Once a library is developed using (the current implementation of)
     =PackageFormer=, the end user only needs to reference the resulting generated
     Agda, without any knowledge of the existence of =PackageFormer=.

     #+latex: \vspace{-1cm}\remark{
      Generated modules are necessarily ‚Äòflattened‚Äô for typechecking with Agda
      ---see section ref:sec:PF:extension.
     #+latex: }

   - We demonstrates how end-users can build upon a library by using /one
     line/ specifications, by reducing over 1500 lines of Agda code to nearly 200
     specifications using =PackageFormer= syntax.

3. Efficient: Our current implementation processes over 200 specifications in $\sim 3$
   seconds; yielding typechecked Agda code /which/ is what consumes the majority
   of the time.
   #+latex: \vspace{-0.9cm}\remark{
   Moreover, all of this happens in the /background/
   preceeding the ussual typechecking command,
   ~C-c C-l~.
   #+latex: }\vspace{1cm}

4. Pragmatic: Common combinators can be defined for library developers, and be
   furnished with concrete syntax for use by end-users.

5. Minimal: The system is essentially invariant over the underlying type system;
   with the exception of the meta-primitive src_emacs-lisp[:exports
   code]{:waist} which requires a dependent type theory to express ‚Äòunbundling‚Äô
   component fields as parameters.

6. Demonstrated expressive power /and/ use-cases.
   - Common boiler-plate idioms in the standard Agda library, and other places,
     are provided with terse solutions using the =PackageFormer= system.
     * E.g., automatically generating homomorphism types and wholesale renaming fields
       using a single function ---see section ref:sec:PF:practicality:renaming:rename.

   #+latex: \vspace{-4cm}\remark{\textbf{
   Over 200 modules are formalised as one-line specifications!
   #+latex: }}\vspace{3cm}

7. Immediately useable to end-users /and/ library developers.
   + We have provided a large library to experiment with
     ---thanks to the MathScheme group for providing an adaptable source file.

   #+latex: \vspace{-2cm}\remark{
     In the online user manual, we show how to formulate module combinators
     using a simple and straightforward subset of Emacs Lisp ---a terse
     introduction to Lisp is provided.
   #+latex: } \vspace{1cm}

Put simply, ~PackageFormer~ provides a tiny (yet extensible) domain specific
language ---whose concrete syntax is similar to Agda's existing syntax--- that
represents packaged structures and offers a /declarative/ interface to obtain
related structures; all the while relegating typechecking to an already existing
and trusted system: Agda.

Recall that we alluded ---in the introduction to section
ref:sec:PF:practicality--- that we have a categorical structure consisting of
=PackageFormers= as objects and those variationals that are signature morphisms.
While this can be a starting point for a semantics for =PackageFormer=, we will
instead pursue a /mechanised semantics/. That is, we shall encode (part of) the
syntax of =PackageFormer= as Agda functions, thereby giving it not only a
semantics but rather a life in a familar setting and lifting it from the status
of /editor extension/ to /language library/.

# *# Research outcomes:*
# 1. Narrow down the meta-primitives that permit a variety of algorithms for generating universal
#    algebra consructions ---the former being the kerneal which has application the latter.
# 2. Realise this for Agda, likely using an editor-extension.
# 3. Provide a semantics to the existing syntax.
# 4. Ensure the resulting semantics is consistent with that of Agda's.

* nomargins                                                          :ignore:
#+latex: \nomargins
* The src_haskell[:exports code]{Context} Library
:PROPERTIES:
 :header-args: :tangle Context.agda
 :CUSTOM_ID: The-Context-Library
 :END:

<<sec:contexts>>
# +latex: \label{sec:contexts}
#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

  # Similar to \framebox and \fbox, we get \dbox and \dashbox[width][pos]{text}
  # Also get \lbox[#layers]{text} for layered boxes and \dlbox[layers]{text} for
  # dashed and layered boxes.
  #+latex_header: \usepackage{dashbox}

#+begin_src agda :noweb yes :exports none
-- <<my-info()>>

open import Level renaming (_‚äî_ to _‚äç_; suc to ‚Ñìsuc; zero to ‚Ñì‚ÇÄ)
open import Relation.Binary.PropositionalEquality
open import Relation.Nullary

open import Data.Nat
open import Data.Fin  as Fin using (Fin)
open import Data.Maybe  hiding (_>>=_)

open import Data.Bool using (Bool ; true ; false)
open import Data.List as List using (List ; [] ; _‚à∑_ ; _‚à∑ ≥_; sum)

import Data.Unit as Unit

-- The map-Args of Reflection is deprecated, and it is advised to use the map-Args
-- within Reflection.Argument.
open import Reflection hiding (name; Type; map-Arg;  map-Args) renaming (_>>=_ to _>>=‚Çú‚Çë·µ£‚Çò_)
open import Reflection.Argument using (map-Args) renaming (map to map-Arg)

‚Ñì‚ÇÅ   = Level.suc ‚Ñì‚ÇÄ

open import Data.Empty using (‚ä•)
open import Data.Sum
open import Data.Product
open import Function using (_‚àò_)

Œ£‚à∂‚Ä¢ : ‚àÄ {a b} (A : Set a) (B : A ‚Üí Set b) ‚Üí Set _
Œ£‚à∂‚Ä¢ = Œ£

infix -666 Œ£‚à∂‚Ä¢
syntax Œ£‚à∂‚Ä¢ A (Œª x ‚Üí B) = Œ£ x ‚à∂ A ‚Ä¢ B

Œ†‚à∂‚Ä¢ : ‚àÄ {a b} (A : Set a) (B : A ‚Üí Set b) ‚Üí Set _
Œ†‚à∂‚Ä¢ A B = (x : A) ‚Üí B x

infix -666 Œ†‚à∂‚Ä¢
syntax Œ†‚à∂‚Ä¢ A (Œª x ‚Üí B) = Œ† x ‚à∂ A ‚Ä¢ B

record ùüô {‚Ñì} : Set ‚Ñì where
  constructor tt

ùüò = ‚ä•

-- [[Single argument application][Single argument application:1]]
_app_ : Term ‚Üí Term ‚Üí Term
(def f args) app arg' = def f (args ‚à∑ ≥ arg (arg-info visible relevant) arg')
(con f args) app arg' = con f (args ‚à∑ ≥ arg (arg-info visible relevant) arg')
{-# CATCHALL #-}
tm app arg' = tm
-- Single argument application:1 ends here

-- [[Reify ‚Ñï term encodings as ‚Ñï values][Reify ‚Ñï term encodings as ‚Ñï values:1]]
to‚Ñï : Term ‚Üí ‚Ñï
to‚Ñï (lit (nat n)) = n
{-# CATCHALL #-}
to‚Ñï _ = 0
-- Reify ‚Ñï term encodings as ‚Ñï values:1 ends here

{- Type annotation -}
syntax has A a = a ‚à∂ A

has : ‚àÄ {‚Ñì} (A : Set ‚Ñì) (a : A) ‚Üí A
has A a = a

-- From: https://alhassy.github.io/PathCat.html  ¬ß Imports
open import Relation.Binary.PropositionalEquality as ‚â° using (_‚âó_ ; _‚â°_)
module _ {i} {S : Set i} where
    open import Relation.Binary.Reasoning.Setoid (‚â°.setoid S) public

open import Agda.Builtin.String

defn-chasing : ‚àÄ {i} {A : Set i} (x : A) ‚Üí String ‚Üí A ‚Üí A
defn-chasing x reason supposedly-x-again = supposedly-x-again

syntax defn-chasing x reason xish = x ‚â°‚ü® reason ‚ü©' xish

infixl 3 defn-chasing
#+end_src

:Hide:


ref:sec:problems - Review the main problems of the thesis:
Unbundling and a single declaration source from which other
packaging forms may be derived.

ref:sec:monadic-notation -
With the aiming of solving only the unbundling problem
---i.e., conflating parameterised records with non-parameterised ones---
We take an exploratory approach to
finding a suitable *pragmatic* syntax that elaborates to both;
our experience in Functional Programming suggested monads may provide a solution
since we want to ‚Äòkeep track of the number of parameters‚Äô throughout a package
declaration and this is reminiscent of state monads.

todo: draw a smartdiagram with records, typeclasses [link to inference section],
and data [link to W-types], with mondic =Context= in the middle.

The need to instantiate parameters (of ‚Äòfactory‚Äô types) ahead of time
leads to an interesting (meta-language) operator Œ†‚ÜíŒª in Section ref:sec:monadic-notation.

:End:

#+latex: \begin{fullwidth}
#+latex: \end{fullwidth}

** Contexts Intro                                                    :ignore:
   :PROPERTIES:
   :CUSTOM_ID: Contexts-Intro
   :END:
# The =PackageFormer= framework is a useful tool to experiment with uncommon ways to
# package things together, but it contradicts our initial philosophy of having a
# singular lingua franca for a language and its tongues.

The =PackageFormer= framework is a useful tool to experiment with uncommon ways to
package things together, but is relies on shuffling (untyped) strings and lacks
a solid semantical basis. Instead of adding semantics after-the-fact, with the
lessons learned from developing =PackageFormer=, we go on in this section to
produce src_haskell[:exports code]{Context}, an /extensible do-it-yourself
packaging mechanism for Agda/
#+latex: \emph{{\bfseries within} Agda}\FOOTNOTE{
A ~30 minute lecture on src_haskell[:exports code]{Context}, given online for
the Agda Implementors Meeting 2020, may be viewed at
https://youtu.be/lSIFM5lhnWc.
#+latex: }.

 We will show an automatic technique for unbundling data at will; thereby
 resulting in /bundling-independent representations/ and in /delayed unbundling/.
 Our contributions are to show:
   1. Languages with sufficiently powerful type systems and meta-programming can
      conflate record and term datatype declarations into one practical
      interface. In addition, the contents of these grouping mechanisms
      may be function symbols as well as propositional invariants ---an example
      is shown at the end of Section [[sec:monadic-notation]].
      We identify the problem and the subtleties in shifting between
      representations in Section [[sec:problems]].

   2. Parameterised records can be obtained dynamically, on-demand, from
      non-parameterised records @@latex:\hbox{@@(Section [[sec:monadic-notation]])
      @@latex:}@@.
      - As with ~Magma‚ÇÄ~, the traditional approach\footcitet{coq_cat_experiences} to
        unbundling a record requires the use of transport along propositional
        equalities, with trivial src_emacs-lisp[:exports code]{refl}exivity proofs
        ---via the Œ£-padding anti-pattern of Section ref:sec:examples:IsX. In
        Section [[sec:monadic-notation]], we develop a combinator, src_emacs-lisp[:exports
        code]{_:waist_}, which removes the boilerplate necessary at the type
        specialisation location as well as at the instance declaration location.

   3. We mechanically regain ubiquitous data structures such as
      src_haskell[:exports code]{‚Ñï, Maybe, List} as the term datatypes of simple
      pointed and monoidal theories (Section [[sec:free-datatypes]]).

#    As an application, in Section [[sec:related-works]] we show that the resulting
#   setup applies as a semantics for declarative pre-processing =PackageFormer=
#   tool ---which also accomplishes the above tasks.

   For brevity, and accessibility, the definitions in this chapter are presented
   in an informal form alongside a concrete implementation /without/ explanation
   of implementation details.
   #+latex: \begin{tcolorbox}[title = A complicated Agda macro, colback=yellow!5!white, colframe=yellow!75!black]
   @@latex: \begin{center}\dbox{\texttt{accessible dashed
   pseudo-code}}\end{center}@@
   {{{code(Code)}}}
   #+begin_src haskell :tangle no
   ... actual Agda implementation,
       requiring intimate familarity with reflection in Agda ...
   #+end_src
   #+latex: \end{tcolorbox}
   Enough is shown to communicate the techniques and ideas, as well as to make
   the resulting library usable.  The details, which users do not need to bother
   with, are nonetheless presented so as to show how accessible these techniques
   are ---in that, they do not require more than 15 lines per core concept. The
   full code, listing the src_haskell[:exports code]{Context} library, may be
   found in Appendix \ref{sec:code}.

{{{localtoc}}}

** Context Examples Header                                 :Agda:noexport:
   :PROPERTIES:
   :CUSTOM_ID: Context-Examples-Header
   :END:

 #+begin_src agda  :tangle Context_examples.agda
-- Agda version 2.6.1.2
-- Standard library version 1.2

module Context_Examples where

open import Context

open import Data.Product
open import Level renaming (zero to ‚Ñì‚ÇÄ; suc to ‚Ñìsuc)
open import Relation.Binary.PropositionalEquality hiding ([_])
open import Data.Empty
open import Relation.Nullary
open import Data.Nat
open import Function using (id)
open import Data.Bool renaming (Bool to ùîπ)
open import Data.Sum

open import Data.List
import Data.Unit as Unit
open import Reflection hiding (name; Type) renaming (_>>=_ to _>>=‚Çú‚Çë·µ£‚Çò_)

 #+end_src

** yesmargins :ignore:
#+latex: \yesmargins
** A Tutorial on Reflection
  :PROPERTIES:
  :header-args: :tangle gentle-intro-to-reflection.agda
  :CUSTOM_ID: Reflection
  :END:

# C-c C-= to see constraints.

# +TITLE: A Gentle Introduction to Reflection in Agda
#+DESCRIPTION: How can we use a single proof to prove two different theorems? One proof pattern, multiple invocations!
#+AUTHOR: Musa Al-hassy
#+EMAIL: alhassy@gmail.com
#+STARTUP: indent
#+PROPERTY: header-args :tangle tangled.agda :comments link

#+CATEGORIES: Agda MetaProgramming
#+OPTIONS: html-postamble:nil toc:nil d:nil tag:nil
# IMAGE: ../assets/img/org_logo.png
# SOURCE: https://raw.githubusercontent.com/alhassy/org-agda-mode/master/literate.lagda

# INCLUDE: ~/Dropbox/MyUnicodeSymbols.org

# Make HTML
#+HTML_HEAD: <link href="https://alhassy.github.io/org-notes-style.css" rel="stylesheet" type="text/css" />
#+HTML_HEAD: <link href="https://alhassy.github.io/floating-toc.css" rel="stylesheet" type="text/css" />
#+HTML_HEAD: <link href="https://alhassy.github.io/blog-banner.css" rel="stylesheet" type="text/css" />
# The last one has the styling for lists.

# A new command agda2-elaborate-give (C-c C-m) normalizes a goal input (it repects
# the C-u prefixes), type checks, and inserts the normalized term into the goal.
#
# 'Solve constraints' (C-c C-s) now turns unsolved metavariables into new interaction holes (see Issue #2273).
#
# Agda's changelog from version 2.2.0 up to 2.6.0 may be read at
# https://hackage.haskell.org/package/Agda-2.6.0.1/changelog.  As of 2.6.1, The
# CHANGELOG.md was split. Changes to previous versions of Agda are in the
# directory doc/release-notes.
#
# *quoteGoal and quoteContext are no longer keywords*

#+latex_header: \newunicodechar{‚îÄ}{---}

#+EXCLUDE_TAGS: noexport html_only
# A mixture of #+BIND, org-export-exclude-tags, and org-export-derived-backend-p ...?

*** Introduction                                                   :ignore:
   :PROPERTIES:
   :CUSTOM_ID: Introduction
   :END:

 /Reflection/ is the ability to convert program code into an abstract syntax, a
 data structure that can be manipulated like any other.  Consider, for example,
 the tedium of writing a decidable equality for an enumerated type.  Besides
 being tedious and error-prone, the inexpressibility of what should be a
 mechanically-derivable concept obscures the corresponding general principle
 underlying it, thus foregoing any machine assistance in ensuring any
 correctness or safety-ness guarantees.  Reflection allows a more economical and
 disciplined approach.

 It is the aim of this section to show
 #+latex: how\FOOTNOTE{
 The [[https://agda.readthedocs.io/en/latest/getting-started/tutorial-list.html][Agda List of Tutorials]] has my own reflection tutorial, which is perhaps the
 most up to date presentation.  Written in 2019, it is already outdated
 ---discussing features no longer in the language. As such, we present in a /very
 lax, and informal tone,/ a small enough tutorial on reflection for our purposes.
 #+latex: }
 to get started with reflection in
 Agda.  To the best of my knowledge there is no up to date tutorial on this
 matter and, as such, we take this as an oppertunity to provide such a tutorial.
 Consequently, this section is reminicient of Chapter
 \ref{sec:packages_and_their_parts} on the introduction to Agda, and aims to be
 a self-contained presentation ---occassionally demonstraing /how/ various tasks
 may be accompalished, even though such tasks may not necessairly make an
 appearence in the rest of the thesis.

 #+latex: \vspace{-6cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Necessary imports)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+begin_src agda
module gentle-intro-to-reflection where

import Level as Level

open import Reflection hiding (name; Type)
open import Reflection.Term
open import Reflection.Pattern

open import Relation.Binary.PropositionalEquality hiding ([_])
open import Relation.Unary using (Decidable)
open import Relation.Nullary

open import Data.Unit
open import Data.Nat as Nat hiding (_‚äì_)
open import Data.Bool renaming (Bool to ùîπ)
open import Data.Product
open import Data.List as List
open import Data.Char as Char
open import Data.String as String
 #+end_src
 #+latex: }}

 There are four main types in Agda's reflection mechanism: ~Name, Arg, Term,
 TC~. We will learn about them with the aid of this following simple enumerated
 typed, as well as other standard types.

  #+latex: \vspace{-1.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{ \def\comma{,}
 {{{code(Red\comma\; Green\comma\; Blue)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
data RGB : Set where
  Red Green Blue : RGB
 #+END_SRC
 #+latex: }} \vspace{-0.5cm}

*** COMMENT ‚ü®NO‚ü© changelog notes for reflection
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-changelog-notes
   :END:
**** Implicit arguments solved by user-defined tactics
    :PROPERTIES:
    :CUSTOM_ID: Implicit-arguments-solved-by-user-defined-tactics
    :END:

 You can declare tactics to be used to solve a particular implicit argument using the following syntax:

 example : {@(tactic f) x : A} ‚Üí B
 where f : Term ‚Üí TC ‚ä§. At calls to example, f is called on the metavariable inserted for x. f can be an arbitrary term and may depend on previous arguments to the function. For instance,

 example‚ÇÇ : (depth : Nat) {@(tactic search depth) x : A} ‚Üí B
 Record fields can also be annotated with a tactic, allowing them to be omitted in constructor applications, record constructions and co-pattern matches:

 record Example : Set where
   constructor mkExample
   field x : A
         @(tactic solveP x) {y} : P x
 where solveP : (x : A) ‚Üí Term ‚Üí TC ‚ä§ is a tactic that tries to prove P x [Issue #4124].

 The legacy reflection framework using quoteGoal and quoteContext has been removed.
**** with functions                                            :changelog:
    :PROPERTIES:
    :CUSTOM_ID: with-functions
    :END:
 The "with inlining" feature of the termination checker has been removed. As a consequence, some functions defined using with are no longer accepted as terminating. See Issue #59 for why this feature was originally introduced and #3604 for why it had to be removed.

 The easiest way to fix termination problems caused by with is to abstract over the offending recursive call before any other withs. For example

 data D : Set where
   [_] : Nat ‚Üí D

 fails : D ‚Üí Nat
 fails [ zero  ] = zero
 fails [ suc n ] with some-stuff
 ... | _ = fails [ n ]
 This fails termination because the relation between [ suc n ] and [ n ] is lost since the generated with-function only gets passed n. To fix it we can abstract over the recursive call:

 fixed : D ‚Üí Nat
 fixed [ zero  ] = zero
 fixed [ suc n ] with fixed [ n ] | some-stuff
 ... | rec | _ = rec
 If the function takes more arguments you might need to abstract over a partial application to just the structurally recursive argument. For instance,

 fails : Nat ‚Üí D ‚Üí Nat
 fails _ [ zero  ] = zero
 fails _ [ suc n ] with some-stuff
 ... | m = fails m [ n ]

 fixed : Nat ‚Üí D ‚Üí Nat
 fixed _ [ zero  ] = zero
 fixed _ [ suc n ] with (Œª m ‚Üí fixed m [ n ]) | some-stuff
 ... | rec | m = rec m
 A possible complication is that later with-abstractions might change the type of the abstracted recursive call:

 T      : D ‚Üí Set
 suc-T  : ‚àÄ {n} ‚Üí T [ n ] ‚Üí T [ suc n ]
 zero-T : T [ zero ]

 fails : (d : D) ‚Üí T d
 fails [ zero  ] = zero-T
 fails [ suc n ] with some-stuff
 ... | _ with [ n ]
 ...   | z = suc-T (fails [ n ])

 still-fails : (d : D) ‚Üí T d
 still-fails [ zero ] = zero-T
 still-fails [ suc n ] with still-fails [ n ] | some-stuff
 ... | rec | _ with [ n ]
 ...   | z = suc-T rec -- Type error because rec : T z
 To solve this problem you can add rec to the with-abstraction messing up its type. This will prevent it from having its type changed:

 fixed : (d : D) ‚Üí T d
 fixed [ zero ] = zero-T
 fixed [ suc n ] with fixed [ n ] | some-stuff
 ... | rec | _ with rec | [ n ]
 ...   | _ | z = suc-T rec
**** You can now use macros in reflected terms [Issue #2130].
    :PROPERTIES:
    :CUSTOM_ID: You-can-now-use-macros-in-reflected-terms-Issue-2130
    :END:

 For instance, given a macro

 macro
   some-tactic : Term ‚Üí TC ‚ä§
   some-tactic = ...

 the term def (quote some-tactic) [] represents a call to the macro. This makes it a lot easier to compose tactics.

**** The reflection machinery now uses normalisation less often:
    :PROPERTIES:
    :CUSTOM_ID: The-reflection-machinery-now-uses-normalisation-less-often
    :END:

 Macros no longer normalise the (automatically quoted) term arguments.

 The TC primitives inferType, checkType and quoteTC no longer normalise their arguments.

 New TC primitive: withNormalisation.

 To recover the old normalising behaviour of inferType, checkType, quoteTC and getContext, you can wrap them inside a call to withNormalisation true:

   withNormalisation : ‚àÄ {a} {A : Set a} ‚Üí Bool ‚Üí TC A ‚Üí TC A

**** New TC primitive: reduce.
    :PROPERTIES:
    :CUSTOM_ID: New-TC-primitive-reduce
    :END:

 reduce : Term ‚Üí TC Term
 Reduces its argument to weak head normal form.

 Added new TC primitive: isMacro [Issue #2182]

 isMacro : Name ‚Üí TC Bool
 Returns true if the name refers to a macro, otherwise false.

 There is a primitive TC monad representing type checking computations. The unquote, unquoteDecl, and the new unquoteDef all expect computations in this monad (see below). The interface to the monad is the following

**** overloaded literals
    :PROPERTIES:
    :CUSTOM_ID: overloaded-literals
    :END:

 Overloaded number literals.

 You can now overload natural number literals using the new builtin FROMNAT:

 {-# BUILTIN FROMNAT fromNat #-}
 The target of the builtin should be a defined name. Typically you would do something like

 record Number (A : Set) : Set where
   field fromNat : Nat ‚Üí A

 open Number {{...}} public

 {-# BUILTIN FROMNAT fromNat #-}
 This will cause number literals n to be desugared to fromNat n before type checking.

 Negative number literals.

 Number literals can now be negative. For floating point literals it works as expected. For integer literals there is a new builtin FROMNEG that enables negative integer literals:

 {-# BUILTIN FROMNEG fromNeg #-}
 This causes negative literals -n to be desugared to fromNeg n.

 Overloaded string literals.

 String literals can be overladed using the FROMSTRING builtin:

 {-# BUILTIN FROMSTRING fromString #-}
 The will cause string literals s to be desugared to fromString s before type checking.

 New pragma options --subtyping and --no-subtyping (default) to turn on/off
 subtyping rules globally [see Issue_#4474]. Currently, this includes subtyping
 for irrelevance, erasure, and flat modalities. Additionally, --subtyping is
 implied by --cumulativity (see below). --subtyping is currently NOT implied by
 --sized-types, and subtyping for sized types is used even when --subtyping is
 not enabled.

**** [NEW] syntax
    :PROPERTIES:
    :CUSTOM_ID: NEW-syntax
    :END:

    Agda will now try to preserve the ellipsis (...) during case splitting when
    possible. To manually expand the ellipsis, you may ask Agda to case split on
    the special identifier ~.~.

***** Patterns can be hidden and marked as private
     :PROPERTIES:
     :CUSTOM_ID: Patterns-can-be-hidden-and-marked-as-private
     :END:


 #+begin_src agda
module _ where

module M where

  data D : Set where
    c : D

  private

    pattern c' = c

open M

x : D
x = c'
     #+end_src
     #+begin_src agda
module _ where

module M where

  data D : Set where
    c : D

  pattern c' = c

open M hiding (c')

x : D
x = c'
 #+end_src

**** Modalities
    :PROPERTIES:
    :CUSTOM_ID: Modalities
    :END:

 New modality @‚ô≠/@flat (previously only available in the branch "flat"). An
 idempotent comonadic modality modeled after spatial/crisp type theory. See Flat
 Modality in the documentation for more.

 New run-time erasure modality (@0 / @erased). Terms marked as erased cannot
 influence computations and are erased at run time [Issue #3855]. See Run-time
 Irrelevance in the documentation for more information.

 https://agda.readthedocs.io/en/v2.6.1/language/runtime-irrelevance.html

***** Fixities can now be changed during import in a renaming directive, see Issue #1346. Example:
     :PROPERTIES:
     :CUSTOM_ID: Fixities-can-now-be-changed-during-import-in-a-renaming-directive-see-Issue-1346-Example
     :END:

 open M using (_‚àô_)
 open M renaming (_‚àô_ to infixl 10 _*_)

 After this, _‚àô_ is in scope with its original fixity, and as _*_ as left associative operator of precedence 10.

***** Idiom brackets
     :PROPERTIES:
     :CUSTOM_ID: Idiom-brackets
     :END:

 Idiom brackets can accommodate none or multiple applications separated by a vertical bar | if there are two additional operations

 empty : ‚àÄ {A} ‚Üí F A
 _<|>_ : ‚àÄ {A} ‚Üí F A ‚Üí F A ‚Üí F A
 i.e. an Alternative type class in Haskell. As usual, the new idiom brackets desugar before scope checking.

 Idiom brackets with multiple applications

 (| e‚ÇÅ a‚ÇÅ .. a‚Çô | e‚ÇÇ a‚ÇÅ .. a‚Çò | .. | e‚Çñ a‚ÇÅ .. a‚Çó |)
 expand to (assuming right associative _<|>_)

 (pure e‚ÇÅ <*> a‚ÇÅ <*> .. <*> a‚Çô) <|> ((pure e‚ÇÇ <*> a‚ÇÅ <*> .. <*> a‚Çò) <|> (pure e‚Çñ <*> a‚ÇÅ <*> .. <*> a‚Çó))
 Idiom brackets with no application (|) or ‚¶á‚¶à are equivalent to empty.

***** Record patterns in telescopes
     :PROPERTIES:
     :CUSTOM_ID: Record-patterns-in-telescopes
     :END:

 Users can now use record patterns in telescope and lambda abstractions. The type of the second projection from a dependent pair is the prototypical example It can be defined as follows:

 snd : ((a , _) : Œ£ A B) ‚Üí B a
 And this second projection can be implemented with a lamba-abstraction using one of these irrefutable patterns:

 snd = Œª (a , b) ‚Üí b
 Using an as-pattern, users can get a name for the value as well as for its subparts. We can for instance prove that any pair is equal to the pairing of its first and second projections:

 eta : (p@(a , b) : Œ£ A B) ‚Üí p ‚â° (a , b)
 eta p = refl

***** [Pythonish] Syntax for large numbers: you can now separate groups of 3 digits using _. e.g. write 1_000_000 instead of 1000000.
     :PROPERTIES:
     :CUSTOM_ID: Pythonish-Syntax-for-large-numbers-you-can-now-separate-groups-of-3-digits-using-e-g-write-1-000-000-instead-of-1000000
     :END:

*** COMMENT ‚ü®NO‚ü© Further Agda Macro content!
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Further-Agda-Macro-content
   :END:

Allow metaprogramming to generate top level definitions other than functions #3699
https://github.com/agda/agda/issues/3699

Let bindings cannot contain arbitrary declarations. See #434 and https://agda.readthedocs.io/en/latest/language/let-and-where.html.
https://github.com/agda/agda/issues/4996

   generated code cannot be marked as ~private~ or have pragmas:
https://github.com/agda/agda/issues/4698

**** Mention related:
    :PROPERTIES:
    :CUSTOM_ID: Mention-related
    :END:
- execTC ‚áí https://github.com/wenkokke/schmitty
- https://umazalakain.info/static/report.pdf
  actually details some of the monoid-syntax stuff I mention but do not elaborate on
- https://oisdk.github.io/agda-ring-solver/README.html
  file:///Users/musa/Downloads/report.pdf Automatically and Efficiently Illustrating Polynomial Equalities in Agda
  https://agda.github.io/agda-stdlib/Algebra.Solver.Ring.html

**** Ulf & Jesper
    :PROPERTIES:
    :CUSTOM_ID: Ulf-Jesper
    :END:

 --------------------------------------------------------------------------------

 This looks very nice and useful, I'm looking forward to experimenting with
 the new features when I have time. Meanwhile, I tried to convert some of my
 - I don't really understand how I would use extendContext and inContext,
 can you give an example?

 See Tactic.Nat.Induction for an example (
 https://github.com/UlfNorell/agda-prelude/blob/new-reflection/src/Tactic/Nat/Induction.agda#L40).
 When you create a new meta (newMeta) you get a term valid in the current
 context, and inferType and checkType does checking relative to the current
 context.

 --------------------------------------------------------------------------------

 Post by Jesper Cockx
 - Since typeError expects a String, maybe it would be useful to have some
 functions for pretty-printing terms/types? Or alternatively we could have a
 richer type for error messages.

 I'm going for the latter. I have an implementation of an error message type
 with string and term constructors that I did before the current overhaul. I
 just need to merge it.

 --------------------------------------------------------------------------------

 Post by Jesper Cockx
 - There seems to be a problem with either unquoteDef (expects an argument
 of type TC T) or deriveEqDef in the prelude (returns a TC (List Clause)).

 You have to use defineFun:

 unquoteDef myEq = defineFun myEq =<< deriveEqDef (quote SomeType)

 I only did the minimal changes necessary to get agda-prelude working. With
 the new framework many things can be cleaned up and made more useful.

 --------------------------------------------------------------------------------

 Post by Jesper Cockx
 - Some functions that used to be pure are now integrated into the TC
 monad, which causes a lot of my code to become monadic as well. I'm mainly
 talking about getType (previously typeOf), getDefinition (previously
 definitionOf), getParameters and getConstructors. Would it be possible to
 keep these functions pure?

 Short answer: no. They were already not quite pure. For instance, you could
 call definitionOf in a mutual block before you actually have the
 definition, but depending on when the call was actually evaluated you may
 or may not get the full definition. With the new API things are even worse
 since you can create new definitions on the fly (with freshName, declareDef
 and defineFun). I guess the parameter and constructor functions could still
 be pure, but it felt more consistent to put everything in the monad.

 --------------------------------------------------------------------------------

 Post by Jesper Cockx
 - One thing I noticed when converting my pure code to monadic code
 (probably has nothing to do with this change): you cannot combine two
 monadic computations at different universe levels (at least with the
 definition of monad in the prelude). This is rather annoying, especially
 since I don't know a workaround.

 There is PMonad type class with a bind function _>>=√¢¬Ä¬≤_ that accepts things
 at different levels. I forgot to make TC an instance though.

 --------------------------------------------------------------------------------

 An example of something that we couldn't do before can be found here
 https://github.com/UlfNorell/agda-prelude/blob/master/test/MonoidTactic.agda.
 This is a simple monoid solver (the Hello World of proof by reflection) that
 uses instance arguments to figure the monoid.

**** Default arguments for implicits
    :PROPERTIES:
    :CUSTOM_ID: Default-arguments-for-implicits
    :END:
 #+begin_src agda
open import Agda.Builtin.Unit
open import Agda.Builtin.Bool
open import Agda.Builtin.Reflection renaming (bindTC to _>>=_)

defaultTo : {A : Set} (x : A) ‚Üí Term ‚Üí TC ‚ä§
defaultTo x goal = do
  `x ‚Üê quoteTC x
  unify goal `x

record Class : Set where
  constructor con
  field
    x : Bool
    @(tactic defaultTo x) {y} : Bool
open Class

test : Class
test = con true {false}

testD : Class
testD = con true

open import Relation.Binary.PropositionalEquality

_ : y testD ‚â° true
_ = refl
 #+end_src

 Src: https://github.com/agda/agda/issues/4124

**** [OLD] New keyword: quoteTerm.
    :PROPERTIES:
    :CUSTOM_ID: OLD-New-keyword-quoteTerm
    :END:

 The construction quoteTerm t is similar to quote n, but whereas quote is restricted to names n, quoteTerm accepts terms t. The construction is handled in the following way:

 The type of t is inferred. The term t must be type-correct.

 The term t is normalised.

 The construction is replaced by the Term representation (see the reflection API above) of the normal form. Any unsolved metavariables in the term are represented by the unknown term constructor.

 Examples:

 test‚ÇÅ : quoteTerm (Œª {A : Set} (x : A) ‚Üí x) ‚â°
         lam hidden (lam visible (var 0 []))
 test‚ÇÅ = refl

 -- Local variables are represented as de Bruijn indices.
 test‚ÇÇ : (Œª {A : Set} (x : A) ‚Üí quoteTerm x) ‚â° (Œª x ‚Üí var 0 [])
 test‚ÇÇ = refl

 -- Terms are normalised before being quoted.
 test‚ÇÉ : quoteTerm (0 + 0) ‚â° con (quote zero) []
 test‚ÇÉ = refl

**** [OLD] New keyword: unquote.
    :PROPERTIES:
    :CUSTOM_ID: OLD-New-keyword-unquote
    :END:

 The construction unquote t converts a representation of an Agda term to actual Agda code in the following way:

 The argument t must have type Term (see the reflection API above).

 The argument is normalised.

 The entire construction is replaced by the normal form, which is treated as syntax written by the user and type-checked in the usual way.

 Examples:

 test : unquote (def (quote ‚Ñï) []) ‚â° ‚Ñï
 test = refl

 id : (A : Set) ‚Üí A ‚Üí A
 id = unquote (lam visible (lam visible (var 0 [])))

 id-ok : id ‚â° (Œª A (x : A) ‚Üí x)
 id-ok = refl


 If x is the name of a definition (function, datatype, record, or a constructor), quote x gives you the representation of x as a value in the primitive type Name (see below).

 Reflection may be useful when working with internal decision procedures, such as the standard library's ring solver.

**** the fact that modules are not within the agda term reflection language is another hint that modules are not proper first class entitites
    :PROPERTIES:
    :CUSTOM_ID: the-fact-that-modules-are-not-within-the-agda-term-reflection-language-is-another-hint-that-modules-are-not-proper-first-class-entitites
    :END:

 Agda's reflection mechanism is pretty recent, it began with Agda 2.3.0
**** tactic keyword
    :PROPERTIES:
    :CUSTOM_ID: tactic-keyword
    :END:

 You can now use quote in patterns.

 New syntactic sugar tactic e and tactic e | e1 | .. | en.

 It desugars as follows and makes it less unwieldy to call reflection-based tactics.

 tactic e                --> quoteGoal g in unquote (e g)
 tactic e | e1 | .. | en --> quoteGoal g in unquote (e g) e1 .. en

 Note that in the second form the tactic function should generate a function from a number of new subgoals to the original goal. The type of e should be Term -> Term in both cases.

**** splicing
    :PROPERTIES:
    :CUSTOM_ID: splicing
    :END:

 unquoting declarations.

 You can now define (recursive) functions by reflection using the new unquoteDecl declaration

 unquoteDecl x = e
 Here e should have type AGDAFUNDEF and evaluate to a closed value. This value is then spliced in as the definition of x. In the body e, x has type QNAME which lets you splice in recursive definitions.

 Standard modifiers, such as fixity declarations, can be applied to x as expected.

**** Reflection-based macros ‚à∑ TODO: implement textual subtitution as a macro; eg ‚Äúzero a E‚Äù is E[a ‚âî 0] ;; and like ‚Äòmagic‚Äô but for evens/odds.
    :PROPERTIES:
    :CUSTOM_ID: Reflection-based-macros-TODO-implement-textual-subtitution-as-a-macro-eg-zero-a-E-is-E-a-0-and-like-magic-but-for-evens-odds
    :END:

 Macros are functions of type t1 ‚Üí t2 ‚Üí .. ‚Üí Term ‚Üí TC ‚ä§ that are defined in a macro block. Macro application is guided by the type of the macro, where Term arguments desugar into the quoteTerm syntax and Name arguments into the quote syntax. Arguments of any other type are preserved as-is. The last Term argument is the hole term given to unquote computation (see above).

 For example, the macro application f u v w where the macro f has the type Term ‚Üí Name ‚Üí Bool ‚Üí Term ‚Üí TC ‚ä§ desugars into unquote (f (quoteTerm u) (quote v) w)

 Limitations:

 Macros cannot be recursive. This can be worked around by defining the recursive function outside the macro block and have the macro call the recursive function.
 Silly example:

 macro
   plus-to-times : Term ‚Üí Term ‚Üí TC ‚ä§
   plus-to-times (def (quote _+_) (a ‚à∑ b ‚à∑ [])) hole = unify hole (def (quote _*_) (a ‚à∑ b ‚à∑ []))
   plus-to-times v hole = unify hole v

 thm : (a b : Nat) ‚Üí plus-to-times (a + b) ‚â° a * b
 thm a b = refl
 Macros are most useful when writing tactics, since they let you hide the reflection machinery. For instance, suppose you have a solver

 magic : Type ‚Üí Term
 that takes a reflected goal and outputs a proof (when successful). You can then define the following macro

 macro
   by-magic : Term ‚Üí TC ‚ä§
   by-magic hole =
     bindTC (inferType hole) Œª goal ‚Üí
     unify hole (magic goal)
 This lets you apply the magic tactic without any syntactic noise at all:

 thm : ¬¨ P ‚â° NP
 thm = by-magic

**** Changed behaviour of unquote
    :PROPERTIES:
    :CUSTOM_ID: Changed-behaviour-of-unquote
    :END:

 The unquote primitive now expects a type checking computation instead of a pure term. In particular unquote e requires

 e : Term ‚Üí TC ‚ä§
 where the argument is the representation of the hole in which the result should go. The old unquote behaviour (where unquote expected a Term argument) can be recovered by

 OLD: unquote v
 NEW: unquote Œª hole ‚Üí unify hole v
 Changed behaviour of unquoteDecl

 The unquoteDecl primitive now expects a type checking computation instead of a pure function definition. It is possible to define multiple (mutually recursive) functions at the same time. More specifically

 unquoteDecl x‚ÇÅ .. x‚Çô = m
 requires m : TC ‚ä§ and that x‚ÇÅ .. x‚Çô are defined (using declareDef and defineFun) after executing m. As before x‚ÇÅ .. x‚Çô : QName in m, but have their declared types outside the unquoteDecl.

*** COMMENT ‚ü®NO‚ü© Abstract                                          :ignore:
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Abstract
   :END:
 #+BEGIN_CENTER org
 *Abstract*
 #+END_CENTER

 /One proof for two different theorems!/

 Let's learn how we can do that in Agda.

 This tutorial is the result of mostly experimenting with the
 [[https://agda.readthedocs.io/en/v2.5.2/language/reflection.html][documentation]] on Agda's reflection mechanism, which essentially
 only exposes the reflection interface and provides a few tiny examples.
 The goal of this tutorial is to contain a diverse variety of examples,
 along with occasional exercises for the reader.

 Examples include:
 + String manipulation of built-in identifier names. üçì
 + Handy dandy combinators for AST formation: ~ùìãùìáùí∂, Œªùìã_‚Ü¶_, ‚Ä¶~. üõ†
 + Numerous examples of quotation of terms and types. üéØ
 + Wholesale derivation of singleton types for an example datatype,
   along with derivable proofs üíõ üéµ
 + Automating proofs that are only ~refl~ /with/ pattern matching üèÑ
 + Discussion of C-style macros in Agda üåµ
 + Abstracting proofs patterns without syntactic overhead using macros üí™ üéº
 + Remarks on what I could not do, possibly since it cannot be done :sob:

 Everything here works with Agda version 2.6.0.
 This document is a literate Agda file written using
 the (poorly coded) [[https://alhassy.github.io/literate/][org-agda]] framework.

 A pure ~.agda~ file can be found [[file:tangled.agda][here]].

 #+TOC: headlines 2

Metaprograms, i.e. programs that create other programs, run in a built-in type checking monad TC:

:armkeh_Agda_smokey_white:

‚Üí Hey Mark, what does it mean when Agda colours some definitions smokey white?

‚Üê Your ‚Äúclause does not hold definitionally‚Äù. Essentially your pattern matching
doesn't line up to the internal case tree; I believe this is usually because
lower cases aren't specific enough. Try putting in more pattern information in
lower cases.

‚Üê But it is a bit of a pain; sometimes it can require splitting one case into
two. Or using a CATCHALL pragma on a case.

‚Üí What are the consequences of ignoring this white smoke altogether?

‚Üê Nothing that I know of.

‚Üí lol wat, then why does this matter?

‚Üê I'm not really sure. So your pattern matching does not match up nicely to the
case trees that are happening behind the scenes. I assume there may be some
inefficiency because of that, just because there's less information. But I
really don't know.

‚Üê Hence the almost imperceptible warning, I guess.
:end:

*** ~NAME~ ‚îÄType of known identifiers
   :PROPERTIES:
   :CUSTOM_ID: NAME-Type-of-known-identifiers
   :END:

 ~Name~ is the type of quoted identifiers, Agda names.  Elements of this type can
 be formed and pattern matched using the ~quote~ keyword. It comes equipped with
 equality, ordering, and a show function. Names, along with numbers and strings,
 constitute the ~Literal~ type.

 #+latex: \vspace{-2cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Constructing \& Pattern Matching on Names)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
a-name : Name
a-name = quote ‚Ñï

isNat : Name ‚Üí ùîπ
isNat (quote ‚Ñï) = true
isNat _         = false
#+END_SRC
#+latex: }} \vspace{-1cm}

Quote will not work on function arguments; the identifier must not be a
variable.  This limitation is why we have a ‚Äòreflection mechanism‚Äô and not a
‚Äòmacro mechanism‚Äô.

 #+latex: \vspace{-1.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Nope!)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+BEGIN_SRC agda
-- bad : Set ‚Üí Name
-- bad s = quote s  {- s is not known -}
 #+END_SRC
#+latex: }}

#+latex: \newpage

 Names can be shown as strings, but are fully qualified.  It would be nice to
 have, say, ~Red~ be shown as just ~‚ÄúRGB.Red‚Äù~.  To do so, we may introduce some
 ‚Äòprogramming‚Äô helpers to treat Agda strings as if they where Haskell/C strings,
 and likewise to treat predicates as decidables. After which, we can show
 unqualified names by obtaining the module's name then dropping it from the data
 constructor's name.

 {{{code(Showing \emph{unqualified} names)}}}
 #+BEGIN_SRC agda
module-of : Name ‚Üí String
module-of n = takeWhile (toDec (Œª c ‚Üí not (c Char.== '.')))
              ‚ü®ùíÆ‚ü© showName n

_ : module-of (quote Red) ‚â° "gentle-intro-to-reflection"
_ = refl

strName : Name ‚Üí String
strName n = drop (1 + String.length (module-of n))
            ‚ü®ùíÆ‚ü© showName n
{- The ‚Äú1 +‚Äù is for the ‚Äú.‚Äù separator in qualified names. -}

_ : strName (quote Red) ‚â° "RGB.Red"
_ = refl
 #+END_SRC

 # ~NAME~ essentially provides us with the internal representation of a known name,
 # for which we can query to obtain its definition or type.
 # Later we will show how to get the type constructors of ~‚Ñï~ from its name.

 #+latex: \vspace{-9.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Showing names)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
_ :   showName (quote _‚â°_)
    ‚â° "Agda.Builtin.Equality._‚â°_"
_ = refl

_ :   showName (quote Red)
    ‚â° "gentle-intro-to-reflection.RGB.Red"
_ = refl
 #+END_SRC
#+latex: }} \vspace{0cm}

 #+latex: \vspace{0cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Programming helpers)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
{- Like ‚Äú$‚Äù but for strings. -}
_‚ü®ùíÆ‚ü©_ : (List Char ‚Üí List Char) ‚Üí String ‚Üí String
f ‚ü®ùíÆ‚ü© s = fromList (f (toList s))

{- This should be in the standard library; I could not locate it. -}
toDec : ‚àÄ {‚Ñì} {A : Set ‚Ñì} ‚Üí (p : A ‚Üí ùîπ) ‚Üí Decidable {‚Ñì} {A} (Œª a ‚Üí p a ‚â° true)
toDec p x with p x
toDec p x | false = no Œª ()
toDec p x | true = yes refl
 #+END_SRC
#+latex: }} \vspace{2cm}

 Finally, if we have a name, we can obtain its fixity, which consists of its
 associativity ---one of ~assocÀ°, assoc ≥, non-assoc~--- and its precedence
 ---either ~unrelated~ or ~related ùìÉ~ for some ‚Äòfloat‚Äô number ùìÉ.  Having /fractional
 precedence levels/ ensures that precedences are /dense/: An operator precedence
 can always be squeezed between any two existing precedences.

 # E.g., infix 3.14 _<_

 #+latex: \vspace{-3cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Necessary imports)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+begin_src agda
open import Data.Float as Float using (from‚Ñï)

_ :   getFixity (quote _+_)
    ‚â° fixity assocÀ° (related (Float.from‚Ñï 6))
_ = refl
#+end_src
#+latex: }} \vspace{0.1cm}

A summary of the reflection interface exposed thus far is in the table below.
We use a prefix ‚Äò‚ãÜ‚Äô to mark elements that may be useful for programming with
reflection, but are not part of Agda's standard library for reflection.  We use
this star convention in the remaining sections as well.

# +caption: Summary
|-----------+-------------------------------------------------------------|
|           |                                                             |
| ~Name~      | The type of program identifiers (excluding variables)       |
| ~quote~     | Constructor for ~Name~, takes an identifier as argument       |
| ~showName~  | Get fully qualified string representation of a name         |
| ~_‚ü®ùíÆ‚ü©_~     | ‚ãÜLift a function on lists of chars to a function on strings |
| ~toDec~     | ‚ãÜLift a Boolean into a =Decidable=                            |
| ~module-of~ | ‚ãÜString name of the parent module of a given ~Name~ argument  |
| ~strName~   | ‚ãÜUnqualified string representation of a name                |
| ~getFixity~ | Get the associtivity and precedence of a name               |
|           |                                                             |
|-----------+-------------------------------------------------------------|

*** ~Arg~ ‚îÄType of arguments
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Arg-Type-of-arguments
   :END:

 Arguments in Agda may be hidden or computationally irrelevant.
 This information is captured by the ~Arg~ type.

 {{{code(œÑ-Argument ‚âÖ Visibility √ó Relevance √ó œÑ)}}}
 #+BEGIN_src agda :tangle no
-- Arguments can be (visible), {hidden}, or ‚¶Éinstance‚¶Ñ
data Visibility : Set where
  visible hidden instance' : Visibility

-- Arguments can be relevant or irrelevant:
data Relevance : Set where
  relevant irrelevant : Relevance

-- Arguments are characterised by their visibility & relevance
data ArgInfo : Set where
  arg-info : (v : Visibility) (r : Relevance) ‚Üí ArgInfo

-- An argument of type œÑ is a value of œÑ and info about it
data Arg (œÑ : Set) : Set where
  arg : (i : ArgInfo) (x : œÑ) ‚Üí Arg œÑ
 #+ENd_src

 #+latex: \vspace{-6.6cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Handy helpers for making argument values)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
{- ùìãisible ùìáelevant ùí∂rgument -}
ùìãùìáùí∂ : {œÑ : Set} ‚Üí œÑ ‚Üí Arg œÑ
ùìãùìáùí∂ = arg (arg-info visible relevant)

{- ùíΩidden ùìáelevant ùí∂rgument -}
ùíΩùìáùí∂ : {œÑ : Set} ‚Üí œÑ ‚Üí Arg œÑ
ùíΩùìáùí∂ = arg (arg-info hidden relevant)
 #+END_SRC
#+latex: }} \vspace{0cm}

 #+latex: \vspace{-.5em} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Handy helpers for making variables)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
{- ùìãisible ùìáelevant ùìãariable -}
ùìãùìáùìã : (debruijn : ‚Ñï) (args : List (Arg Term))
    ‚Üí Arg Term
ùìãùìáùìã n args = ùìãùìáùí∂ (var n args)

{- ùíΩidden ùìáelevant ùìãariable -}
ùíΩùìáùìã : (debruijn : ‚Ñï) (args : List (Arg Term))
    ‚Üí Arg Term
ùíΩùìáùìã n args = ùíΩùìáùí∂ (var n args)
 #+END_SRC
#+latex: }} \vspace{-0.5cm}

So much for reflected arguments.

In the next section we will turn to variables ---which live in the ~Term~
datatype. Variables are arguments ---i.e., entities with a visibility and
relevance--- whose payload is a natural number (along with a list of arguments);
this /nameless variables/ approach is known as /De Bruijn indexing/.  The index /n/
refers to the argument that is /n/ locations away from ‚Äòhere‚Äô.

Given a ‚Äòusual‚Äô Œª-term ~t~, its De Bruijn index presentation is \newline ~‚àÖ ‚ï±‚ÇÄ t~ where the ~Œì
‚ï±‚Çô s~ has Œì denoting ‚Äúthe bound variables encountered thus far‚Äù and /n/ denotes
‚Äúthe depth, how many lambdas have been encountered‚Äù.  For example,
#+latex: \vspace{-1em}
#+begin_center
src_haskell[:exports code]{‚àÖ ‚ï±‚ÇÄ (Œª f. Œª g. Œª x. f x (g x))  =  Œª Œª Œª 2 0 (1 0)}
#+end_center
#+latex: \vspace{-1em}
Notice that the first ‚Äò2‚Äô refers to the variable bound by the Œª that is ‚Äú2
lambdas away‚Äù.

# + Variables are De Bruijn indexed and may be applied to a list of arguments.

 #+latex: \vspace{-6cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Mechanically going nameless)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+begin_src haskell :tangle no
-- The œÑ·µ¢ are existing Œª-terms
Usual-Œª-Term ‚à∑= x | œÑ‚ÇÅ œÑ‚ÇÇ | (Œª x ‚Ä¢ œÑ‚ÇÉ)

-- Treating contexts Œì as functions, as in Ch2,
-- with comma for function extension (patching)

-- For variables x
Œì ‚ï±‚Çô x  =  if x ‚àà domain Œì then n - Œì(x) else x fi

-- For abstractions
Œì ‚ï±‚Çô (Œª x ‚Ä¢ e)  =  Œª  (Œì, (x, n)) ‚ï±‚Çô‚Çä‚ÇÅ e

-- For applications
Œì ‚ï±‚Çô (s t)      =  (Œì ‚ï±‚Çô s) (Œì ‚ï±‚Çô t)
#+end_src
#+latex: }} \vspace{1cm}

# +caption: Summary
|------------+----------------------------------------------------------------------------------|
|            |                                                                                  |
| ~Arg œÑ~      | A value of type œÑ along with its visibility and relevance                        |
|            | Example: ~arg (arg-info visibile relevant) 3~                                      |
| ~ùìãùìáùí∂ e~      | ‚ãÜConstructs a ùìãisibile ùìáelevant ùí∂rgument with value ~e~                            |
| ~ùíΩùìáùí∂ e~      | ‚ãÜConstructs a ùíΩidden ùìáelevant ùí∂rgument with value ~e~                              |
| ~ùìãùìáùìã n args~ | ‚ãÜConstructs a ùìãisible ùìáelevant ùìãariable with debruijn index ~n~ and arguments ~args~ |
| ~ùíΩùìáùìã n args~ | ‚ãÜConstructs a ùíΩidden ùìáelevant ùìãariable with debruijn index ~n~ and arguments ~args~  |
|            |                                                                                  |
|------------+----------------------------------------------------------------------------------|

*** ~Term~ ‚îÄType of terms
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Term-Type-of-terms
   :END:

 The src_agda[:exports code]{quoteTerm} keyword is used to turn a well-typed
fragment of code ---concrete syntax--- into a value of the src_agda[:exports
code]{Term} datatype ---abstract syntax tree (AST).  Before any examples, here
is the definition of src_agda[:exports code]{Term}.

  {{{code(Abstract Syntax Trees ---Reflected Terms)}}}
 #+BEGIN_src agda :tangle no
data Term where

  var       : (x : ‚Ñï)  (args : List (Arg Term)) ‚Üí Term

  con       : (c : Name) (args : List (Arg Term)) ‚Üí Term
  def       : (f : Name) (args : List (Arg Term)) ‚Üí Term

  lam       : (v : Visibility) (t : Abs Term) ‚Üí Term
  pat-lam   : List Clause ‚Üí List (Arg Term) ‚Üí Term

  -- Telescopes, or function types; Œª-abstraction for types.
  pi        : (a : Arg Type) (b : Abs Type) ‚Üí Term

  -- ‚ÄúSet n‚Äù or some term that denotes a type
  agda-sort : (s : Sort) ‚Üí Term

  -- Metavariables; introduced via quoteTerm
  meta      : (x : Meta) ‚Üí List (Arg Term) ‚Üí Term

  -- Literal  ‚âÖ  ‚Ñï | Word64 | Float | Char | String | Name | Meta
  lit       : (l : Literal) ‚Üí Term

  -- Items not representable by this AST; e.g., a hole.
  unknown   : Term {- Treated as '_' when unquoting. -}
#+end_src

#+latex: \vspace{-9cm}\remark{
A variable has a De Bruijn index and may be applied to arguments.
#+latex: }

#+latex: \vspace{1ex}\remark{
Constructors and definitions may be applied to a list of arguments.
#+latex: }\vspace{1ex}

#
#+macro: hbox @@latex:\hbox{@@ $1 @@latex:}@@

#+latex: \remark{
Œª-abstractions bind one variable, ~t~ is the variable name along with the Œª-body.
#+latex: {\scriptsize
\newline\vspace{1ex}\centerline{ ‚ãÜ ‚ãÜ ‚ãÜ }\vspace{1em}
{{{hbox(src_haskell[:exports code]{Abs A  ‚âÖ  String √ó A})}}}
\newline\vspace{0.5em}\newline
{{{hbox(src_haskell[:exports code]{Sort   ‚âÖ  LevelTerm | ‚Ñï | unknown })}}}
\newline\vspace{0.5em}\newline
src_haskell[:exports code]{Clause  ‚âÖ  List (Arg Pattern) √ó Term}
#+latex: \newline \hbox{{\color{white}.} \hspace{2.4em}
src_haskell[:exports code]{| List (Arg Pattern}
#+latex: }
\newline\vspace{0.5em}\newline
{{{hbox(src_haskell[:exports code]{Pattern ‚âÖ  ‚Äúcon Name (List (Arg Pattern))‚Äù})}}}
#+latex: \newline \hbox{{\color{white}.} \hspace{2.9em}
src_haskell[:exports code]{| Literal |‚Äúproj Name‚Äù}
#+latex: }
#+latex: \newline \hbox{{\color{white}.} \hspace{2.9em}
src_haskell[:exports code]{| ‚Äúabsurd‚Äù | ‚Äúvar String‚Äù}
#+latex: }
#+latex: }}\vspace{6cm}

:Hide:
#+begin_src agda :tangle no
data Sort where
  set     : (t : Term) ‚Üí Sort {- A Set of a given (possibly neutral) level. -}
  lit     : (n : Nat) ‚Üí Sort  {- A Set of a given concrete level. -}
  unknown : Sort

data Clause where
  clause        : (ps : List (Arg Pattern)) (t : Term) ‚Üí Clause
  absurd-clause : (ps : List (Arg Pattern)) ‚Üí Clause
 #+END_src
:End:

**** Example: Simple Reflections                                  :ignore:

# To the right are examples of src_haskell[:exports code]{def}ined names.  The
# first two are constants whereas the third requires a visible and relevant
# argument, ùìãùìáùí∂, that happens to be a literal natural.
#
An example reflected term is in the following snippet.  Even though the /concrete
syntax/ for propositional equalities takes two ùìãisible \newline ùìáelevant
ùí∂rguments ---the left side and right side---, the resulting /abstract syntax/ tree
exposes the fact that there are actually an /additional/ two ùíΩidden ùìáelevant
ùí∂rguments that happen to be inferred: The common type of the explicit arguments
and the level of said type.  The propositional equality is a
src_haskell[:exports code]{def}ined name; whose ùíΩidden arguments also happen to
be src_haskell[:exports code]{def}ined names, whereas its ùìãisibile arguments are
src_haskell[:exports code]{lit}eral src_haskell[:exports code]{string}s.

#+latex: \vspace{-4cm}\remark{
The reflected term could be presented more compactly by invoking
src_agda[:exports code]{quoteTerm} in the AST.
#+latex: }\vspace{2em}

 #+latex: \vspace{0cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Reflecting a partially-applied type)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
_ :   quoteTerm _‚â°_
    ‚â° def (quote _‚â°_) []
_ = refl

_ :  quoteTerm (_‚â°_ "l")
   ‚â° def (quote _‚â°_) ( ùíΩùìáùí∂ (quoteTerm Level.zero)
                      ‚à∑ ùíΩùìáùí∂ (quoteTerm String)
                      ‚à∑ ùìãùìáùí∂  (quoteTerm "l")
                      ‚à∑ [])
_ = refl
#+END_SRC
#+latex: }} \vspace{-1.7cm}

{{{code(Reflecting a fully-applied type)}}}
#+BEGIN_SRC agda
_ : quoteTerm ("l" ‚â° "r") ‚â° def (quote _‚â°_)
                            (  ùíΩùìáùí∂ (def (quote Level.zero) [])
                             ‚à∑ ùíΩùìáùí∂ (def (quote String)     [])
                             ‚à∑ ùìãùìáùí∂ (lit (string "l"))
                             ‚à∑ ùìãùìáùí∂ (lit (string "r"))
                             ‚à∑ [])
_ = refl
 #+END_SRC

#+latex: \vspace{-3cm}\vspace{1em}\remark{
The above is not the /section/ src_agda[:exports code]{"l" ‚â°_} !  \newline Sections
are syntactic abbreviations for Œª-abstractions! Keep reading ;-)
#+latex: }\vspace{3cm}


:More:
#+BEGIN_SRC agda
open import Data.Vec using (Vec) -- Set‚Çô ‚Üí ‚Ñï ‚Üí Set‚Çô

_ : quoteTerm Vec ‚â° def (quote Vec) []
_ = refl

_ : quoteTerm (Vec ‚Ñï) ‚â° def (quote Vec) (ùíΩùìáùí∂ (quoteTerm Level.zero) ‚à∑ ùìãùìáùí∂ (quoteTerm ‚Ñï) ‚à∑ [])
_ = refl

_ : quoteTerm (Vec ‚Ñï 3) ‚â° def (quote Vec) (ùíΩùìáùí∂ (quoteTerm Level.zero) ‚à∑ ùìãùìáùí∂ (quoteTerm ‚Ñï) ‚à∑ ùìãùìáùí∂ (lit (nat 3)) ‚à∑ [])
_ = refl
#+END_SRC
:End:

Besides src_haskell[:exports code]{def}ined names and src_haskell[:exports
code]{lit}erals, we may also reflect src_haskell[:exports code]{con}structors
and use polymorphism; as shown below.
{{{code(Constructors and Polymorphism)}}}
#+BEGIN_SRC agda
_ : quoteTerm 1 ‚â° lit (nat 1)
_ = refl

_ :    quoteTerm (suc zero)
     ‚â° con (quote suc) (ùìãùìáùí∂ (quoteTerm zero) ‚à∑ [])
_ = refl

_ : quoteTerm true ‚â° con (quote true) []
_ = refl


_ : ‚àÄ {level : Level.Level}{Type : Set level} (x y : Type)
    ‚Üí   quoteTerm (x ‚â° y)
       ‚â° def (quote _‚â°_)
           (ùíΩùìáùìã 3 [] ‚à∑ ùíΩùìáùìã 2 [] ‚à∑ ùìãùìáùìã 1 [] ‚à∑ ùìãùìáùìã 0 [] ‚à∑ [])

_ = Œª x y ‚Üí refl
 #+END_SRC
#+latex: \vspace{-7.1cm}\remark{
A /constructor/, well, constructs a value of an algebraic data type; whereas a
/defined name/ is a (possibly nullary) user-defined function (including type
formers). Unlike functions, constructors have no computation, reduction, rules.
#+latex: }\vspace{1.9cm}

#+latex: \vspace{0cm}\remark{
 As discussed in the previous section, a De Bruijn index $n$ refers to the
 lambda variable that is ‚Äú$n$ lambdas away‚Äù from its use site.  For example,
 src_agda[:exports code]{ùìãùìáùìã 1} means starting at the position where /ùìãùìáùìã 1/
 occurs in the text, go 1 lambdas away thereby getting the variable
 src_agda[:exports code]{x}: The first lambda away is src_agda[:exports
 code]{(y : Type)} and so the second lambda away is src_agda[:exports code]{(x :
 Type)}. (Scoped declarations are an abbreviation for multiple declarations, as
 discussed in Chapter \ref{sec:packages_and_their_parts}.)
#+latex: }\vspace{3cm}

**** Example: Representing Œª-functions as ~Term~ values           :ignore:


# I need this line since I've done some \vspace shenanigans above.
#+latex: {\color{white} hi}

     #+latex: \vspace{1cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Reflecting a Œª)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
_ :   quoteTerm (Œª (x : ùîπ) ‚Üí x)
    ‚â° lam visible (abs "x" (var 0 []))
_ = refl
 #+END_SRC
 #+latex: }}
#+latex: \vspace{-1em}\remark{\begin{center}
Eek! Reflected Œªs are untyped!
\newline
\vspace{1ex}
We'll return to this later!
#+latex: \end{center}}\vspace{-2.5cm}

 With the above example mentioning variables, it is natural to consider
 representing Œª-src_haskell[:exports code]{abs}tractions as ~Term~ values.  For
 example, a simple identity function, say, on the Booleans $(Œª x : ùîπ ‚Ä¢ x)$
 consists of a src_haskell[:exports code]{lam}bda with a ùìãisible ùí∂ùí∑ùìàtract
 argument named src_haskell[:exports code]{"x"} along with a body merely being
 the 0-nearest bound variable, applied to an empty list of arguments.  Below is
 a slightly more complex example.

 {{{code(Reflecting a function application operator ---brutally)}}}
 #+BEGIN_SRC agda
_ : quoteTerm (Œª (a : ‚Ñï) (f : ‚Ñï ‚Üí ‚Ñï) ‚Üí f a)
    ‚â°  lam visible (abs "a"
         (lam visible (abs "f"
           (var 0 (arg (ùìãùìáùí∂ (var 1 []) ‚à∑ [])))))
_ = refl
 #+END_SRC

#+latex: \vspace{-3cm}\remark{
 The application, ~f a~, is represented as the variable 0 lambdas away from the
 body applied to the variable 1 lambdas away from the body.
#+latex: }\vspace{0cm}

 #+latex: \vspace{1.9cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Œªs with ùìãisibile and ùíΩidden arguments)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
infixr 5 Œªùìã_‚Ü¶_  ŒªùíΩ_‚Ü¶_

Œªùìã_‚Ü¶_  ŒªùíΩ_‚Ü¶_ : String ‚Üí Term ‚Üí Term
Œªùìã x ‚Ü¶ body  = lam visible (abs x body)
ŒªùíΩ x ‚Ü¶ body  = lam hidden (abs x body)
 #+END_SRC
#+latex: }} \vspace{-2.6cm}

#+latex: \noindent
This is rather messy, but it can be made more readable by the aid of some
syntactic sugar.
 {{{code(Reflecting a function application operator ---elegantly)}}}
 #+BEGIN_SRC agda
_ :   quoteTerm (Œª (a : ‚Ñï) (f : ‚Ñï ‚Üí ‚Ñï) ‚Üí f a)
    ‚â° Œªùìã "a" ‚Ü¶ Œªùìã "f" ‚Ü¶ var 0 [ ùìãùìáùí∂ (var 1 []) ]
_ = refl
 #+END_SRC

#+latex: \vspace{-1.5cm}\remark{
Much easier on the eyes, hands, and brains!
#+latex: }\vspace{1.5cm}

 Using these syntactic abbreviation, we can quickly compare how Œª-arguments can
 be ‚Äúshunted‚Äù into a quotation, as follows for the constant function.
#+latex: \vspace{-0.5cm}\remark{
Delicious, delicious, (syntactic) sugar!
#+latex: }\vspace{0.5cm}
 {{{code(Shunting the ‚Äúwaist‚Äù of a constant function)}}}
 #+BEGIN_SRC agda
_ : {A B : Set} ‚Üí   quoteTerm (Œª (a : A) (b : B) ‚Üí a)
                  ‚â° Œªùìã "a" ‚Ü¶ (Œªùìã "b" ‚Ü¶ var 1 [])
_ = refl

_ :   quoteTerm (Œª {A B : Set} (a : A) (_ : B) ‚Üí a)
    ‚â° ŒªùíΩ "A" ‚Ü¶ ŒªùíΩ "B" ‚Ü¶ Œªùìã "a" ‚Ü¶ Œªùìã "_" ‚Ü¶ var 1 []
_ = refl
#+END_SRC

#+latex: \vspace{-1cm}\remark{
Œª-terms are governed by the rules below.
Such terms are formed by
the /Œª-abstraction rule/: If $E : Œ≤$ whenever $x : Œ±$, then $(Œª x
‚Üí E) : (Œ± ‚Üí Œ≤)$. Their ‚Äòcomputation‚Äô is captured by the Œ≤-rule
and ‚ÄòŒ¥efinition lookup‚Äô is captured by the Œ¥-rule.
#+latex: \centerline{\emph{Œ∑-rule}: $(Œª x ‚Üí f\, x) = f$ }
#+latex: \centerline{\emph{Œ≤-rule}: $(Œª x ‚Üí E)\, v = E[x ‚âî v]$              }
#+latex: \centerline{\emph{Œ¥-rule}: $f\, v = E[x ‚âî v]$ for $f = (Œª x ‚Üí E)$ }
#+latex: }\vspace{0.5cm}

#+latex: \noindent
We can now return to the above remark about reflecting /sections/: For a binary
operation ~_‚äï_ ‚à∂ Œ± ‚Üí Œ≤ ‚Üí Œ≥~, its /left section/ by any value ~a ‚à∂ Œ±~ is the function
~(Œª b ‚Üí a ‚äï b) ‚à∂ Œ≤ ‚Üí Œ≥~, which is generally denoted by ~a ‚äï_~ or, informally by $(a
‚äï)$. Likewise for right sections.

 {{{code(Left Sections: No Œªùìã after normalisation)}}}
#+BEGIN_SRC agda
_ :   quoteTerm ("l" ‚â°_)
    ‚â° def (quote _‚â°_)
          ( ùíΩùìáùí∂ (quoteTerm Level.zero)
          ‚à∑ ùíΩùìáùí∂ (quoteTerm String)
          ‚à∑ ùìãùìáùí∂ (quoteTerm "l")
          ‚à∑ [])
_ = refl
#+END_SRC

 #+latex: \vspace{-3.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Right Sections: Required Œªùìã)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+BEGIN_SRC agda
_ :   quoteTerm (_‚â° "r")
    ‚â° Œªùìã "section" ‚Ü¶
        def (quote _‚â°_)
            ( ùíΩùìáùí∂ (quoteTerm Level.zero)
            ‚à∑ ùíΩùìáùí∂ (quoteTerm String)
            ‚à∑ ùìãùìáùí∂ (var 0 [])
            ‚à∑ ùìãùìáùí∂ (quoteTerm "r")
            ‚à∑ [])
_ = refl
#+END_SRC
#+latex: }} \vspace{-.3cm}

#+latex: \noindent
As the above example shows, quotation automatically performs Œ∑-reduction.  The
relationships of src_agda[:exports code]{quoteTerm} with Œª's governing rules are
summarised as follows ---including the above ‚Äòargument-shunting‚Äô observation.

 #+latex: \vspace{-1.7cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Helper for concrete examples below)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+BEGIN_SRC agda
id : {A : Set} ‚Üí A ‚Üí A
id x = x
#+END_SRC
#+latex: }} \vspace{-.5cm}

# i.e., a computation rule
#+latex: \begin{myexamplebox}{Shunting Law ---‚Äú\texttt{quoteTerm} computation rule‚Äù}\hbox{\hspace{-.5em}
src_agda[:exports code]{quoteTerm (Œª (x : œÑ) ‚Üí e)  ‚â°  Œªùìã "x" ‚Ü¶ quoteTerm e}
#+latex: }\end{myexamplebox}

#+latex: \begin{myexamplebox}{Eta Law}\begin{center}
src_agda[:exports code]{quoteTerm (Œª x ‚Üí f x)  ‚â°  quoteTerm f}
#+latex: \end{center}\end{myexamplebox}
 #+latex: \vspace{-2cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Œ∑ in action)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+BEGIN_SRC agda
_ :   quoteTerm (Œª (x : ‚Ñï) ‚Üí id x)
    ‚â° def (quote id) (ùíΩùìáùí∂ (quoteTerm ‚Ñï) ‚à∑ [])
_ = refl
 #+END_SRC
#+latex: }} \vspace{-.5cm}

#+latex: \begin{myexamplebox}{Beta Law}\begin{center}
src_agda[:exports code]{quoteTerm} typechecks and Œ≤Œ∑-normalises its argument
before yielding a ~Term~ value.
#+latex: \end{center}\end{myexamplebox}
 #+latex: \vspace{-2.1cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Œ≤ in action!)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
   #+BEGIN_SRC agda
_ :    quoteTerm ((Œª x ‚Üí x) "nice")
    ‚â°  lit (string "nice")
_ = refl
 #+END_SRC
#+latex: }} \vspace{0cm}

#+latex: \begin{myexamplebox}{No Delta Law}\begin{center}
src_agda[:exports code]{quoteTerm} does no Œ¥-reduction: Function definitions are
not elaborated.
#+latex: \end{center}\end{myexamplebox}

 #+latex: \vspace{-2cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(Œ¥ \emph{not} in action!)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
    #+BEGIN_SRC agda
_ :    quoteTerm (id "a")
    ‚â°  def (quote id)
           ( ùíΩùìáùí∂ (quoteTerm String)
           ‚à∑ ùìãùìáùí∂ (quoteTerm "a")
           ‚à∑ [])
_ = refl
 #+END_SRC
#+latex: }} \vspace{0cm}

**** Observation: A relationship between ~quote~ and ~quoteTerm~  :ignore:

#+latex: \vspace{1ex}\remark{
*A relationship between src_agda[:exports code]{quote} and src_agda[:exports
code]{quoteTerm}*!
#+latex: }\vspace{-1cm}

Since Œ¥-reduction does not happen, known names ~ùíª~ in a quoted term are denoted by
a src_agda[:exports code]{quote ùíª} ---since no Œ¥efinitional elaboration
happens--- in the AST representation; as shown below.
 {{{code(No Œ¥-reduction for top-level defined names)}}}
 #+BEGIN_SRC agda
ùíª : ‚Ñï ‚Üí ‚Ñï
ùíª x = x

_ : quoteTerm ùíª ‚â° def (quote ùíª) []
_ = refl
 #+END_SRC

 #+latex: \noindent
 In contrast, names that /vary/ are denoted by a src_agda[:exports code]{var} term
constructor in the AST representation.
 {{{code(Names that \emph{vary} are reflected as \texttt{var} terms)}}}
 #+BEGIN_SRC agda
module _ {A B : Set} {f : A ‚Üí B} where

  _ : quoteTerm f ‚â° var 0 []
  _ = refl
#+END_SRC

#+latex: \vspace{-3cm}\remark{
Local names are /not/ considered top-level defined names.
#+latex: }\vspace{0.8em}

 #+latex: \vspace{-0cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
 {{{code(\texttt{let}s give rise to \texttt{var}s)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+BEGIN_SRC agda
_ : let ùíª‚ÇÅ : ‚Ñï ‚Üí ‚Ñï; ùíª‚ÇÅ x = x
    in  quoteTerm ùíª‚ÇÅ  ‚â°  Œªùìã "x" ‚Ü¶ var 0 []
_ = refl
 #+END_SRC
#+latex: }} \vspace{-0cm}

As such, we could form a ~module~ and ~let~ rules for src_agda[:exports
code]{quoteTerm} ---e.g., the latter could be src_agda[:exports code]{let x = E
in quoteTerm P = quoteTerm (P[x ‚âî E]) }.

# src_agda[:exports code]{module M (params) where f : œÑ; f = E}
# ‚âà  src_agda2[:exports code]{f : params ‚Üí œÑ; f = E}


# +caption: Summary
|-----------------+--------------------------------------------------------------|
|                 |                                                              |
| ~quoteTerm~       | Reify concrete Agda syntax as ~Term~ values, ASTs              |
| ~Œªùìã_‚Ü¶_~ and ~ŒªùíΩ_‚Ü¶_~ | ‚ãÜMake lambda ~Term~ values with ùìãisibile, or ùíΩidden, arguments |
|                 |                                                              |
|-----------------+--------------------------------------------------------------|

\newpage

*** newpage                                                        :ignore:
   \newpage
*** Metaprogramming with the Type-Checking Monad ~TC~

   A monadic interface to Agda's ‚ÄòT‚Äôype‚ÄòC‚Äôhecking utility is available through
   the ~TC~ type former.  Below are a few notable (postulated) bindings to the
   typechecking utility; the offical Agda [[https://agda.readthedocs.io/en/v2.6.0/language/reflection.html#type-checking-computations][documentation]] pages mention further
   primitives for the current context, type errors, and metavariables.
   #+Latex: \vspace{-1.5cm}\remark{
Since src_haskell[:exports code]{TC : ‚àÄ {‚Ñì} ‚Üí Set ‚Ñì ‚Üí Set ‚Ñì} is a monad, we may
use src_agda[:exports code]{do}-notation when forming typechecking computations.
#+latex: }\vspace{1.5cm}

{{{code(Interface to Agda's Typechecker)}}}
 #+BEGIN_src agda :tangle no
{- Take what you have and try to make it fit
   into the current goal. -}
unify : (have : Term) (goal : Term) ‚Üí TC ‚ä§

{- Try first computation;
   if it crashes with a type error, try the second. -}
catchTC : ‚àÄ {a} {A : Set a} ‚Üí TC A ‚Üí TC A ‚Üí TC A

{- Infer the type of a given term. -}
inferType : Term ‚Üí TC Type

{- Check a term against a given type. -}
checkType : Term ‚Üí Type ‚Üí TC Term

{- Compute the normal form of a term. -}
normalise : Term ‚Üí TC Term

{- Quote a value, returning the corresponding Term. -}
quoteTC : ‚àÄ {a} {A : Set a} ‚Üí A ‚Üí TC Term

{- Unquote a Term, returning the corresponding value. -}
unquoteTC : ‚àÄ {a} {A : Set a} ‚Üí Term ‚Üí TC A

{- Declare a new function of the given type.  -}
declareDef : Arg Name ‚Üí Type ‚Üí TC ‚ä§

{- Define a declared function. -}
defineFun : Name ‚Üí List Clause ‚Üí TC ‚ä§

{- Get the type of a defined name. -}
getType : Name ‚Üí TC Type

{- Get the definition of a defined name. -}
getDefinition : Name ‚Üí TC Definition
#+end_src

:Unused:
#+begin_src agda :tangle no
{-  Change the behaviour of inferType, checkType, quoteTC, getContext
    to normalise (or not) their results. The default behaviour is no
    normalisation. -}
withNormalisation : ‚àÄ {a} {A : Set a} ‚Üí ùîπ ‚Üí TC A ‚Üí TC A
 #+END_src
:End:

   #+Latex: \vspace{-13cm}\remark{
*Warning:* There's a src_haskell[:exports code]{freshName : String ‚Üí TC Name}
primitive, which is, currently, /mostly/ useless: It [[https://github.com/agda/agda/issues/3699][seems]] that the scope checker
runs before any reflection code and so any names exposed by reflection code are
‚Äúnot in scope‚Äù when the scope checker runs.  Since scope checking is a crucial
component of type checking, a possible workaround would be to have multiple
phases of scope and type checking with message passing occurring between the
checkers.
#+latex: }
# [[https://github.com/agda/agda/issues/3699][Allow metaprogramming to generate top level definitions other than functions #3699]]

   #+Latex: \vspace{4cm}\remark{
src_haskell[:exports code]{checkType} checks a term against a given type. This
   may resolve implicit arguments in the term, so a new refined term is
   returned.
#+latex: }

#+Latex: \vspace{3cm}\remark{
For src_haskell[:exports code]{declareDef}, the function must be defined later
using src_haskell[:exports code]{defineFun}.  @@remark: Takes an Arg Name to
allow declaring instances and irrelevant functions. The Visibility of the Arg
must not be hidden.@@ For src_haskell[:exports code]{defineFun}, the function
may have been declared using src_haskell[:exports code]{declareDef} or with an
explicit top-level type signature.
#+latex: }\vspace{4cm}

 ~TC~ computations, or /metaprograms/, can be run by declaring them as /macros/ or by
 unquoting. Let us begin with the former.

*** Unquoting ‚îÄMaking new functions and types
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Unquoting-Making-new-functions-types
   :END:

 Recall our ~RGB~ example type was a simple enumeration consisting of ~Red, Green,
 Blue~.  Consider the singleton type, predicate, ~IsRed~ whose only inhabitant is
 ~Red~.  The name ~Red~ completely determines this datatype; so let's try to
 generate it mechanically. Unfortunately, as far as I could tell, there is
 currently no way to unquote src_agda[:exports code]{data} declarations. As
 such, we'll settle for its isomorphic functional formulation.  Below, the
 src_agda[:exports code]{unquoteDecl} keyword allows us to obtain a ~Name~ value,
 say ~IsRed~.  We then quote the desired type, ~œÑ~, declare a function of that type,
 then define it using the provided ~Name~.

 #+latex: \vspace{-4cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Using Agda's syntactic sugar)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_src agda :tangle no
data IsRed : RGB ‚Üí Set where
  yes : IsRed Red
 #+END_src
#+latex: }} \vspace{0cm}

 #+latex: \vspace{-.5cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(No sugar)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_src agda :tangle no
IsRed : RGB ‚Üí Set
IsRed x = x ‚â° Red
 #+END_src
#+latex: }} \vspace{0cm}

#+Latex: \vspace{0cm}\remark{
For readability, let's quote the relevant parts.
#+latex: }\vspace{0cm}

 #+latex: \vspace{0cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(Quoted abbreviations)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
‚Äµ‚Ñì‚ÇÄ : Arg Term
‚Äµ‚Ñì‚ÇÄ = ùíΩùìáùí∂ (def (quote Level.zero) [])

‚ÄµRGB : Arg Term
‚ÄµRGB = ùíΩùìáùí∂ (def (quote RGB) [])

‚ÄµRed : Arg Term
‚ÄµRed = ùìãùìáùí∂ (con (quote Red) [])
 #+END_SRC
 #+latex: }} \vspace{-4cm}
 # The first two have a nearly identical definition and it would be nice to
 # mechanically derive them... macros ;-)

{{{code(Unquoting a singleton type predicate)}}}
 #+BEGIN_SRC agda
unquoteDecl IsRed =
  do œÑ ‚Üê quoteTC (RGB ‚Üí Set)
     declareDef (ùìãùìáùí∂ IsRed) œÑ
     defineFun IsRed
        [ clause [ ùìãùìáùí∂ (var "x") ]
                 (def (quote _‚â°_)
                      (‚Äµ‚Ñì‚ÇÄ ‚à∑ ‚ÄµRGB ‚à∑ ‚ÄµRed ‚à∑ ùìãùìáùìã 0 [] ‚à∑ []))]
 #+END_SRC

 #+latex: \vspace{-0.4cm} $\,$ \hfill \hspace{.95\textwidth} {\Large \maxsizebox{.6\textwidth}{\textheight}{
{{{code(\hspace{-1em}Let's try out our newly \emph{unquote} declared type!)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
 #+BEGIN_SRC agda
red-is-a-solution : IsRed Red
red-is-a-solution = refl

green-is-not-a-solution : ¬¨ (IsRed Green)
green-is-not-a-solution = Œª ()

red-is-only-solution : ‚àÄ {c} ‚Üí IsRed c ‚Üí c ‚â° Red
red-is-only-solution refl = refl
 #+END_SRC
#+latex: }} \vspace{-3cm}

 There is a major problem with using src_agda[:exports code]{unquoteDecl}
outright like this: We cannot step-wise refine our program using holes
src_agda[:exports code]{{! !}}, since that would result in unsolved
meta-variables. Instead, we split this process into two stages: A programming
stage, then an unquotation stage.

{{{code(A generalised 2-stage process to unquotation)}}}
 #+BEGIN_SRC agda
-- ‚ü®0‚ü© Definition stage, we can use ‚Äò?‚Äô as we form this program
define-Is : Name ‚Üí Name ‚Üí TC ‚ä§
define-Is is-name qcolour
    = defineFun is-name
         [ clause [ ùìãùìáùí∂ (var "x") ]
                  (def (quote _‚â°_)
                       (‚Äµ‚Ñì‚ÇÄ ‚à∑ ‚ÄµRGB ‚à∑ ùìãùìáùí∂ (con qcolour []) ‚à∑ ùìãùìáùìã 0 [] ‚à∑ []))]

-- ‚ü®1‚ü© Unquotation stage with a *mandatory* type declaration
IsRed' : RGB ‚Üí Set
unquoteDef IsRed' = define-Is IsRed' (quote Red)

-- ‚ü®2‚ü© Usage state: Trying it out
_ : IsRed' Red
_ = refl
 #+END_SRC

 Notice that if we use ~unquoteDef~, we must provide a type signature.  We only do
 so for illustration; the next code block avoids such a redundancy by using
 ~unquoteDecl~.  The above general approach lends itself nicely to the other data
 constructors as well:
 {{{code(Unquoting multiple singleton predicate types)}}}
 #+BEGIN_SRC agda
-- ‚ü®0‚ü©‚Ä≤ Definition stage *with* a type declaration.
declare-Is : Name ‚Üí Name ‚Üí TC ‚ä§
declare-Is is-name qcolour =
  do let Œ∑ = is-name
     œÑ ‚Üê quoteTC (RGB ‚Üí Set)
     declareDef (ùìãùìáùí∂ Œ∑) œÑ
     define-Is is-name qcolour
     defineFun is-name
        [ clause [ ùìãùìáùí∂ (var "x") ]
                   (def (quote _‚â°_) (‚Äµ‚Ñì‚ÇÄ ‚à∑ ‚ÄµRGB ‚à∑ ùìãùìáùí∂ (con qcolour []) ‚à∑ ùìãùìáùìã 0 [] ‚à∑ []))]

-- ‚ü®1‚ü©‚Ä≤ Unquotation stage, in one line.
unquoteDecl IsBlue  = declare-Is IsBlue  (quote Blue)
unquoteDecl IsGreen = declare-Is IsGreen (quote Green)

{- Example use -}
disjoint-rgb  : ‚àÄ{c} ‚Üí ¬¨ (IsBlue c √ó IsGreen c)
disjoint-rgb (refl , ())
 #+END_SRC

 The next natural step is to avoid manually invoking ~declare-Is~ for each
 constructor.  Unfortunately, as disucussed earlier, fresh names are not
 accessible, since they come into scope /after/ typechecking.  @@html: üò¢ @@

**** Exercises                                                 :html_only:
    :PROPERTIES:
    :CUSTOM_ID: Exercises
    :END:
  For example, you would think the following would produce a function
  named ~gentle-intro-to-reflection.identity~. Yet, it is not in scope.
  I even tried extracting the definition to its own file and no luck.
  #+BEGIN_SRC agda
unquoteDecl {- identity -}
  = do {- let Œ∑ = identity -}
       Œ∑ ‚Üê freshName "identity"
       œÑ ‚Üê quoteTC (‚àÄ {A : Set} ‚Üí A ‚Üí A)
       declareDef (ùìãùìáùí∂ Œ∑) œÑ
       defineFun Œ∑ [ clause [ ùìãùìáùí∂ (var "x") ] (var 0 []) ]

{- ‚Äúidentity‚Äù is not in scope!?
_ : ‚àÄ {x : ‚Ñï}  ‚Üí  identity x  ‚â°  x
_ = refl
-}
  #+END_SRC

  *Exercises*:
  0. Comment out the ~freshName~ line above and uncomment the surrounding artifacts to so that the above
     unit test goes through.
  1. Using that as a template, unquote-declare a function ~everywhere-0 : ‚Ñï ‚Üí ‚Ñï~ that is constantly 0.
  2. Unquote the constant combinator ~K : {A B : Set} ‚Üí A ‚Üí B ‚Üí A~.
  #+BEGIN_EXAMPLE agda
unquoteDecl everywhere-0
  = do ‚ãØ

_ : everywhere-0 3 ‚â° 0
_ = refl

unquoteDecl K
  = do ‚ãØ

_ : K 3 "cat" ‚â° 3
_ = refl
  #+END_EXAMPLE

  *Bonus:* Proofs of a singleton type such as ~IsRed~ are essentially the same for all singelton types
  over ~RGB~. Write, in two stages, a metaprogram that demonstrates each singleton type has a single member
  ‚îÄc.f., ~red-is-the-only-solution~ from above. Hint: This question is as easy as the ones before it.
  #+BEGIN_EXAMPLE agda
{- Programming stage }
declare-unique : Name ‚Üí (RGB ‚Üí Set) ‚Üí RGB ‚Üí TC ‚ä§
declare-unique it S colour =
  = do ‚ãØ

{- Unquotation stage -}
unquoteDecl red-unique = declare-unique red-unique IsRed Red
unquoteDecl green-unique = declare-unique green-unique IsGreen Green
unquoteDecl blue-unique = declare-unique blue-unique IsBlue Blue

{- Test -}
_ : ‚àÄ {c} ‚Üí IsGreen c ‚Üí c ‚â° Green
_ = green-unique
  #+END_EXAMPLE

  :Solutions:
  #+BEGIN_SRC agda
{- Exercise: -}
unquoteDecl everywhere-0
  = do let Œ∑ = everywhere-0
       œÑ ‚Üê quoteTC (‚Ñï ‚Üí ‚Ñï)
       declareDef (ùìãùìáùí∂ Œ∑) œÑ
       defineFun Œ∑ [ clause [ ùìãùìáùí∂ (var "x") ] (con (quote zero) []) ]

_ : everywhere-0 3 ‚â° 0
_ = refl
{- End -}

{- Exercise: -}
unquoteDecl K
  = do let Œ∑ = K
       œÑ ‚Üê quoteTC ({A B : Set} ‚Üí A ‚Üí B ‚Üí A)
       declareDef (ùìãùìáùí∂ Œ∑) œÑ
       defineFun Œ∑ [ clause (ùìãùìáùí∂ (var "x") ‚à∑ ùìãùìáùí∂ (var "y") ‚à∑ []) (var 1 []) ]

_ : K 3 "cat" ‚â° 3
_ = refl
{- End -}

{- Exercise: -}
declare-unique : Name ‚Üí (RGB ‚Üí Set) ‚Üí RGB ‚Üí TC ‚ä§
declare-unique it S colour =
  do let Œ∑ = it
     œÑ ‚Üê quoteTC (‚àÄ {c} ‚Üí S c ‚Üí c ‚â° colour)
     declareDef (ùìãùìáùí∂ Œ∑) œÑ
     defineFun Œ∑ [ clause [ ùìãùìáùí∂ (con (quote refl) []) ] (con (quote refl) []) ]

unquoteDecl red-unique = declare-unique red-unique IsRed Red
unquoteDecl green-unique = declare-unique green-unique IsGreen Green
unquoteDecl blue-unique = declare-unique blue-unique IsBlue Blue

_ : ‚àÄ {c} ‚Üí IsGreen c ‚Üí c ‚â° Green
_ = green-unique
{- End -}
  #+END_SRC
  :End:

  :Failed_exploration:
  #+BEGIN_EXAMPLE agda
RGB-constructors : Definition ‚Üí Name √ó Name √ó Name
RGB-constructors (data-type pars (x ‚à∑ y ‚à∑ z ‚à∑ cs)) = x , y , z
RGB-constructors _ = n , n , n where n = quote RGB

unquoteDecl
  =    do Œ¥ ‚Üê getDefinition (quote RGB)

          let r , g , b = RGB-constructors Œ¥
       -- TODO: get unqualified name, then prefix it with "Is",
       -- then make that into a new name. Then declare a function with that name.

          Œ∑ ‚Üê freshName "IsX"
          -- let Œ∑ = r
          œÑ ‚Üê quoteTC (RGB ‚Üí Set)
          declareDef (ùìãùìáùí∂ Œ∑) œÑ
          define-Is Œ∑

-- _ : {!!} -- IsX Red -- gentle-intro-to-reflection.IsX
-- _ = {!IsX!}
--
  #+END_EXAMPLE
  :End:

*** @@html:Sidequest:@@ @@latex: Example:@@ Avoid tedious ~refl~ proofs
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Sidequest-Avoid-tedious-refl-proofs
   :END:

   We are now in a position to tackle a ‚Äòreal-world‚Äô situation.

 @@html: Time for a breather (‚Ä¢ÃÄ·¥ó‚Ä¢ÃÅ)Ÿà@@

 # Look around your code base for a function that makes explicit pattern matching, such as:

 When functions perform a lot of pattern matching, then to prove properties
 about them, it becomes necessary to pattern match on the arguments they pattern
 match against ---so that a particular clause of the function applies.  For
 instance, consider the following two functions with overly excessive pattern
 matching.
 {{{code(Too much pattern matching...)}}}
 #+BEGIN_SRC agda
just-Red : RGB ‚Üí RGB
just-Red Red   = Red
just-Red Green = Red
just-Red Blue  = Red

only-Blue : RGB ‚Üí RGB
only-Blue Blue = Blue
only-Blue _   = Blue
 #+END_SRC

 #+latex: \noindent
 Then, to show that the above function ~just-Red~ is constantly ~Red~ requires
 pattern matching then a ~refl~ /for each clause/. Likewise, for ~just-Blue~.
 {{{code(...results in more pattern matching)}}}
 #+BEGIN_SRC agda
just-Red-is-constant : ‚àÄ{c} ‚Üí just-Red c ‚â° Red
just-Red-is-constant {Red}   = refl
just-Red-is-constant {Green} = refl
just-Red-is-constant {Blue}  = refl

{- Yuck, another tedious proof -}
only-Blue-is-constant : ‚àÄ{c} ‚Üí only-Blue c ‚â° Blue
only-Blue-is-constant {Blue}  = refl
only-Blue-is-constant {Red}   = refl
only-Blue-is-constant {Green} = refl
 #+END_SRC

 In such cases, we can encode the general design decisions ---/pattern match and
 yield refl/--- then apply the schema to each use case.  Here is the schema:
 #+begin_margin :width "0.45\\textwidth"
Now, ~unquoteDecl f = by-refls-on œÑ f (quote P)~ results in the following function
---where the ~c·µ¢~ are the constructors of œÑ.

#+latex: \kern1ex
#+resize:
{{{code(Elaboration of ‚Äòby-refls-on‚Äô)}}}
 #+ATTR_LATEX: :options fontsize=\normalsize
#+BEGIN_SRC agda :tangle no
f : ‚àÄ {e : œÑ} ‚Üí P e
f c‚ÇÅ  = refl
  ‚ãÆ    ‚ãÆ   ‚ãÆ
f c‚Çô  = refl
 #+END_SRC
#+end_margin
 {{{code(Factoring out the insight)}}}
 #+BEGIN_SRC agda
constructors : Definition ‚Üí List Name
constructors (data-type pars cs) = cs
constructors _ = []

by-refls-on : Name ‚Üí Name ‚Üí Term ‚Üí TC ‚ä§
by-refls-on Œ¥Œ±œÑŒ±œÑŒ≥œÅŒµ nom thm-you-hope-is-provable-by-refls
 = let mk-cls : Name ‚Üí Clause
       mk-cls qcolour = clause [ ùíΩùìáùí∂ (con qcolour []) ]
                               ( con (quote refl) []   )
   in
   do let Œ∑ = nom
      Œ¥ ‚Üê getDefinition Œ¥Œ±œÑŒ±œÑŒ≥œÅŒµ
      let clauses = List.map mk-cls (constructors Œ¥)
      declareDef (ùìãùìáùí∂ Œ∑) thm-you-hope-is-provable-by-refls
      defineFun Œ∑ clauses
#+END_SRC

 Here is a use case.
 #+BEGIN_SRC agda
obviously : Name ‚Üí Term ‚Üí TC ‚ä§
obviously = by-refls-on (quote RGB)

_ : ‚àÄ{c} ‚Üí just-Red c ‚â° Red
_ = nice
  where unquoteDecl nice = obviously nice (quoteTerm (‚àÄ{c} ‚Üí just-Red c ‚â° Red))
 #+END_SRC

 #+latex: \noindent
 Where,
 0. The first ~nice~ refers to the function created by the right-hand side (RHS)
    of the unquote.
 1. The RHS ~nice~ refers to the ~Name~ value provided by the left-hand side (LHS).
 2. The LHS ~nice~ is a declaration of a ~Name~ value.

 This is rather clunky since the theorem to be proven was repeated twice
 ‚îÄrepetition is a signal that something's wrong! In the next section we
 use macros to avoid such repetiton, as well as the ~quoteTerm~ keyword.

  [[https://github.com/agda/agda/issues/4996][*Warning!*]] We use a ~where~ clause since unquotation cannot occur in a ~let~.

 Here's another use case of the proof pattern @@html: (‚Ä¢ÃÄ·¥ó‚Ä¢ÃÅ)Ÿà@@
 #+BEGIN_SRC agda
_ : ‚àÄ{c} ‚Üí only-Blue c ‚â° Blue
_ = nice
  where unquoteDecl nice = obviously nice (quoteTerm ‚àÄ{c} ‚Üí only-Blue c ‚â° Blue)
 #+END_SRC

 One proof pattern, multiple invocations!
 @@html: Super neat stuff :grin:@@

*** Macros ---Abstracting Proof Patterns
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Macros-Abstracting-Proof-Patterns
   :END:

  Macros are functions of type ~œÑ‚ÇÄ ‚Üí œÑ‚ÇÅ ‚Üí ‚ãØ ‚Üí Term ‚Üí TC ‚ä§~ that are defined in a
  ~macro~ block. The last argument is supplied by the type checker and denotes the
  ‚Äúgoal‚Äù of where the macro is placed: One generally unifies what they have with
  the goal, what is desired in the use site.  In contrast to splicing terms with
  ~unquoteDecl~, Agda /macros/ have the following benefits:

  1. Metaprograms can be run in a term position.
  2. Without the macro block, we run computations using the ~unquote~ and ~unquoteDecl~
     keyphrases.
  3. Quotations are performed automatically; e.g.,
     if ~f ‚à∂ Term ‚Üí Name ‚Üí ùîπ ‚Üí Term ‚Üí TC ‚ä§~
     then an application ~f u v w~ desugars into
     ~unquote (f (quoteTerm u) (quote v) w)~.
  4. No syntactic overhead: Macros are applied like normal functions.

 Macros cannot be recursive; instead one defines a recursive function outside the
 macro block then has the macro call the recursive function.

**** C-style macros
    :PROPERTIES:
    :CUSTOM_ID: C-style-macros
    :END:

 In the C language one defines a macro, say, by ~#define luckyNum 1729~ then later uses
 it simply by the name ~luckyNum~. Without macros, we have syntactic overhead using
 the ~unquote~ keyword:
 #+BEGIN_SRC agda
luckyNum‚ÇÄ : Term ‚Üí TC ‚ä§
luckyNum‚ÇÄ goal = unify goal (quoteTerm 1729)

num‚ÇÄ : ‚Ñï
num‚ÇÄ = unquote luckyNum‚ÇÄ
 #+END_SRC
 Instead, we can achieve C-style behaviour by placing our metaprogramming code within a ~macro~ block.
 #+BEGIN_SRC agda
macro
  luckyNum : Term ‚Üí TC ‚ä§
  luckyNum goal = unify goal (quoteTerm 1729)
num = luckyNum
 #+END_SRC
 Unlike C, all code fragments must be well-defined.

**** Exercises                                                 :html_only:
    :PROPERTIES:
    :CUSTOM_ID: Exercises
    :END:
  *Exercise:* Write a macro to always yield the first argument in a function.
  The second example shows how it can be used to access implicit arguments
  without mentioning them :b
  #+BEGIN_EXAMPLE agda
macro
  first : Term ‚Üí TC ‚ä§
  first goal = ‚ãØ

myconst : {A B : Set} ‚Üí A ‚Üí B ‚Üí A
myconst = Œª x ‚Üí Œª y ‚Üí first

mysum : ( {x} y : ‚Ñï) ‚Üí ‚Ñï
mysum y = y + first
  #+END_EXAMPLE
  :Solution:
  #+BEGIN_SRC agda
{- exercise -}
macro
  first : Term ‚Üí TC ‚ä§
  first goal = unify goal (var 1 [])

myconst : {A B : Set} ‚Üí A ‚Üí B ‚Üí A
myconst = Œª x ‚Üí Œª y ‚Üí first

mysum : ( {x} y : ‚Ñï) ‚Üí ‚Ñï
mysum y = y + first
{- end -}
  #+END_SRC
  :End:

  C-style macros ‚îÄunifying against a concretely quoted term‚îÄ are helpeful
  when learning reflection. For example, define a macro ~use~ that yields
  different strings according to the shape of their input ‚îÄthis exercise
  increases familiarity with the ~Term~ type. Hint: Pattern match on the
  first argument ;-)
  #+BEGIN_EXAMPLE agda
macro
  use : Term ‚Üí Term ‚Üí TC ‚ä§
  use = ‚ãØ
  #+END_EXAMPLE
  :Solution:
  #+BEGIN_SRC agda
macro
  use : Term ‚Üí Term ‚Üí TC ‚ä§
  use (def _ []) goal = unify goal (quoteTerm "Nice")
  use v goal = unify goal  (quoteTerm "WoahThere")
  #+END_SRC
  :End:
  #+BEGIN_SRC agda
{- Fully defined, no arguments. -}

2+2‚âà4 : 2 + 2 ‚â° 4
2+2‚âà4 = refl

_ : use 2+2‚âà4 ‚â° "Nice"
_ = refl

{- ‚Äòp‚Äô has arguments. -}

_ : {x y : ‚Ñï} {p : x ‚â° y} ‚Üí use p ‚â° "WoahThere"
_ = refl
  #+END_SRC

**** Tedious Repetitive Proofs No More!
    :PROPERTIES:
    :CUSTOM_ID: Tedious-Repetitive-Proofs-No-More
    :END:
 Suppose we wish to prove that addition, multiplication, and exponentiation have
 right units 0, 1, and 1 respectively. We obtain the following nearly identical
 proofs.

 #+BEGIN_SRC agda
+-rid : ‚àÄ{n} ‚Üí n + 0 ‚â° n
+-rid {zero}  = refl
+-rid {suc n} = cong suc +-rid

*-rid : ‚àÄ{n} ‚Üí n * 1 ‚â° n
*-rid {zero}  = refl
*-rid {suc n} = cong suc *-rid

^-rid : ‚àÄ{n} ‚Üí n ^ 1 ‚â° n
^-rid {zero}  = refl
^-rid {suc n} = cong suc ^-rid
 #+END_SRC

 There is clearly a pattern here screaming to be abstracted, let's comply.
 @@html: ‚ô•‚Äø‚ô• @@ The natural course of action in a functional language is to try
 a higher-order combinator:
 #+BEGIN_SRC agda
{- ‚Äúfor loops‚Äù or ‚ÄúInduction for ‚Ñï‚Äù -}
foldn : (P : ‚Ñï ‚Üí Set) (base : P zero) (ind : ‚àÄ n ‚Üí P n ‚Üí P (suc n))
      ‚Üí ‚àÄ(n : ‚Ñï) ‚Üí P n
foldn P base ind zero    = base
foldn P base ind (suc n) = ind n (foldn P base ind n)
 #+END_SRC

 Now the proofs are shorter:
 #+BEGIN_SRC agda
_ : ‚àÄ (x : ‚Ñï) ‚Üí x + 0 ‚â° x
_ = foldn _ refl (Œª _ ‚Üí cong suc)    {- This and next two are the same -}

_ : ‚àÄ (x : ‚Ñï) ‚Üí x * 1 ‚â° x
_ = foldn _ refl (Œª _ ‚Üí cong suc)    {- Yup, same proof as previous -}

_ : ‚àÄ (x : ‚Ñï) ‚Üí x ^ 1 ‚â° x
_ = foldn _ refl (Œª _ ‚Üí cong suc)    {- No change, same proof as previous -}
 #+END_SRC
 Unfortunately, we are manually copy-pasting the same proof /pattern/.
 #+begin_quote
 When you see repetition, copy-pasting, know that there is room for improvement!

 Don't repeat yourself!
 #+end_quote

 Repetition can be mitigated a number of ways, including typeclasses or
 metaprogramming, for example.  The latter requires possibly less thought and
 it is the topic of this article, so let's do that.  @@html: :smile: @@

***** COMMENT Exercise                                        :html_only:
     :PROPERTIES:
     :CUSTOM_ID: Exercise
     :END:
 *Exercise*: Following the template of the previous exercises, fill in the missing parts below.
 Hint: It's nearly the same level of difficulty as the previous exercises.
 #+BEGIN_EXAMPLE agda
make-rid : (let A = ‚Ñï) (_‚äï_ : A ‚Üí A ‚Üí A) (e : A) ‚Üí Name ‚Üí TC ‚ä§
make-rid _‚äï_ e nom
 = do ‚ãØ

_ : ‚àÄ{x : ‚Ñï} ‚Üí x + 0 ‚â° x
_ = nice where unquoteDecl nice = make-rid _+_ 0 nice
 #+END_EXAMPLE
 :Solution:
 #+BEGIN_SRC agda
make-rid : (let A = ‚Ñï) (_‚äï_ : A ‚Üí A ‚Üí A) (e : A) ‚Üí Name ‚Üí TC ‚ä§
make-rid _‚äï_ e nom
 = do let Œ∑ = nom
      let clauses =   clause [ ùíΩùìáùí∂ (con (quote zero) []) ] (con (quote refl) [])
                    ‚à∑ clause [ ùíΩùìáùí∂ (con (quote suc)  [ ùìãùìáùí∂ (var "n") ]) ]
                             (def (quote cong) (ùìãùìáùí∂ (quoteTerm suc) ‚à∑ ùìãùìáùí∂ (def nom []) ‚à∑ [])) ‚à∑ []
      œÑ ‚Üê quoteTC (‚àÄ{x : ‚Ñï} ‚Üí x ‚äï e ‚â° x)
      declareDef (ùìãùìáùí∂ Œ∑) œÑ
      defineFun Œ∑ clauses

_ : ‚àÄ{x : ‚Ñï} ‚Üí x + 0 ‚â° x
_ = nice where unquoteDecl nice = make-rid _+_ 0 nice
 #+END_SRC
 :End:

***** trivially-has-rid                                          :ignore:
     :PROPERTIES:
     :CUSTOM_ID: trivially-has-rid
     :END:

 # There's too much syntactic overhead here, let's use macros instead.
 Rather than use unquotes and their syntactic overhead, we use macros instead.
 The definition below essentially produce the repeated proofs, ~foldn P refl (Œª _ ‚Üí cong suc)~,
 at each call.
 # However, the underlying proof pattern is not abstracted out.
 #+BEGIN_SRC agda
macro
  _trivially-has-rid_ : (let A = ‚Ñï) (_‚äï_ : A ‚Üí A ‚Üí A) (e : A) ‚Üí Term ‚Üí TC ‚ä§
  _trivially-has-rid_ _‚äï_ e goal
   = do œÑ ‚Üê quoteTC (Œª(x : ‚Ñï) ‚Üí x ‚äï e ‚â° x)
        unify goal (def (quote foldn)            {- Using foldn    -}
          ( ùìãùìáùí∂ œÑ                                {- Type P         -}
          ‚à∑ ùìãùìáùí∂ (con (quote refl) [])            {- Base case      -}
          ‚à∑ ùìãùìáùí∂ (Œªùìã "_" ‚Ü¶ quoteTerm (cong suc))  {- Inductive step -}
          ‚à∑ []))
 #+END_SRC

 Now the proofs have minimal repetition /and/ the proof pattern is written only /once/:
 #+BEGIN_SRC agda
_ : ‚àÄ (x : ‚Ñï) ‚Üí x + 0 ‚â° x
_ = _+_ trivially-has-rid 0

_ : ‚àÄ (x : ‚Ñï) ‚Üí x * 1 ‚â° x
_ = _*_ trivially-has-rid 1

_ : ‚àÄ (x : ‚Ñï) ‚Üí x * 1 ‚â° x
_ = _^_ trivially-has-rid 1
 #+END_SRC

**** COMMENT quoteGoal‚ãØin‚ãØ  ‚à∑ No longer part of Agda's Reflection mechanism
    :PROPERTIES:
    :CUSTOM_ID: COMMENT-quoteGoal-in-No-longer-part-of-Agda's-Reflection-mechanism
    :END:
 # quoteGoal‚ãØin‚ãØ is no longer part of Agda
 #
 Note we could look at the type of the goal, find the operator ~_‚äï_~ and the unit;
 they need not be passed in. Later we will see how to reach into the goal type
 and pull pieces of it out for manipulation (‚Ä¢ÃÄ·¥ó‚Ä¢ÃÅ)Ÿà

 It would have been ideal if we could have defined our macro without using ~foldn~;
 I could not figure out how to do that. üòß

 Before one abstracts a pattern into a macro, it is useful to have a few instances
 of the pattern beforehand. When abstracting, one may want to compare how we think
 versus how Agda's thinking. For example, you may have noticed that in the previous
 macro, Agda normalised the expression ~suc n + 0~ into ~suc (n + 0)~ by invoking the definition
 of ~_+_~. We may inspect the goal of a function with the ~quoteGoal ‚ãØ in ‚ãØ~ syntax:

 #+BEGIN_SRC agda
+-rid' : ‚àÄ{n} ‚Üí n + 0 ‚â° n
+-rid' {zero}  = refl
+-rid' {suc n} = quoteGoal e in
  let
    suc-n : Term
    suc-n = con (quote suc) [ ùìãùìáùí∂ (var 0 []) ]

    lhs : Term
    lhs = def (quote _+_) (ùìãùìáùí∂ suc-n ‚à∑ ùìãùìáùí∂ (lit (nat 0)) ‚à∑ [])

    {- Check our understanding of what the goal is ‚Äúe‚Äù. -}
    _ : e ‚â° def (quote _‚â°_)
                 (ùíΩùìáùí∂ (quoteTerm Level.zero) ‚à∑ ùíΩùìáùí∂ (quoteTerm ‚Ñï)
                 ‚à∑ ùìãùìáùí∂ lhs ‚à∑ ùìãùìáùí∂ suc-n ‚à∑ [])
    _ = refl

    {- What does it look normalised. -}
    _ :   quoteTerm (suc (n + 0) ‚â° n)
         ‚â° unquote Œª goal ‚Üí (do g ‚Üê normalise goal; unify g goal)
    _ = refl
  in
  cong suc +-rid'
 #+END_SRC

 It would be really nice to simply replace the last line by a macro, say ~induction~.
 Unfortunately, for that I would need to obtain the name ~+-rid'~, which as far as I could
 tell is not possible with the current reflection mechanism.

*** COMMENT ‚ü®NO‚ü© Our First Real Proof Tactic: Implicit Symmetry :orginal:too_much_a_tutorial:
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Our-First-Real-Proof-Tactic
   :END:

 When we have a proof ~p : x ‚â° y~ it is a nuisance to have to write ~sym p~ to prove
 ~y ‚â° x~ ---we have to remember which ‚Äòdirection‚Äô ~p~. Let's alleviate such a small
 burden, then use the tools here to alleviate a larger burden later; namely,
 rewriting subexpressions.

 Given ~p : x ‚â° y~, we cannot simply yield ~def (quote sym) [ ùìãùìáùí∂ p ]~ since ~sym~ actually
 takes four arguments ‚îÄcompare when we quoted ~_‚â°_~ earlier. Instead, we infer type of ~p~
 to be, say, ~quoteTerm (_‚â°_ {‚Ñì} {A} x y)~. Then we can correctly provide all the required arguments.

 #+BEGIN_SRC agda
‚â°-type-info : Term ‚Üí TC (Arg Term √ó Arg Term √ó Term √ó Term)
‚â°-type-info (def (quote _‚â°_) (ùìÅ ‚à∑ ùíØ ‚à∑ arg _ l ‚à∑ arg _ r ‚à∑ [])) = return (ùìÅ , ùíØ , l , r)
‚â°-type-info _ = typeError [ strErr "Term is not a ‚â°-type." ]
 #+END_SRC

 What if later we decided that we did not want a proof of ~y ‚â° x~, but rather of ~x ‚â° y~.
 In this case, the orginal proof ~p~ suffices. Rather than rewriting our proof term, our
 macro could try providing it if the symmetry application fails.

 #+BEGIN_SRC agda
{- Syntactic sugar for trying a computation, if it fails then try the other one -}
try-fun : ‚àÄ {a} {A : Set a} ‚Üí TC A ‚Üí TC A ‚Üí TC A
try-fun = catchTC

-- syntax try-fun t f = try t or-else f
syntax catchTC t f = try t or-else f
 #+END_SRC

 With the setup in hand, we can now form our macro:
 #+BEGIN_SRC agda
macro
  apply‚ÇÅ : Term ‚Üí Term ‚Üí TC ‚ä§
  apply‚ÇÅ p goal = try (do œÑ ‚Üê inferType p
                          ùìÅ , ùíØ , l , r ‚Üê ‚â°-type-info œÑ
                          unify goal (def (quote sym) (ùìÅ ‚à∑ ùíØ ‚à∑ ùíΩùìáùí∂ l ‚à∑ ùíΩùìáùí∂ r ‚à∑ ùìãùìáùí∂ p ‚à∑ [])))
                  or-else
                       unify goal p
 #+END_SRC

 For example:
 #+BEGIN_SRC agda
postulate ùìç ùìé : ‚Ñï
postulate ùìÜ : ùìç + 2 ‚â° ùìé

{- Same proof yields two theorems! (‡∏á‡≤†_‡≤†)‡∏á -}
_ : ùìé ‚â° ùìç + 2
_ = apply‚ÇÅ ùìÜ

_ : ùìç + 2 ‚â° ùìé
_ = apply‚ÇÅ ùìÜ
 #+END_SRC

 Let's furnish ourselves with the ability to inspect the /produced/ proofs.
 #+BEGIN_SRC agda
{- Type annotation -}
syntax has A a = a ‚à∂ A

has : ‚àÄ (A : Set) (a : A) ‚Üí A
has A a = a
 #+END_SRC
 We are using the ‚Äòghost colon‚Äô obtained with input ~\:~.

 Let's try this on an arbitrary type:
 #+BEGIN_SRC agda
woah : {A : Set} (x y : A) ‚Üí x ‚â° y ‚Üí (y ‚â° x) √ó (x ‚â° y)
woah x y p = apply‚ÇÅ p , apply‚ÇÅ p

  where -- Each invocation generates a different proof, indeed:

  first-pf : (apply‚ÇÅ p ‚à∂ (y ‚â° x)) ‚â° sym p
  first-pf = refl

  second-pf : (apply‚ÇÅ p ‚à∂ (x ‚â° y)) ‚â° p
  second-pf = refl
 #+END_SRC

 It is interesting to note that on non ‚â°-terms, ~apply‚ÇÅ~ is just a no-op.
 Why might this be the case?
 #+BEGIN_SRC agda
_ : ‚àÄ {A : Set} {x : A} ‚Üí apply‚ÇÅ x ‚â° x
_ = refl

_ : apply‚ÇÅ "huh" ‚â° "huh"
_ = refl
 #+END_SRC

 *Exercise:* When we manually form a proof invoking symmetry we simply write, for example, ~sym p~
 and the implict arguments are inferred. We can actually do the same thing here! We were a bit dishonest above. üëÇ
 Rewrite ~apply‚ÇÅ~, call it ~apply‚ÇÇ, so that the ~try~ block is a single, unparenthesised, ~unify~ call.
 :Solution:
 #+BEGIN_SRC agda
macro
  apply‚ÇÇ : Term ‚Üí Term ‚Üí TC ‚ä§
  apply‚ÇÇ p goal = try unify goal (def (quote sym)  (ùìãùìáùí∂ p ‚à∑ []))
                  or-else unify goal p

_ : {A : Set} (x y : A) ‚Üí x ‚â° y ‚Üí (y ‚â° x) √ó (x ‚â° y)
_ = Œª x y p ‚Üí apply‚ÇÇ p , apply‚ÇÇ p
 #+END_SRC
 :End:

 *Exercise:* Extend the previous macro so that we can prove statements of the form ~x ‚â° x~ regardless of what ~p~
 proves. Aesthetics hint: ~try_or-else_~ doesn't need brackets in this case, at all.
 #+BEGIN_EXAMPLE agda
macro
  apply‚ÇÉ : Term ‚Üí Term ‚Üí TC ‚ä§
  apply‚ÇÉ p goal = ‚ãØ

yummah : {A : Set} {x y : A} (p : x ‚â° y)  ‚Üí  x ‚â° y  √ó  y ‚â° x  √ó  y ‚â° y
yummah p = apply‚ÇÉ p , apply‚ÇÉ p , apply‚ÇÉ p
 #+END_EXAMPLE
 :Solution:
 #+BEGIN_SRC agda
macro
  apply‚ÇÉ : Term ‚Üí Term ‚Üí TC ‚ä§
  apply‚ÇÉ p goal = try unify goal (def (quote sym) (ùìãùìáùí∂ p ‚à∑ []))
                  or-else try unify goal p
                          or-else unify goal (con (quote refl) [])

yummah : {A : Set} {x y : A} (p : x ‚â° y)  ‚Üí  x ‚â° y  √ó  y ‚â° x  √ó  y ‚â° y
yummah p = apply‚ÇÉ p , apply‚ÇÉ p , apply‚ÇÉ p
 #+END_SRC
 :End:

 *Exercise:* Write the following seemingly silly macro.
 Hint: You cannot use the ~‚â°-type-info~ method directly, instead you must invoke ~getType~ beforehand.
 #+BEGIN_EXAMPLE agda
‚â°-type-info' : Name ‚Üí TC (Arg Term √ó Arg Term √ó Term √ó Term)
‚â°-type-info' = ‚ãØ

macro
  sumSides : Name ‚Üí Term ‚Üí TC ‚ä§
  sumSides n goal = ‚ãØ

_ : sumSides ùìÜ ‚â° ùìç + 2 + ùìé
_ = refl
 #+END_EXAMPLE
 :Solution:
 #+BEGIN_SRC agda
‚â°-type-info' : Name ‚Üí TC (Arg Term √ó Arg Term √ó Term √ó Term)
‚â°-type-info' n = do œÑ ‚Üê getType n; ‚â°-type-info œÑ

macro
  sumSides : Name ‚Üí Term ‚Üí TC ‚ä§
  sumSides n goal = do _ , _ , l , r ‚Üê ‚â°-type-info' n; unify goal (def (quote _+_) (ùìãùìáùí∂ l ‚à∑ ùìãùìáùí∂ r ‚à∑ []))

_ : sumSides ùìÜ ‚â° ùìç + 2 + ùìé
_ = refl
 #+END_SRC
 :End:

 *Exercise:* Write two macros, ~left~ and ~right~, such that
 ~sumSides q  ‚â° left q + right q~, where ~q~ is a known name.
 These two macros provide the left and right hand sides of the
 ‚â°-term they are given.
 :Solution:
 #+BEGIN_SRC agda
macro
  left : Name ‚Üí Term ‚Üí TC ‚ä§
  left n goal = do _ , _ , l , r ‚Üê ‚â°-type-info' n; unify goal l

  right : Name ‚Üí Term ‚Üí TC ‚ä§
  right n goal = do _ , _ , l , r ‚Üê ‚â°-type-info' n; unify goal r

_ : sumSides ùìÜ  ‚â°  left ùìÜ + right ùìÜ
_ = refl

_ : left ùìÜ ‚â° ùìç + 2
_ = refl

_ : right ùìÜ ‚â° ùìé
_ = refl
 #+END_SRC
 :End:

*** COMMENT Unquoting Declarations from Macro Calls
   :PROPERTIES:
   :CUSTOM_ID: Unquoting-Declarations-from-Macro-Calls
   :END:

  We may use the ~unquoteDecl~ keyword to splice in the result to a call involving
  computations within the typechecking monad. However, it is not clear how to
  splice in results from computations marked as ~macro~ operations ---since they
  have implicit quotation around them.  Since we cannot declare top level
  functions from macros directly, here is a /hack/: We declare an anoynmous value,
  say 1, but in the process we declare our desired function.

  For example, ~_ = 1~ is an anonymous computation: It is a computation whose
  name, ~_~, is not accessible beyond its declaration. Such anynomous constants
  are useful to demonstrate /examples/ without the need for cumbersome
  place-holder names. They are also useful for forming *unit tests*: We write ~_ :
  l ‚â° r; _ = refl~ and if everything typechecks then indeed ~l~ and ~r~ are
  identical, and so the implementation ~refl~ is valid, otherwise a type error is
  raised. However, this is bit ugly, and we may reduce it slightly to, say, ~_ =
  l ‚â° r ‚úì~ as outlined earlier: The ~_‚úì~ is a macro yielding a constant, say 1, and
  along the way it declares the anonymous function witnessing the unit test.

  First, we need a helper tool to get the implicit type information of a quoted
  propositional equality proof, whether it be a ~Term~ or a ~Name~ ---the latter is
  used later on.
#+begin_src agda
‚â°-type-info : Term ‚Üí TC (Arg Term √ó Arg Term √ó Term √ó Term)
‚â°-type-info (def (quote _‚â°_) (ùìÅ ‚à∑ ùíØ ‚à∑ arg _ l ‚à∑ arg _ r ‚à∑ [])) = return (ùìÅ , ùíØ , l , r)
‚â°-type-info _ = typeError [ strErr "Term is not a ‚â°-type." ]

‚â°-type-info' : Name ‚Üí TC (Arg Term √ó Arg Term √ó Term √ó Term)
‚â°-type-info' n = do œÑ ‚Üê getType n; ‚â°-type-info œÑ
#+end_src

The macro is now formed as an inaccessible function having the given type, œÑ,
and implemented by ~refl~ ---it is inaccessible since ~freshName~ produces names
that are ‚Äúnot in scope‚Äù, as discussed earlier.
#+begin_src agda
infix -999 _‚úì
macro
  _‚úì : Term  ‚Üí Term ‚Üí TC ‚ä§
  _‚úì    œÑ goal  = do ùìÅ , A , l , r ‚Üê ‚â°-type-info œÑ
                     name ‚Üê freshName "_"
                     declareDef (arg (arg-info visible relevant) name) œÑ
                     defineFun name (clause [] (con (quote refl) (ùìÅ ‚à∑ A ‚à∑ ùíΩùìáùí∂ l ‚à∑ [])) ‚à∑ [])
                     unify goal (quoteTerm 1)
-- Examples
_ = 2 ‚â° 2 ‚úì
_ = 1 + 1 ‚â° 2 * 1 ‚úì

-- Crashes
-- _ = 2 ‚â° 3 ‚úì
#+end_src

*** COMMENT Our First Real Proof Tactic: Implicit Reflexivity, Symmetry, and Congruence
   :PROPERTIES:
   :CUSTOM_ID: Our-First-Real-Proof-Tactic-Implicit-Reflexivity-Symmetry-and-Congruence
   :END:

 When we have a proof ~p : x ‚â° y~ it is a nuisance to have to write ~sym p~ to prove
 ~y ‚â° x~ ---we have to remember which ‚Äòdirection‚Äô ~p~. Let's alleviate such a small
 burden, then use the tools here to alleviate a larger burden later; namely,
 rewriting subexpressions.

 What if later we decided that we did not want a proof of ~y ‚â° x~, but rather of ~x
 ‚â° y~.  In this case, the orginal proof ~p~ suffices. Rather than rewriting our
 proof term, our macro could try providing it if the symmetry application fails.
 For added fun, we also give our macro the ability to prove statements of the
 form ~x ‚â° x~ regardless of what ~p~ actually proves, and to prove ~f x ‚â° f y~ from
 proofs ~p : x ‚â° y~ ---‚Äúsubtituting equals for equals‚Äù.

 # Finally, what if instead of equality ‚Äò‚â°‚Äô we wanted to use symmetry of addition
 # ‚Äò+‚Äô or any other symmetric operator ‚Äò‚äï‚Äô; so we parameterise along the symmetry
 # proof and operator.

 #+BEGIN_SRC agda
{- If we have ‚Äúf $ args‚Äù return ‚Äúf‚Äù. -}
$-head : Term ‚Üí Term
$-head (var v args) = var v []
$-head (con c args) = con c []
$-head (def f args) = def f []
$-head (pat-lam cs args) = pat-lam cs []
$-head t = t
 #+END_SRC

 #+BEGIN_SRC agda
{- Syntactic sugar for trying a computation, if it fails then try the other one -}
try-fun : ‚àÄ {a} {A : Set a} ‚Üí TC A ‚Üí TC A ‚Üí TC A
try-fun = catchTC

infixr -999 try-fun
syntax try-fun t f = t or-else f
 #+END_SRC

 With the setup in hand, we can now form our macro:
 #+BEGIN_SRC agda
macro
  apply‚ÇÄ : Term ‚Üí Term ‚Üí TC ‚ä§
  apply‚ÇÄ p goal =  {- Do we have the proof already? -}
                   unify goal p
                   {- Does a flipped symmetric form work? -}
                   or-else unify goal (def (quote sym)  (ùìãùìáùí∂ p ‚à∑ []))
                   {- What about a reflexitivity proof? -}
                   or-else unify goal (con (quote refl) [])
                   {- Perhaps equals-for-equals? -}
                   or-else do œÑ ‚Üê inferType goal
                              _ , _ , l , r ‚Üê ‚â°-type-info œÑ
                              unify goal ((def (quote cong) (ùìãùìáùí∂ ($-head l) ‚à∑ ùìãùìáùí∂ p ‚à∑ [])))

{- Same proof yields four theorems! -}
_ : {A : Set} {x y : A} {f : A ‚Üí A} (p : x ‚â° y)  ‚Üí  x ‚â° y  √ó  y ‚â° x  √ó  y ‚â° y  √ó  f x ‚â° f y
_ = Œª p ‚Üí apply‚ÇÄ p , apply‚ÇÄ p , apply‚ÇÄ p , apply‚ÇÄ p
 #+END_SRC

 It is interesting to note that on non ‚â°-terms, ~apply‚ÇÄ~ is just a no-op ---as
 specified by the first clause of the ~_or-else_~ construct.
 #+BEGIN_SRC agda
_ : ‚àÄ {A : Set} {x : A} ‚Üí  apply‚ÇÄ x  ‚â°  x
_ = refl
 #+END_SRC

*** COMMENT ‚ü®NO‚ü© Heuristic for Writing a Macro        :too_much_a_tutorial:
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Heuristic-for-Writing-a-Macro
   :END:

 I have found the following stepwise refinement approach to be useful in constructing
 macros. ‚îÄTest Driven Development in a proof-centric setting‚îÄ

 1. Write a no-op macro: ~mymacro p goal = unify p goal~.
 1. Write the test case ~mymacro p ‚â° p~.
 2. Feel good, you've succeeded.
 3. Alter the test ever so slightly to become closer to your goal.
 4. The test now breaks, go fix it.
 5. Go to step 3.

 For example, suppose we wish to consider proofs ~p~ of expressions of the form ~h x ‚â° y~
 and our macro is intended to obtain the function ~h~. We proceed as follows:
 0. Postulate ~x, y, h, p~ so the problem is well posed.
 1. Use the above approach to form a no-op macro.
 2. Refine the test to ~mymacro p ‚â° Œª e ‚Üí 0~ and refine the macro as well.
 3. Refine the test to ~mymacro p ‚â° Œª e ‚Üí e~ and refine the macro as well.
 4. Eventually succeeded in passing the desired test ~mymacro p ‚â° Œª e ‚Üí h e~
     ‚îÄthen eta reduce.

    Along the way, it may be useful to return the /string/ name of ~h~
    or rewrite the test as ~_‚â°_ {Level.zero} {‚Ñï ‚Üí ‚Ñï} (mymacro p) ‚â° ‚ãØ~.
    This may provide insight on how to repair or continue with macro construction.

 5. Throw away the postultes, one at a time, making them arguments declared in the test;
     refine macro each time so the test continues to pass as each postulate is removed.
     Each postulate removal may require existing helper functions to be altered.

 6. We have considered function applications, then variable funcctions, finally
    consider constructors. Ensure tests cover all these, for this particular problem.

 *Exercise:* Carry this through to produce the above discussed example macro, call it ~‚â°-head~. To help you on your
 way, here is a useful function:
 #+BEGIN_SRC agda
{- If we have ‚Äúf $ args‚Äù return ‚Äúf‚Äù. -}
$-head : Term ‚Üí Term
$-head (var v args) = var v []
$-head (con c args) = con c []
$-head (def f args) = def f []
$-head (pat-lam cs args) = pat-lam cs []
$-head t = t
 #+END_SRC
 :Solution:
 #+BEGIN_SRC agda

postulate ùíΩ : ‚Ñï ‚Üí ‚Ñï
postulate ùíπ ùìÆ : ‚Ñï
postulate ùìÖùíª : ùíΩ ùíπ ‚â° ùìÆ
postulate ùìÖùíª' : suc ùíπ ‚â° ùìÆ

macro
  ‚â°-head : Term ‚Üí Term ‚Üí TC ‚ä§
  ‚â°-head p goal = do œÑ ‚Üê inferType p
                     _ , _ , l , _ ‚Üê ‚â°-type-info œÑ
                     {- Could have used ‚Äòr‚Äô here as well. -}
                     unify goal ($-head l)

_ : quoteTerm (left ùìÖùíª) ‚â° def (quote ùíΩ) [ ùìãùìáùí∂ (quoteTerm ùíπ) ]
_ = refl

_ : ‚â°-head ùìÖùíª ‚â° ùíΩ
_ = refl

_ : ‚â°-head ùìÖùíª' ‚â° suc
_ = refl

_ : ‚àÄ {g : ‚Ñï ‚Üí ‚Ñï} {pf‚Ä≥ : g ùíπ ‚â° ùìÆ} ‚Üí ‚â°-head pf‚Ä≥ ‚â° g
_ = refl

_ : ‚àÄ {l r : ‚Ñï} {g : ‚Ñï ‚Üí ‚Ñï} {pf‚Ä≥ : g l ‚â° r} ‚Üí ‚â°-head pf‚Ä≥ ‚â° g
_ = refl

_ : ‚àÄ {l r s : ‚Ñï} {p : l + r ‚â° s} ‚Üí ‚â°-head p ‚â° _+_
_ = refl
 #+END_SRC
 :End:


 With the ability to obtain functions being applied in propositional equalities,
 we can now turn to lifiting a proof from ~x ‚â° y~ to suffice proving ~f x ‚â° f y~.
 We start with the desired goal and use the stepwise refinement approach outlined
 earlier to arrive at:
 #+BEGIN_SRC agda
macro
  apply‚ÇÑ : Term ‚Üí Term ‚Üí TC ‚ä§
  apply‚ÇÑ p goal = try (do œÑ ‚Üê inferType goal
                          _ , _ , l , r ‚Üê ‚â°-type-info œÑ
                          unify goal ((def (quote cong) (ùìãùìáùí∂ ($-head l) ‚à∑ ùìãùìáùí∂ p ‚à∑ []))))
                  or-else unify goal p

_ : ‚àÄ {x y : ‚Ñï} {f : ‚Ñï ‚Üí ‚Ñï} (p : x ‚â° y)  ‚Üí f x ‚â° f y
_ = Œª p ‚Üí apply‚ÇÑ p

_ : ‚àÄ {x y : ‚Ñï} {f g : ‚Ñï ‚Üí ‚Ñï} (p : x ‚â° y)
    ‚Üí  x ‚â° y
    -- ‚Üí  f x ‚â° g y {- ‚Äúapply‚ÇÑ p‚Äù now has a unification error ^_^ -}
_ = Œª p ‚Üí apply‚ÇÑ p
 #+END_SRC

*** COMMENT What about somewhere deep within a subexpression?
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-What-about-somewhere-deep-within-a-subexpression
   :END:

 Consider,
 #+BEGIN_EXAMPLE agda
             suc X + (X * suc X + suc X)
           ‚â°‚ü® cong (Œª it ‚Üí suc X + it) (+-suc _ _) ‚ü©
             suc X + suc (X * suc X + X)
 #+END_EXAMPLE
 Can we find ~(Œª it ‚Üí suc X + it)~ mechanically ;-)

 Using the same refinement apporach outlined earlier, we begin with the following
 working code then slowly, one piece at a time, replace the whole thing with an
 ~unquote (unify (quoteTerm ‚ãØworkingCodeHere‚ãØ))~. Then we push the ~quoteTerm~
 further in as much as possible and construct the helper functions to make
 this transation transpire.
 #+BEGIN_SRC agda
open import Data.Nat.Properties
{- +-suc : ‚àÄ m n ‚Üí m + suc n ‚â° suc (m + n) -}

test‚ÇÄ : ‚àÄ {m n k : ‚Ñï} ‚Üí k + (m + suc n) ‚â° k + suc (m + n)
test‚ÇÄ {m} {n} {k} = cong (k +_) (+-suc m n)
 #+END_SRC

 Let's follow the aforementioned approach by starting out with some postulates.
 #+BEGIN_SRC agda
postulate ùí≥ : ‚Ñï
postulate ùí¢ : suc ùí≥ + (ùí≥ * suc ùí≥ + suc ùí≥)  ‚â°  suc ùí≥ + suc (ùí≥ * suc ùí≥ + ùí≥)

ùíÆùí≥ : Arg Term
ùíÆùí≥ = ùìãùìáùí∂ (con (quote suc) [ ùìãùìáùí∂ (quoteTerm ùí≥) ])

ùí¢À° ùí¢ ≥ : Term
ùí¢À° = def (quote _+_) (ùíÆùí≥ ‚à∑ ùìãùìáùí∂ (def (quote _+_) (ùìãùìáùí∂ (def (quote _*_) (ùìãùìáùí∂ (quoteTerm ùí≥) ‚à∑ ùíÆùí≥ ‚à∑ [])) ‚à∑ ùíÆùí≥ ‚à∑ [])) ‚à∑ [])
ùí¢ ≥ = def (quote _+_) (ùíÆùí≥ ‚à∑ ùìãùìáùí∂ (con (quote suc) [ ùìãùìáùí∂ (def (quote _+_) (ùìãùìáùí∂ (def (quote _*_) (ùìãùìáùí∂ (quoteTerm ùí≥) ‚à∑ ùíÆùí≥ ‚à∑ [])) ‚à∑ ùìãùìáùí∂ (quoteTerm ùí≥) ‚à∑ [])) ]) ‚à∑ [])
 #+END_SRC

 It seems that the left and right sides of ùí¢ ‚Äúmeet‚Äù at ~def (quote _+_) (ùíÆùí≥ ‚à∑ [])~:
 We check the equality of the quoted operator, ~_+_~, then recursively check the arguments.
 Whence the following naive algorithm:
 #+BEGIN_SRC agda
{- Should definitily be in the standard library -}
‚åä_‚åã : ‚àÄ {a} {A : Set a} ‚Üí Dec A ‚Üí ùîπ
‚åä yes p ‚åã = true
‚åä no ¬¨p ‚åã = false

import Agda.Builtin.Reflection as Builtin

_$-‚âü_ : Term ‚Üí Term ‚Üí ùîπ
con c args $-‚âü con c' args' = Builtin.primQNameEquality c c'
def f args $-‚âü def f' args' = Builtin.primQNameEquality f f'
var x args $-‚âü var x' args' = ‚åä x Nat.‚âü x' ‚åã
_ $-‚âü _ = false

{- Only gets heads and as much common args, not anywhere deep. :'( -}
infix 5 _‚äì_
{-# TERMINATING #-} {- Fix this by adding fuel (con c args) ‚âî 1 + length args -}
_‚äì_ : Term ‚Üí Term ‚Üí Term
l ‚äì r with l $-‚âü r | l | r
...| false | x | y = unknown
...| true | var f args | var f' args' = var f (List.zipWith (Œª{ (arg i!! t) (arg j!! s) ‚Üí arg i!! (t ‚äì s) }) args args')
...| true | con f args | con f' args' = con f (List.zipWith (Œª{ (arg i!! t) (arg j!! s) ‚Üí arg i!! (t ‚äì s) }) args args')
...| true | def f args | def f' args' = def f (List.zipWith (Œª{ (arg i!! t) (arg j!! s) ‚Üí arg i!! (t ‚äì s) }) args args')
...| true | ll | _ = ll {- Left biased; using ‚Äòunknown‚Äô does not ensure idempotence. -}
 #+END_SRC

 # You would think the ~var~ and ~con~ cases /should/ also be considered, but they're not. Why is that?
 #
 The bodies have names involving ~!!~, this is to indicate a location of improvement.
 Indeed, this naive algorithm ignores visibility and relevance of arguments ‚îÄfar from ideal.

 Joyously this works!  üòÇ
 #+BEGIN_SRC agda
_ : ùí¢À° ‚äì ùí¢ ≥ ‚â° def (quote _+_) (ùíÆùí≥ ‚à∑ ùìãùìáùí∂ unknown ‚à∑ [])
_ = refl

{- test using argument function ùí∂ and argument number X -}
_ : {X : ‚Ñï} {ùí∂ : ‚Ñï ‚Üí ‚Ñï}
  ‚Üí
    let gl = quoteTerm (ùí∂ X + (X * ùí∂ X + ùí∂ X))
        gr = quoteTerm (ùí∂ X + ùí∂ (X * ùí∂ X + X))
    in gl ‚äì gr ‚â° def (quote _+_) (ùìãùìáùí∂ (var 0 [ ùìãùìáùí∂ (var 1 []) ]) ‚à∑ ùìãùìáùí∂ unknown ‚à∑ [])
_ = refl
 #+END_SRC
 The ~unknown~ terms are far from desirable ‚îÄwe ought to replace them with sections; i.e., an anonoymous lambda.
 My naive algorithm to achieve a section from a term containing ‚Äòunknown‚Äôs is as follows:
 1. Replace every ~unknown~ with a De Bruijn index.
 2. Then, find out how many unknowns there are, and for each, stick an anonoymous lambda at the front.
    + Sticking a lambda at the front breaks existing De Bruijn indices, so increment them for each lambda.

 There is clear inefficiency here, but I'm not aiming to be efficient, just believable to some degree.

 #+BEGIN_SRC agda
{- ‚Äòunknown‚Äô goes to a variable, a De Bruijn index -}
unknown-elim : ‚Ñï ‚Üí List (Arg Term) ‚Üí List (Arg Term)
unknown-elim n [] = []
unknown-elim n (arg i unknown ‚à∑ xs) = arg i (var n []) ‚à∑ unknown-elim (n + 1) xs
unknown-elim n (arg i (var x args) ‚à∑ xs) = arg i (var (n + suc x) args) ‚à∑ unknown-elim n xs
unknown-elim n (arg i x ‚à∑ xs)       = arg i x ‚à∑ unknown-elim n xs
{- Essentially we want: body(unknown·µ¢)  ‚áí  Œª _ ‚Üí body(var 0)
   However, now all ‚Äúvar 0‚Äù references in ‚Äúbody‚Äù refer to the wrong argument;
   they should now refer to ‚Äúi more lambdas away than before‚Äù. -}

unknown-count : List (Arg Term) ‚Üí ‚Ñï
unknown-count [] = 0
unknown-count (arg i unknown ‚à∑ xs) = 1 + unknown-count xs
unknown-count (arg i _ ‚à∑ xs) = unknown-count xs

unknown-Œª : ‚Ñï ‚Üí Term ‚Üí Term
unknown-Œª zero body = body
unknown-Œª (suc n) body = unknown-Œª n (Œªùìã "section" ‚Ü¶ body)

{- Replace ‚Äòunknown‚Äô with sections -}
patch : Term ‚Üí Term
patch it@(def f args) = unknown-Œª (unknown-count args) (def f (unknown-elim 0 args))
patch it@(var f args) = unknown-Œª (unknown-count args) (var f (unknown-elim 0 args))
patch it@(con f args) = unknown-Œª (unknown-count args) (con f (unknown-elim 0 args))
patch t = t
 #+END_SRC

 Putting meet, ~_‚äì_~, and this ~patch~ together into a macro:
 #+BEGIN_SRC agda
macro
  spine : Term ‚Üí Term ‚Üí TC ‚ä§
  spine p goal
    = do œÑ ‚Üê inferType p
         _ , _ , l , r ‚Üê ‚â°-type-info œÑ
         unify goal (patch (l ‚äì r))
 #+END_SRC

 The expected tests pass ‚îÄso much joy :joy:
 #+BEGIN_SRC agda
_ : spine ùí¢ ‚â° suc ùí≥ +_
_ = refl

module testing-postulated-functions where
  postulate ùí∂ : ‚Ñï ‚Üí ‚Ñï
  postulate _ùí∑_ : ‚Ñï ‚Üí ‚Ñï ‚Üí ‚Ñï
  postulate ùì∞ : ùí∂ ùí≥  ùí∑  ùí≥  ‚â°  ùí∂ ùí≥  ùí∑  ùí∂ ùìç

  _ : spine ùì∞ ‚â° (ùí∂ ùí≥ ùí∑_)
  _ = refl

_ : {X : ‚Ñï} {G : suc X + (X * suc X + suc X)  ‚â°  suc X + suc (X * suc X + X)}
  ‚Üí quoteTerm G ‚â° var 0 []
_ = refl
 #+END_SRC

 The tests for ~‚â°-head~ still go through using ~spine~
 which can thus be thought of as a generalisation ;-)
 :OlderTests:
 #+BEGIN_SRC agda
_ : spine ùìÖùíª ‚â° ùíΩ
_ = refl

_ : spine ùìÖùíª' ‚â° suc
_ = refl

_ : ‚àÄ {g : ‚Ñï ‚Üí ‚Ñï} {pf‚Ä≥ : g ùíπ ‚â° ùìÆ} ‚Üí spine pf‚Ä≥ ‚â° g
_ = refl

_ : ‚àÄ {l r : ‚Ñï} {g : ‚Ñï ‚Üí ‚Ñï} {pf‚Ä≥ : g l ‚â° r} ‚Üí spine pf‚Ä≥ ‚â° g
_ = refl

_ : ‚àÄ {l r s : ‚Ñï} {p : l + r ‚â° s} ‚Üí spine p ‚â° _+_
_ = refl
 #+END_SRC
 :End:

 Now the original problem is dealt with as a macro:
 #+BEGIN_SRC agda
macro
  apply‚ÇÖ : Term ‚Üí Term ‚Üí TC ‚ä§
  apply‚ÇÖ p hole
    = do œÑ ‚Üê inferType hole
         _ , _ , l , r ‚Üê ‚â°-type-info œÑ
         unify hole ((def (quote cong)
              (ùìãùìáùí∂ (patch (l ‚äì r)) ‚à∑ ùìãùìáùí∂ p ‚à∑ [])))
 #+END_SRC

 Curious, why in the following tests we cannot simply use ~+-suc _ _~?
 #+BEGIN_SRC agda
_ : suc ùí≥ + (ùí≥ * suc ùí≥ + suc ùí≥)  ‚â°  suc ùí≥ + suc (ùí≥ * suc ùí≥ + ùí≥)
_ = apply‚ÇÖ (+-suc (ùí≥ * suc ùí≥) ùí≥)

test : ‚àÄ {m n k : ‚Ñï} ‚Üí k + (m + suc n) ‚â° k + suc (m + n)
test {m} {n} {k} = apply‚ÇÖ (+-suc m n)
 #+END_SRC

 This is super neat stuff ^_^

*** TODO COMMENT ‚ü®NO‚ü© ‚Äútest‚Äù macro
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-test-macro
   :END:

 test t ‚Ü¶   _ : t; _ = refl

 Agda has no support for ,@list style &rest args like in lisp :'(

*** COMMENT ‚ü®NO‚ü© nope, not here yet
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-nope-not-here-yet
   :END:
 Let's use this. Below is an extraction of one of the first assignments for a class
 I taught this year ‚îÄCompSci 3EA3 Specfications and Correctness. Unfortunately, the
 ~cong~ and explicit associativity made Agda appear a bit clunky at first; let's change that
 impression.
 #+BEGIN_SRC agda
open import Relation.Binary.PropositionalEquality using () renaming (refl to definition-chasing)
open import Data.Nat.Properties

module PrerequisiteExam where

  open ‚â°-Reasoning

  lemma : ‚àÄ (X : ‚Ñï) ‚Üí Œ£[ m ‚àà ‚Ñï ] (2 * m  ‚â°  X * X + X)
  lemma zero    = 0 , refl
  lemma (suc X) = m , sym pf
    where
      inductive-hypothesis = lemma X
      m' = proj‚ÇÅ inductive-hypothesis
      pf' = proj‚ÇÇ inductive-hypothesis

      m = suc X + m'

      pf = begin
             {- We start with the rhs, since it's more complicated. -}
             (suc X) * (suc X) + (suc X)
           ‚â°‚ü® definition-chasing ‚ü©
             {- Go into the hole blow and enter C-c C-Enter to fill it. -}
             (suc X + X * suc X) + suc X
           ‚â°‚ü® +-assoc (suc X) (X * suc X) (suc X) ‚ü©
             {- We have to explicitly invoke associativity! -}
             suc X + (X * suc X + suc X)
           ‚â°‚ü® cong (Œª it ‚Üí suc X + it) (+-suc _ _) ‚ü©
             {- We also have to explicitly invoke congruence,
                similar to using monotonicity in 2DM3. -}
             suc X + suc (X * suc X + X)
           ‚â°‚ü® cong (Œª it ‚Üí suc X + suc (it + X)) (*-comm X (suc X)) ‚ü©
             suc X + suc (suc X * X + X)
           ‚â°‚ü® definition-chasing ‚ü©
             {- Definition chasing (reflexivity) steps are optional,
                but we'll often put them in for readability. -}
             suc X + suc (X + X * X + X)
           ‚â°‚ü® cong (Œª it ‚Üí suc X + suc it) (+-assoc X (X * X) X) ‚ü©
             suc X + suc (X + (X * X + X))
           ‚â°‚ü® cong (Œª it ‚Üí suc X + suc (X + it)) (sym pf') ‚ü©
             {- Here we can use the induction hypothesis. -}
             suc X + suc (X + 2 * m')
           ‚â°‚ü® definition-chasing ‚ü©
             suc X + (suc X + 2 * m')
           ‚â°‚ü® sym (+-assoc (suc X) (suc X) (2 * m')) ‚ü©
             (suc X + suc X) + 2 * m'
           ‚â°‚ü® cong (Œª it ‚Üí (suc X + it) + 2 * m') (sym (+-identity ≥ _)) ‚ü©
             (suc X + (suc X + 0)) + 2 * m'
           ‚â°‚ü® definition-chasing ‚ü©
             2 * suc X + 2 * m'
           ‚â°‚ü® sym (*-distribÀ°-+ 2 (suc X) m') ‚ü©
             2 * (suc X + m')
           ‚â°‚ü® definition-chasing ‚ü©
             {- (suc X + m') looks like a good candidate for m,
                so we can define m to be it by filling the hole for m above. -}
             2 * m
           ‚àé
 #+END_SRC

 Takes II:
 #+BEGIN_SRC agda
macro
  apply : Term ‚Üí Term ‚Üí TC ‚ä§
  apply p goal = try (do œÑ ‚Üê inferType goal
                         _ , _ , l , r ‚Üê ‚â°-type-info œÑ
                         unify goal ((def (quote cong) (ùìãùìáùí∂ ($-head l) ‚à∑ ùìãùìáùí∂ p ‚à∑ []))))
                 or-else try unify goal (def (quote sym) (ùìãùìáùí∂ p ‚à∑ []))
                         or-else try unify goal p
                                 or-else unify goal (con (quote refl) [])

module ‚â°-Reasoning-with-tactics {a} {A : Set a} where

  open ‚â°-Reasoning public hiding (_‚â°‚ü®_‚ü©_)

  -- infixr 2 _‚â°‚ü®_‚ü©_

  -- _‚â°‚ü®_‚ü©_ : ‚àÄ (x {y z} : A) ‚Üí x ‚â° y ‚Üí y ‚â° z ‚Üí x ‚â° z
  -- _ ‚â°‚ü® x‚â°y ‚ü© y‚â°z = trans (apply x‚â°y) y‚â°z

open import Relation.Binary.PropositionalEquality using () renaming (refl to definition-chasing)
open import Data.Nat.Properties

module my/‚â°-Reasoning where -- {a} {A : Set a} where

  private
    a = Level.zero
    A = ‚Ñï

  infix  3 _‚àé
  infixr 2 _‚â°‚ü®‚ü©_ _‚â°‚ü®_‚ü©_ _‚â°Àò‚ü®_‚ü©_
  infix  1 begin_

  begin_ : ‚àÄ{x y : A} ‚Üí x ‚â° y ‚Üí x ‚â° y
  begin_ x‚â°y = x‚â°y

  _‚â°‚ü®‚ü©_ : ‚àÄ (x {y} : A) ‚Üí x ‚â° y ‚Üí x ‚â° y
  _ ‚â°‚ü®‚ü© x‚â°y = x‚â°y

  _‚â°‚ü®_‚ü©_ : ‚àÄ (x {y z} : A) ‚Üí x ‚â° y ‚Üí y ‚â° z ‚Üí x ‚â° z
  _ ‚â°‚ü® x‚â°y ‚ü© y‚â°z = trans x‚â°y y‚â°z

  infixr 2 _‚â°‚ü®_‚ü©'_
  macro
    _‚â°‚ü®_‚ü©'_ : ‚àÄ (x {y} : A) (x‚â°y : x ‚â° y) (y‚â°z : Term) ‚Üí Term ‚Üí TC ‚ä§
    _‚â°‚ü®_‚ü©'_ xx x‚â°y y‚â°z hole
      = do œÑ ‚Üê inferType y‚â°z
           _ , _ , `y , `z ‚Üê ‚â°-type-info œÑ
           -- y ‚Üê unquoteTC {Level.zero} {‚Ñï} l
           -- x‚âày ‚Üê unquoteTC {Level.zero} {xx ‚â° y} x‚â°y
           x‚âày ‚Üê quoteTC x‚â°y
           `x  ‚Üê quoteTC xx
           unify hole (def (quote trans) (
                   ùíΩùìáùí∂ (quoteTerm Level.zero)
                 ‚à∑ ùíΩùìáùí∂ (quoteTerm ‚Ñï)
                 ‚à∑ ùíΩùìáùí∂ `x
                 ‚à∑ ùíΩùìáùí∂ `y
                 ‚à∑ ùíΩùìáùí∂ `z
                 ‚à∑
                 ùìãùìáùí∂ x‚âày ‚à∑ ùìãùìáùí∂ y‚â°z ‚à∑ []))
    -- trans x‚â°y y‚â°z

  _‚â°Àò‚ü®_‚ü©_ : ‚àÄ (x {y z} : A) ‚Üí y ‚â° x ‚Üí y ‚â° z ‚Üí x ‚â° z
  _ ‚â°Àò‚ü® y‚â°x ‚ü© y‚â°z = trans (sym y‚â°x) y‚â°z

  _‚àé : ‚àÄ (x : A) ‚Üí x ‚â° x
  _‚àé _ = refl

module PrerequisiteExam‚îÄwith‚îÄtactics where

  open my/‚â°-Reasoning -- {Level.zero} {‚Ñï} -- -with-tactics

  lemma : ‚àÄ (X : ‚Ñï) ‚Üí Œ£[ m ‚àà ‚Ñï ] (2 * m  ‚â°  X * X + X)
  lemma zero    = 0 , refl
  lemma (suc X) = m , sym pf
    where
      inductive-hypothesis = lemma X
      m' = proj‚ÇÅ inductive-hypothesis
      pf' = proj‚ÇÇ inductive-hypothesis

      m = suc X + m'

      -- neato
      _ : X + (m + suc m') ‚â° X + suc (m + m')
      _ = apply‚ÇÖ (+-suc m m')

      _ : X + (m + suc m') ‚â° X + suc (m + m')
      _ = begin (
          _‚â°‚ü®_‚ü©_  (X + (m + suc m'))
                  {X + suc (m + m')} {X + suc (m + m')} {- items that could not be inferred -}
                  (apply‚ÇÖ (+-suc m m'))
                  (X + suc (m + m')‚àé))

      te : X + (m + suc m') ‚â° X + suc (m + m')
      -- te =  _‚â°‚ü®_‚ü©'_ (X + (m + suc m')) (apply‚ÇÖ (+-suc m m')) (refl {x = X + suc (m + m')})
      te = _‚â°‚ü®_‚ü©'_ (X + (m + suc m')) {y = X + suc (m + m')} (apply‚ÇÖ (+-suc m m')) (refl {x = X + suc (m + m')})
      -- begin X + (m + suc m') ‚â°‚ü® apply‚ÇÖ (+-suc m m') ‚ü©' (X + suc (m + m') ‚àé)
      -- apply‚ÇÖ (+-suc m m')

      {-
      _ : (suc X + X * suc X) + suc X  ‚â°  suc X + suc (X * suc X + X)
      _ = begin
             (suc X + X * suc X) + suc X
           ‚â°‚ü® +-assoc (suc X) (X * suc X) (suc X) ‚ü©
             suc X + (X * suc X + suc X)
           ‚â°‚ü® it ‚ü© -- apply‚ÇÖ (+-suc (X * suc X) X) ‚ü©
             suc X + suc (X * suc X + X)
           ‚àé
           where it :  suc (X + (X * suc X + suc X)) ‚â° suc (X + suc (X * suc X + X))
                 it = apply‚ÇÖ (+-suc {!!} {!!})
      -}

      pf : (suc X + X * suc X) + suc X  ‚â°  2 * m
      pf = begin
             (suc X + X * suc X) + suc X
           ‚â°‚ü® +-assoc (suc X) (X * suc X) (suc X) ‚ü©
             suc X + (X * suc X + suc X)
           ‚â°‚ü® cong (Œª it ‚Üí suc X + it) (+-suc _ _) ‚ü© -- apply‚ÇÖ (+-suc (X * suc X) X) ‚ü© -- cong (Œª it ‚Üí suc X + it) (+-suc _ _) ‚ü©
             suc X + suc (X * suc X + X)
           ‚â°‚ü® cong (Œª it ‚Üí suc X + suc (it + X)) (*-comm X (suc X)) ‚ü©
             suc X + suc (X + X * X + X)
           ‚â°‚ü® cong (Œª it ‚Üí suc X + suc it) (+-assoc X (X * X) X) ‚ü©
             suc X + suc (X + (X * X + X))
           ‚â°‚ü® cong (Œª it ‚Üí suc X + suc (X + it)) (sym pf') ‚ü©
             suc X + (suc X + 2 * m')
           ‚â°‚ü® apply (+-assoc (suc X) (suc X) (2 * m')) ‚ü© -- no sym ‚ô•‚Äø‚ô•
             (suc X + suc X) + 2 * m'
           ‚â°‚ü® cong (Œª it ‚Üí (suc X + it) + 2 * m') (sym (+-identity ≥ _)) ‚ü©
             (suc X + (suc X + 0)) + 2 * m'
           ‚â°‚ü® definition-chasing ‚ü©
             2 * suc X + 2 * m'
           ‚â°‚ü® apply (*-distribÀ°-+ 2 (suc X) m') ‚ü©  -- no sym ‚ô•‚Äø‚ô•
             2 * (suc X + m')
           ‚â°‚ü® definition-chasing ‚ü©
             2 * m
           ‚àé
 #+END_SRC

*** COMMENT ‚ü®NO‚ü© Flatenning ‚îÄ& mixins ‚îÄanaphoric macros in Agda?
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Flatenning-mixins-anaphoric-macros-in-Agda
   :END:

 #+BEGIN_SRC agda

data Empty : Set‚ÇÅ where

record Type : Set‚ÇÅ where
  field Carrier : Set

-- record Magma : Set‚ÇÅ where
--
-- Magma ‚âî Empty ‚ü´ Type ‚ü´ (Carrier ‚Üí Carrier ‚Üí Carrier)

{- Specfication

   field' name ‚à∂ type
‚âÖ  record Anon : TypeOf(type) where field name : type
‚âÖ  name : TypeOf(type)
   name = type

   œÑ ‚ü´ œÑ'
‚âÖ  anon : Set $ Typeof(œÑ) ‚äî Typeof (œÑ')
   anon = Œ£ t : œÑ ‚Ä¢ œÑ'

-}

macro
  _‚ü´_ : Term ‚Üí Term ‚Üí Term ‚Üí TC ‚ä§
  _‚ü´_ œÑ œÅ goal = do unify goal
                      (def (quote Œ£) (ùìãùìáùí∂ œÑ ‚à∑ ùìãùìáùí∂ œÅ ‚à∑ []))

testf : Set
testf = Char ‚ü´ Œª (x : Char) ‚Üí ‚Ñï

el : testf
el = 'c' , 0

--------------------------------------------------------

record Two : Set where
  field
   a : ‚Ñï
   b : ‚Ñï

-- get first field from a record
fields : Definition ‚Üí TC Name
fields (record' c (arg _ f ‚à∑ fs)) = return f
fields _ = typeError [ strErr "Nope: No fields" ]

macro
  field‚ÇÅ : Name ‚Üí Term ‚Üí TC ‚ä§
  field‚ÇÅ n goal = do œÑ ‚Üê getDefinition n; f ‚Üê fields œÑ; unify goal (def f [])

two‚ÇÇ : Two ‚Üí ‚Ñï
two‚ÇÇ = field‚ÇÅ Two

-- :smile: yay (‡∏á‡≤†_‡≤†)‡∏á

-- it would be nice to generate the names field·µ¢ rather than write them out by hand.

 #+END_SRC

*** TODO COMMENT ‚ü®NO‚ü© ideas
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-ideas
   :END:

 + deriving decidable equality

 #+BEGIN_EXAMPLE agda
data RGB : Set where
  Red Green Blue : RGB

_‚âü_ : (p q : RGB) ‚Üí Dec (p ‚â° q)

Red ‚âü Red = yes refl
Red ‚âü Green = no (Œª ())
Red ‚âü Blue = no (Œª ())

Green ‚âü Red = no (Œª ())
Green ‚âü Green = yes refl
Green ‚âü Blue = no (Œª ())

Blue ‚âü Red = no (Œª ())
Blue ‚âü Green = no (Œª ())
Blue ‚âü Blue = yes refl
 #+END_EXAMPLE

 + theory combinators

 #+BEGIN_SRC agda
macro
    plus-to-times : Term ‚Üí Term ‚Üí TC ‚ä§
    plus-to-times (def (quote _+_) (a ‚à∑ b ‚à∑ [])) hole = unify hole (def (quote _*_) (a ‚à∑ b ‚à∑ []))
    plus-to-times v hole = unify hole v

thm : (a b : ‚Ñï) ‚Üí plus-to-times (a + b) ‚â° a * b
thm a b = refl

 #+END_SRC

 + flatten: Take a nested record hierarchy and produce a flattened telescope, since
   records cannot be unquoted.

 + 2^50 * 3^313 ‚â°  3^313 * 2^50 is true by symmetry of *,
   but may timeout if we try to prove things by refl.

*** COMMENT ‚ü®NO‚ü© Further Reads
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Further-Reads
   :END:

+ Proof by Rewriting in Agda by Victor Miraldo
  - https://victorcmiraldo.github.io/data/MiraldoMsc.pdf
  - Use metaprogramming to infer substitutions from context in calculations;
    e.g., ~++-assoc ?‚ÇÅ ?‚ÇÇ ?‚ÇÉ~ generally has its arguments inferrable from context
    in a calculation, and this work aims to reduce explicitly providing such
    details.

    We have an example of this above? See ùí¢‚ÇÅ‚äìùí¢‚ÇÇ?
** nomargins                                                        :ignore:
#+latex: \nomargins
** The Problems
   :PROPERTIES:
   :CUSTOM_ID: The-Problems
   :END:
   <<sec:problems>>
# +latex: \label{sec:problems}

Let us begin anew by briefly reviewing the main problems, but this time directly
using Agda as the language of discourse.

 There are a number of problems when packaging up data, with the number of
 parameters being exposed being the pivotal concern. To exemplify the
 distinctions at the type level as more parameters are exposed, consider the
 following approaches to formalising a dynamical system ---a collection of
 states, a designated start state, and a transition function.

{{{code(Dynamical Systems)}}}
 #+begin_src agda  :tangle Context_examples.agda
record DynamicSystem‚ÇÄ : Set‚ÇÅ where
  field
    State  : Set
    start  : State
    next   : State ‚Üí State

record DynamicSystem‚ÇÅ (State : Set) : Set where
  field
    start : State
    next  : State ‚Üí State

record DynamicSystem‚ÇÇ (State : Set) (start : State) : Set where
  field
    next : State ‚Üí State
 #+end_src

 #+latex: \noindent
 Each =DynamicSystem·µ¢= is a type constructor of =i=-many arguments; but it is
 *the types of these constructors that provide insight into the sort of data they
 contain* as shown in the following table and discussed in Sections
 ref:sec:examples:IsX and ref:sec:examples:readability.
  #+latex: \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]
 | Type           | Kind                      |
 |----------------+---------------------------|
 | =DynamicSystem‚ÇÄ= | =Set‚ÇÅ=                      |
 | =DynamicSystem‚ÇÅ= | =Œ† X ‚à∂ Set ‚Ä¢ Set=           |
 | =DynamicSystem‚ÇÇ= | =Œ† X ‚à∂ Set ‚Ä¢ Œ† x ‚à∂ X ‚Ä¢ Set= |
 #+latex: \end{tcolorbox}
 :AgdaCheckedEvidence:
{{{code( ? )}}}
#+begin_src agda  :tangle Context_examples.agda
_ : Set‚ÇÅ
_ = DynamicSystem‚ÇÄ

_ : Œ† X ‚à∂ Set ‚Ä¢ Set
_ = DynamicSystem‚ÇÅ

_ : Œ† X ‚à∂ Set ‚Ä¢ Œ† x ‚à∂ X ‚Ä¢ Set
_ = DynamicSystem‚ÇÇ
 #+end_src
 :End:

 # Below: (The \" here is a ``trema'', not an ``Umlaut''.)
 #+latex: \noindent
 Recall, say from Section ref:sec:PF:problem_statement, that we refer to the
 concern of moving from a record to a parameterised record as
 #+latex: \textbf{the unbundling problem}\footcitet{packaging_mathematical_structures}.
 For example, moving from the
 /type/ src_agda[:exports code]{Set‚ÇÅ} to the /function type/ @@latex:\quad@@
 src_agda[:exports code]{Œ† X ‚à∂ Set ‚Ä¢ Set} @@latex:\quad@@ gets us from
 ~DynamicSystem‚ÇÄ~ to something resembling ~DynamicSystem‚ÇÅ~, which we arrive at if we
 can obtain a /type constructor/ of the form @@latex:\quad@@ src_agda[:exports code]{Œª X ‚à∂ Set
 ‚Ä¢ ‚ãØ}. @@latex:$\,$@@ We shall refer to the latter change as @@latex:
 \emph{re\"{\i}fication}@@ since the result is more concrete: It can be
 applied. This transformation will be denoted by ~Œ†‚ÜíŒª~. To clarify this subtlety,
 consider the following forms of the /type/ of the polymorphic identity
 function. Notice that $\mathsf{id}œÑ·µ¢$ /exposes/ ùíæ-many details at the type level
 to indicate the sort of data it consists of. However, notice that
 src_agda[:exports code]{id‚ÇÄ} is a *type of functions* whereas src_agda[:exports
 code]{id‚ÇÅ} is a *function on types*. Indeed, the final form is derived from the
 first one: src_agda[:exports code]{idœÑ‚ÇÇ = Œ†‚ÜíŒª idœÑ‚ÇÄ}. This equation is true by
 src_emacs-lisp[:exports code]{refl}exivity, as shown below.

 {{{code( Polymorphic Identity Functions )}}}
 #+begin_src agda  :tangle Context_examples.agda
idœÑ‚ÇÄ : Set‚ÇÅ
idœÑ‚ÇÄ = Œ† X ‚à∂ Set ‚Ä¢ Œ† e ‚à∂ X ‚Ä¢ X

idœÑ‚ÇÅ : Œ† X ‚à∂ Set ‚Ä¢ Set
idœÑ‚ÇÅ = Œª (X : Set) ‚Üí Œ† e ‚à∂ X ‚Ä¢ X

idœÑ‚ÇÇ : Œ† X ‚à∂ Set ‚Ä¢ Œ† e ‚à∂ X ‚Ä¢ Set
idœÑ‚ÇÇ = Œª (X : Set) (e : X) ‚Üí X

{- Surprisingly, the latter is derivable from the former -}
_ : idœÑ‚ÇÇ ‚â° Œ†‚ÜíŒª idœÑ‚ÇÄ
_ = refl

{- The relationship with idœÑ‚ÇÅ is clarified later when we get to _:waist_ -}
#+end_src

 #+latex: \noindent
 Of course, there is also the need for descriptions of values, which leads to
 term datatypes. We shall refer to the shift from record types to algebraic data
 types as *the termtype problem*.  Our aim is to obtain all of these notions ---of
 ways to group data together--- from a single user-friendly context declaration,
 using monadic notation.

 :Ignore:
 Mark: Maybe a note that State = DSTerms‚ÇÄ in the first one? Whereas DSTerms·µ¢ ‚àà State for i = 1,2.
{{{code( ? )}}}
 #+begin_src agda  :tangle no
data DSTerms‚ÇÄ : Set where
  start : DSTerms‚ÇÄ
  next  : DSTerms‚ÇÄ ‚Üí DSTerms‚ÇÄ

data DSTerms‚ÇÅ (State : Set) : Set where
  start : State ‚Üí DSTerms‚ÇÅ State
  next  : DSTerms‚ÇÅ State ‚Üí DSTerms‚ÇÅ State

data DSTerms‚ÇÇ (State : Set) (start : State) : Set where
  next : DSTerms‚ÇÇ State start ‚Üí DSTerms‚ÇÇ State start
 #+end_src

 Yet another way to encode dynamical systems would be by their syntax, as it
 would be desirable when serialising them ---i.e., to obtain first-class
 descriptions of dynamical system values.


 Notice that the first algebraic data type is isomorphic to ~‚Ñï~, whereas the
 remaining two are isomorphic to ~State √ó ‚Ñï~ which keeps track of how many =next=
 steps are necessary until a =State= value is reached ---this may be called
 =Eventually State=.
 The ~DSTerms·µ¢~ share the same pattern of kind exposure as the ~DynamicSystem·µ¢~ types.

 AgdaCheckedEvidence
{{{code( ? )}}}
 #+begin_src agda  :tangle no
_ : Set
_ = DSTerms‚ÇÄ

_ : Œ† X ‚à∂ Set ‚Ä¢ Set
_ = DSTerms‚ÇÅ

_ : Œ† X ‚à∂ Set ‚Ä¢ Œ† x ‚à∂ X ‚Ä¢ Set
_ = DSTerms‚ÇÇ
 #+end_src
 :End:

 # +latex: \noindent
** Monadic Notation
   :PROPERTIES:
   :CUSTOM_ID: Monadic-Notation
   :END:
   <<sec:monadic-notation>>
# +latex: \label{sec:monadic-notation}

   There is little use in an idea that is difficult to use in practice.  As such,
   we conflate records and termtypes by starting with an ideal syntax they would
   share, then derive the necessary artefacts that permit it. As discussed at
   the start of the chapter, our choice of
   syntax is monadic src_haskell[:exports code]{do}-notation
   \cite{DBLP:journals/iandc/Moggi91,DBLP:conf/haskell/MarlowJKM16}:

{{{code( Idealised syntax for one source of truth )}}}
 #+begin_src agda :tangle no
DynamicSystem : Context ‚Ñì‚ÇÅ
DynamicSystem = do State ‚Üê Set
                   start ‚Üê State
                   next  ‚Üê (State ‚Üí State)
                   End
 #+end_src
  #+begin_src agda :exports none :tangle Context_examples.agda
DynamicSystem : Context ‚Ñì‚ÇÅ
DynamicSystem = do State ‚Üê Set
                   start ‚Üê State
                   next  ‚Üê (State ‚Üí State)
                   End {‚Ñì‚ÇÄ}
 #+end_src
  #+latex: \noindent
  Here ~Context, End~, and the underlying monadic bind operator are unknown.
  Since we want to be able to /expose/ a number of fields at will, we may take
  ~Context~ to be types indexed by a number denoting exposure.  Moreover, since
  records are product types, we expect there to be a recursive definition whose
  base case will be the identity of products, the unit type src_haskell[:exports
  code]{ùüô} ---which corresponds to src_agda[:exports code]{‚ä§} in the Agda
  standard library and to src_haskell[:exports code]{()} in Haskell.  The
  following table shows example exposure ‚Äòwaists‚Äô for the =DynamicSystem= context.

  # +latex: \newunicodechar{Œ£}{\ensuremath{\color{red}\Sigma}}

# The newunicodechar package says that a \newunicodechar{X}{Y} clause
# can be rendered using \@namedef.
# https://ctan.math.illinois.edu/macros/latex/contrib/newunicodechar/newunicodechar.pdf
# Since \newunicodechar can only be used in LaTeX header, we make an org macro.
#+macro: newunicodechar  @@latex: \makeatletter\@namedef{u8:\detokenize{$1}}{$2}\makeatother @@


# Temporarily switch to coloured Œ£,Œ† so the ‚Äútriangles‚Äù look noticable
{{{newunicodechar(Œ£, \color{red!50!black} \!\!\!\ensuremath{\Sigma})}}}
{{{newunicodechar(Œ†, \color{blue!50!black} \!\!\!\ensuremath{\Pi})}}}

  # +caption: Elaborations of DynamicSystem at various exposure levels
  # +latex: {\renewcommand{\arraystretch}{1.3}
 #+name: elaborations
  #+latex: \begin{tcolorbox}[title = \centering \TABLE{Elaborations of \texttt{DynamicSystem} at various exposure levels}, colback=yellow!5!white, colframe=yellow!75!black]
 |   <c>    |   |                             <c>                             |
 | Exposure |   |                         Elaboration                         |
 |----------+---+-------------------------------------------------------------|
 |    0     |   | =Œ£ State ‚à∂ Set  ‚Ä¢ Œ£ start ‚à∂ X  ‚Ä¢ Œ£ next ‚à∂ State ‚Üí State  ‚Ä¢ ùüô= |
 |    1     |   | =Œ† State ‚à∂ Set  ‚Ä¢ Œ£ start ‚à∂ X  ‚Ä¢ Œ£ next ‚à∂ State ‚Üí State  ‚Ä¢ ùüô= |
 |    2     |   | =Œ† State ‚à∂ Set  ‚Ä¢ Œ† start ‚à∂ X  ‚Ä¢ Œ£ next ‚à∂ State ‚Üí State  ‚Ä¢ ùüô= |
 |    3     |   | =Œ† State ‚à∂ Set  ‚Ä¢ Œ† start ‚à∂ X  ‚Ä¢ Œ† next ‚à∂ State ‚Üí State  ‚Ä¢ ùüô= |
 #+latex: \end{tcolorbox}
 # +latex: }

# Back to normal black colouring
{{{newunicodechar(Œ£, \!\!\ensuremath{\Sigma})}}}
{{{newunicodechar(Œ†, \!\!\ensuremath{\Pi})}}}

 #+latex: \noindent
 With these elaborations of ~DynamicSystem~ to guide the way, we resolve
 two of our unknowns.
{{{code( Context and End )}}}
 #+begin_src agda
{- ‚ÄúContexts‚Äù are exposure-indexed types -}
Context = Œª ‚Ñì ‚Üí ‚Ñï ‚Üí Set ‚Ñì

{- Every type can be used as a context -}
‚Äµ_ : ‚àÄ {‚Ñì} ‚Üí Set ‚Ñì ‚Üí Context ‚Ñì
‚Äµ S = Œª _ ‚Üí S

{- The ‚Äúempty context‚Äù is the unit type -}
End : ‚àÄ {‚Ñì} ‚Üí Context ‚Ñì
End {‚Ñì} = ‚Äµ ùüô {‚Ñì}
 #+end_src

 #+latex: \noindent
 It remains to identify the definition of the underlying bind operation
 src_haskell[:exports code]{>>=}.  Usually, for a type constructor
 src_emacs-lisp[:exports code]{m}, bind is typed src_agda[:exports code]{‚àÄ {A
 B : Set} ‚Üí m A ‚Üí (A ‚Üí m B) ‚Üí m B}. It allows one to ‚Äúextract an
 src_haskell[:exports code]{A}-value for later use‚Äù in the src_haskell[:exports
 code]{m B} context. Since our src_haskell[:exports code]{m = Context} is from
 levels to types, we need to slightly alter bind's typing.

 {{{code( Defining Bind ---First Attempt )}}}
 #+begin_src agda :tangle no
-- >>= : ‚àÄ {A B : Set}   ‚Üí      m A        ‚Üí         (A   ‚Üí m B)       ‚Üí m B
_>>=_  : ‚àÄ {a b : Level} ‚Üí (Œì : Context a) ‚Üí (‚àÄ {n} ‚Üí Œì n ‚Üí Context b) ‚Üí Context (a ‚äç b)
(Œì >>= f) zero    = Œ£ Œ≥ ‚à∂ Œì 0 ‚Ä¢ f Œ≥ 0
(Œì >>= f) (suc n) = Œ† Œ≥ ‚à∂ Œì n ‚Ä¢ f Œ≥ n
 #+end_src
 #+latex: \noindent
 The definition here accounts for the current exposure index: If zero, we have
 /record types/, otherwise /function types/. Using this definition, the above
 dynamical system context would need to be expressed using the lifting quote
 operation.
  #+latex: \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]
  *The extensibility of src_haskell[:exports code]{Context} is provided by the*
  *definition of bind: Rather than Œ£ and Œ†, users may use or augment the*
  *framework in other forms ---e.g., Œ† ∑, ùì¶, or let‚ãØin‚ãØ (as shown in ùí©‚ÇÅ' below)
  *or combinations thereof.*
 #+latex: \end{tcolorbox}

# +LATEX_HEADER: \usepackage{placeins}
 # +latex: \FloatBarrier
 # The FloatBarrier stops floats (figures are floats) from jumping over them. I
 # will need to look into passing [tbh] options to figures from org mode further.

{{{code( Example Use )}}}
  #+begin_src agda :tangle no
‚Äµ Set >>= Œª State
       ‚Üí ‚Äµ State >>= Œª start
                 ‚Üí ‚Äµ (State ‚Üí State) >>= Œª next
                                      ‚Üí End

{- or -}

do State ‚Üê ‚Äµ Set
   start ‚Üê ‚Äµ State
   next  ‚Üê ‚Äµ (State ‚Üí State)
   End
 #+end_src
 # See page 275.
 #+latex: \noindent Interestingly\footcitet{Bird_2009}$^,$\footcitet{DBLP:conf/hopl/HudakHJW07},
 use of src_haskell[:exports code]{do}-notation in preference to bind,
 src_haskell[:exports code]{>>=}, was suggested by John Launchbury in 1993 and
 was first implemented by Mark Jones in Gofer.  Anyhow, with our goal of
 practicality in mind, we shall ‚Äúbuild the lifting quote into the definition‚Äù of
 bind:

 #+caption: Semantics: Context do-syntax is interpreted as Œ†-Œ£-types
{{{code( The Definition of Bind )}}}
# +ATTR_LaTeX: :placement [!htpb]
 #+begin_src agda
_>>=_ : ‚àÄ {a b}
      ‚Üí (Œì : Set a)  -- Main difference
      ‚Üí (Œì ‚Üí Context b)
      ‚Üí Context (a ‚äç b)
(Œì >>= f) zero    = Œ£ Œ≥ ‚à∂ Œì ‚Ä¢ f Œ≥ 0
(Œì >>= f) (suc n) = Œ† Œ≥ ‚à∂ Œì ‚Ä¢ f Œ≥ n
 #+end_src

 :Ignore:
 Using the definition of bind, we can elaborate
 #+begin_center
 #+begin_export latex
 \dashbox{\texttt{DynamicSystem 0 = Œ£ State ‚à∂ Set  ‚Ä¢ Œ£ start ‚à∂ State  ‚Ä¢ Œ£ next ‚à∂
 State ‚Üí State  ‚Ä¢ ùüô}}
 #+end_export
 #+end_center
 :End:

#+latex: \noindent
With this definition, the above declaration ~DynamicSystem~ typechecks.  However,
we do /not/ have an isomorphism ~DynamicSystem ùíæ ‚âÖ DynamicSystem·µ¢~, instead
=DynamicSystem ùíæ= are ‚Äúfactories‚Äù: Given ùíæ-many arguments, a product value is
formed. What if we want to /instantiate/ some of the factory arguments ahead of
time?

{{{code( Factories and Instantiation ---‚Ñïatural numbers form a dynamic system )}}}
#+begin_src agda :tangle Context_examples.agda
ùí©‚ÇÄ : DynamicSystem 0   {- See the above elaborations  -}
ùí©‚ÇÄ = ‚Ñï , 0 , suc , tt

-- ùí©‚ÇÅ : DynamicSystem 1
-- ùí©‚ÇÅ = Œª State ‚Üí ??? {- Impossible to complete if ‚ÄúState‚Äù is empty! -}

{- ‚ÄòInstantiaing‚Äô State to be ‚Ñï in ‚ÄúDynamicSystem 1‚Äù -}

ùí©‚ÇÅ‚Ä≤ : let State = ‚Ñï in Œ£ start ‚à∂ State  ‚Ä¢ Œ£ s ‚à∂ (State ‚Üí State)  ‚Ä¢ ùüô {‚Ñì‚ÇÄ}
ùí©‚ÇÅ‚Ä≤ = 0 , suc , tt
#+end_src

#+latex: \noindent
 To get from src_haskell[:exports code]{ùí©‚ÇÅ} to src_haskell[:exports code]{ùí©‚ÇÅ‚Ä≤},
 it seems what we need is a method, say src_haskell[:exports code]{Œ†‚ÜíŒª}, that
 takes a src_haskell[:exports code]{Œ†}-type and transforms it into a
 src_haskell[:exports code]{Œª}-expression.  One could use a universe, an
 algebraic type of codes denoting types, to define src_haskell[:exports
 code]{Œ†‚ÜíŒª}. However, one can no longer then easily use existing types since
 they are not formed from the universe's constructors, thereby resulting in
 duplication of existing types via the universe encoding. This is neither
 practical nor pragmatic.  As such, we are left with pattern matching on the
 language's type formation primitives as the only reasonable approach.  The
 method src_haskell[:exports code]{Œ†‚ÜíŒª} is thus a
 #+latex: macro\FOOTNOTE{
 A /macro/ is a function that manipulates the abstract syntax trees of the
 host language. In particular, it may take an arbitrary term, shuffle its syntax
 to provide possibly meaningless terms or terms that could not be formed without
 pattern matching on the possible syntactic constructions.
 #+latex: }
 that acts on the
 syntactic term representations of types.  Below is the main transformation.

 #+latex: \begin{tcolorbox}[title = Œ†‚ÜíŒª, colback=yellow!5!white, colframe=yellow!75!black]
 #+begin_center org
 #+latex: \dbox{
 src_haskell[:exports code]{Œ†‚ÜíŒª (Œ† a ‚à∂ A ‚Ä¢ œÑ) = (Œª a ‚à∂ A ‚Ä¢ Œ†‚ÜíŒª œÑ)}
 #+latex: }
 #+end_center

 {{{code(Source)}}}
#+begin_src agda :tangle Context.agda
Œ†‚ÜíŒª-type : Term ‚Üí Term
Œ†‚ÜíŒª-type (pi a (abs x b)) = pi a  (abs x (Œ†‚ÜíŒª-type b))
Œ†‚ÜíŒª-type x = unknown

Œ†‚ÜíŒª-helper : Term ‚Üí Term
Œ†‚ÜíŒª-helper (pi a (abs x b)) = lam visible (abs x (Œ†‚ÜíŒª-helper b))
Œ†‚ÜíŒª-helper x = x

macro
  Œ†‚ÜíŒª : Term ‚Üí Term ‚Üí TC Unit.‚ä§
  Œ†‚ÜíŒª tm goal =  normalise tm
                 >>=‚Çú‚Çë·µ£‚Çò Œª tm' ‚Üí checkType goal (Œ†‚ÜíŒª-type tm')
                 >>=‚Çú‚Çë·µ£‚Çò Œª _ ‚Üí  unify goal (Œ†‚ÜíŒª-helper tm')
#+end_src

#+begin_src agda :exports none :reason "This is an old implementation, new one thanks to Ulf!" :tangle no
Œ†‚ÜíŒª-helper : Term ‚Üí Term
Œ†‚ÜíŒª-helper (pi  a b)         = lam visible b
Œ†‚ÜíŒª-helper (lam a (abs x y)) = lam a (abs x (Œ†‚ÜíŒª-helper y))
{-# CATCHALL #-}
Œ†‚ÜíŒª-helper x = x

macro
  Œ†‚ÜíŒª : Term ‚Üí Term ‚Üí TC Unit.‚ä§
  Œ†‚ÜíŒª tm goal = normalise tm >>=‚Çò Œª tm' ‚Üí unify (Œ†‚ÜíŒª-helper tm') goal
#+end_src

 Thanks to [[https://github.com/agda/agda/issues/4997][Ulf Norell]] for helping update this function to the most recent
 version of Agda (2.6.1.2).
 #+latex: \end{tcolorbox}

 #+latex: \noindent
 That is, we walk along the term tree replacing (consecutive) occurrences of ~Œ†~ with
 ~Œª~; as shown in the following /formal/ (i.e., typechecked) calculation.

 #+latex: {\renewcommand{\arraystretch}{1.3}
{{{code( Example use of Œ†‚ÜíŒª )}}}
 #+begin_src agda :tangle Context_examples.agda
_ = Œ†‚ÜíŒª (DynamicSystem 2)
  ‚â°‚ü® "Definition of DynamicSystem at exposure level 2" ‚ü©'
    Œ†‚ÜíŒª (Œ† X ‚à∂ Set ‚Ä¢ Œ† s ‚à∂ X ‚Ä¢ Œ£ n ‚à∂ (X ‚Üí X)  ‚Ä¢ ùüô {‚Ñì‚ÇÄ})
  ‚â°‚ü® "Definition of Œ†‚ÜíŒª; replace a ‚ÄòŒ†‚Äô by a ‚ÄòŒª‚Äô" ‚ü©'
    (Œª (X : Set) ‚Üí Œ†‚ÜíŒª (Œ† s ‚à∂ X ‚Ä¢ Œ£ n ‚à∂ (X ‚Üí X)  ‚Ä¢ ùüô {‚Ñì‚ÇÄ}))
  ‚â°‚ü® "Definition of Œ†‚ÜíŒª; replace a ‚ÄòŒ†‚Äô by a ‚ÄòŒª‚Äô" ‚ü©'
    (Œª (X : Set) ‚Üí Œª (s : X) ‚Üí Œ†‚ÜíŒª (Œ£ n ‚à∂ (X ‚Üí X)  ‚Ä¢ ùüô {‚Ñì‚ÇÄ}))
  ‚â°‚ü® "Next symbol is not a ‚ÄòŒ†‚Äô, so Œ†‚ÜíŒª stops" ‚ü©'
    Œª (X : Set) ‚Üí Œª (s : X) ‚Üí Œ£ n ‚à∂ (X ‚Üí X)  ‚Ä¢ ùüô {‚Ñì‚ÇÄ}
 #+end_src
 #+begin_src agda :tangle no :exports none :reason old
  Œ†‚ÜíŒª (Œ†‚ÜíŒª (DynamicSystem 2))
‚â°{- Definition of DynamicSystem at exposure level 2 -}
  Œ†‚ÜíŒª (Œ†‚ÜíŒª (Œ† X ‚à∂ Set ‚Ä¢ Œ† s ‚à∂ X  ‚Ä¢ Œ£ n ‚à∂ X ‚Üí X  ‚Ä¢ ùüô))
‚â°{- Definition of Œ†‚ÜíŒª -}
  Œ†‚ÜíŒª (Œª X ‚à∂ Set ‚Ä¢ Œ† s ‚à∂ X  ‚Ä¢ Œ£ n ‚à∂ X ‚Üí X  ‚Ä¢ ùüô)
‚â°{- Homomorphy of Œ†‚ÜíŒª -}
  Œª X ‚à∂ Set ‚Ä¢ Œ†‚ÜíŒª (Œ† s ‚à∂ X  ‚Ä¢ Œ£ n ‚à∂ X ‚Üí X  ‚Ä¢ ùüô)
‚â°{- Definition of Œ†‚ÜíŒª -}
  Œª X ‚à∂ Set ‚Ä¢ Œª s ‚à∂ X  ‚Ä¢ Œ£ n ‚à∂ X ‚Üí X  ‚Ä¢ ùüô
 #+end_src
 #+latex: }

 #+latex: \noindent
 # For practicality, we define a macro  ~_:waist_~ acting on contexts that /repeats/ ~Œ†‚ÜíŒª~ a number of times in order to lift a number of field components to the parameter level.
 For pragmatism, we define a macro ~_:waist_~ such that ~œÅ :waist n ‚â° Œ†‚ÜíŒª (œÅ n)~.
 Were we to attempt to prove such an equation in Agda, supposing, say, ~œÅ ‚à∂ ‚Ñï ‚Üí
 Set~ and ~n ‚à∂ ‚Ñï~, by definition chasing (i.e., normalisation) the left side would
 immediatly reduce to ~œÅ~ whereas the right side would reduce to ~œÅ n~; resulting in
 two distinct expressions. However, by inspecting the definitions, the only
 difference between the two is in the first line: Œ†‚ÜíŒª takes an instantiated
 context, whereas ~_‚à∂waist_~ takes a context and a ‚Äòwaist integer‚Äô to instantiate
 the given context.
 # +latex: \vspace{1ex}
 #+latex: \begin{tcolorbox}[title = Waist, colback=yellow!5!white, colframe=yellow!75!black]
 #+begin_center org
 #+latex: \dbox{\parbox{0.4\textwidth}{%
 src_haskell[:exports code]{œÅ :waist n  =  Œ†‚ÜíŒª (œÅ n)}

 #  src_haskell[:exports code]{œÑ :waist n  =  Œ†‚ÜíŒª‚Åø (œÑ n)}

 # src_haskell[:exports code]{f‚Å∞   x ¬†¬†¬†¬†¬†¬†=  x}

 # src_haskell[:exports code]{f‚Åø‚Å∫¬π x ¬†¬†¬†=  f‚Åø (f x)}
 #+latex:  }}
 #+end_center
 {{{code(Source)}}}
 #+begin_src agda :tangle Context.agda
{- œÅ :waist n  ‚â°  Œ†‚ÜíŒª (œÅ n)  -}
macro
  _:waist_ : (pkg : Term) (height : Term) (goal : Term) ‚Üí TC Unit.‚ä§
  _:waist_ pkg n goal = normalise (pkg app n)
                        >>=‚Çú‚Çë·µ£‚Çò Œª œÅ ‚Üí checkType goal (Œ†‚ÜíŒª-type œÅ)
                        >>=‚Çú‚Çë·µ£‚Çò Œª _ ‚Üí unify goal (Œ†‚ÜíŒª-helper œÅ)
#+end_src
#+begin_src agda :tangle Context.agda :exports none :reason "This is an old implementation, new one thanks to Ulf!" :tangle no
waist-helper : ‚Ñï ‚Üí Term ‚Üí Term
waist-helper zero t    = t
waist-helper (suc n) t = waist-helper n (Œ†‚ÜíŒª-helper t)

macro
  _:waist_ : Term ‚Üí Term ‚Üí Term ‚Üí TC Unit.‚ä§
  _:waist_ t ùìÉ goal =      normalise (t app ùìÉ)
                      >>=‚Çò Œª t' ‚Üí unify (waist-helper (to‚Ñï ùìÉ) t') goal
#+end_src
 #+latex: \end{tcolorbox}

 #+latex: \vspace{1ex}\noindent
 We can now ‚Äúfix arguments ahead of time‚Äù. Before such demonstration, we need to
 be mindful of our practicality goals: One declares a grouping mechanism with
 src_haskell[:exports code]{do ‚Ä¶ End}, which in turn has its instance values
 constructed with ~‚ü® ‚Ä¶ ‚ü©~, as defined below.
{{{code( Syntactic Sugar for Context Values )}}}
 #+begin_src agda
-- Expressions of the form ‚Äú‚ãØ , tt‚Äù may now be written ‚Äú‚ü® ‚ãØ ‚ü©‚Äù
infixr 5 ‚ü® _‚ü©
‚ü®‚ü© : ‚àÄ {‚Ñì} ‚Üí ùüô {‚Ñì}
‚ü®‚ü© = tt

‚ü® : ‚àÄ {‚Ñì} {S : Set ‚Ñì} ‚Üí S ‚Üí S
‚ü® s = s

_‚ü© : ‚àÄ {‚Ñì} {S : Set ‚Ñì} ‚Üí S ‚Üí S √ó (ùüô {‚Ñì})
s ‚ü© = s , tt
 #+end_src
 #+latex: \noindent
 The following instances of grouping types demonstrate how information moves from
 the body level to the parameter level.
{{{code( Unbundling: Lifting Fields into Parameters )}}}
 #+BEGIN_SRC agda :tangle Context_examples.agda
ùí©‚Å∞ : DynamicSystem :waist 0
ùí©‚Å∞ = ‚ü® ‚Ñï , 0 , suc ‚ü©

ùí©¬π : (DynamicSystem :waist 1) ‚Ñï
ùí©¬π = ‚ü® 0 , suc ‚ü©

ùí©¬≤ : (DynamicSystem :waist 2) ‚Ñï 0
ùí©¬≤ = ‚ü® suc ‚ü©

ùí©¬≥ : (DynamicSystem :waist 3) ‚Ñï 0 suc
ùí©¬≥ = ‚ü®‚ü©
 #+END_SRC
 #+latex: \noindent
 Using ~:waist ùíæ~ we may fix the first ~ùíæ~-parameters ahead of time.  Indeed, the
 type @@latex:\newline@@ src_agda[:exports code]{(DynamicSystem :waist 1) ‚Ñï} is /the type of dynamic
 systems over carrier ‚Ñï/, whereas @@latex:\newline@@ src_agda[:exports code]{(DynamicSystem :waist 2)
 ‚Ñï 0} is /the type of dynamic systems over carrier ‚Ñï and start state 0/.

 Examples of the need for such on-the-fly unbundling can be found in numerous
 places in the Haskell standard library. For instance, the standard libraries\footcitet{data_monoid}
 have two isomorphic copies of the integers, called ~Sum~ and ~Product~, whose reason
 for being is to distinguish two common monoids: The former is for /integers with
 addition/ whereas the latter is for /integers with multiplication/.
 An orthogonal solution would be to use contexts:
{{{code( Monoids without commitment )}}}
 #+begin_src agda :tangle Context_examples.agda
Monoid : ‚àÄ ‚Ñì ‚Üí Context (‚Ñìsuc ‚Ñì)
Monoid ‚Ñì = do Carrier ‚Üê Set ‚Ñì
              _‚äï_     ‚Üê (Carrier ‚Üí Carrier ‚Üí Carrier)
              Id      ‚Üê Carrier
              leftId  ‚Üê ‚àÄ {x : Carrier} ‚Üí x ‚äï Id ‚â° x
              rightId ‚Üê ‚àÄ {x : Carrier} ‚Üí Id ‚äï x ‚â° x
              assoc   ‚Üê ‚àÄ {x y z} ‚Üí (x ‚äï y) ‚äï z  ‚â°  x ‚äï (y ‚äï z)
              End {‚Ñì}
 #+end_src
 #+latex: \noindent
 With this context, (~Monoid ‚Ñì‚ÇÄ :waist 2) M _‚äï_~ is the type of monoids over
 /particular/ types ~M~ and /particular/ operations ~_‚äï_~.  Of course, this is
 orthogonal, since traditionally unification on the carrier type ~M~ is what makes
 typeclasses and canonical structures\footcitet{coq_canonical_tutorial} useful
 for ad-hoc polymorphism.

 # since Haskell's use-case is for canonical typeclasses, which utilise unification
 # on the carrier type ~M~ to find instance implementations.

** Termtypes as Fixed-points
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Termtypes-as-Fixed-points
   :END:
   <<sec:termtypes-as-fixedpoints>>
# +latex: \label{sec:termtypes-as-fixedpoints}

*** Intro :ignore:
    :PROPERTIES:
    :CUSTOM_ID: Intro
    :END:

   We have a practical monadic syntax for possibly parameterised record types
   that we would like to extend to termtypes.  As discussed in the previous
   section, we could alter the bind operator to account for ùí≤-types, but we
   shall present a different technique so as to avoid ‚Äúmaking bind do too much‚Äù.
   Algebraic data types are a means to declare concrete representations of the
   least fixed-point of a functor; see
   Swierstra\footcitet{DBLP:journals/jfp/Swierstra08} for more on this idea.  In
   particular, the description language ~ùîª~ for dynamical systems, below, declares
   concrete constructors for a fixpoint of a certain functor ùíü; i.e., ~ùîª ‚âÖ Fix ùíü~
   where: {{{code( ADTs and Functors )}}}
   #+begin_src agda :tangle no
data ùîª : Set where
    startD : ùîª
    nextD  : ùîª ‚Üí ùîª

ùíü : Set ‚Üí Set
ùíü = Œª (D ‚à∂ Set) ‚Üí ùüô ‚äé D

data Fix (F : Set ‚Üí Set) : Set where
  Œº : F (Fix F) ‚Üí Fix F
 #+end_src
 #+latex: \noindent
  The problem is whether we can derive ùíü from ~DynamicSystem~.
  Let us attempt a quick calculation
  sketching the necessary transformation steps (informally expressed via ``‚üø''):
 # Avoid overfull \hboxes. E.g., \scalebox{0.9}[1]{The whole comments}
 # +name: termtypes-guide
 # +caption: Guide to termtypes
{{{code( From Contexts to Fixed-points: A Roadmap )}}}
 #+BEGIN_SRC agda :tangle no
  do S ‚Üê Set; s ‚Üê S; n ‚Üê (S ‚Üí S); End
‚üø{- Use existing interpretation to obtain a record. -}
  Œ£ S : Set ‚Ä¢ Œ£ s : S ‚Ä¢ Œ£ n : (S ‚Üí S) ‚Ä¢ ùüô
‚üø{- Pull out the carrier using ‚Äú:waist 1‚Äù,
    then obtain a type constructor using ‚ÄúŒ†‚ÜíŒª‚Äù. -}
  Œª S : Set ‚Ä¢ Œ£ s : S ‚Ä¢ Œ£ n : (S ‚Üí S) ‚Ä¢ ùüô
‚üø{- Termtype constructors target the declared type,
    so only their sources matter. E.g., ‚Äòs : S‚Äô is a
    nullary constructor targeting the carrier ‚ÄòS‚Äô.
    As a design decision, this introduces ùüô types, so any existing
    occurrences are dropped via ùüò. -}
  Œª S : Set ‚Ä¢ Œ£ s : ùüô ‚Ä¢ Œ£ n : S ‚Ä¢ ùüò
‚üø{- Termtypes are sums of products. -}
  Œª S : Set ‚Ä¢       ùüô   ‚äé     S  ‚äé ùüò
‚üø{- Termtypes are fixpoints of type constructors. -}
  Fix (Œª S ‚Ä¢ ùüô ‚äé S)  -- i.e., Fix ùíü; i.e., ùîª; i.e., ‚Ñï
  #+END_SRC
 #+latex: \noindent
  Since we may view an algebraic data-type as a fixed-point of the functor
   obtained from the union of the sources of its constructors, it suffices to
   treat the fields of a record as constructors, then obtain their sources, then
   union them.  That is, since algebraic-datatype constructors necessarily target
   the declared type, they are determined by their sources.  For example,
   considered as a unary constructor ~op ‚à∂ A ‚Üí B~ targets the termtype ~B~ and
   so its source is ~A~.
   Hence, we can form the src_emacs-lisp[:exports code]{termtype}  of a context
   as the src_emacs-lisp[:exports code]{Fix}-point
   of the sum ---using =Œ£‚Üí‚äé=--- of the
   src_emacs-lisp[:exports code]{sources} of the context, as shown
   below. Where the operation ~Œ£‚Üí‚äé~ rewrites dependent-sums into disjoint sums,
   which requires the second argument to lose its reference to the first argument
   which is accomplished by ~‚áä~; further details can be found in the appendices.
 #+latex: \vspace{1ex}
 #+begin_center org
 #+latex: \dbox{\parbox{0.70\textwidth}{%

 src_haskell[:exports code]{sources (Œª x ‚à∂ (Œ† a ‚à∂ A ‚Ä¢ Ba) ‚Ä¢ œÑ) = (Œª x ‚à∂ A ‚Ä¢ sources œÑ)}

 src_haskell[:exports code]{sources (Œª x ‚à∂ A ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† ‚Ä¢ œÑ) = (Œª x ‚à∂ ùüô ‚Ä¢
 sources œÑ)}

#+latex: \vspace{1ex}
src_haskell[:exports code]{‚áä œÑ = ‚Äúreduce all de-bruijn indices within œÑ by 1‚Äù}

 #+latex: \vspace{1ex}
 src_haskell[:exports code]{Œ£‚Üí‚äé (Œ£ a ‚à∂ A ‚Ä¢ Ba) = A ‚äé Œ£‚Üí‚äé (‚áä Ba)}

#+latex: \vspace{1ex}
src_haskell[:exports code]{termtype œÑ = Fix (Œ£‚Üí‚äé (sources œÑ))}

 #+latex: }}
 #+end_center

\noindent
Before moving to an instructive *use* of this combinator,
let us touch a bit on the details of its *formation*.

*** The =termtype= combinator
    :PROPERTIES:
    :CUSTOM_ID: The-termtype-combinator
    :END:

 Using the guiding calculation above,
 we shall work up to the desired functor ùíü
 by /implementing/ each stage ùíæ of the calculation
 and showing the approximation =D·µ¢= of the functor ùíü at
 that stage.

{{{code(Building up to the \texttt{termtype} combinator)}}}

**** Stage 1: Records
     :PROPERTIES:
     :CUSTOM_ID: Stage-1-Records
     :END:

The first step is already possible, using the existing =Context= setup.
 #+begin_src agda  :tangle Context_examples.agda
D‚ÇÅ = DynamicSystem 0

1-records : D‚ÇÅ ‚â° (Œ£ X ‚à∂ Set ‚Ä¢ Œ£ z ‚à∂ X ‚Ä¢ Œ£ s ‚à∂ (X ‚Üí X) ‚Ä¢ ùüô {‚Ñì‚ÇÄ})
1-records = refl
 #+end_src
**** Stage 2: Parameterised Records
     :PROPERTIES:
     :CUSTOM_ID: Stage-2-Parameterised-Records
     :END:
The second step is also already implemented,
using the existing =_:waist_= mechanism.

     #+begin_src agda  :tangle Context_examples.agda
D‚ÇÇ = DynamicSystem :waist 1

2-funcs : D‚ÇÇ ‚â° (Œª (X : Set) ‚Üí Œ£ z ‚à∂ X ‚Ä¢ Œ£ s ‚à∂ (X ‚Üí X) ‚Ä¢ ùüô {‚Ñì‚ÇÄ})
2-funcs = refl
 #+end_src

**** Stage 3: Sources
     :PROPERTIES:
     :CUSTOM_ID: Stage-3-Sources
     :END:
 <<sec:sources>>
 # +latex: \label{sec:sources}

As per the informal description of =sources= in the guiding calculation, we
reinforce the idea with a number of desired test cases ---as usual, formal
machine checked test cases and Agda code can be found on the thesis repository.
In particular, we make a *design decision* for the resulting =termtype= combinator:
Types starting with implicit arguments are /invariants/, not /constructors/ ---and
so are dropped from the resulting ADT by replacing them with the empty type ‚Äòùüò‚Äô.

  #+latex: \begin{tcolorbox}[title = Example uses of \texttt{sources}, colback=red!5!white, colframe=red!75!black]
#+begin_center
| =œÑ=                         |   | =sources œÑ=                   |
|---------------------------+---+-----------------------------|
|---------------------------+---+-----------------------------|
| ~Src ‚Üí Tgt~                 |   | ~Src~                         |
| ~Œ£ f ‚à∂ (Src ‚Üí Tgt) ‚Ä¢ Bdy~   |   | ~Œ£ x ‚à∂ Src ‚Ä¢ Bdy~             |
|---------------------------+---+-----------------------------|
| ~œÑ‚ÇÅ ‚Üí ‚ãØ ‚Üí œÑ‚Çô~               |   | ~œÑ‚ÇÅ √ó ‚ãØ √ó œÑ‚Çô‚Çã‚ÇÅ √ó ùüô~           |
| ~Œ£ f ‚à∂ œÑ‚ÇÅ ‚Üí ‚ãØ ‚Üí œÑ‚Çô ‚Ä¢ Bdy~   |   | ~Œ£ x ‚à∂ (œÑ‚ÇÅ √ó ‚ãØ √ó œÑ‚Çô‚Çã‚ÇÅ) ‚Ä¢ Bdy~ |
|---------------------------+---+-----------------------------|
| =‚àÄ {x : ‚Ñï} ‚Üí x ‚â° x=         |   | =ùüò=                           |
| =(‚àÄ {x y z : ‚Ñï} ‚Üí x ‚â° y)= |   | =ùüò=                           |
|---------------------------+---+-----------------------------|
| ~ùüô~                         |   | ~ùüò~                         |
#+end_center
  #+latex: \end{tcolorbox}

 #+latex: \noindent
The third stage can now be formed.
 #+begin_src agda  :tangle Context_examples.agda :exports none
_ : sources (ùîπ ‚Üí ‚Ñï) ‚â° ùîπ
_ = refl

_ : sources (Œ£ f ‚à∂ (‚Ñï ‚Üí ùîπ) ‚Ä¢ Set) ‚â° (Œ£ x ‚à∂ ‚Ñï ‚Ä¢ Set)
_ = refl

_ : sources (Œ£ f ‚à∂ (‚Ñï ‚Üí Set ‚Üí ùîπ ‚Üí ‚Ñï) ‚Ä¢ 1 ‚â° 1) ‚â° (Œ£ x ‚à∂ (‚Ñï √ó Set √ó ùîπ) ‚Ä¢ 1 ‚â° 1)
_ = refl

_ : ‚àÄ {‚Ñì} ‚Üí sources (ùüô {‚Ñì}) ‚â° ùüò
_ = refl

_ = (sources (‚àÄ {x : ‚Ñï} ‚Üí ‚Ñï)) ‚â° ùüò
_ = refl {‚Ñì‚ÇÅ} {Set} {ùüò}
#+end_src
#+begin_src agda :tangle Context_examples.agda
D‚ÇÉ = sources D‚ÇÇ

3-sources : D‚ÇÉ ‚â° Œª (X : Set) ‚Üí Œ£ z ‚à∂ ùüô ‚Ä¢ Œ£ s ‚à∂ X ‚Ä¢ ùüò
3-sources = refl
 #+end_src

 #+latex: \noindent
With the following definitions.
# We now form two sources-helper utilities, although we suspect they could be
# combined into one function.

 # +latex: \begin{tcolorbox}[title = \texttt{sources} , colback=yellow!5!white, colframe=yellow!75!black]
 #+begin_center org
 #+latex: \dbox{\parbox{0.80\textwidth}{%
 src_haskell[:exports code]{sources‚Çú (Œ† a ‚à∂ A ‚Ä¢ Ba) = A}

 src_haskell[:exports code]{sources (‚Ñ¨ x ‚à∂ (Œ† a ‚à∂ A ‚Ä¢ Ba) ‚Ä¢ œÑ) = (‚Ñ¨ x ‚à∂ A ‚Ä¢ sources œÑ)}

 src_haskell[:exports code]{sources (‚Ñ¨ x ‚à∂ A ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† ‚Ä¢ œÑ) = (‚Ñ¨ x ‚à∂ ùüô ‚Ä¢ sources œÑ)}

 Where ‚Ñ¨ is one of the binders Œª or Œ£.
 #+latex: }}
 #+end_center

#+begin_src agda :tangle Context.agda
-- The source of a type, not an arbitrary term.
-- E.g., sources (Œ£ x ‚à∂ œÑ ‚Ä¢ body) = Œ£ x ‚à∂ sources‚Çú œÑ ‚Ä¢ sources body
sources‚Çú : Term ‚Üí Term

{- ‚ÄúŒ† {a ‚à∂ A} ‚Ä¢ Ba‚Äù  ‚Ü¶  ùüò -}
sources‚Çú (pi (arg (arg-info hidden _) A) _) = quoteTerm ùüò

{-  ‚ÄúŒ† a ‚à∂ A ‚Ä¢ Œ† b ‚à∂ Ba ‚Ä¢ C a b‚Äù ‚Ü¶ ‚ÄúŒ£ a ‚à∂ A ‚Ä¢ Œ£ b ‚à∂ B a ‚Ä¢ sources‚Çú (C a b)‚Äù  -}
sources‚Çú (pi (arg a A) (abs ‚Äúa‚Äù (pi (arg b Ba) (abs ‚Äúb‚Äù Cab)))) =
  def (quote Œ£) (vArg A
                ‚à∑ vArg (lam visible (abs ‚Äúa‚Äù
                   (def (quote Œ£)
                          (vArg Ba
                         ‚à∑ vArg (lam visible (abs ‚Äúb‚Äù (sources‚Çú Cab)))
                         ‚à∑ []))))
                ‚à∑ [])

{-  ‚ÄúŒ† a ‚à∂ A ‚Ä¢ Ba‚Äù ‚Ü¶ ‚ÄúA‚Äù provided Ba does not begin with a Œ†  -}
sources‚Çú (pi (arg a A) (abs ‚Äúa‚Äù Ba)) = A

{- All other non function types have an empty source; since X ‚âÖ (ùüô ‚Üí X) -}
sources‚Çú _ = quoteTerm (ùüô {‚Ñì‚ÇÄ})

{-# TERMINATING #-} -- Termination via structural smaller arguments is not clear due to the call to List.map
sources‚Çú‚Çë·µ£‚Çò : Term ‚Üí Term

sources‚Çú‚Çë·µ£‚Çò (pi a b) = sources‚Çú (pi a b)
{- ‚ÄúŒ£ x ‚à∂ œÑ ‚Ä¢ Bx‚Äù ‚Ü¶  ‚ÄúŒ£ x ‚à∂ sources‚Çú œÑ ‚Ä¢ sources Bx‚Äù -}
sources‚Çú‚Çë·µ£‚Çò (def (quote Œ£) (‚Ñì‚ÇÅ ‚à∑ ‚Ñì‚ÇÇ ‚à∑ œÑ ‚à∑ body))
    = def (quote Œ£) (‚Ñì‚ÇÅ ‚à∑ ‚Ñì‚ÇÇ ‚à∑ map-Arg sources‚Çú œÑ ‚à∑ List.map (map-Arg sources‚Çú‚Çë·µ£‚Çò) body)

{- This function introduces ùüôs, so let's drop any old occurances a la ùüò. -}
sources‚Çú‚Çë·µ£‚Çò (def (quote ùüô) _) = def (quote ùüò) []

-- TODO: Maybe we do not need these cases.
sources‚Çú‚Çë·µ£‚Çò (lam v (abs s x))     = lam v (abs s (sources‚Çú‚Çë·µ£‚Çò x))
sources‚Çú‚Çë·µ£‚Çò (var x args) = var x (List.map (map-Arg sources‚Çú‚Çë·µ£‚Çò) args)
sources‚Çú‚Çë·µ£‚Çò (con c args) = con c (List.map (map-Arg sources‚Çú‚Çë·µ£‚Çò) args)
sources‚Çú‚Çë·µ£‚Çò (def f args) = def f (List.map (map-Arg sources‚Çú‚Çë·µ£‚Çò) args)
sources‚Çú‚Çë·µ£‚Çò (pat-lam cs args) =  pat-lam cs (List.map (map-Arg sources‚Çú‚Çë·µ£‚Çò) args)

-- sort, lit, meta, unknown
sources‚Çú‚Çë·µ£‚Çò t = t

macro
  sources : Term ‚Üí Term ‚Üí TC Unit.‚ä§
  sources tm goal = normalise tm >>=‚Çú‚Çë·µ£‚Çò Œª tm' ‚Üí unify (sources‚Çú‚Çë·µ£‚Çò tm') goal
#+end_src

#+begin_src agda :tangle no :exports none :reason "old"
sources‚ÇÄ : Term ‚Üí Term
sources‚ÇÄ (Œ†[ a ‚à∂ arg i A ] (Œ†[ b ‚à∂ arg _ Ba ] Cab)) =
    def (quote _√ó_) (vArg A
                    ‚à∑ vArg (def (quote _√ó_)
                                (var-dec Ba)
                                     ‚à∑ vArg (sources‚ÇÄ Cab) ‚à∑ []))
                    ‚à∑ [])
sources‚ÇÄ (Œ†[ a ‚à∂ arg (arg-info hidden _) A ] Ba) = quoteTerm ùüò
sources‚ÇÄ (Œ†[ x ‚à∂ arg i A ] Bx) = A
{-# CATCHALL #-}
-- sort, lit, meta, unknown
sources‚ÇÄ t = quoteTerm ùüô

{-# TERMINATING #-}
sources‚ÇÅ : Term ‚Üí Term
sources‚ÇÅ (Œ†[ a ‚à∂ arg (arg-info hidden _) A ] Ba) = quoteTerm ùüò
sources‚ÇÅ (Œ†[ a ‚à∂ arg i A ] (Œ†[ b ‚à∂ arg _ Ba ] Cab)) = def (quote _√ó_) (vArg A ‚à∑
  vArg (def (quote _√ó_) (vArg (var-dec Ba)
                             ‚à∑ vArg (var-dec (var-dec (sources‚ÇÄ Cab))) ‚à∑ [])) ‚à∑ [])
sources‚ÇÅ (Œ†[ x ‚à∂ arg i A ] Bx) = A
sources‚ÇÅ (def (quote Œ£) (‚Ñì‚ÇÅ ‚à∑ ‚Ñì‚ÇÇ ‚à∑ œÑ ‚à∑ body))
    = def (quote Œ£) (‚Ñì‚ÇÅ ‚à∑ ‚Ñì‚ÇÇ ‚à∑ map-Arg sources‚ÇÄ œÑ ‚à∑ List.map (map-Arg sources‚ÇÅ) body)
-- This function introduces ùüôs, so let's drop any old occurances a la ùüò.
sources‚ÇÅ (def (quote ‚ä§) _) = def (quote ùüò) []
sources‚ÇÅ (lam v (abs s x))     = lam v (abs s (sources‚ÇÅ x))
sources‚ÇÅ (var x args) = var x (List.map (map-Arg sources‚ÇÅ) args)
sources‚ÇÅ (con c args) = con c (List.map (map-Arg sources‚ÇÅ) args)
sources‚ÇÅ (def f args) = def f (List.map (map-Arg sources‚ÇÅ) args)
sources‚ÇÅ (pat-lam cs args) = pat-lam cs (List.map (map-Arg sources‚ÇÅ) args)
{-# CATCHALL #-}
-- sort, lit, meta, unknown
sources‚ÇÅ t = t


macro
  sources : Term ‚Üí Term ‚Üí TC Unit.‚ä§
  sources tm goal = normalise tm >>=‚Çò Œª tm' ‚Üí unify (sources‚ÇÅ tm') goal
#+end_src
# +latex: \end{tcolorbox}

Put simply, an ADT is generated by the following abstract grammar.
#+begin_export latex
\[\begin{array}{lclc}
ùëª          &::=& ùüò & \text{(the empty type)} \\
           & | & (c : œÑ) + ùëª & \text{(adding a new constructor consuming arguments of type œÑ)}
\end{array}\]
#+end_export
Such terms $ùüò + (c‚ÇÅ : œÑ‚ÇÅ) + ‚ãØ + (c‚Çô : œÑ‚Çô)$ are essentially the result of
~sources~.
# \noindent It is then reasonable to abbreviate a ùëª-term $ùüò + (c‚ÇÅ : œÑ‚ÇÅ) + ‚ãØ +
# (c‚Çô : œÑ‚Çô)$ as $Œ£^n_{i = 0} ‚Ä¢ (c·µ¢ : œÑ·µ¢)$. Such an ‚Äòabbreviation‚Äô is
# accomplished by the combinator ‚ÄòŒ£‚Üí‚äç‚Äô

**** Stage 4: ~Œ£‚Üí‚äé~ --Replacing Products with Sums
     :PROPERTIES:
     :CUSTOM_ID: Stage-4-Œ£-Replacing-Products-with-Sums
     :END:
     <<sec:sigma-to-sum>>

As another tersely introduced utility, let us flesh-out =Œ£‚Üí‚äé= by means of a few
desired unit tests ---notice that the final
example concerns a parameterised dynamical system.
As mentioned in the guiding calculation, we will replace
unit types by empty types ---i.e., ‚Äúempty Œ£-products by empty ‚äé-sums‚Äù.

  #+latex: {\renewcommand{\arraystretch}{1.3} % Extra vertical space between rows in table
 #+latex: \begin{tcolorbox}[colback=red!5!white, colframe=red!75!black]
| ~œÑ~                                       |   | ~Œ£‚Üí‚äé œÑ~                       |
|-----------------------------------------+---+-----------------------------|
| ~Œ† S ‚à∂ Set ‚Ä¢ (S ‚Üí S)~                     |   | ~Œ† S ‚à∂ Set ‚Ä¢ (S ‚Üí S)~         |
| ~Œ† S ‚à∂ Set ‚Ä¢ Œ£ n ‚à∂ S ‚Ä¢ S~                 |   | ~Œ† S ‚à∂ Set ‚Ä¢ S ‚äé S)~          |
| ~Œ† S ‚à∂ Set ‚Ä¢ Œ£ n ‚à∂ (S ‚Üí S) ‚Ä¢ S~           |   | ~Œ† S ‚à∂ Set ‚Ä¢ (S ‚Üí S) ‚äé S)~    |
| @@latex:{\footnotesize@@ ~Œª S ‚à∂ Set ‚Ä¢ Œ£ s ‚à∂ S ‚Ä¢ Œ£ n ‚à∂ (S ‚Üí S) ‚Ä¢ ùüô~ @@latex: }@@   |   | ~Œª S ‚à∂ Set ‚Ä¢ S ‚äé (S ‚Üí S) ‚äé ùüò~      |
#+latex: \end{tcolorbox} }
 #+begin_src agda :tangle Context_examples.agda :exports none
_ : Œ£‚Üí‚äé (Œ† S ‚à∂ Set ‚Ä¢ (S ‚Üí S)) ‚â° (Œ† S ‚à∂ Set ‚Ä¢ (S ‚Üí S))
_ = refl

_ : Œ£‚Üí‚äé (Œ† S ‚à∂ Set ‚Ä¢ Œ£ n ‚à∂ S ‚Ä¢ S) ‚â° (Œ† S ‚à∂ Set ‚Ä¢ S ‚äé S)
_ = refl

_ : Œ£‚Üí‚äé (Œª (S : Set) ‚Üí Œ£ n ‚à∂ S ‚Ä¢ S) ‚â° Œª S ‚Üí S ‚äé S
_ = refl

_ : Œ£‚Üí‚äé (Œ† S ‚à∂ Set ‚Ä¢ Œ£ s ‚à∂ S ‚Ä¢ Œ£ n ‚à∂ (S ‚Üí S) ‚Ä¢ ùüô {‚Ñì‚ÇÄ}) ‚â° (Œ† S ‚à∂ Set ‚Ä¢ S ‚äé (S ‚Üí S) ‚äé ùüò)
_ = refl

_ : Œ£‚Üí‚äé (Œª (S : Set) ‚Üí Œ£ s ‚à∂ S ‚Ä¢ Œ£ n ‚à∂ (S ‚Üí S) ‚Ä¢ ùüô {‚Ñì‚ÇÄ}) ‚â° Œª S ‚Üí S ‚äé (S ‚Üí S) ‚äé ùüò
_ = refl
#+end_src

*Decreasing de Brujin Indices:* Any given quantification ~(Œ£ x ‚à∂ œÑ ‚Ä¢ fx)~ may have
its body ~fx~ refer to the free variable ~x~.  If we decrement all de Bruijn indices
~fx~ contains, then there would be no reference to ~x~.  ( In the repository code, =‚áä=
appears as =var-dec=. )

 #+latex: \begin{tcolorbox}[title = ‚áä, colback=yellow!5!white, colframe=yellow!75!black]

#+begin_src agda :tangle Context.agda
arg-term : ‚àÄ {‚Ñì} {A : Set ‚Ñì} ‚Üí (Term ‚Üí A) ‚Üí Arg Term ‚Üí A
arg-term f (arg i x) = f x

{-# TERMINATING #-}
length‚Çú : Term ‚Üí ‚Ñï
length‚Çú (var x args)      = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (con c args)      = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (def f args)      = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (lam v (abs s x)) = 1 + length‚Çú x
length‚Çú (pat-lam cs args) = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (pi X (abs b Bx)) = 1 + length‚Çú Bx
{-# CATCHALL #-}
-- sort, lit, meta, unknown
length‚Çú t = 0
-- The Length of a Term:1 ends here

-- [[The Length of a Term][The Length of a Term:2]]
_ : length‚Çú (quoteTerm (Œ£ x ‚à∂ ‚Ñï ‚Ä¢ x ‚â° x)) ‚â° 10
_ = refl

--
var-dec‚ÇÄ : (fuel : ‚Ñï) ‚Üí Term ‚Üí Term
var-dec‚ÇÄ zero t  = t
-- Let's use an ‚Äúimpossible‚Äù term.
var-dec‚ÇÄ (suc n) (var zero args)      = def (quote ùüò) []
var-dec‚ÇÄ (suc n) (var (suc x) args)   = var x args
var-dec‚ÇÄ (suc n) (con c args)         = con c (map-Args (var-dec‚ÇÄ n) args)
var-dec‚ÇÄ (suc n) (def f args)         = def f (map-Args (var-dec‚ÇÄ n) args)
var-dec‚ÇÄ (suc n) (lam v (abs s x))    = lam v (abs s (var-dec‚ÇÄ n x))
var-dec‚ÇÄ (suc n) (pat-lam cs args)    = pat-lam cs (map-Args (var-dec‚ÇÄ n) args)
var-dec‚ÇÄ (suc n) (pi (arg a A) (abs b Ba)) = pi (arg a (var-dec‚ÇÄ n A)) (abs b (var-dec‚ÇÄ n Ba))
-- var-dec‚ÇÄ (suc n) (Œ†[ s ‚à∂ arg i A ] B) = Œ†[ s ‚à∂ arg i (var-dec‚ÇÄ n A) ] var-dec‚ÇÄ n B
{-# CATCHALL #-}
-- sort, lit, meta, unknown
var-dec‚ÇÄ n t = t

var-dec : Term ‚Üí Term
var-dec t = var-dec‚ÇÄ (length‚Çú t) t
 #+end_src
   #+latex: \end{tcolorbox}

 #+latex: \noindent
 Notice that we made the decision that ~x~,
 in the body of ~(Œ£ x ‚Ä¢ x)~, will reduce to ~ùüò~,
 the empty type. Indeed, in such a situation the only DeBrujin index cannot be
 reduced further; e.g.,
 ~‚áä(quoteTerm x) ‚â° quoteTerm ‚ä•~.

 #+latex: \begin{tcolorbox}[title = Œ£‚Üí‚äé, colback=yellow!5!white, colframe=yellow!75!black]
 #+begin_center org
 #+latex: \dbox{\parbox{0.80\textwidth}{%
src_haskell[:exports code]{var-dec œÑ = ‚Äúreduce all de-bruijn indices within œÑ by 1‚Äù}

src_haskell[:exports code]{Œ£‚Üí‚äé (Œ£ a ‚à∂ A ‚Ä¢ Ba) = A ‚äé Œ£‚Üí‚äé (var-dec Ba)}

src_haskell[:exports code]{Œ£‚Üí‚äé (‚Ñ¨ a ‚à∂ A ‚Ä¢ Ba) = (‚Ñ¨ a ‚à∂ A ‚Ä¢ Œ£‚Üí‚äé Ba)}
for other binders ‚Ñ¨, such as Œ† or Œª.
 #+latex: }}
 #+end_center

 #+begin_src agda :tangle Context.agda
{-# TERMINATING #-}
Œ£‚Üí‚äé‚ÇÄ : Term ‚Üí Term

{-  ‚ÄúŒ£ a ‚à∂ A ‚Ä¢ Ba‚Äù ‚Ü¶ ‚ÄúA ‚äé B‚Äù where ‚ÄòB‚Äô is ‚ÄòBa‚Äô with no reference to ‚Äòa‚Äô  -}
Œ£‚Üí‚äé‚ÇÄ (def (quote Œ£) (ùíΩ‚ÇÅ ‚à∑ ùíΩ‚ÇÄ ‚à∑ arg i A ‚à∑ arg i‚ÇÅ (lam v (abs s x)) ‚à∑ []))
  =  def (quote _‚äé_) (ùíΩ‚ÇÅ ‚à∑ ùíΩ‚ÇÄ ‚à∑ arg i A ‚à∑ vArg (Œ£‚Üí‚äé‚ÇÄ (var-dec x)) ‚à∑ [])

-- Interpret ‚ÄúEnd‚Äù in do-notation to be an empty, impossible, constructor.
-- See the unit tests above ;-)
-- For some reason, the inclusion of this caluse obscures structural termination.
Œ£‚Üí‚äé‚ÇÄ (def (quote ùüô) _) = def (quote ùüò) []

 -- Walk under Œª's and Œ†'s.
Œ£‚Üí‚äé‚ÇÄ (lam v (abs s x)) = lam v (abs s (Œ£‚Üí‚äé‚ÇÄ x))
Œ£‚Üí‚äé‚ÇÄ (pi A (abs a Ba)) = pi A (abs a (Œ£‚Üí‚äé‚ÇÄ Ba))
Œ£‚Üí‚äé‚ÇÄ t = t

macro
  Œ£‚Üí‚äé : Term ‚Üí Term ‚Üí TC Unit.‚ä§
  Œ£‚Üí‚äé tm goal = normalise tm >>=‚Çú‚Çë·µ£‚Çò Œª tm' ‚Üí unify (Œ£‚Üí‚äé‚ÇÄ tm') goal
#+end_src

#+latex: \end{tcolorbox}

 #+latex: \vspace{0.5em} \noindent
We can now form the fourth stage approximation of the functor ùíü;
in-fact we will use this form as /the definition/ of the desired
functor ùíü ---since the sum with ùüò /essentially/ contributes nothing.
 #+begin_src agda  :tangle Context_examples.agda
D‚ÇÑ = Œ£‚Üí‚äé D‚ÇÉ

4-unions : D‚ÇÑ ‚â° Œª X ‚Üí ùüô ‚äé X ‚äé ùüò
4-unions = refl
 #+end_src
**** Stage 5: Fixpoint
     :PROPERTIES:
     :CUSTOM_ID: Stage-5-Fixpoint
     :END:

     Since we want to define algebraic data-types as fixed-points, we are led
     inexorably to using a recursive type that fails to be positive.

     #+begin_src agda :tangle Context.agda
{-# NO_POSITIVITY_CHECK #-}
data Fix {‚Ñì} (F : Set ‚Ñì ‚Üí Set ‚Ñì) : Set ‚Ñì where
  Œº : F (Fix F) ‚Üí Fix F
#+end_src

#+begin_src agda :tangle no
ùîª = Fix D‚ÇÑ
 #+end_src

 We summarise the stages together into one macro:
 #+latex: \begin{tcolorbox}[title = Termtype, colback=yellow!5!white, colframe=yellow!75!black]
 #+begin_center org
 #+latex: \dbox{\parbox{0.80\textwidth}{%
src_agda[:exports code]{termtype : UnaryFunctor ‚Üí Type}

src_haskell[:exports code]{termtype œÑ = Fix (Œ£‚Üí‚äé (sources œÑ))}
 #+latex: }}
 #+end_center
 #+begin_src agda :tangle Context.agda
macro
  termtype : Term ‚Üí Term ‚Üí TC Unit.‚ä§
  termtype tm goal =
                normalise tm
           >>=‚Çú‚Çë·µ£‚Çò Œª tm' ‚Üí unify goal (def (quote Fix) ((vArg (Œ£‚Üí‚äé‚ÇÄ (sources‚Çú‚Çë·µ£‚Çò tm'))) ‚à∑ []))
  #+end_src
  #+latex: \end{tcolorbox}
 #+latex: \noindent
 Then, we may instead declare:
 #+begin_src agda  :tangle no
ùîª = termtype (DynamicSystem :waist 1)
     #+end_src

*** Instructive Example: ùîª ‚âÖ ‚Ñï
    :PROPERTIES:
    :CUSTOM_ID: Instructive-Example-ùîª-‚Ñï
    :END:

 #+latex: \vspace{1ex}\noindent
 It is instructive to work through the process of how ~ùîª~ is obtained from ~termtype~
 in order to demonstrate that this approach to algebraic data types
 is practical *within Agda*.
{{{code( Declaring a Derived Termtype )}}}
#+name: free-dynamical-system-1
 #+begin_src agda :tangle no
ùîª = termtype (DynamicSystem :waist 1)

-- Pattern synonyms for more compact presentation
pattern startD  = Œº (inj‚ÇÅ tt)       -- : ùîª
pattern nextD e = Œº (inj‚ÇÇ (inj‚ÇÅ e)) -- : ùîª ‚Üí ùîª
 #+end_src
 #+latex: \noindent
 With these  src_agda[:exports code]{pattern} declarations, we can actually use the more meaningful names
 ~startD~ and ~nextD~ when pattern matching, instead of the seemingly daunting
 Œº-~inj~-ections.  For instance, we can immediately see that the natural numbers
 act as the description language for dynamical systems:
{{{code( Seemingly Trivial Remappings )}}}
#+name: free-dynamical-system-2
 #+begin_src agda :tangle no
to : ùîª ‚Üí ‚Ñï
to startD    = 0
to (nextD x) = suc (to x)

from : ‚Ñï ‚Üí ùîª
from zero    = startD
from (suc n) = nextD (from n)
               #+end_src

 # Put everything in this section under a single module
 #+begin_src agda :tangle Context_examples.agda :noweb yes
module free-dynamical-system where

    <<free-dynamical-system-1>>

    <<free-dynamical-system-2>>
 #+end_src

 #+latex: \noindent
 Readers whose language does not have src_agda[:exports code]{pattern} clauses
 need not despair.  With the following macro
 #+latex: \begin{tcolorbox}[title = , colback=yellow!5!white, colframe=yellow!75!black]
 #+begin_center org
#+latex:\dbox{
src_haskell[:exports code]{Inj n x = Œº (inj‚ÇÇ ‚Åø (inj‚ÇÅ x))}
#+latex: }
 #+end_center
#  It is interesting to note that in place of ~pattern~ clauses, say for languages
# that do not support them, we would resort to ‚Äúfancy injections‚Äù.
 #+begin_src agda :tangle Context.agda
-- ùíæ-th injection:  (inj‚ÇÇ ‚àò ‚ãØ ‚àò inj‚ÇÇ) ‚àò inj‚ÇÅ
Inj‚ÇÄ : ‚Ñï ‚Üí Term ‚Üí Term
Inj‚ÇÄ zero c    = con (quote inj‚ÇÅ) (arg (arg-info visible relevant) c ‚à∑ [])
Inj‚ÇÄ (suc n) c = con (quote inj‚ÇÇ) (vArg (Inj‚ÇÄ n c) ‚à∑ [])

macro
  Inj : ‚Ñï ‚Üí Term ‚Üí Term ‚Üí TC Unit.‚ä§
  Inj n t goal = unify goal ((con (quote Œº) []) app (Inj‚ÇÄ n t))
 #+end_src
  #+latex: \end{tcolorbox}\noindent
 we may define src_haskell[:exports code]{ startD = Inj 0 tt } and
 src_haskell[:exports code]{ nextD e = Inj 1 e } --- that is,
 constructors of@@latex: \linebreak@@ termtypes
 are particular injections into the possible summands that the termtype consists
 of.

** Free Datatypes from Theories
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Free-Datatypes-from-Theories
   :END:
   <<sec:free-datatypes>>
# +latex: \label{sec:free-datatypes}

 Astonishingly, useful programming datatypes arise from termtypes of theories
 (contexts). That is, if a parameterised context src_agda[:exports code]{ùíû : Set
 ‚Üí Context ‚Ñì‚ÇÄ} is given, then \newline
src_haskell[:exports code]{‚ÑÇ = Œª X ‚Üí termtype (ùíû X :waist 1)}
 can be used to form ‚Äòfree, lawless, ùíû-instances‚Äô. For instance, earlier we
 witnessed that the termtype of dynamical systems is essentially the natural
 numbers.

  #+latex: \begin{tcolorbox}[title = \TABLE{Data structures as free theories}, colback=red!5!white, colframe=red!75!black]
 | Theory             | Termtype     |
 |--------------------+--------------|
 | Dynamical Systems  | ‚Ñï            |
 | Pointed Structures | Maybe        |
 | Actions            | Streams      |
 | Monoids            | Binary Trees |
  #+latex: \end{tcolorbox}

 :Ignore:
 Similarly, by starting at ‚Äútheories of
 pointed sets over a given set Œû‚Äù, the resulting termtype is the ~Maybe~
 type constructor ---another instructive exercise to the reader: Show that ~‚Ñô ‚âÖ Maybe~.
{{{code( ? )}}}
 #+begin_src agda :tangle no
PointedOver  : Set ‚Üí Context (‚Ñìsuc ‚Ñì‚ÇÄ)
PointedOver Œû    = do Carrier ‚Üê Set ‚Ñì‚ÇÄ
                      point   ‚Üê Carrier
                      embed   ‚Üê (Œû ‚Üí Carrier)
                      End

‚Ñô : Set ‚Üí Set
‚Ñô X = termtype (PointedOver X :waist 1)

-- Pattern synonyms for more compact presentation
pattern nothingP = Œº (inj‚ÇÅ tt)       -- : ‚Ñô
pattern justP e  = Œº (inj‚ÇÇ (inj‚ÇÅ e)) -- : ‚Ñô ‚Üí ‚Ñô
 #+end_src
 :End:

  # In addition, the contents of these grouping mechanisms
   #    may be function symbols as well as propositional invariants ---an example
    #   is shown at the end of [[sec:monadic-notation]].


 # We present the setup
 # and leave it as an instructive exercise to the reader to present a
 # bijective pair of functions between =ùïÑ= and =TreeSkeleton=.

 #+latex: \vspace{-0em}\noindent
 The final entry in the above table is a well known
 correspondence that we can now not only formally express, but also prove to be
 true.  As we did with dynamical systems, we begin with forming ùïÑ the termtype
 of monoids, then using src_agda[:exports code]{pattern} clauses to provide
 compact names, and explicitly form the algebraic src_agda[:exports code]{data}
 type of trees.

{{{code( Trees from Monoids )}}}
 #+begin_src agda  :tangle Context_examples.agda :exports none
module termtype[Monoid]‚âÖTreeSkeleton where
 #+end_src
#+begin_src agda :tangle Context_examples.agda
  ùïÑ : Set
  ùïÑ = termtype (Monoid ‚Ñì‚ÇÄ :waist 1)

  that-is : ùïÑ ‚â° Fix (Œª X ‚Üí X √ó X √ó ùüô -- _‚äï_, branch
                          ‚äé ùüô        -- Id, nil leaf
                          ‚äé ùüò        -- invariant leftId
                          ‚äé ùüò        -- invariant rightId
                          ‚äé ùüò        -- invariant assoc
                          ‚äé ùüò)       --  the ‚ÄúEnd {‚Ñì}‚Äù
  that-is = refl

  -- Pattern synonyms for more compact presentation
  pattern emptyM      = Œº (inj‚ÇÇ (inj‚ÇÅ tt))              -- : ùïÑ
  pattern branchM l r = Œº (inj‚ÇÅ (l , r , tt))           -- : ùïÑ ‚Üí ùïÑ ‚Üí ùïÑ
  pattern absurdM a   = Œº (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ a)))) -- absurd ùüò-values

  data TreeSkeleton : Set where
    empty  : TreeSkeleton
    branch : TreeSkeleton ‚Üí TreeSkeleton ‚Üí TreeSkeleton
 #+end_src
 #+latex: \noindent
 Using Agda's Emacs interface, we may interactively
 case-split on values of =ùïÑ= until the declared patterns appear, then we associate them
 with the constructors of ~TreeSkeleton~.
{{{code( Seemingly Trivial Remappings )}}}
 #+begin_src agda  :tangle Context_examples.agda
  to : ùïÑ ‚Üí TreeSkeleton
  to emptyM        = empty
  to (branchM l r) = branch (to l) (to r)
  to (absurdM (inj‚ÇÅ ()))
  to (absurdM (inj‚ÇÇ ()))

  from : TreeSkeleton ‚Üí ùïÑ
  from empty        = emptyM
  from (branch l r) = branchM (from l) (from r)
 #+end_src
 #+latex: \noindent
 That these two operations are inverses is easily demonstrated.
{{{code( Trees from Monoids )}}}
 #+begin_src agda  :tangle Context_examples.agda
  from‚àòto : ‚àÄ m ‚Üí from (to m) ‚â° m
  from‚àòto emptyM        = refl
  from‚àòto (branchM l r) = cong‚ÇÇ branchM (from‚àòto l) (from‚àòto r)
  from‚àòto (absurdM (inj‚ÇÅ ()))
  from‚àòto (absurdM (inj‚ÇÇ ()))

  to‚àòfrom : ‚àÄ t ‚Üí to (from t) ‚â° t
  to‚àòfrom empty        = refl
  to‚àòfrom (branch l r) = cong‚ÇÇ branch (to‚àòfrom l) (to‚àòfrom r)
 #+end_src

 #+latex: \noindent
 Without the src_agda[:exports code]{pattern} declarations the result would
 remain true, but it would be quite difficult to believe in the correspondence
 without a machine-checked proof.

 To obtain a data structure over some ‚Äòvalue type‚Äô Œû, one must start with
 ‚Äútheories containing a given set Œû‚Äù. For example, we could begin with the
 theory of abstract collections, then obtain lists as the associated termtype.
 #+begin_src agda  :tangle Context_examples.agda :exports none
module termtype[Collection]‚âÖList where
 #+end_src

{{{code( Lists from Paramterised Collections )}}}
 #+begin_src agda :tangle Context_examples.agda
  Collection : ‚àÄ ‚Ñì ‚Üí Context (‚Ñìsuc ‚Ñì)
  Collection ‚Ñì = do Elem    ‚Üê Set ‚Ñì
                    Carrier ‚Üê Set ‚Ñì
                    insert  ‚Üê (Elem ‚Üí Carrier ‚Üí Carrier)
                    ‚àÖ       ‚Üê Carrier
                    End {‚Ñì}

  ‚ÑÇ : Set ‚Üí Set
  ‚ÑÇ Elem = termtype ((Collection ‚Ñì‚ÇÄ :waist 2) Elem)

  pattern _::_ x xs = Œº (inj‚ÇÅ (x , xs , tt))
  pattern  ‚àÖ        = Œº (inj‚ÇÇ (inj‚ÇÅ tt))
 #+end_src
 # +latex: \newpage
{{{code( Realising Collection ASTs as Lists )}}}
 #+begin_src agda  :tangle Context_examples.agda
  to : ‚àÄ {E} ‚Üí ‚ÑÇ E ‚Üí List E
  to (e :: es) = e ‚à∑ to es
  to ‚àÖ         = []
 #+end_src

 It is then little trouble to show that src_emacs-lisp[:exports code]{to} is
 invertible.  We invite the readers to join in on the fun and try it out
 themselves.
 :Hide:
{{{code( ? )}}}
 #+begin_src agda  :tangle Context_examples.agda
  from : ‚àÄ {E} ‚Üí List E ‚Üí ‚ÑÇ E
  from []       = ‚àÖ
  from (x ‚à∑ xs) = x :: from xs

  to‚àòfrom : ‚àÄ {E} (xs : List E) ‚Üí to (from xs) ‚â° xs
  to‚àòfrom []       = refl
  to‚àòfrom (x ‚à∑ xs) = cong (x ‚à∑_) (to‚àòfrom xs)

  from‚àòto : ‚àÄ {E} (e : ‚ÑÇ E) ‚Üí from (to e) ‚â° e
  from‚àòto (e :: es) = cong (e ::_) (from‚àòto es)
  from‚àòto ‚àÖ         = refl
 #+end_src
 :End:

 Finally, indexed unary algebras give rise to streams as follows.
 {{{code(Actions ‚Üî Streams)}}}
 #+begin_src agda
-- 0: The useful structure
Action  : Context ‚Ñì‚ÇÅ
Action  = do Value    ‚Üê Set
             Program  ‚Üê Set
             run      ‚Üê (Program ‚Üí Value ‚Üí Value)
             End {‚Ñì‚ÇÄ}

-- 1: Its termtype and syntactic sugar
ùî∏ùïîùï•ùïöùï†ùïü : Set ‚Üí Set
ùî∏ùïîùï•ùïöùï†ùïü X = termtype ((Action :waist 2) X)

pattern _¬∑_ head tail = Œº (inj‚ÇÅ (tail , head , tt))

-- 2: Notice that it's just streams
record Stream (X : Set) : Set   where
  coinductive {- Streams are characterised extensionally -}
  field
    hd : X
    tl : Stream X

open Stream

-- Here's one direction
view : ‚àÄ {I} ‚Üí ùî∏ùïîùï•ùïöùï†ùïü I ‚Üí Stream I
hd (view (t ¬∑ h)) = t
tl (view (t ¬∑ h)) = view h
 #+end_src

*** COMMENT to add: termtype ùí≥ ‚âÖ ‚ãØ

****  ~termtype PointedSet ‚âÖ ùüô~

PSet  : Context (‚Ñìsuc ‚Ñì‚ÇÄ)
PSet  = do Carrier ‚Üê Set ‚Ñì‚ÇÄ
           point  ‚Üê Carrier
           End {‚Ñì‚ÇÄ}

‚Ñôùïäùïñùï• : Set
‚Ñôùïäùïñùï• = termtype (PSet :waist 1)

to : ‚Ñôùïäùïñùï• ‚Üí ùüô {‚Ñì‚ÇÄ}
to emptyM = tt

from : ùüô {‚Ñì‚ÇÄ} ‚Üí ‚Ñôùïäùïñùï•
from _ = Œº (inj‚ÇÅ tt)

**** termtype relations ‚âÖ pairs

From simple graphs (relations) to a syntax about them:
One describes a simple graph by presenting edges as pairs of vertices!

{- discussion session or footnote
RSetsOn  : Set ‚Üí Context (‚Ñìsuc ‚Ñì‚ÇÄ)
RSetsOn Elem = do TruthValues ‚Üê Set ‚Ñì‚ÇÄ
                  relation ‚Üê (Elem ‚Üí Elem ‚Üí TruthValues)
                  End {‚Ñì‚ÇÄ}
-}


{- discussion / footnote
GraphOn  : Set ‚Üí Context (‚Ñìsuc ‚Ñì‚ÇÄ)
GraphOn Node = do Edge ‚Üê Set ‚Ñì‚ÇÄ
                  adjacency ‚Üê (Node ‚Üí Node ‚Üí Edge)
                  End {‚Ñì‚ÇÄ}

ùîæùï£ùïíùï°ùïô : Set ‚Üí Set
ùîæùï£ùïíùï°ùïô X = termtype (GraphOn X :waist 1)

pattern _‚áå_ x y = Œº (inj‚ÇÅ (x , y , tt))

view : ‚àÄ {X} ‚Üí ùîæùï£ùïíùï°ùïô X ‚Üí X √ó X
view (x ‚áå y) = x , y

-
}

Graph  : Context (‚Ñìsuc ‚Ñì‚ÇÄ)
Graph = do Node ‚Üê Set
           Edge ‚Üê Set
           adjacency ‚Üê (Node ‚Üí Node ‚Üí Edge)
           End {‚Ñì‚ÇÄ}

-- The current implementation of ‚Äútermtype‚Äù only allows for one ‚ÄúSet‚Äù in the body.
-- So we lift both out; thereby regaining ‚Ñô‚ÇÇ!

ùîæùï£ùïíùï°ùïô : Set ‚Üí Set
ùîæùï£ùïíùï°ùïô X = termtype ((Graph :waist 2) X)

pattern _‚áå_ x y = Œº (inj‚ÇÅ (x , y , tt))

view : ‚àÄ {X} ‚Üí ùîæùï£ùïíùï°ùïô X ‚Üí X √ó X
view (x ‚áå y) = x , y

-- Claim: Mention in paper.
--
--    P‚ÇÅ : Set ‚Üí Context = Œª Œû ‚Üí do ‚ãØ End
-- ‚âÖ  P‚ÇÇ :waist 1
-- where P‚ÇÇ : Context = do Œû ‚Üê Set; ‚ãØ End

**** indexed unary algebras (‚Äúactions‚Äù) give rise to streams


** Language Agnostic Construction
  :PROPERTIES:
  :header-args: :tangle no
  :END:

#+latex: \label{sec:language_agnostic}

In contrast to the generic approach to semantics for contexts of section
\ref{sec:semantics_for_contexts}, here we generalise the previous setup to an
arbitrary Generalised Type Theory ---as defined in Chapter
\ref{sec:packages_and_their_parts}, and used to place the prototype on solid
foundations. We present a quick sketch ---and so /omit/ the full typing rules of
the claimed operators, leaving that as an exercise for the interested reader
(some of which are already present in Chapter
\ref{sec:packages_and_their_parts}; consult Lee et
all\footcitet{modules:mechanised_meta_theory} for a mechansisation of the
metatheory of modules).

Suppose we have a language consisting of ‚Äòterms‚Äô and a typing relation ‚Äò‚ä¢‚Äô. To
implement the src_haskell[:exports code]{Context} library for such a language,
we need to have access to 3 classes of constructions:

1. Dependent function types src_haskell[:exports code]{Œ† a ‚à∂ A ‚Ä¢ Ba} with values
   src_haskell[:exports code]{Œª a : A ‚Ä¢ ba} and the usual function application
   eliminator ---where ~A ‚à∂ Type~ and ~a ‚à∂ A ‚ä¢ Ba ‚à∂ Type~ and ~a ‚à∂ A ‚ä¢ ba : Ba~--- and
   there is a unit and type ~¬†‚ä¢ ùüô ‚à∂ Type~ and the natural numbers ~¬†‚ä¢ ‚Ñï ‚à∂ Type~.

2. Dependent record types src_haskell[:exports code]{Œ£ a ‚à∂ A ‚Ä¢ Ba} ---where ~A ‚à∂
   Type~ and ~a ‚à∂ A ‚ä¢ Ba ‚à∂ Type~--- and there is an empty type and ~¬†‚ä¢ ùüò ‚à∂ Type~.

3. An operator src_haskell[:exports code]{Fix} that maps /polynomial functors/ to
   their initial algebras ---notice that it does not need to be a generic
   fixpoint operator.

We have 3 classes corresponding to the 3 primitive ways to view a context ---Œ†,
Œ£, and ùí≤ as discussed in Chapter \ref{sec:Pi-Sigma-W}. The more of these
features that a language has, the more of the src_haskell[:exports
code]{Context} system it can implement.

{{{code(Œ†; Œª; ‚Ñï; ùüô ‚áí Context)}}}
#+begin_src haskell
-- ‚ä¢ Context : Type
Context  =  Œ† _ ‚à∂ ‚Ñï ‚Ä¢ Type

-- ‚ä¢ End : Context
End      =  Œª _ : ‚Ñï ‚Ä¢ ùüô
#+end_src

{{{code(Œ£ ‚áí ‚ü´=)}}}
#+begin_src haskell
-- ‚ä¢ _‚ü´=_ : Œ† Œì ‚à∂ Type ‚Ä¢ Œ† _ ‚à∂ (Œ† _ ‚à∂ Œì ‚Ä¢ Context) ‚Ä¢ Context
(Œì ‚ü´= f) 0        =  Œ£ Œ≥ ‚à∂ Œì ‚Ä¢ f Œ≥ 0
(Œì ‚ü´= f) (n + 1)  =  Œ† Œ≥ ‚à∂ Œì ‚Ä¢ f Œ≥ n
#+end_src

{{{code(ùüò ‚áí Typeclasses with Œ†‚ÜíŒª)}}}
#+begin_src haskell
-- ‚ä¢ Œ†‚ÜíŒª : Œ† A ‚à∂ Type ‚Ä¢ Œ† _ ‚à∂ Type ‚Ä¢ Œ† _ ‚à∂ A ‚Ä¢ Type
Œ†‚ÜíŒª A (Œ† a ‚à∂ A ‚Ä¢ œÑ)  =  Œª a ‚à∂ A ‚Ä¢ Œ†‚ÜíŒª œÑ
Œ†‚ÜíŒª A _              =  Œª a ‚à∂ A ‚Ä¢ ùüò

-- ‚ä¢ :waist : Œ† A ‚à∂ Type ‚Ä¢ Œ† _ ‚à∂ Context ‚Ä¢ Œ† _ ‚à∂ ‚Ñï ‚Ä¢ Œ† _ ‚à∂ A ‚Ä¢ Type
:waist A œÅ n  =   Œ†‚ÜíŒª (œÅ n)
#+end_src

The final piece, regarding termtypes, requires a mechanism ~provided~ for forming
guarded definitions ---in Agda this is accomplished with the src_agda[:exports
code]{with} keyword.

{{{code(Fixpoints ‚áí ùí≤-types)}}}
#+begin_src haskell
-- ‚ä¢ sources : Œ† _ ‚à∂ (Œ† _ ‚à∂ Type ‚Ä¢ Type) ‚Ä¢ Œ† _ ‚à∂ Type ‚Ä¢ Type
sources (Œª x ‚à∂ (Œ† a ‚à∂ A ‚Ä¢ Ba) ‚Ä¢ œÑ) = Œª x ‚à∂ A ‚Ä¢ sources œÑ
sources (Œª x ‚à∂ A              ‚Ä¢ œÑ) = Œª x ‚à∂ ùüô ‚Ä¢ sources œÑ
sources _                          = Œª x : ùüò ‚Ä¢ ùüò

-- ‚ä¢ Œ£‚Üí‚äé : Œ† _ ‚à∂ Type ‚Ä¢ Type
Œ£‚Üí‚äé (Œ£ a ‚à∂ A ‚Ä¢ B)  =  A ‚äé Œ£‚Üí‚äé B   provided   ‚ä¢ B : Type
Œ£‚Üí‚äé _              =  ùüò

-- ‚ä¢ termtype : Œ† œÑ ‚à∂ (Œ† _ ‚à∂ Type ‚Ä¢ Type) ‚Ä¢ Type
termtype œÑ = Fix (Œ£‚Üí‚äé (sources œÑ))
#+end_src

Since ~‚ü´=~ ensures that ~Context~ values are always formed from sums Œ£ and products
Œ†, we have polynomial constructions and so it suffices to find the initial
algebra of such operators ---which always exist; see section \ref{sec:W-types}
on ùí≤-types. We assumed ~Fix~ yields such algebras.

** Conclusion
   :PROPERTIES:
   :CUSTOM_ID: Contexts-Conclusion
   :END:

 # In addition, the contents of these grouping mechanisms
  #    may be function symbols as well as propositional invariants ---an example
   #   is shown at the end of [[sec:monadic-notation]].

 Starting from the insight that related grouping mechanisms could be unified, we
 showed how *related structures can be obtained from a single declaration using
 a practical interface.* The resulting framework, based on contexts, still
 captures the familiar record declaration syntax as well as the expressivity of
 usual algebraic datatype declarations ---at the minimal cost of using
 src_agda[:exports code]{pattern} declarations to aide as user-chosen
 constructor names.  We believe that our approach to using contexts as general
 grouping mechanisms /with/ a practical interface are interesting contributions.

 We used the focus on practicality to guide the design of our context interface,
 and provided interpretations both for the rather intuitive ‚Äúcontexts are
 name-type records‚Äù view, and for the novel ‚Äúcontexts are fixed-points‚Äù view for
 termtypes.  In addition, to obtain parameterised variants, we needed to
 explicitly form ‚Äúcontexts whose contents are over a given ambient context‚Äù
 ---e.g., contexts of vector spaces are usually discussed with the understanding
 that there is a context of fields that can be referenced--- which we did using
 the name binding machanism of src_haskell[:exports code]{do}-notation. These
 relationships are summarised in the following table.

# +latex_header: \tcbuselibrary{poster, skins}

#+macro: IN  \hspace{-1em}
  #+latex: \begin{tcolorbox}[title = \TABLE{$\;\;$ Contexts embody all kinds of grouping mechanisms}, colback=red!5!white, colframe=red!75!black, left=-5pt, right=3pt]
 # +caption: Contexts embody all kinds of grouping mechanisms
 | Concept            | {{{IN}}}Concrete Syntax                        |  {{{IN}}} Description           |
 |--------------------+------------------------------------------------+------------------------|
 | Context            | {{{IN}}} =do S ‚Üê Set; s ‚Üê S; n ‚Üê (S ‚Üí S); End=   |  {{{IN}}} ‚Äúname-type pairs‚Äù     |
 |--------------------+------------------------------------------------+------------------------|
 | Record Type        | {{{IN}}} =Œ£ S ‚à∂ Set ‚Ä¢ Œ£ s ‚à∂ S ‚Ä¢ Œ£ n ‚à∂ S ‚Üí S ‚Ä¢ ùüô= |  {{{IN}}} ‚Äúbundled-up data‚Äù     |
 | Function Type      | {{{IN}}} =Œ† S ‚Ä¢ Œ£ s ‚à∂ S ‚Ä¢ Œ£ n ‚à∂ S ‚Üí S ‚Ä¢ ùüô=       |  {{{IN}}} ‚Äúa type of functions‚Äù |
 | Type constructor   | {{{IN}}} =Œª S ‚Ä¢ Œ£ s ‚à∂ S ‚Ä¢ Œ£ n ‚à∂ S ‚Üí S ‚Ä¢ ùüô=       |  {{{IN}}} ‚Äúa function on types‚Äù |
 | Algebraic datatype | {{{IN}}} ~data ùîª ‚à∂ Set where s ‚à∂ ùîª; n ‚à∂ ùîª ‚Üí ùîª~   |  {{{IN}}} ‚Äúa descriptive syntax‚Äù |
 #+latex: \FloatBarrier
 # The FloatBarrier stops floats (figures are floats) from jumping over them. I
 # will need to look into passing [tbh] options to figures from org mode further.
  #+latex: \end{tcolorbox}

 To those interested in exotic ways to group data together ---such as,
 mechanically deriving product types and homomorphism types of theories---
 we offer an interface that is extensible using Agda's reflection mechanism.
 In comparison with, for example, special-purpose preprocessing tools, this
 has obvious advantages in accessibility and semantics.

 To Agda programmers, this offers a standard interface for grouping mechanisms
 that had been sorely missing, with an interface that is so familiar that there
 would be little barrier to its use. In particular, as we have shown, it acts as
 *an in-language library for exploiting relationships between free theories and
 data structures.* As we have presented the high-level definitions of the core
 combinators ---alongside Agda-specific details which may be safely ignored---
 it is also straightforward to translate the library into other
 dependently-typed languages (where appropriate reflection features are
 available).

** COMMENT Misc
*** Why PackageFormer is not enough.
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Why-PackageFormer-is-not-enough
   :END:
*** Discuss Agda macros ---need to be self-contained.
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Discuss-Agda-macros-need-to-be-self-contained
   :END:
*** Motivate the need for a practical syntax.
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Motivate-the-need-for-a-practical-syntax
   :END:
*** The reason it's a "do it yourself" system is that the semantics, >>=,
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-The-reason-it's-a-do-it-yourself-system-is-that-the-semantics
   :END:
     can be tweaked easily for other forms of grouping besides Pi/Sigma ;-)
*** Current limitations; e.g., lack of termination/positivity of certain constructs;
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Current-limitations-e-g-lack-of-termination-positivity-of-certain-constructs
   :END:
     or how termtype generation requires the ADT carrier to be the first element
     of the sequence/context, whereas a DAG interpretation of Contexts would be better?
*** How does this compare with PF?
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-How-does-this-compare-with-PF
   :END:
*** What are the benefits of Context?
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-What-are-the-benefits-of-Context
   :END:
*** Concrete problems its usage can solve.
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Concrete-problems-its-usage-can-solve
   :END:

--------------------------------------------------------------------------------


*** Related Works
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-Related-Works
   :END:
   <<sec:related-works>>
#+latex: \label{sec:related-works}
   <<sec:context:related-works>>
#+latex: \label{sec:context:related-works}

   Surprisingly, conflating parameterised and non-parameterised record types
   with termtypes /within a language in a practical fashion/ has not been done before.

   The =PackageFormer= citet:DBLP:conf/gpce/Al-hassyCK19,alhassy_thesis_proposal
   editor extension reads contexts ---in nearly the same notation as =Context=---
   enclosed in dedicated comments, then generates and imports Agda code from them
   seamlessly in the background whenever typechecking happens. The framework
   provides a fixed number of meta-primitives for producing arbitrary notions of
   grouping mechanisms, and allows arbitrary Emacs Lisp citet:10.5555/229872 to be
   invoked in the construction of complex grouping mechanisms.

   #+latex: \begin{tcolorbox}[title=\TABLE{Comparing the in-language Context mechanism with the PackageFormer editor extension}, colback=red!5!white, colframe=red!75!black]
   # +caption: Comparing the in-language =Context= mechanism with the =PackageFormer= editor extension
   |                          | PackageFormer      | Contexts             |
   |--------------------------+--------------------+----------------------|
   | Type of Entity           | Preprocessing Tool | Language Library     |
   | Specification Language   | Lisp + Agda        | Agda                 |
   | Well-formedness Checking | ‚ùå               | ‚úì                    |
   | Termination Checking     | ‚úì                  | ‚úì                    |
   | Elaboration Tooltips     | ‚úì                  | ‚ùå                 |
   | Rapid Prototyping        | ‚úì                  | ‚úì (Slower)           |
   | Usability Barrier        | None               | None                 |
   | Extensibility Barrier    | Lisp               | Weak Metaprogramming |
  #+latex: \end{tcolorbox}

   The previous chapter provided the syntax of =PackageFormer=
   necessary to form useful grouping mechanisms but was shy on the semantics of
   such constructs.  We have chosen the names of the =Context= combinators to
   closely match those of =PackageFormer='s with an aim of furnishing the
   mechanism with semantics by construing the syntax as semantics-functions;
   i.e., we have a shallow embedding of =PackageFormer='s constructs as Agda
   entities:

 #+latex: \begin{tcolorbox}[title=\TABLE{Context as a semantics for PackageFormer constructs}, colback=red!5!white, colframe=red!75!black]
 # +caption: =Context= as a semantics for =PackageFormer= constructs
 | Syntax          | Semantics                    |
 |-----------------+------------------------------|
 | ~PackageFormer~   | ~Context~                      |
 | ~:waist~          | ~:waist~                       |
 | ~‚ü¥~               | Forward function application |
 | ~:kind~           | ~:kind~, see below             |
 | ~:level~          | Agda built-in                |
 | ~:alter-elements~ | Agda macros                  |
  #+latex: \end{tcolorbox}
 # Moreover, it is nearly as readable
 #  and is a library method, rather than an editor extension.

 =PackageFormer='s ~_:kind_~ meta-primitive dictates how an abstract grouping
 mechanism should be viewed in terms of existing Agda syntax.  However, unlike
 =PackageFormer=, *all of our syntax consists of legitimate Agda terms.*
 Since language syntax is being manipulated,
 we are forced to implement the ~_:kind_~ meta-primitive as a macro.
{{{code( Codes for Agda's first-class grouping mechanisms )}}}
 #+latex: \begin{tcolorbox}[title = Kind, colback=yellow!5!white, colframe=yellow!75!black]
 #+begin_center org
 #+latex: \dbox{\parbox{0.60\textwidth}{%
 src_haskell[:exports code]{ùíû :kind ‚Äµrecord ¬†¬†¬†= ùíû 0}

 src_haskell[:exports code]{ùíû :kind ‚Äµtypeclass = ùíû :waist 1}

 src_haskell[:exports code]{ùíû :kind ‚Äµdata¬†¬†¬†¬†¬†¬†= termtype (ùíû :waist 1)}
#+latex:  }}
 #+end_center
   #+begin_src agda :tangle Context.agda
data Kind : Set where
  ‚Äµrecord    : Kind
  ‚Äµtypeclass : Kind
  ‚Äµdata      : Kind

macro
  _:kind_ : Term ‚Üí Term ‚Üí Term ‚Üí TC Unit.‚ä§
  _:kind_ t (con (quote ‚Äµrecord) _)    goal
      = normalise (t app (quoteTerm 0))
        >>=‚Çò Œª t' ‚Üí unify (waist-helper 0 t') goal
  _:kind_ t (con (quote ‚Äµtypeclass) _) goal
      = normalise (t app (quoteTerm 1))
        >>=‚Çò Œª t' ‚Üí unify (waist-helper 1 t') goal
  _:kind_ t (con (quote ‚Äµdata) _) goal
      = normalise (t app (quoteTerm 1))
        >>=‚Çò Œª t' ‚Üí normalise (waist-helper 1 t')
        >>=‚Çò Œª tt ‚Üí unify goal (def (quote Fix)
                                        ((vArg (Œ£‚Üí‚äé‚ÇÄ (sources‚ÇÅ tt))) ‚à∑ []))
  _:kind_ t _ goal = unify t goal
#+end_src
  #+latex: \end{tcolorbox}

 #+latex: \vspace{0.5em}\medbreak\noindent
 We did not expect to be able to define a full Agda implementation of the semantics of
 =PackageFormer='s
 syntactic constructs due to Agda's rather constrained metaprogramming mechanism.
 However, it is important to note that =PackageFormer='s Lisp extensibility
 expedites the process of trying out arbitrary grouping mechanisms ---such as
 partial-choices of pushouts and pullbacks along user-provided assignment
 functions--- since it is all either string or symbolic list manipulation. On the
 Agda side, using =Context=, it would require substantially more effort due to the
 limited reflection mechanism and the intrusion of the stringent type system.

 :Ignore:
 For PackageFormer, we have implemented its primitives ~:waist~ and ~:kind~, the
 other core meta-primitives are ~_‚ü¥_~ and ~:alter-elements~. The former is a
 syntactic form of function application, ~x ‚ü¥ f ‚âà f x~, which we already have by
 juxtaposition in Agda. The latter, however, is a ‚Äúhammer‚Äù that alters the
 constituents of a grouping mechanism in an arbitrary fashion using the entire
 power of Emacs Lisp ---which includes a large portion of Common Lisp.  We have
 currently presented a partial semantics of PackageFormer's syntactic entities by
 presenting them here as semantic functions on contexts.
 :End:

* nomargins                                                          :ignore:
#+latex: \nomargins
* Conclusion
  :PROPERTIES:
  :CUSTOM_ID: Conclusion
  :END:

<<sec:conclusion>>
# +latex: \label{sec:conclusion}
#+latex: \setcounter{footnote}{0} \setcounter{sidenote}{0}

** Intro :ignore:
  The initial goal of this work was to explore how investigations into
  packaging-up-data ---and language extension in general--- could benefit from
  mechanising tedious patterns, thereby reinvigorating the position of universal
  algebra within computing. Towards that goal, we have decided to create an
  editor extension that can be used, for instance, to quickly introduce
  universal algebra constructions for the purposes of ‚Äúgetting things done‚Äù in a
  way that does not force users of an interface to depend on features they do
  not care about ---the so-called Interface Segregation Principle.  Moreover, we
  have repositioned the prototype from being an auxiliary editor extension to
  instead being an in-language library and have presented its key insights so
  that it can be implemented in other dependently-typed settings besides Agda.

  Based on the results ---such as the over 80% line savings in the MathScheme
  library--- we are convinced that the (one-line) specification of common
  theories (data-structures) can indeed be used to reinvigorate the position of
  universal algebra in computing, as far as DTLs are concerned. The focus on the
  modular nature of algebraic structures, for example, allows for the /mechanical/
  construction of novel and unexpected structures in a practical and elegant way
  ---for instance, using the src_emacs-lisp[:exports code]{keeping} combinator
  to extract the /minimal/ interface for an operation, or proof, to be
  valid. Also, we believe that the correspondence between abstract mathematical
  theories and data structures in computing only strengthens the need for a
  mechanised approach for the under-utilised constructions available on the
  mathematical side of the correspondence.

  Some preliminary experiences show that the approach used in this thesis can be
  used with immediate success. For example, the editor extension allows a host
  of renamings to be done, along with the relevant relationship mappings, and so
  allow proofs to be written in a more readable fashion.  As another example,
  the in-language library allows one to show that the free algebra associated
  with a theory is a particular useful and practical data-structure ---such as
  src_haskell[:exports code]{‚Ñï, Maybe,} and src_haskell[:exports
  code]{List}. These two examples are more than encouraging, for the continual
  of this effort. Also, the success claimed by related work like
  #+latex: Arend\footcitet{arend:webpage}$^,$\footcitet{arend:DBLP:journals/corr/abs-2004-14195}
  makes us believe that we can have a positive impact.

  This thesis has focused on various aspects of furnishing packages with a
  status resembling that of a first-class citizen in a dependently-typed
  language. Where possible, we will give an indication of future work which has
  still to be done to get more insight in this direction.


# +latex: \begin{fullwidth}
{{{localtoc}}}
# +latex: \end{fullwidth}

** Questions, Old and New

#+latex_header: \newunicodechar{Ãá}{\ensuremath{\!\!\!{}^.}}

   Herein we revisit the research questions posed in the introductory chapter,
   summarise our solutions to each, and discuss future work.

  *Practical Concern ‚ôØ1: Renaming & Remembering Relationships.* A given structure
  may naturally give rise to various ‚Äòchildren structures‚Äô, such as by
  adding-new/dropping-old/renaming components, and it is useful to have a
  (possibly non-symmetric) coercion between the child and the original parent.

  We have succeeded to demonstrate that ubiquitous constructions can be
  mechanised and the coercions can also be requested by a simple keyword in
  the specification of the child structure. As far as this particular problem is
  concerned, we see no missing feature and are content with the success that the
  PackageFormer prototype has achieved. However, the in-language Context library
  does leave room for improvement, but this is a limitation of the current Agda
  reflection mechanism rather than of the approach outlined by PackageFormer.

  *Practical Concern ‚ôØ2: Unbundling.* A given structure may need to have some of
  its components ‚Äòfixed ahead of time‚Äô.  For instance, if we have a type =Graph=
  of graphs but we happen to be discussing only graphs with natural numbers as
  nodes, then we need to work with =Œ£ G ‚à∂ Graph ‚Ä¢ G.Node ‚â° ‚Ñï= and so work with
  pairs =(G, refl)= whose second component is a necessarily technical burden, but
  is otherwise insightful.

  Our frameworks fully achieve this goal.  An improvement would be not
  to blindly lift the first /n/-many components to the type level but instead to
  expose the induced dependency subgraph of a given set of components. The
  PackageFormer already does this for the src_emacs-lisp[:exports code]{keeping}
  combinator and the same code could be altered for the src_emacs-lisp[:exports
  code]{waist} combinator. At first, it would seem that a similar idea would
  work for the in-language library, however this is not the case.  The Context
  library, unlike PackageFormer, does not work with flat strings but instead
  transforms the inner nodes of abstract syntax trees ---such as replacing Œ†s by
  Œªs or Œ£s--- and so the need to lift a subgraph of a structure's signature no
  longer becomes a linear operation that alters inner nodes.

  For an example to illuminate the problem,
  consider the following signature:

  {{{code(PSGwId¬≤ ---‚ÄòP‚Äôointed ‚ÄòS‚Äôemi‚Äòg‚Äôroup ‚Äòw‚Äôith ‚ÄòId¬≤‚Äô ‚âà Id)}}}
  #+begin_src agda
  record PSGwId¬≤ : Set‚ÇÅ where
    field
      -- We have a semigroup
      C     : Set
      _‚äï_   : C ‚Üí C ‚Üí C
      assoc : ‚àÄ x y z  ‚Üí  (x ‚äï y) ‚äï z  ‚â°  x ‚äï (y ‚äï z)
      -- with a selected point
      id    : C

    twice : C ‚Üí C
    twice = Œª x ‚Üí x ‚äï x

    -- Such that the point is idempotent
    field
      id¬≤ : twice id ‚â° id
  #+end_src
  Suppose we want to have the field =id¬≤= at the type level, then we must also
  expose the parts of the signature that make it well-defined; namely, =C, _‚äï_, id,
  twice=.  At a first pass, =id¬≤= only needs =id= and the operation =twice=; however,
  if we look at each of these in-turn we see that we also need =C= and =_‚äï_=. As
  such, in the worst case, this operation is quadratic.  Moving on, as the
  signature is traversed, we can mark fields to be lifted but we need a
  combinator to ‚Äúshift leftward (upward)‚Äù the names that are to be at the type
  level ---in this case, we need to move =id¬≤= and =id= to come before =assoc=.  This
  is essentially the algorithm implemented in PackageFormer's
  src_emacs-lisp[:exports code]{keeping} combinator.  However, for Context's
  src_haskell[:exports code]{do}-notation, this may not be possible since
  inner-nodes are no longer replaced, linearly, according to a single toggle.
  Future work would be to investigate whether it would be possible and, if so,
  how to do so in a /pragmatic and usable/ fashion.

  *Theoretical Concern ‚ôØ1: Exceptionality.* If an integer $m$ divides an integer
  $n$, then division $n \div m$ yields an integer witnessing $n$ as a multiple of
  $m$; likewise, if a package $p$ is structurally (nominally) contained in a
  package $q$, then we can form a package, say, $\;q \,-Ãá\, p\;$ that contains the extra
  matter and it is parameterised by an instance of $p$ ---e.g., =Monoid= is
  contained in =Group= and so =Group -Ãá Monoid = Œª (M : Monoid) ‚Üí (_‚Åª¬π : ‚ãØ,
  left-inverse : ‚ãØ, right-inverse: ‚ãØ)= is the parameterised package that can
  adjoin inverses to monoids. As such, packages are like numbers ---compare with
  the idea that a list is like a number, the latter being a list of unit
  (trivial) information.

  Our goal was to determined the /feasibility/ of this idea /within/
  dependently-typed settings. The implementation of the Context in-language
  library yields a resounding positive. As mentioned already, limitations of the
  host DTL's reflection mechanism are inherited by our approach.

  Future work would focus on the precise relationship between features of the
  host language and a library treating packages as first-class. Moreover, it
  would be useful to investigate how packages can be promoted to first-class
  /after/ the construction of a language. Such an investigation would bring to
  light the interplay of how packages actually influence other parts of a
  language ---which is sorely lacking from our work.

  Perhaps the most pressing concern would be how the promotion of packages would
  influence typechecking.  At first, for instance, the package =PSGwId¬≤= from
  above could be typed as =Set‚ÇÅ= but that would be wildly inappropriate since we
  cannot apply arbitrary package combinators, such as ~_-Ãá_~, to arbitrary types
  ---just as we cannot apply ~_√∑_~ to arbitrary types.  Instead, we would need a
  dedicated type, say, ~Package~. Things now become exceedingly hairy.  Do we need
  a hierarchy or avoid paradoxes, as is the case with =Set‚Çô=?  A parameterised
  type is a Œ†-type, but a parameterised package /is a/ package ---so do Œ†-types get
  ‚Äòabsorbed‚Äô into =Package=? What are the types of the package combinators
  introduced in this thesis, such as unbundling Œ†‚ÜíŒª?

  These questions are not only interesting by themselves, but they would also be
  a stepping stone to having full-fledged first-class packages in
  dependently-typed languages.

  *Theoretical Concern ‚ôØ2: Syntax.* The theories-as-data-structures lens presented
  in this work showcases how a theory (a record type, signature, admitting
  instances) can have useful data-structures (algebraic data types) associated
  with it.  For instance, monoids give rise to binary trees whose leaf values
  are drawn from a given carrier (variable) set. One can then encode a sentence
  of a model structure using the syntax, perform a syntactic optimisation,
  then interpret the sentence using the given instance.

  # Dangerous claim?
  # We are delighted with the rather unexpected success of this aspect of our work.
  # The formal methods community is well-aware that monoids are related to binary trees
  # and that pointed sets are related to maybe (nullable) types, yet we have had the
  # honour of being the first to actually derive the latter from the former /mechanically/.

  Future work would focus on the treatment non-function-symbols.  For instance,
  instead of discarding properties from a theory, one could keep them thereby
  obtaining ‚Äòhigher-order
  #+latex: datatypes‚Äô\footcitet{DBLP:journals/pacmpl/VezzosiM019}
  or could have them lifted as parameters in a (mechanically generated)
  subsequent module.  Moreover, the current implementation of Context has a
  basic predicate determining what constitutes a function-symbol, it would be
  interesting to make that a parameter of the theories-as-data-structures
  src_emacs-lisp[:exports code]{termtype} construction.

  *Proof.* Finally, there are essentially no formal theorems proven in this work.
  The constructions presented rely on /typechecking/: One can phrase a desired
  construction and typechecking determines whether it is meaningful or not.  It
  would be useful to determine the necessary conditions that guarantee the
  well-definedness of the constructions ---so that we may then ‚Äúgo up another
  level‚Äù and produce meta-constructions that invoke our current constructions
  mechanically and ‚Äúwholesale‚Äù. More accurately, in Agda, proof-checking is part
  of type-checking since all proofs are terms ---in particular, the
  well-formedness of a construction ---via either src_haskell[:exports
  code]{PackageFormer} or src_haskell[:exports code]{Context}--- is certified
  at typechecking time.

** Concluding Remarks

 In dependently-typed settings (DTS), it is common practice to operate on
 packages ---by renaming them, hiding parts, adding new parts, etc.--- and the
 frameworks presented in this thesis show that it is indeed possible to treat
 packages nearly as first-class citizens ‚Äúafter the fact‚Äù even when a language
 does not assign them such a status. The techniques presented show that this
 approach is feasible as an in-language library for DTS as well as for the any
 highly customisable and extensible text editor.

 The combinators presented in this thesis were guided not by theoretical
 concerns on the algebraic nature of containers but rather on the practical
 needs of actual users working in DTS. We legitimately believe that our stance
 on packages as first-class citizens should ---and hopefully one day would--- be
 an integral part of any DTS. The Context library is a promising approach to
 promoting the status of packages, to reducing the gap between different
 ‚Äúsub-languages‚Äù in a language, and allowing users to benefit from a streamlined
 and familiar approach to packages ---as if they were the ‚Äòfancy numbers‚Äô
 abstracted by rings, fields, and vector spaces.

 Finally, even though we personally believe in the import of packages, we do not
 expect the same belief to trickle-down to mainstream languages immediately
 since they usually do not have sufficiently
 #+latex: sophisticated\FOOTNOTE{
 The static typing of some languages, such as C, is so pitiful that is makes
type systems seem more like a burden then anything useful ---in C, one often
uses void pointers to side-step the type system's limitations, thereby
essentially going untyped.  The dynamically typed languages, however, could be
an immediate test-bed for package combinators ---indeed, Lisp, Python, and
JavaScript use ‚Äòsplicing‚Äô operators to wholesale include structures in other
structures, within the core language.
 #+latex: }
 type systems to permit the treatment of packages as first-class citizens, on
 the same footing as numbers.  Nonetheless, we believe that the work in this
 thesis is yet another stepping-stone on the road of
 #+latex: \emph{DRY}\FOOTNOTE{
 /Don't Repeat Yourself!/
 #+latex: }
 endeavours.

* Bib                                                                :ignore:

# +LATEX_HEADER: \usepackage[citestyle=authoryear-icomp,style=alphabetic,hyperref=true,backref=true,maxcitenames=3,url=true,backend=biber,natbib=true] {biblatex}

# Example: This citet:agda_overview or \cite{agda_overview} ^_^

# +latex_header: \usepackage{\string /Users/musa/kaobook/styles/kaobiblio} \let\cite=\sidecite
#+latex_header: \usepackage{biblatex}
#+latex_header: \addbibresource{papers/References.bib}


# +latex_header: \usepackage[style=verbose, autocite=footnote, backend=biber]{biblatex} \let\cite=\autocite
# +latex_header: % Load the bibliography package
# +latex_header: \usepackage{styles/kaobiblio}
# +LATEX_HEADER: \addbibresource{papers/References.bib}

# +LaTeX: \addcontentsline{toc}{part}{References}
# +LaTeX: \printbibliography

# +latex: \defbibnote{bibnote}{Here are the references.\par\bigskip} % Prepend
# this text to the bibliography
#+latex: \defbibnote{bibnote}{} % Prepend this text to the bibliography
#+latex: \nomargins
#+latex: \printbibliography[heading=bibintoc, title=Bibliography, prenote=bibnote] % Add the bibliography heading to the ToC, set the title of the bibliography and output the bibliography note
#+latex: \yesmargins

# +latex:  \backmatter
# +latex: \bibliography{papers/References.bib} \bibliographystyle{plainnat}

# +latex: \printbibliography

* appendix marker :ignore:
\appendix

:Musa:
The appendix marker must occur before the section on appendices.
:End:

* nomargins                                                          :ignore:
#+latex: \nomargins
* Code

<<sec:code>>
# +latex: \label{sec:code}

# +latex: \begin{fullwidth}
{{{localtoc}}}
# +latex: \end{fullwidth}

** 265 Line ~Context~ Implementation

#+latex_header: \newunicodechar{‚âó}{EQUAL}
# +LATEX_HEADER: \BeforeBeginEnvironment{minted}{\begin{tcolorbox}[title=\hfill \mytitle]}%
# +LATEX_HEADER: \AfterEndEnvironment{minted}{\end{tcolorbox}}%
#+latex: \renewenvironment{tcolorbox}[1][\unskip]{}{}

{{{code(Context Implementation)}}}
#+INCLUDE: "Context.agda" src agda -n
# :lines "20-50"

** Example uses of ~Context~

These are the examples from Chapter \ref{sec:contexts}, in a self-contained
listing.

#+INCLUDE: "Context_Examples.agda" src agda -n

* Footnotes

[fn:64]   Incidentally, the particular choice src_haskell[:exports code]{ùí≥‚ÇÅ}, a
  predicate on one carrier, deserves special attention. In Haskell, instances of
  such a type are generally known as /typeclass instances/ and
  src_haskell[:exports code]{ùí≥‚ÇÅ} is known as a /typeclass/. As discussed earlier,
  in Agda, we may mark such implementations for instance search using the
  keyword src_emacs-lisp[:exports code]{instance}.

[fn:63] Thereby having no empty types at all ---roughly put, this is what
Haskell does. Agda lets us do this with the ~postulate~ keyword.

[fn:62] Leaving users the burden of ensuring that any call ~head l~ never happens
with ~l = []~! Otherwise, we need to parameterise our function by a ‚Äúdefault
value‚Äù.


[fn:61] For example, to make rings!

[fn:60] The three green arrows in the diagram above!

[fn:59]   It is important to remark that the mechanical construction of such
  views (coercions) is *not built-in*, but rather a /user-defined/ variational that
  is constructed from =PackageFormer='s meta-primitives.

[fn:58] \textbf{Arbitrary functions act on modules:} When only one variational
  is applied to a context, the one and only ‚Äò‚ü¥‚Äô may be omitted. As such,
  =Semantics‚ÇÉ= is defined as ~Semantics rename f~, where =f= is the decoration
  function.  In this form, one is tempted to believe
  #+latex: \begin{center}
  src_haskell[:exports code]{ _rename_ : PackageFormer} \\
  src_haskell[:exports code]{¬†¬†¬†¬†¬†¬†¬†¬†‚Üí (Name ‚Üí Name) } \\
  src_haskell[:exports code]{¬†¬†¬†¬†¬†¬†¬†¬†‚Üí PackageFormer }
  #+latex: \end{center}
  That is, we have a binary operation in which functions may act on modules
  ---this is yet a new feature that Agda cannot perform.


[fn:57] \textbf{Conflating fields, parameters, and definitional extensions:}
  The lack of a src_agda[:exports code]{field} keyword and forbidding parameters
  means that arbitrary programs may ‚Äòlive within‚Äô a =PackageFormer= and it is up
  to a variational to decide how to treat them and their optional definitions.

[fn:56] For every (special comment) declaration ~‚Ñí = ‚Ñõ~ in the source file, the
     name ~‚Ñí~ obtains a tooltip which mentions its specification ~‚Ñõ~ and the
     resulting legitimate Agda code. This feature is indispensable as it lets
     one generate grouping mechanisms and quickly ensure that they are what one
     intends them to be.

[fn:55]
[fn:54] A prototype's raison d'etre is a testing ground for ideas, so its ease
of development may well be more important than its usability.

[fn:53]
[fn:52]

[fn:51] In theory, numbers can be presented equivalently using Arabic or Roman
numerals.  In practice, doing arithmetic is much more efficient using the former
presentation.

[fn:50] For example, to find how many elements are in a list, a function
\newline
src_agda[:exports code]{length : ‚àÄ {A} ‚Üí List A ‚Üí ‚Ñï}
\newline
must ‚Äúwalk along each
prepending constructor until it reaches the empty constructor‚Äù and so it
requires as many steps to compute as there are elements in the list. As such, it
is impossible to write a function that requires a constant amount of steps to
obtain the length of a list.  In contrast, a function
\newline
src_agda[:exports
code]{length : ‚àÄ {A n} ‚Üí Vec A n ‚Üí ‚Ñï}
\newline
requires /zero steps/ to compute its result
---namely, src_agda[:exports code]{length {A} {n} l = n}--- and so this
function, for vectors, is rather facetious.

[fn:49] The definition of this type, and the subsequent ~head~ function, have been
discussed in section ref:sec:agda_tour:ADTs, in the introduction to
dependently-typed programming with Agda.


[fn:48] A variation of this problem is discussed in
        #+latex: section \ref{sec:packages_and_their_parts:sigma_pi}.
        #+latex: \\[0.2ex]
        The purpose of this section is to demonstrate the related, yet different, ideas below.
        #+latex: \\[0.6ex]
        (1) Isomorphism is not indistinguishable from equality.
        #+latex: \\[0.3ex]
        (2) Propositional equality is not equal to definitional equality.
        #+latex: \\[0.3ex]
        (3) Equivalent presentations are not equivalent in different, real usage scenarios.
        #+latex: \\[0.7ex]
        The first two subsections here are concrete instances of the more
        general situation
        and readers familiar with DTLs are encouraged to skip ahead to section
        #+latex:        \ref{sec:examples:IsX}.


[fn:47] Formally, one could show, for instance, that every list corresponds to a
vector, src_agda[:exports code]{List X ‚âÖ (Œ£ n : ‚Ñï ‚Ä¢ Vec X n)}. Informally, any
list src_agda[:exports code]{x‚ÇÅ ‚à∑ x‚ÇÇ ‚à∑ ‚Ä¶ ‚à∑ x‚Çô ‚à∑ []} can be treated as a vector
(since we are using the same /overloaded/ constructors for both types) of /length/
~n~; conversely, given a vector in =Vec X n=, we ‚Äúforget‚Äù the length to obtain a
list.


[fn:46]


[fn:45]

[fn:44] In these diagrams, the arrows are used to denote a dependency
relationship.

[fn:43]

[fn:42]
[fn:41]


[fn:40]
[fn:39]


[fn:38]

[fn:37]

[fn:32] See \cite{hottbook}
  # and \cite{emmenegger18:_w} for an introduction to ùí≤-types.@@

   # The dual, non-well-founded (coinductive) types, are called \emph{M-types}
   # and they are derivable from W-types; see \cite{DBLP:journals/corr/AhrensCS15}.
   # The generic concept of ‚Äòcontainers‚Äô is described in \cite{DBLP:journals/jfp/AltenkirchGHMM15}.

# See https://arxiv.org/abs/1504.02949

[fn:25] The Œ£-types denote disjoint unions and are sometimes written
as ‚àê ---the ‚Äòdual‚Äô symbol to Œ†.
# \coprod


[fn:24] Those familiar with set theory may remark that dependent types are not
/necessary/ in the presence of power sets: Instead of a /single/ name =call=, one uses
a (possibly infinite) /family of names/ $\mathsf{call}_‚Ñì$ for each possible name
$‚Ñì$. Even though power sets are not present in our setting, dependent types
provide a natural and elegant approach to /indexed types/ in lieu of an encoding
in terms of /families of sets or operations/.  Moreover, an encoding /hides/
essential features of an idea such as dual concepts: Œ£ and Œ† are ‚Äòadjoint
functors‚Äô.  Even more surprising, working with Œ£ and Œ† leads one to interpret
‚Äúpropositions as types‚Äù with predicate logic quantifiers ‚àÄ/‚àÉ encoded via
dependent types Œ†/Œ£; whence the slogan:
#+begin_center
*/‚ÄúProgramming ‚âà Proving‚Äù/*
#+end_center


[fn:23] The initiated may recognise this problem as identifying
the relationship between /slice categories/ $ùíû/A$ whose objects
are /A/-indexed families and /arrow categories/ $ùíû^‚Üí$ whose
objects are /all/ the /A/-indexed families /for all/ possible $A$.
In particular, identifying the relationship between the
categorial transformations $\_{}/A$ and $\_{}^‚Üí$ ---for which
there is a non-full inclusion from the former to the latter,
which we call ‚ÄúŒ£-padding‚Äù.

[fn:20]     We write =List X= for the type of lists with values from =X=. The empty
    list is written =[]= and =[x‚ÇÅ, x‚ÇÇ, ‚Ä¶, x‚Çô]= denotes the list of $n$ elements ~x·µ¢~
    from ~X~; one says $n$ is the /length/ of the list.

[fn:17]



[fn:16]  The standard type ~Vec A n~, consisting of lists of elements of ~A~ having
 length ~n~, is defined in Appendix B.


[fn:15] Up to observational equality. For example, there are multiple
sorting algorithms but they achieve the same end-goal.

[fn:14]
Here are a few concrete instances:
=Vec œÑ 1 ‚âÖ œÑ=; $\quad$ =Vec œÑ 2 ‚âÖ œÑ √ó œÑ=; $\quad$ =Vec œÑ 3 ‚âÖ œÑ √ó œÑ √ó œÑ=.
# MA: I could not have a src block in a footnote

[fn:13] It is common to see /binder notation/ as =ùí¨ x ‚à∂ œÑ ‚Üí ‚ãØ=, =(ùí¨ x ‚à∂ œÑ) ‚ãØ=, and in
~ùí¨ x ‚à∂ œÑ ‚Ä¢ ‚ãØ~. We prefer the final form.  Agda uses =ùí¨ (x ‚à∂ œÑ) ‚Üí ‚ãØ= for binders, and
uses ~‚àÄ~ in-place of ~Œ†~ and ~record~-syntax in-place of ~Œ£~.  To emphasise that Œ†/Œ£
/extend/ the usual √ó/‚Üí, one may write ~(a : A) ‚Üí B a~ and ~(a : A) √ó B a~.  The
appendix shows how to use Agda's =syntax= declarations to allow one to use nearly
any desired, linear, syntax.  Our demonstration language, Agda, happens to use a
/hierarchy of types/ which it calls =Set·µ¢= instead of ~Type·µ¢~; however, DTLs do not
need such a hierarchy; indeed some have a single universe ~Type~ with the rule
~Type ‚à∂ Type~.

[fn:12]
https://alhassy.github.io/next-700-module-systems/prototype/package-former.html

[fn:11]
[fn:10] The current implementation uses a single ‚Äòwaist‚Äô /number/ =j= to identify the first
=j=-many parameters.

[fn:9] The =PackageFormer= manual provides the expected Lisp methods one is
interested in, such as ~(list x‚ÇÄ ‚Ä¶ x‚Çô)~ to make a list and ~first, rest~ to
decompose it, and ~(--map (‚ãØit‚ãØ) xs)~ to traverse it. Moreover, an Emacs Lisp
cheat sheet covering the basics is provided.


[fn:8]

[fn:7] None of my colleagues thought Lisp was at all the ‚Äòright‚Äô choice;
of course, none of them had the privilege to use the language enough to
appreciate it for the wonder that it is.

[fn:6] Latin for: /From falsehood ---ex falso--- anything (lit: whatever you wish) follows ---quodlibet./
Also known as ‚Äúthe principle of explosion‚Äù.

[fn:5] A comparison of module systems of other dependently-typed languages
is covered in section ref:sec:module_existing.

[fn:4]

[fn:3]

[fn:2] Don't Repeat Yourself

[fn:1] Arbitrary, semantic, properties can be attached to data constructors.
However, properties encoded via syntactic structure can be mechanically checked
via typechecking. Whereas needing /a proof of a property/ may require human intervention.
* COMMENT Misc
** my-info addendum

subjective marks:


--------------------------------------------------------------------------------

Set and Prop are no longer keywords but are now primitives defined in the module
Agda.Primitive. They can be renamed when importing this module, for example:

#+begin_src agda
open import Agda.Primitive renaming (Set to Type)

test : Type‚ÇÅ
test = Type
#+end_src

To preserve backwards compatibility, each top-level Agda module now starts with an implicit statement:

#+begin_src agda
open import Agda.Primitive using (Set; Prop)
#+end_src

This implicit import can be disabled with the --no-import-sorts flag.


New (experimental) option --cumulativity

When the --cumulativity flag is enabled, Agda uses the subtyping rule Set i =<
Set j whenever i =< j. For example, in addition to its usual type Set, Nat also
has the type Set‚ÇÅ and even Set i for any i : Level. More information about this
new option can be found in section Cumulativity of the user manual.

--------------------------------------------------------------------------------

Mention in Ch2?

Agda now has support for sorts Setœâ·µ¢ (alternative syntax: Setœâi) for natural
numbers i, where Setœâ‚ÇÄ = Setœâ. These sorts form a second hierarchy Setœâ·µ¢ :
Setœâ·µ¢‚Çä‚ÇÅ similar to the standard hierarchy of Set·µ¢, but do not support universe
polymorphism. It should not be necessary to refer to these sorts during normal
usage of Agda, but they might be useful for defining reflection-based macros
(see #2119 and #4585).

Agda now supports a cubical mode which adds new features from Cubical Type
Theory, including univalence and higher inductive types. Option --cubical
enables the cubical mode, and cubical primitives are defined in the module
Agda.Primitive.Cubical. See the user manual for more info.
- https://arxiv.org/abs/1611.02108 CTT
- https://agda.readthedocs.io/en/v2.6.1.1/language/cubical.html

Agda now supports the new sort Prop of definitionally proof-irrelevant
propositions. Option --prop enables the Prop universe but is off by
default. Option --no-prop disables the Prop universe. See the user manual for
more details.
- https://hal.inria.fr/hal-01859964
- https://agda.readthedocs.io/en/v2.6.1.1/language/prop.html


Agda will no longer reduce irrelevant definitions and definitions with a type in
Prop. This does not have an effect on the semantics, but should lead to improved
performance (see Issues #4115, #4118, #4120, #4122).
- https://github.com/agda/agda/issues/4115
- https://github.com/agda/agda/issues/4118
- https://github.com/agda/agda/issues/4120
- https://github.com/agda/agda/issues/4122
- https://github.com/agda/agda/issues/3337

Terms of a type in Prop are now printed as _.

Maybe mention in ch5-contexts?
https://agda.readthedocs.io/en/v2.6.1/language/flat.html

** TODO ‚ü®ùëµùë∂‚ü© Introduction via graphs              :intro:conclusion:

 In dependently-typed programming languages, such as Agda
 citet:Norell-2007,agda_overview, there is a tendency to define concepts
 repeatedly along syntactic constructs provided by the language.  In particular,
 one bundles up related data into a record structure, then considers the need to
 expose some of the fields as parameters and so provides a parameterised record
 construction, then for the need to have a description language for terms of
 these record types, one forms an associated algebraic datatype.  For example, we
 may form a type ~Monoid‚ÇÄ~ of monoids, which consists of a type along with an
 operation and some laws, but may want ~Monoid‚ÇÅ M ‚äï~ to speak of monoids over
 /particular/ types ~M~ and particular operations ~‚äï~ ---the latter is handled, say in
 the Haskell standard library, by having isomorphic copies of types for each
 binary operation, such as ~Sum ‚âÖ Prod ‚âÖ Int~ for the classical additive and
 multiplicative monoidal structures on integers.  This is the problem we are
 solving: /How can parameterised records and their associated algebraic datatypes
 be obtained from a core declaration?/

 The humblest notion of a grouping mechanism is described by a pair type ~A √ó B √ó
 C~, usually later values depend on earlier values and so we have the
 dependent-pair type src_agda[:exports code]{Œ£ a ‚à∂ A ‚Ä¢ Œ£ b ‚à∂ B a ‚Ä¢ Œ£ C a b}. The kind of these types is
 ~Set‚ÇÅ~, the type of small types. If we wish to speak of groupings where ~a ‚à∂ A~ is
 /fixed/, then we must lift it from being a /field/ component to being a /parameter/,
 thereby arriving at the /function/ ~Œª a ‚à∂ A ‚Ä¢ Œ£ b ‚à∂ B a ‚Ä¢ Œ£ C a b~ which has /type/ ~Œ† a ‚à∂
 A ‚Ä¢ Set~. Similarly, we may expose ~b~ as a parameter to further indicate the
 possible grouping structure.

 | Grouping Description          |   | Kind                      |
 |-------------------------------+---+---------------------------|
 | =Œ£ a ‚à∂ A ‚Ä¢ Œ£ b ‚à∂ B a ‚Ä¢ Œ£ C a b= |   | ~Set~                       |
 | =Œª a ‚à∂ A ‚Ä¢ Œ£ b ‚à∂ B a ‚Ä¢ Œ£ C a b= |   | ~Œ† a ‚à∂ A ‚Ä¢ Set~             |
 | =Œª a ‚à∂ A ‚Ä¢ Œª b ‚à∂ B a ‚Ä¢ Œ£ C a b= |   | ~Œ† a ‚à∂ A ‚Ä¢ Œ† b ‚à∂ B a ‚Ä¢ Set~ |

 At each step, we ‚Äúpull out‚Äù more information at the kind level; at first we have
 a ~Set~, an opaque grouping mechanism, then we obtain a ~Œ† a ‚à∂ A ‚Ä¢ Set~ which is a
 grouping mechanism that somehow makes use of an ~A~-value.

 1. *Type constructor reification Œ†‚ÜíŒª:* Function /types/ like ~Œ† a ‚à∂ A ‚Ä¢ Set~ cannot be
    applied since they are not functions, so how do we get to ~Œª a : A ‚Ä¢ Set~?

    + Œª-terms are values of Œ†-types, but in general there is no natural
      construction to transform a type into one of its values.

    + Given ~œÑ = Œ† (X : Set) ‚Ä¢ ‚ãØ : Set‚ÇÅ~, we want ~Œ†‚ÜíŒª œÑ = Œª (X : Set) ‚Ä¢ ‚ãØ : Œ† (X :
      Set) ‚Ä¢ Set~; the former's type states it to be a =Set‚ÇÅ=, a grouping mechanism of
      which we know nothing, whereas the latter's type indicates it to be a
      parameterised grouping mechanism. Since ~Œ†‚ÜíŒª œÑ~ can be applied and is thus more
      concrete, we call ~Œ†‚ÜíŒª~ a reification combinator.

 2. *Unbundling* citet:packaging_mathematical_structures:
    How do we go from ~Set~ to ~Œ† a ‚à∂ A ‚Ä¢ Set~?

    A function from function-types to functions-on-types necessarily requires a
    way to pattern match on the possible type constructions in a language.

    Perhaps an example will clarify the issue. The ubiquitous graph structure
    is contravariant in its collection of vertices. Recall that a multi-graph, or
    quiver, is a collection of vertices along with a collection of edges between
    any two vertices; here's the traditional record form:
{{{code( ? )}}}
    #+begin_src agda
Graph  : Context ‚Ñì‚ÇÅ
Graph  = do Vertex ‚Üê Set
            Edges  ‚Üê (Vertex ‚Üí Vertex ‚Üí Set)
            End {‚Ñì‚ÇÄ}
 #+end_src

    Using the record form, it is akward to phrase contravariance, which simply
    ‚Äúrelabels the vertices‚Äù. Even worse, the awkward phrasing only serves to
    ensure certain constraints hold ---which are reified at the value level via
    the uninsightful ~refl~-exivity proof.
{{{code( ? )}}}
    #+begin_src agda
comap‚ÇÄ : ‚àÄ {A B : Set}
      ‚Üí (f : A ‚Üí B)
      ‚Üí Œ£ G ‚à∂ Graph :kind ‚Äµrecord ‚Ä¢ Field 0 G ‚â° B
      ‚Üí Œ£ G ‚à∂ Graph :kind ‚Äµrecord ‚Ä¢ Field 0 G ‚â° A
comap‚ÇÄ {A} {B} f (‚ü® .B , edgs ‚ü© , refl) = (A , (Œª a‚ÇÅ a‚ÇÇ ‚Üí edgs (f a‚ÇÅ) (f a‚ÇÇ)) , tt) , refl
        #+end_src
    /Without redefining graphs/, we can phrase the definition at the typeclass
    level ---i.e., records parameterised by the vertices. This form is not only
    clearer and easier to implement at the value-level, it also makes it clear
    that we are ‚Äúpulling back‚Äù the vertex type and so have also shown graphs are
    closed under reducts.
{{{code( ? )}}}
        #+begin_src agda
-- Way better and less awkward!
comap : ‚àÄ {A B : Set}
     ‚Üí (f : A ‚Üí B)
     ‚Üí (Graph :kind ‚Äµtypeclass) B
     ‚Üí (Graph :kind ‚Äµtypeclass) A
comap f ‚ü® edgs ‚ü©‚ÇÅ = ‚ü® (Œª a‚ÇÅ a‚ÇÇ ‚Üí edgs (f a‚ÇÅ) (f a‚ÇÇ)) ‚ü©‚ÇÅ
    #+end_src

    Later we show how to form ~Context~, its do-notation, and the ~:kind~ mechanism
    which shifts between records, typeclasses, and algebraic datatypes.

    It is important to note that we are using the word ‚Äòtypeclass‚Äô as an
    abbreviation for ‚Äúparameterised record‚Äù. In particular, we have no support
    for the traditional unification algorithm that makes typeclasses and
    canonical structures citet:coq_canonical_tutorial useful for ad-hoc
    polymorphism.
 # eval  : A √ó (A ‚Üí B) ‚Üí B
 # curry : (A √ó B ‚Üí C) ‚Üí (A ‚Üí (B ‚Üí C))
 # #
 # Œ† a ‚à∂ A ‚Ä¢ (Œ† f ‚à∂ (Œ† x ‚à∂ A ‚Ä¢ B x)) ‚Ä¢ B a
 # Œ† f ‚à∂ (Œ† p ‚à∂ (Œ† x ‚à∂ A ‚Ä¢ B x) ‚Ä¢ C p) ‚Ä¢ Œ† a ‚à∂ A ‚Ä¢ Œ† b ‚à∂ B a ‚Ä¢ C (a, b)
 # Œ† f ‚à∂ Set ‚Ä¢ (Œ† x ‚à∂ A ‚Ä¢ Set)

 We shall outline how this can be achieved in dependently-typed languages which
 have support for reflection. Our target language will be Agda, but the ideas
 easily transfer to other languages. In particular, the resulting in-language
 syntax we obtain is rather close to the existing Agda record syntax for
 declarations and Agda constructor tuples for instances.  In the next section, we
 begin by way of a more concrete example of a grouping mechanism, then we take a
 goal-driven approach to building the necessarily apparatus for a clean
 imperative-like declaration notation, then we conclude with a brief discussion
 on how the resulting framework can act as a simple theory for the Agda
 PackageFormer editor extension citet:DBLP:conf/gpce/Al-hassyCK19 ---which solves
 the =Monoid·µ¢= problem mentioned earlier.

 In order to be language-agnostic and underscore the ideas, we shall present the
 core definitions along with Agda-checked examples. Details can be read at the
 following URL in a literate and reproducible fashion
 citet:DBLP:conf/europar/StanisicL14.
 # Details are left to an
 # appendix(?) or can be read below (MA: Haven't decided yet):
 | =https://github.com/alhassy/next-700-module-systems/tree/master/prototype= |

*** COMMENT OLD Abstract                                           :ignore:
   #+begin_abstract org
   Folklore has held that any ‚Äòsemantic unit‚Äô is essentially a type-theoretic
   context ---this includes, for example, records and algebraic datatypes.  We
   provide foundation for such an observation.

   We show that languages with a sufficiently powerful type system and reflection
   mechanism permit a /single declaration interface/ for functions, records, type
   classes, type constructors, and algebraic data types. Moreover, the interface
   is monadic and thus actually practical to use.

   Along the way, we solve the bundling problem: Record fields can be lifted to
   parameters as needed. Traditionally, unbundling a record requires the use of
   transport along propositional equalities, with trivial ~refl~-exivity proofs.
   The ~:waist~ approach presented here removes the boilerplate necessary at the
   type specialisation location as well as at the instance declaration location.

   An application of our setup will be to provide a semantics for the
   PackageFormer editor extension, which realises the aforementioned folklore
   observation by providing users with meta-primitives for making modules to
   allow arbitrary grouping mechanisms to be derived, such as obtaining the
   homomorphism type of a given record.
 #+end_abstract

** ‚ü®ùëµùë∂‚ü© Discussion, Conclusion, and Future Work

<<sec:conclusion>>
#+latex: \label{sec:conclusion}

# Conclusion
#   - What we have done
#   - How it is useful to others, now.

As discussed in the introduction, Section ref:sec:many_tongues, there is a lack of a
unified and practical language for dealing with grouping mechanisms as standard
and unexceptional /values/.  In an effort to address this issue, this thesis has
presented a framework for modelling grouping mechanisms as first class values.
This framework aids in advancing the current understanding of grouping
mechanisms ---as summarised in the table below.

| Grouping Mechanism | Distinguishing Features                                      |
|--------------------+------------------------------------------------------------|
| =record=             | Opaque /fields/                                              |
| =data=               | Uninterpreted /constructors/                                 |
| =module=             | Namespacing for derived results or definitional extensions |
| =Context=            | Mixture of fields, constructors, and derived results       |

This chapter summarises and discusses the contributions of this thesis and
points to future research directions resulting from this work.  Specifically,
Section ref:sec:conclusion:contributions highlights, discuss, and assesses the
contributions that are made by this thesis. Section ref:sec:conclusion:futurework
suggests avenues for future work resulting from the prototypical =PackageFormer=
framework, and its applications and tools. Finally, Section
ref:sec:conclusion:closing makes final comments and closing remarks.

*** Highlights of the Contributions
<<sec:conclusion:contributions>>
#+latex: \label{sec:conclusion:contributions}


The contributions related to the proposed framework for the modelling grouping
mechanisms as first class values include:

1. *Necessary conditions for the first-class grouping mechanisms:*

   This thesis proposed a set of necessary conditions for a programming language
   to treat grouping mechanisms as ordinary values.  If the language provides a
   fixed-point operator and metaprogramming, then algebraic data types can be
   obtained from contexts. The minimal number of constraints aid in advancing
   the current understanding of grouping mechanisms by serving as a basis
   permitting exotic notions of grouping to be experimented with ---such as
   soundly deriving homomorphism types from a given context declaration.

2. *Specification of the relationships between grouping mechanisms:*

   This thesis builds atop well-established foundations
   but /without dictatorially declaring/ what grouping mechanisms are ‚Äòuseful‚Äô
   and which should be omitted. Instead, we provide primitives from which new
   grouping notions may be derived. This is akin to a programming language
   providing a set of combinators from which complex programs may be constructed.

3. *Two tools to experiment with new notions of grouping mechanisms:*

   This thesis provides the dynamic =PackageFormer= Emacs extension for /rapid,
   albeit practical, prototyping/ of new notions of grouping mechanisms.  For
   example, as discussed in Section ref:sec:PF:practicality:pushout, partial
   choices of pushouts can be quickly expressed and usefully so.  In contrast,
   the thesis also provides the =Context= library for /sound, typechecked,/
   developments of new notions of grouping mechanisms.

4. *Two semantics for a practical and pragmatic tool for developing grouping
   mechanisms:*

   This thesis provides a rewrite-based semantics for the
   =PackageFormer= Emacs editor extension, as well as interpreting
   its syntax as semantically as Agda-functions via the correspondence
   with =Context= outlined in Section ref:sec:context:related-works.

5. *Numerous examples of common grouping mechanisms:*

   This thesis presented a number of way to group data together, in the setting
   of =PackageFormer= in Section ref:sec:PF:practicality, with many more
   formalised in the tool's online repository[fn:12]. The usability of these
   notions of grouping mechanisms were found by exploring existing libraries on
   dependently typed languages, in Section ref:sec:examples_from_the_wild, which
   then led us to provide a listing of ‚Äòdesign patterns for dependently typed
   languages‚Äô.

*** Future Work

<<sec:conclusion:futurework>>
#+latex: \label{sec:conclusion:futurework}

The frameworks presented in this thesis can be extended in a number of
different directions. The following subsections describe possible
extensions and further work with respect to the proposed framework
and applications thereof.

**** Theory: Models and Techniques

Concerning the proposed framework for capturing the relationships of
grouping mechanisms, the following directions can be explored:

1. An investigation into providing more, and potentially better semantical
   models, of =PackageFormer= ought to be undertaken. For instance, since
   grouping mechanisms are about organising data and we wish to treat
   them as first-class citizens, a natural semantics would be using
   a form of closed categories, institutions, or rooms and corridors
   citet:institution_interpretations,institutions,cats_logic_shulman,dtl_cat_correspondences,Z_categorical,modules_categorically.

2. Further investigation into the interplay between external and internal
   grouping mechanisms. For instance, in Agda record projections can be costly
   citet:perna but every record-valued function is essentially a
   parameterised module, so an automatic shift in tools could result in
   increased efficiency.

3. A further study into the relationships between the module primitives
   and the ambient type theories is needed. For example, one can study how
   different Œª-calculi can be used in place of the MLTT-fragment in our
   initial semantics for =PackageFormer=. This can allow for flexible representations
   and varying degrees of expressivity. Moreover, such an investigation can
   allow for different way to reason about modules, such as using a little
   theories approach citet:little_theories.

4. There are a number of directions that can be explored with regard to a
   re-implementation of the =Context= library. For example, sufficiently careful
   definitions could be used to mitigate the need to side-step Agda's
   termination checker. Moreover, rather than leap to =do=-notation there is an
   interesting class of modules that could be defined using an applicative
   structure ---a sort-of Cartesian functor. Such modules would consist of
   entities that are defined independently of each other and thus the order of
   their declaration is essentially irrelevant, and as such could provide
   an opportunity for optimisation.

5. With regard to the existing representation of =Context=, there are a number of
   possible extensions. For example, rather than simply using Œ£ and Œ† based on
   whether the exposure is zero or not, what if the library were parameterised
   by a /family/ of such ‚Äòbinding quantifiers‚Äô, say /‚®Å/, and for each level of
   exposure /n/ we used the quantifier /‚®Å‚Çô/.  For instance, we may be interested in
   interleaving arbitrary meets and joins of a complete lattice rather
   than just consider types.

6. The =Context= semantics to =PackageFormer='s =:alter-elements= sledgehammer is the
   notion of Agda macros. It would be ideal to consider well-behaved
   approximations to this primitive that also have well-behaved semantical
   counterparts. This would necessitate an investigation into what people
   actually want to do to the components of a module and how to do so
   coherently. From our experience of implementing multiple notions of modules,
   we feel that =p :alter-elements f= will likely be a colimit construction so as
   to account for possibly ‚Äòdangling edges‚Äô when deletion happens and to also
   account for ‚Äògluing components‚Äô when items are identified.

7. The material presented in Chapter 5 ref:sec:PF:practicality can serve as the
   basis for many future research directions into /mechanising/ notions of
   grouping mechanisms. In particular, work can be done in order to further
   articulate how constructions from universal algebra can be used to produce
   useful notions of grouping mechanisms.

**** Applications

With respect to the possible applications of the proposed framework,
the following directions can be investigated further.

1. The range of the application domain of =Context= can be explored further.  Such
   domains include the Œª-calculi of programming languages with varying degrees
   of type expressivity ----from unityped to dependently-typed languages. This
   can lead to new and innovative ways to think and reason about modular
   programming in such systems, as well as to provide insight into the interplay
   between seemingly different notions of modularisation.  For example, by
   modelling the C language's =#include= approach to modules using =Context=, it may
   be possible to mechanically derive algebraic data types which may act as a
   ‚Äòdescription language‚Äô for the purposes of serialisation.

2. A study of how the proposed framework can be used to support the treatment of
   modules as standard values /derivable/ from other values is another fruitful
   future research opportunity.  For example, a constant is essentially a module
   consisting of one entity, whereas a function is essentially a parameterised
   module. It would be interesting to see which properties of functions could be
   transformed into ideas about modules; here is a preliminary sketch.

   | Functional concept | Modular counterpart     |
   |--------------------+-------------------------|
   | Application        | Parameter instantiation |
   | Œª-abstraction      | Module formation        |
   | Currying           | Module nesting          |
   | Continuations      | ???                     |

   Continuations, also known as ‚Äògeneralised double negation‚Äô, can be used to
   provide structural control-flow and, specialised as difference lists, provide
   efficiency gains. Perhaps similar benefits lie on the side of modules.

3. An exploration into how the proposed framework could be used to ‚Äòdiscover‚Äô
   modular patterns in existing systems for the purposes of releasing modular
   libraries /after/ an initial library has been written.
   This could allow library developers to rapidly produce systems
   with, say, ‚Äòspecification hints‚Äô to guide the automation of discovering
   certain kinds of packaging structures and hierarchical organisations.

4. Further investigations into how contexts can be developed such that the
   resulting interplay of contexts, within a system, exhibit a set of desirable
   properties, such as well-behaved cyclic dependencies.  This can lead to new
   and innovative ways to construct modules.  In conjunction with the previous
   item, this can be used in new applications of modules such as large-scale
   refactoring of libraries, say, by requesting the pullback, ‚Äòintersection‚Äô, of
   two libraries to find their well-behaved, implicitly shared, common parent
   module. More concretely, in object-oriented programming, this is tantamount
   to taking two classes ~Q, R~ and requesting they be re-factored by introducing
   a new parent ~P~ class with children classes ~Q', R'~ which are /observationally
   indistinguishable/ from ~Q, R~.

**** Tools and Automation

This thesis developed a prototype tool, =PackageFormer=, to mitigate the amount of
duplication present in designing a library by declaratively specifying how new
packages are to be formed from existing ones. Moreover, the =Context= library has
been developed in order to provide a type-checked analogue; thereby, showing
that the treatment of modular values is promising in languages with sufficient
power. There are a number of ways in which these tools can be enhanced and
extended to provide a more comprehensive tool for specifying packages.

1. The prototype tool can be enhanced by further testing.  In particular,
   further work into investigating ways in which the tool can be used to model
   commonly occurring notions of packaging as inspired by universal algebra and
   category theory, such as forming products and limits, then proving coherence
   results.

2. The prototype tool can be extended by incorporating the functionality to
   support ‚Äòdiscovarability‚Äô. Currently, the prototype can be programmed by
   the user to form intersections of packages, but this only results in a new
   package rather than in a new /library/. Given one library, we would like to
   produce a new library where discovered shared packages are factored-out.

3. The prototype provides rapid development whereas the =Contenxt= library gives
   rise to analysis and verification, as such it would be beneficial for the
   prototype tool to interface directly with =Context=.

# - Asts for PF

# - More power for Context

*** Closing Remarks
<<sec:conclusion:closing>>
#+latex: \label{sec:conclusion:closing}

The treatment of packages as unexceptional values is an ongoing and ambitious
endeavour, particular with the respect to the increasing connectedness
and complexity of large software developments.
A reduction in the number of tongues that a user needs to be familiar with
in a programming language reduces accessibility barriers, thereby reducing
the amount of repetitive code.

Using the little theories approach citet:little_theories to software development
can mitigate duplication of code. However, it is unreasonable and impractical to
always enforce a disciplined and fine-grained approach to developing software.
Instead, the prototype allows /after the fact/ library refactoring by specifying
relationships between grouping mechanisms ---as demonstrated in Section ref:sec:PF:extracting_little_theories.
# See the example on the PF website for extracting a proof for Id¬≤‚âàId
** ‚ü®ùëµùë∂‚ü© Conclusion
*** What we have done
*** How it is useful to others, now.

*** Intro                                                          :ignore:
   :PROPERTIES:
   :CUSTOM_ID: conclusion
   :END:

 As already discussed,
 more often than not a module system is an afterthought secondary citizen
 whose primary purpose is to act as a namespace delimiter
 ---e.g., C#'s ~namespace~ construct---
 while relatively more effort is given to their abstraction encapsulation
 counterpart, e.g., C#'s ~class~'es.
 Some languages' module systems blend both namespace management and
 implementation hiding, e.g., as in the Haskell programming language.
 Other languages such as OCaml take modules even further: Not only are modules
 used for namespace organisation and datatype abstraction, but they can also be
 passed around as values for manipulation as if they were nothing special, thereby
 collapsing the distinction between record constructs and organisational constructs.

 The proposed research is to build upon the existing state of module
 systems and develop an extension to a compiler to substantiate our claims,
 and to ultimately discover new semantical relationships between programming
 language constructs in a dependently typed setting with modules as first-class
 citizens. This involves redesigning and enhancing existing module systems
 to take into account dependent types as well as producing rewrite theorems
 to ensure acceptable performance times.

 Intended outcomes include:
   1. A clean module system for DTLs
      + Dependent types blur many distinctions therefore rendering certain
        traditional programming constructs as inter-derivable and so only
        a minimal amount need be supported directly, while the rest can be
        defined within the extended type theory we will be creating.
        Since modules are records, which are
        one-field algebraic data types, and we can form sums of modules, it
        would not be surprising if first-class modules suffice for arbitrary data type
        definitions.

        # syntactic sugar ‚âà pre-processing

   2. /Utility Objectives/: A variety of use-cases contrasting the resulting system with previous
      approaches. In particular, the system should:

      + Reduce amount of ‚Äònoise‚Äô necessary for working with grouping mechanisms in a number of ways.
      + It should be easy and elegant to use and, possibly, to extend.
   3. A module system that enables rather than inhibits (or worse) efficiency.
      + Currently Agda modules, for example, are sugar for extra functional parameters
        and so all implicit sharing in modules is lost at compilation time.
      + Deeply nested, deeply tagged, operations could be costly and so being apply
        to /soundly/ flatten modules and /soundly/ extract operations and results
        is a necessity when speed is concerned ---moreover, this needs to be mechanical and succinct if it is to be useful.
   4. Demonstrate that module features usually requiring meta-programming can be brought
      to the data-value level.
      + Names and types, for example, in a module should be accessible
        and alterable. For example, we can obtain a rig by combining two instances
        of a monoid module where we would rename the fields of one, or both, of them.
      + Thereby relegating abstract syntax tree and programs-as-strings manipulations
        to the edges of the computing environment.

 Most importantly, we intend to implement our theory to obtain
 validation that it ‚Äúworks‚Äù!

 # It goes without saying, these are preliminary goals, as the outcomes are likely to
 # change and evolve multiple times as the research is carried out.
*** COMMENT OLD COMMENT Next Steps                           :Maybe_Delete:

   We have shown how a bit of reflection allows us to have a compact, yet
   practical, one-stop-shop notation for records, typeclasses, and algebraic
   data types. There are a number of interesting directions to pursue:

   + How to write a function working homogeneously over one variation and having
     it lift to other variations.
     - Recall the ~comap~ from the introductory section was written over
       ~Graph :kind ‚Äµtypeclass~; how could that particular implementation
        be massaged to work over ~Graph :kind ùìÄ~ for any ~ùìÄ~.

   + The current implementation for deriving termtypes presupposes only one
     carrier set positioned as the first entity in the grouping mechanism.
     - How do we handle multiple carriers or choose a carrier from an arbitrary
       position or by name? =PackageFormer= handles this by comparing names.

   + How do we lift properties or invariants, simple ~‚â°~-types that ‚Äòdefine‚Äô
     a previous entity to be top-level functions in their own right?

 Lots to do, so little time.
** ‚ü®ùëµùë∂‚ü© PROPOSAL ‚à∑ The Next 700 Module Systems

*** Approach and Timeline
   :PROPERTIES:
   :CUSTOM_ID: approach_and_timeline
   :END:


 Packages, modules, classes, (dependent) records, (named) contexts, telescopes, theories, specifications
 ---whatever you wish to call them are essential structuring principles that
 enable modularity, encapsulation, inheritance, and reuse in formal libraries and programs.
 Moreover, as we have demonstrated, with the exception of use-cases,
 there are no significant differences between them in a dependently-typed setting, as citet:theories_as_types present a type theoretic calculus
 of a variant of record types that corresponds to theories.

**** Implementation Matter

 We will realise our proposal in an existing compiler
 and so working with it necessitates our implementations to be more than
 just ‚Äòresearch quality‚Äô but actually ready for a broad audience.

 Which compiler and for which language?

 Since our attention is focused on dependently typed languages within the
 realm of @@latex: Martin-L\"{o}f's@@ Type Theory
 citet:lof_constructive_math}, Agda \parencite{agda_web is a natural
 candidate.

 Agda is currently one of the most used tools for proof and program experimentation
 involving dependent types. With its support for mixfix Unicode lexemes, it has
 become a strong competitor to Coq citet:coq_website,coq_inductive_coc, coq_coc} for both proof construction \parencite{agda_fixpoints, agda_quantifier_elim, agda_nondeterministic, agda_mergesort, agda_type_Safety, agda_aop
 and general program construction citet:agda_web, agda_trains, agda_bitcoin, agda_hardware
 ---Agda's lack of /syntactic/ distinction between
 programs and propositions, along with its pattern matching utilities in-place of
 ‚Äòtactic sledgehammers‚Äô citet:tactics, it has also become an attractive
 language for introducing dependent types and functional programming
 citet:agda_iowa_book, agda_plf, agda_teaching. With its syntactic similarity to Haskell, many Agda users treat
 their Agda code as if it were lazy with the ~let~ and ~where~ clauses preserving sharing
 ---which is not the case, since such clauses rewrite to top-level functions
 citet:agda_docs.
 Instead, Agda's evaluation strategy is normal order: Function definitions
 are invoked before arguments are evaluated, but computations of arguments
 are /not/ shared. This is a prime location for efficiency issues since type-checking
 in a dependently typed language tends to involve evaluation of terms.
 Surprisingly this has not stopped users from producing large-scale software
 developments citet:RATH, agda_trains, agda_web.

 # for agda's evluation strategy, see also
 # https://stackoverflow.com/questions/21210569/is-the-evaluation-strategy-of-agda-specified-anywhere

 Needless to say,
 a poor choice of elaboration strategy can lead to a loss of sharing
 ---not that Agda has sharing to begin with---,
 contain too many undesirable side-effects, hinder efficiency, or forgo compile-time optimisations.
 For example,
 Agda, as currently implemented using the Glasgow Haskell Compiler (GHC), is a realisation
 of @@latex: Martin-L\"{o}f's@@ Type Theory (MLTT) that is heralded as
 both a programming language and proof assistant.
 Unfortunately MLTT, as many other dependent logics
 ---such as the Calculus of Constructions with inductive types, which underlies both
 the Coq and Lean proof assistants---
 does not account for modules, thereby leaving these as consistency-preserving hacks thrown onto the implementation.
 As mentioned earlier, Agda simply rewrites modules into top
 level functions with module parameters realised as parameters to the resulting functions.
 This is an implementation detail and has little impact on theory construction,
 however, code reuse becomes unreasonably slow
 due to the loss of sharing that happens when module arguments need to be
 re-normalised in each function-counterpart.
 Consequently, only a minor subset of the Agda community actually /executes/ their
 programs. The rest of the community is generally content with type checking only;
 which does not hinder the reliability of proof.

 It is important to note that we employ Agda only as a proof-of-concept for
 our proposed exploration of first-class structuring-mechanisms in dependently typed languages.
 Admittedly Agda's support for Unicode mixfix lexemes makes it a pleasure to work
 in, with mechanised proofs being little work more than their LaTeX renditions.

**** Next Steps

 The approach we intend to follow consists of the following steps.
 Notice that feedback loop of practice into theory.

 :Weakness:
 1. Really study the other mechanisms that already exist.

    *Exhibiting such a weakness may suggest insufficient preparatory work!*
    *Possibly resulting in a fail!*

    - Survey module systems in theory, in existing DTLs, *and* in non-DTLs.

    - As far as we can tell, besides the MTT cite{mmt_main_paper, mmt_api}
      group, no one else is working on actually implementing
      solutions to the flaws we have identified, such as combination over
      structures.

    - This is promising in terms of novelty, if anything.

    - Analyse why there are not multiple implementations of such seemingly
      immensely useful concepts.

 :End:

 1. Distill the /true/ requirements for a solution;
    ensure good /fit for purpose/ criteria exists.

    - Understand the requirements of `modularity mechanisms' for DTLs.
    - Narrow down a design by choosing a set of requirements.
    - Identify necessary, and practical, trade-offs.
      Conflicting feature sets? Usability?
    - Ideally we want our implementations to avoid too much overhead,
      such as creating an entire new language; this may necessitate the
      weakening of other functionality.

 2. Deepen understanding of the opportunities given by DTL.

    - Understand the relationships between
       modules, records, contexts, telescopes, and signatures.
      * Do they have differing `types'?
      * As types themselves, do they have differing `values'?
      * In the setting of DTLs, are they essentially isomorphic?
      * What are the intended uses? What intentions do particular choices communicate?
        - E.g., ‚Äú$x = y$‚Äù communicates an equality and nothing more, whereas
      ‚Äú$x\! \iff\! y$‚Äù communicates a Boolean equality: A redundant, particularised, equality
      symbol serves to succinctly and elegantly communicate more information.

 3. Formulate basic, draft, semantics for a small set of DTL module primitives.

    - What is the type of a package former?
    - How does it fit into Agda's existing type hierarchy?
    - What are the types of the primitives themselves?
      + We wish to avoid metaprogramming
        after all, and so wish to remain within the language rather than
        in a metalanguage.

 4. Prototype some mechanisms; a combination of old, adapted, and novel ones
    to demonstrate the power of the system.

    + Implement the structuring mechanism combinators discussed earlier
      ---such as combination over common-substructures.

      + Possibly begin with reifying first class grouping mechanisms by
        representing contexts ---i..e, sequences of declarations with optional definitions---
        as records in Agda with the undefined declarations being fields and the rest being
        derived or definitional.

 5. Evaluate the mechanisms ---using fit-for-criteria.

    + Since the realisation would be in Agda, we would keep in touch with the community
      to ensure that the additions contribute to program design.

    + Evaluate the strength of the resulting additions in terms
      of practical use for library designers as well as in terms of program speed.

 6. Make sure to have a denotational semantics for the mechanisms.

    + Ensure that the additions are minimal, orthogonal, and construct a sound
      type theory around them.

 7. Refine 2-6 until elegance, or deadline, is reached, whichever comes first.

 # More importantly, as our results will likely need to be re-proven for definitional adjustment,
 # we intend to /mechanise/ all of our proofs in Agda as well ---when possible.
 # Therefore, Agda plays multiple roles: A dependently-typed language to experiment
 # with, as well as a proof checker for our results.

 Our timeline will discuss how we will carry out this approach in multiple
 passes and will discuss the conditions of a successful pass.

**** Timeline

 We shall iterate through the `approach phase' three times,
 utilising a feedback loop of practice into theory.
 The phases are discussed below.

 As our results will likely need to be re-proven for definitional adjustment,
 we intend to /mechanise/ all of our proofs in Agda as well ---when possible.
 Therefore, Agda plays multiple roles: A dependently-typed language to experiment
 with, as well as a proof checker for our results.

***** The First Pass: May-October 2019
 This stage concludes successfully provided the following checkpoints are achieved.

 + A thorough understanding of what is being done by others, and how
   our approach differs, is obtained /and/ documented.

 + Understand the Agda compilation ecosystem, provide a report on how to make
   alterations to it, and actually implement at least one structuring mechanism
   and provide use cases as well as preliminary efficiency analysis.

 + A publication covering existing mechanisms, their features and flaws,
   and possibly an explanation of why there is theoretical work on these issues
   but little to no implementation on them
   ---with a focus on practical uses and possible hurdles to use.

   - A side-effect of this is to produce an evaluation strategy for the mechanisms.
   - Moreover, this necessitates looking into the associated semantics,
     evaluating them, and proposing semantics for the mechanism we have designed.

 + Thesis writing should have begun and nearing completion are sections
   on introduction and background.

***** The Middle Pass: November 2019 - February 2020
 This stage concluded successfully provided the following checkpoints are achieved.

 + The success of the previous stage ensures an understanding of the Agda compilation
   ecosystem, as such it should take less time to implement the more mechanisms,
   theory combinators. The goal is to have the remaining mechanisms implemented,
   with a focus on the combination-over-a-structure mechanism.

   - With each implementation, reach-out to the Agda community to solicit
     feedback regarding improvements and possible use cases.

 + Extending the semantics for the newly implemented mechanisms.

   - Evaluating which mechanisms are more primitive, which are derived, and
     which can be used to /allow users to make their own *using* the concrete language itself/!

 + A publication of case studies utilising these combinators, as well as
   a comparison of how these are an improvement over traditional methods.

   - Analysing the interactions between features; does the addition of one
     hinder another.

   - Empirical tests for efficiency and utility.

 + Thesis writing should have progressed with sections on
   use cases, semantics, and feature design,
   having substantial matter if not nearing completion.

***** The Final Pass: March - April 2020
 This stage concluded successfully provided the following checkpoints are achieved.

 + Ensure that our implementations are meeting our requirements for a solution.

 + Begin mechanisation of proofs authenticating that the denotational
   semantics has desired, expected, properties; such as soundness and safeness.

***** Concluding Phase
 Wrap up all proof matters and finish the thesis.

 Suffice to say life tends to be more hectic than a schedule may permit
 and as such some times may deviate from the above intentions.
 Regardless, the goal will be to complete the thesis within 2 years time;
 in particular before September 2020.
*** COMMENT footer                                                 :ignore:

 eval (progn (org-babel-goto-named-src-block "make-reports-class") (org-babel-execute-src-block) (outline-hide-sublevels 1))
 compile-command (progn (org-babel-tangle) (org-latex-export-to-pdf) (async-shell-command "open thesis-proposal.pdf"))
** ‚ü®ùëµùë∂‚ü© Thesis Checklist
*** What's a thesis? [0%]
   + [ ] The argument
     - What is it? Is it being argued clearly?
     - What's the plan?
   + [ ] An exposition of an orginal piece of research.
   + [ ] Distinctive contribution to the knowledge of the subject?
   + [ ] Evidence of orginality shown by the discovery of new facts?
   + [ ] How is the research best appreciated?
   + [ ] Ideas not mentioned in the thesis might as well not exist! Mention ideas.

*** Planning an Argument [0%]
   One sentence for each:
   + [ ] Introduction to the area of study.
   + [ ] The problem being tackled.
   + [ ] What the literature says about the problem.
     - A review of previous work shows you know the subject.
     - Besides being descriptive, the review needs to be critical.
     - Summary of the essential features of other work as it relates to this study.
   + [ ] How /I/ tackle this problem.
     - What is the philosophy of approach?
     - How were you systematic?
     - How is this linked back to the literature review?
   + [ ] How /I/ implement my solution.
     - Provide details so that others can follow what was done.
     - Justify the approach taken.
     - Does the software appear to work satisfcatorily?
   + [ ] The result.
     - Application of the approach reduces thousands of lines of code to
       human-readable specfications with an extensible system?
     - *Link back to how the solutions obtained relate to the questions posed?*
     - Accurately identitfy & summarise patterns or trends in the results.
     - Provide a critical analysis to show you know its limitations.
     - ‚ÄòFuture Work‚Äô to show what's missing.
     - Beware of specfulations not grounded in the results.
   + [ ] Conclusion ---repetition of the intro, but with reference to the detail.

   An outline acts as a workplan for which the entire research process is an
   exercise addressing each item. Each item becomes at least one section in
   the writeup.

   + [ ] Set out clearly what each chapter should say.

*** Say everything thrice [0%]

   It's not repetition, but linking and rationale.

   + [ ] In the thesis as a whole.
     - [ ] Introduction - What the thesis will say.
     - [ ] Body - Details of the work.
     - [ ] Conclusion - What the thesis said.

   + [ ] Within each chapter/section.
     - [ ] Signposting - What this section says.
     - [ ] Body - The details.
     - [ ] Summary - What this section has said.

   + [ ] Within each paragraph.
     - [ ] Each paragraph describes a single idea.
     - [ ] The first sentence introduces the idea ---linking it with the previous one.
     - [ ] The last sentence concludes the idea ---linking it with the next one.

   Signposts ensure it's clear what's being discussed and why
   ---from a writer's perspective, they help get the contents right.

*** The Examiner's View

   They'll read it in meetings, trains, or planes.
   They're busy and an initial scan may be:

   1. abstract - what's it about?
   2. bibliography - Does it cite the right stuff? Has it been published already?
   3. conclusions - What was achieved? Do I believe it?
   4. contents listing - Is everything there? Is the argument clear?

   Weakeness in these locations might suggest large corrections.

   + [ ] Run spellchecking everywhere.
   + [ ] Run the grammar checker as well.

*** What If I'm stuck?

   1. The task at hand may be too difficult.
   2. *Ask for help!*
   3. Change the plan.
   4. Cut away irrelevant bits.

*** COMMENT Our Approach [0%]
  --Remaining Tasks--
  + [ ] Plan of Attack
  + [ ] Implementation Details
  + [ ] Discussion of Results
  + [ ] Future Work

** ‚ü®ùëµùë∂‚ü© Leftovers

*** Let us conclude by attempting to justify the title of this thesis.

 Landin's /The Next 700 Programming Languages/ citet:seven_hundred_langs inspired a
 number of works, including
 citet:seven_hundred_tt_models,seven_hundred_provers,seven_hundred_hoas,seven_hundred_libraries,seven_hundred_data
 and more. The intended aim of the thesis is a requirements driven approach to
 coherent modularisation constructs in DTLs. In particular, we wish to extend
 Agda to be powerful enough to implement the module system features, in the core
 language, that people actually want and currently mimic by-hand or using
 third-party preprocessors. An eager fix would be to provide metaprogramming
 features, but unless one is altering the syntax or producing efficient code,
 this is glorified pre-processing ---it is a means to fake missing abstraction
 features. Moreover, metaprogramming would be a hammer too big for the nail we
 are interested in; so big that its introduction might ruin the soundness of the
 DTLs ---e.g., two terms may be ill-typed and ill-formed, such as ~x +~ and ~5 = 3~,
 but are meaningful when joined together, as in ~x + 5 = 3~. Our aim is to provide
 just the right level of abstraction so that, if anything, users can write a type
 of container or method upon it then derive ‚Äò700‚Äô simple alternate views of the
 same container and method.

 To be clear, consider a semi-ring ---or any simple record of 17 different kinds
 of data. A semi-ring consists of two monoids ---each consisting of a total of 7
 items of data and proof matter--- where one of them is commutative and there are
 two distributivity axioms. Hence, a semi-ring consists of 17 items. If we wanted
 to expose, say, 3 such items ---for example, the shared carrier and the
 identities of each monoid--- then there are a total of $\binom{17}{3} = 680$
 ways, and if we jump to 4 items we have $\binom{17}{4} = 2380$ possible forms.
 Of course these numbers are only upper bounds when record fields depend on
 earlier items. In section 3, we provide explicit examples of different
 structural presentations of packages.

 Usually, library designers provide one or two views, along with conversion functions,
 and commit to those; instead we want to liberate them to choose whatever presentation
 is convenient for the tasks at hand and to work comfortably with the guarantee that
 all the presentations are isomorphic. Humans should be left to tackle difficult and
 interesting problems; machines should derive the tedious and uninteresting
 ---even if it's simple, it saves time, is less error-prone, and clearly communicates
 the underlying principle.

 If anything, our aim is practical ---to save developers from ad hoc copy-paste
 preprocessing hacks.

*** Introduction to diy modules

    A fundamental argument for the use of module systems in the design of large
  programs is that the structure of the program is partitioned into coherent
  semantical units that are furnished with an interface belying the complexity of
  their implementations. A well-established example is the use of the humble
  record to ‚Äòbundle‚Äô up the extensional properties of an object; here one works
  with objects as if they were atomic, rather than considering the
  collection of their identifying properties.  Users of dependently-typed
  languages like Agda and Coq will argue strongly that the effective use of
  module systems is extremely important for subsequent program development, and
  even users of dynamically typed languages like Javascript will admit that, for
  example, namespace violations are an area of concern.  A fundamental aspect of
  =PackageFormer= is that the relationship between a grouping mechanism and its
  constituent structuring sub-grouping mechanisms is made explicit: One extracts
  grouping mechanisms from declarations involving existing grouping mechanisms.
  In contrast to type theory wherein a type is specified by characterising how
  its elements may be formed, our approach allows both the building-up of
  grouping mechanisms from their parts and, also, the ‚Äòtearing down‚Äô of parts of
  existing grouping mechanisms ---as is the case of dropping a property from a
  record type to obtain another record type, or of transforming a record type
  into an algebraic data type.  Depending on their nature, grouping
  specifications may either allow the automatic derivation of ‚Äòintroduction
  rules‚Äô wherein the teared-down grouping is transformed into the new grouping,
  or allow ‚Äòelimination rules‚Äô wherein the individual groupings that built-up the
  new grouping can be identified.  The semantics of a grouping specification
  is essentially the ‚Äòflattening‚Äô of properties that extensionally constitute it.
  Our work describes the necessary primitives that allow grouping declarations.

  The intention is not to provide a fixed set of general-purpose grouping
  combinators that are sufficient to encompass all the future needs of all
  programmers but to provide a small kerneal of ‚Äòmeta-primitives‚Äô whereby
  programmers may invent their own grouping mechanisms peculiar to their own
  problem domain.

*** ADTS Again

 Another way to look at ADTs and their constructors is as encoding propositions.

 For example, consider conjunction:
 1. If ~A~ and ~B~ are /propositions/, then ~A ‚àß B~ is a /proposition/.
    - If ~A~ and ~B~ are /types/, then ~A √ó B~ is a /type/.
 2. To /prove/ ~A ‚àß B~, one must /prove/ ~A~ and one must /prove/ ~B~.
    - To construct an /element/ of ~A √ó B~, one must /construct/ an element of ~A~
      and /construct/ an element of ~B~.

    This is known as an /axiom scheme/, or /parametric datatype/, since it abstracts
    over propositions/types.

 #+BEGIN_SRC agda
data Pair (A B : Set) : Set where
  MkPair : A ‚Üí B ‚Üí Pair A B
 #+END_SRC

 Henceforthe, to reduce duplication in terms of types and propositions,
 we shall write only once
 #+BEGIN_SRC haskell
data P ((e‚ÇÅ : œÑ‚ÇÅ) ‚ãØ (e‚Çô : œÑ‚Çô)) : Set where
  MkP : (a‚ÇÅ : Œ±‚ÇÅ) ‚ãØ (a‚Çò : Œ±‚Çò) ‚Üí P e‚ÇÅ e‚ÇÇ ‚ãØ e‚Çô
 #+END_SRC
 With the understanding that it defines a /new/ type/proposition ~P~
 along with an constructor/‚Äòintroduction-rule‚Äô named ~MkP~:
 #+BEGIN_SRC haskell
Œì ‚ä¢ e‚ÇÅ : œÑ‚ÇÅ     ‚ãØ   Œì, e‚ÇÅ : œÑ‚ÇÅ, ‚Ä¶, e‚Çô‚Çã‚ÇÅ : œÑ‚Çô‚Çã‚ÇÅ ‚ä¢ e‚Çô : œÑ‚Çô
--------------------------------------------------------------------------------
       Œì ‚ä¢ P e‚ÇÅ e‚ÇÇ ‚ãØ e‚Çô : Set

{- and -}

Œì ‚ä¢ a‚ÇÅ : Œ±‚ÇÅ    ‚ãØ    Œì, a‚ÇÅ : Œ±‚ÇÅ, ‚Ä¶, a‚Çò‚Çã‚ÇÅ : Œ±‚Çò‚Çã‚ÇÅ ‚ä¢ a‚Çò : Œ±‚Çò
--------------------------------------------------------------------------------
        Œì ‚ä¢ MkP a‚ÇÅ a‚ÇÇ ‚Ä¶ a‚Çò : P e‚ÇÅ e‚ÇÇ ‚ãØ e‚Çô
 #+END_SRC
 Likewise if there are multiple constructors ~MkP·µ¢~.
 Hence, ADTs are proof tree datatypes.

 A /type checker/ is then a form of /proof checking/:
 Encode a proposition as a type, and if the type checker
 accepts a definition ~x : œÑ~, then we can regard ~œÑ~ as proven.

 Simple type theories do not allow quantification over arbitrary types
 and so we cannot express predicates; Agda, however, has dependent types
 which solve this concern.

 An undefined loop can be of any type and so any proposition could be proven
 by this approach, but total language need all terms to terminate thereby
 avoiding this possibility. Indeed, Agda is total.

 In practical terms, the more expressive a logic, the more precise specifications
 we can give to program definitions; for example, consider how we could
 specfiy the ~map~ function:
 #+BEGIN_SRC haskell
{- Untyped spec: map takes two arguments -}
map(f, xs) = ‚ãØ

{- Basic type annotations: map takes a function and a collection -}
map(f : function, xs : collection) = ‚ãØ

{- Simple types: map takes a function Œ± ‚Üí Œ≤, a collection of the function's source
type, and returns a collection of the function's target type. -}
map : (Œ± ‚Üí Œ≤) ‚Üí List Œ± ‚Üí List Œ≤

{- Dependent types: map takes a function and a collection of the function's start
type and returns a collection, of the *same length*, of the function's target type -}
map : (Œ± ‚Üí Œ≤) ‚Üí Vec Œ± n ‚Üí Vec Œ± n
 #+END_SRC
 Notice that as the specfication increased in precision, the number of possible
 implementations was refined. In particular, the third instance could have simply
 returned the empty lists on all input and it would have met the specification,
 whereas the last instance can have one possible implementation
 ---up to permutation of the output.

 #+caption: Dependency notions; in increasing order of strength.
 | _Idea_             | _Description_              |
 | Function         | Terms depending on terms |
 | Type constructor | Types depending on types |
 | Polymorphism     | Terms depending on types |
 | ‚ÄòPredicates‚Äô     | Types depending on terms |

 A /dependent type/ ~œÑ~ is a type for which given a term ~e~, the application ~œÑ e~ is
 then a new type. It may be called a /predicate/ since the elements of ~œÑ e~
 ‚Äòall have the property e‚Äô ---e.g., all values of ~Vec ‚Ñï 3~ have the property of
 having length 3.

 In a dependently-typed setting, the type construction schema Œ† generalises the
 notion of function types, so that the /type of the result depends on the value of
 the argument:/
 #+BEGIN_SRC haskell
Œì ‚ä¢ A : Set     Œì, x : A ‚ä¢ B : Set
--------------------------------------------------------------------------------
       Œì  ‚ä¢  Œ† x ‚à∂ A ‚Ä¢ B : Set

Œì ‚ä¢ A : Set   Œì, x : A ‚ä¢ e : B
--------------------------------------------------------------------------------
       Œì ‚ä¢ (Œª x ‚à∂ A ‚Ä¢ e) : (Œ† x : A ‚Ä¢ B)

Œì ‚ä¢ f : Œ† x ‚à∂ A ‚Ä¢ B      Œì ‚ä¢ e : A
--------------------------------------------------------------------------------
     Œì ‚ä¢ f e : B[x ‚âî e]


--
data Œ† (A : Set) (B : A ‚Üí Set) : Set where
  Œª : ((x : A) ‚Üí B x) ‚Üí Œ† A B
 #+END_SRC
 Unlike Haskell GADTs, the Œ†-type can depend on /arbitrary/ terms, not just
 constructors of a datatype.

 The type construction schema Œ£ generalises the notion of product types, so that
 the /type of the second coordinate depends on the value of the first coordinate/:
 #+BEGIN_SRC haskell
Œì ‚ä¢ A : Set    Œì, x ‚à∂ A ‚ä¢ B ‚à∂ Set
--------------------------------------------------------------------------------
      Œì ‚ä¢ Œ£ x ‚à∂ A ‚Ä¢ B  :  Set

Œì ‚ä¢ a : A     Œì ‚ä¢ b : B[x ‚âî a]
--------------------------------------------------------------------------------
       Œì ‚ä¢ (a, b) : (Œ£ x ‚à∂ A ‚Ä¢ B)

Œì ‚ä¢ e : (Œ£ x ‚à∂ A ‚Ä¢ B)
--------------------------------------------------------------------------------
Œì ‚ä¢ proj‚ÇÅ e : A

Œì ‚ä¢ e : (Œ£ x ‚à∂ A ‚Ä¢ B)
--------------------------------------------------------------------------------
Œì ‚ä¢ proj‚ÇÇ e : B[x ‚âî proj‚ÇÅ e]
 #+END_SRC

** ‚ü®ùëµùë∂‚ü© [!] section 4? curapr ‚Üê Solution Requirements
   :PROPERTIES:
   :CUSTOM_ID: solution_requirements
   :END:

  From the outset we have proposed a particular approach to resolving the
  needless duplication present in current module systems that are utilised in
  non-dependently-typed languages. Up to this point, we have only discussed how
  our approach could mitigate certain troubles; such as a difference of
  perspectives of modules, or of equivalent operations acting on different
  perspectives of modules. We now turn to discussing, in the following
  subsections, what it is that is missing from existing module systems, what one
  actually wants to do with modules, and conclude with a checklist of features
  that a proposed system should meet in order to be considered a practical and
  pragmatic improvement over existing systems.

**** Missing Features
    :PROPERTIES:
    :header-args: :tangle translate_functions.agda :comments link
    :END:

 # Our preliminary research, and personal use with dependently-typed systems,
 # has yielded three strongly desirable features of a module system for DTLs.

 Certain mechanically-derivable concepts, such as different perspectives, are
 needlessly delegated to the user by pedestrian packaging systems. Besides being
 tedious and error-prone, the inexpressibility of derivates obscures the
 corresponding general principles underlying them, thus foregoing any machine
 assistance in ensuring any correctness or safety-ness guarantees. The desire to
 pursue a more economical yet powerful packaging system follows from our
 research team's expedited efforts that could have been mechanised . We will
 only mention two such use cases.

 # [[https://www.google.com/search?ei=MeLSXLaTIuqN5wLSsaTwDw&q=derivate&oq=derivate&gs_l=psy-ab.3..0i67j0i10j0j0i10l7.27397.29434..29651...0.0..0.100.195.1j1......0....1..gws-wiz.......0i71j0i7i10i30.ZZBrC21FopE][define derivate]] :: something derived, especially a product obtained chemically from a raw material.
 # #
 #       derivates
 #  or   what could be considered as derived views

**** Expressivity
 # #+latex: \noindent
 # *Expressivity*
 #
 # #+latex: \noindent
  A common pattern that can be seen, for example, in the Agda standard library,
  is of a predicate ensuring desirable properties *of* its inputs, then of a record
  containing the inputs as fields along with a proof of said predicate ---c.f.,
  section ref:sec:examples:IsX. More concretely, suppose we have a binary predicate named
  ~IsSemi~ and the record is named ~Semi~; the predicate form allows us to quantify
  over inputs as in ~‚àÄ x y ‚Üí IsSemi x y ‚Üí ‚ãØ~, in contrast the latter approach is
  intrinsic in nature: ~‚àÄ (s ‚à∂ Semi) ‚Üí ‚ãØ~ ---contrast this with a mathematician
  naturally declaring /‚Äúlet ~s~ be a semigroup‚Äù/, whereas almost never do
  mathematicians say /‚Äúlet ~x~ be a set and ~y~ be an operation on it that together
  constitute a semigroup‚Äù/.

  At a first glance, it does not seem too troublesome to produce the record
  presentation from the predicate presentation: Simply /repeat all/ the inputs
  under a record declaration along with a proof obligation. However, the word
  ‚Äòrepeat‚Äô already suggests a problem, and ‚Äòall‚Äô suggests another one. What if
  one desires to utilise the record associated to the predicate by only packaging
  certain inputs but not others? This is akin to the problem of constructors in
  object-oriented languages: In Java, for example, one uses overloading to
  provide a number of user-written constructors for only a few resonable input
  invocations to construct an object; in contrast, Common Lisp permits optional
  named arguments, and so in one fell swoop, with one user-written, constructor,
  provides all possible combinations of constructor invocations ---this is the
  ideal level of power and flexibility.
  #
  # WK: [OCaml] permits optional named arguments.

  Lest it's unclear, let's elaborate slightly on the idea.
  :Setup:
  #+begin_src haskell
open import Relation.Binary.PropositionalEquality
open ‚â°-Reasoning

-- Z-notation for sums
open import Level
open import Data.Product using (Œ£ ; proj‚ÇÅ ; proj‚ÇÇ ; _√ó_ ; _,_)
Œ£‚à∂‚Ä¢ : {a b : Level} (A : Set a) (B : A ‚Üí Set b) ‚Üí Set (a ‚äî b)
Œ£‚à∂‚Ä¢ = Œ£
infix -666 Œ£‚à∂‚Ä¢
syntax Œ£‚à∂‚Ä¢ A (Œª x ‚Üí B) = Œ£ x ‚à∂ A ‚Ä¢ B
  #+end_src
  :End:

  A semigroup is an algebraic structure that models (untyped) compositionality:
  It consists of a collection of objects of interest called the ~Carrier~ set, and
  an operation ~_‚®æ_~ to compose existing items to produce new items, and the
  operation is associative. Below is a spectrum of ways to bundle up such a
  structure ---starting from being completely bundled up all the way to being
  completely exposed.
 {{{code(A value of ‚ÄòSemigroup‚ÇÄ‚Äô is an arbitrary semigroup)}}}
  #+begin_src haskell :tangle semigroup.agda :prologue "open import Notation"
-- One extreme: Completely bundled up
record Semigroup‚ÇÄ : Set‚ÇÅ where
  field
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    assoc   : ‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
  #+end_src
  {{{code(A value of ‚ÄòSemigroup‚ÇÅ C‚Äô is a semigroup ‚Äústructure on‚Äù type ‚ÄòC‚Äô)}}}
  #+begin_src haskell :tangle semigroup.agda
-- ‚ÄòTypeclass‚Äô on a given Carrier
-- Alternatively: Carrier is known as runtime.
record Semigroup‚ÇÅ (Carrier : Set): Set‚ÇÅ where
  field
    _‚®æ_   : Carrier ‚Üí Carrier ‚Üí Carrier
    assoc : ‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
  #+end_src
  {{{code(A value of ‚ÄòSemigroup‚ÇÇ C op‚Äô is a ‚Äúproof‚Äù that ‚ÄòC‚Äô with ‚Äòop‚Äô forms a semigroup)}}}
  #+begin_src haskell :tangle semigroup.agda
-- Two items known at run time --c.f., ‚ÄúIsSemi‚Äù above.
record Semigroup‚ÇÇ
 (Carrier : Set)
 (_‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier) : Set where
  field
    assoc : ‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
  #+end_src
  {{{code(The other extreme: Completely unbundled)}}}
  #+begin_src haskell :tangle semigroup.agda
-- A value of ‚ÄòSemigroup‚ÇÉ C op pf‚Äô is trivially the empty record, if any,
-- provided ‚Äòpf‚Äô is a proof that ‚ÄòC‚Äô forms a semigroup with ‚Äòop‚Äô.
-- This type is usualy written Œ£ C ‚à∂ Set ‚Ä¢ Œ£ _‚®æ_ ‚à∂ C ‚Üí C ‚Üí C ‚Ä¢ Œ£ assoc ‚à∂ ‚ãØ.
record Semigroup‚ÇÉ
 (Carrier : Set)
 (_‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier)
 (assoc : ‚àÄ x y z ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)) : Set where
 {- no fields -}
  #+end_src
  Depending on the user's needs, it may be useful to have one form or another.
  Unfortunately they are enslaved to the choices of the library designer,
  or if they deviate then they must produce tedious conversion methods and use
  them to pad all the library methods for the structures.
  Even worse, such back and forth conversions will not only be representation
  shuffling but also wasteful of resources.

  For example, every bijective function $f : A \to B$ furnishes its target $B$
  with a semigroup structure provided its source $A$ has the structure to begin
  with. Since the statement mentions the carriers of semigroups, it is only
  natural to formulate it an prove it using presentation ~Semigroup‚ÇÅ~ where the
  carrier is exposed at the type level.
  {{{code(Elementary Properties of Functions)}}}
  #+begin_src haskell :tangle semigroup.agda
Surjection : ‚àÄ{A B : Set} ‚Üí (A ‚Üí B) ‚Üí Set
Surjection {A} {B} f = ‚àÄ (b : B) ‚Üí Œ£ a ‚à∂ A ‚Ä¢ b ‚â° f a
-- (Œ£ a ‚à∂ A ‚Ä¢ P a) ‚âà { (a, proof) ‚ùô a ‚àà A ‚àß pf is a proof of P(a) }

Injection : ‚àÄ{A B : Set} ‚Üí (A ‚Üí B) ‚Üí Set
Injection {A} {B} f = ‚àÄ {x y} ‚Üí  f x ‚â° f y ‚Üí x ‚â° y
  #+end_src
  {{{code(An Involved Proof That We Would Like to Reuse)}}}
  #+begin_src haskell :tangle semigroup.agda
translate‚ÇÅ : ‚àÄ{A B} ‚Üí (f : A ‚Üí B) ‚Üí Surjection f ‚Üí Injection f
       ‚Üí Semigroup‚ÇÅ A ‚Üí Semigroup‚ÇÅ B
translate‚ÇÅ f surj inj AS =
  let
    open ‚â°-Reasoning
    open Semigroup‚ÇÅ AS

    -- x ‚®æ' y is obtained by applying f to the ‚®æ-composition of the pre-images of x, y
    infix 5 _‚®æ'_
    _‚®æ'_ = Œª x y ‚Üí let a‚ÇÄ = proj‚ÇÅ (surj x); a‚ÇÅ = proj‚ÇÅ (surj y) in f (a‚ÇÄ ‚®æ a‚ÇÅ)

    -- f distributes over ‚®æ turning it into ‚®æ'
    factor : ‚àÄ {a a'} ‚Üí f a ‚®æ' f a' ‚â° f (a ‚®æ a')
    factor {a} {a'} =
           let ùí∂  , m  = surj (f a)
               ùí∂' , w  = surj (f a')
           in
           begin
             f a ‚®æ' f a'
           ‚â°‚ü® refl ‚ü©
             f (ùí∂ ‚®æ ùí∂')
           ‚â°‚ü® cong f (cong‚ÇÇ _‚®æ_ (inj (sym m)) (inj (sym w)))  ‚ü©
             f (a ‚®æ a')
           ‚àé

    distribute : ‚àÄ {a a'} ‚Üí f (a ‚®æ a') ‚â° f a ‚®æ' f a'
    distribute {a} {a'} = sym (factor {a} {a'})

  in {- Bundle up ‚®æ' along with a proof of associativity -}
    record { _‚®æ_ = _‚®æ'_; assoc = Œª x y z ‚Üí
     let
    -- Obtain f-pre-images
    a‚ÇÄ , x‚âàfa‚ÇÄ  =  surj x
    a‚ÇÅ , y‚âàfa‚ÇÅ  =  surj y
    a‚ÇÇ , z‚âàfa‚ÇÇ  =  surj z
     in
      {- Tersely: We rewrite along the pre-images,
     factor f, perform the associativity of ‚®æ,
     then distribute f and rewrite along the pre-images. -}
       begin
         (x ‚®æ' y) ‚®æ' z
       ‚â°‚ü® cong‚ÇÇ _‚®æ'_ (cong‚ÇÇ _‚®æ'_ x‚âàfa‚ÇÄ y‚âàfa‚ÇÅ) z‚âàfa‚ÇÇ ‚ü©
         (f a‚ÇÄ ‚®æ' f a‚ÇÅ) ‚®æ' f a‚ÇÇ
       ‚â°‚ü® cong (_‚®æ' f a‚ÇÇ) factor ‚ü©
         f (a‚ÇÄ ‚®æ a‚ÇÅ) ‚®æ' f a‚ÇÇ
       ‚â°‚ü® factor ‚ü©
         f ((a‚ÇÄ ‚®æ a‚ÇÅ) ‚®æ a‚ÇÇ)
       ‚â°‚ü® cong f (assoc _ _ _)  ‚ü©
         f (a‚ÇÄ ‚®æ (a‚ÇÅ ‚®æ a‚ÇÇ))
       ‚â°‚ü® distribute ‚ü©
         f a‚ÇÄ ‚®æ' f (a‚ÇÅ ‚®æ a‚ÇÇ)
       ‚â°‚ü® cong (f a‚ÇÄ ‚®æ'_) distribute ‚ü©
         f a‚ÇÄ ‚®æ' (f a‚ÇÅ ‚®æ' f a‚ÇÇ)
       ‚â°‚ü® sym (cong‚ÇÇ _‚®æ'_ x‚âàfa‚ÇÄ (cong‚ÇÇ _‚®æ'_ y‚âàfa‚ÇÅ z‚âàfa‚ÇÇ))  ‚ü©
         x ‚®æ' (y ‚®æ' z)
       ‚àé }
  #+end_src
  ~translate‚ÇÅ~ is a lengthy proof, we could repeat it, or invoke it. Since
  duplication with alteration is error-prone and non-generic, we perform the
  latter.
 {{{code(Conversions are a Nuisance)}}}
  #+begin_src haskell :tangle semigroup.agda
translate‚ÇÄ : ‚àÄ{B : Set} (AS : Semigroup‚ÇÄ) (f : Semigroup‚ÇÄ.Carrier AS ‚Üí B)
       ‚Üí Surjection f ‚Üí Injection f
       ‚Üí Semigroup‚ÇÄ
translate‚ÇÄ {B} AS f surj inj = record { Carrier = B ; _‚®æ_ = _‚®æ_ ; assoc = assoc }
  where

       -- Repackage ‚ÄòAS‚Äô from a ‚ÄòSemigroup‚ÇÄ‚Äô to a ‚ÄòSemigroup‚ÇÅ‚Äô
       -- only to immediatley unpack it, so that its contents
       -- are available to be repacked above as a ‚ÄòSemigroup‚ÇÄ‚Äô.

       pack : Semigroup‚ÇÅ (Semigroup‚ÇÄ.Carrier AS)
       pack = let open Semigroup‚ÇÄ AS in record {_‚®æ_ = _‚®æ_; assoc = assoc }

       open Semigroup‚ÇÅ (translate‚ÇÅ f surj inj pack)
  #+end_src
  Observe that ~translate‚ÇÄ~ repackages ~AS~ via ~pack~, then passes that as an argument
  to ~translate‚ÇÅ~, which in turn unpacks it to form a new ~Semigroup‚ÇÄ~, which is then
  unpacked in the last line above. Regardless of any possible wasteful amount of
  packing and unpacking of records ---which may be mitigated via inlining--- the
  way ~translate‚ÇÄ~ is written is far from ideal; whereas ~translate‚ÇÅ~ is the
  appropriate level of abstraction to pose the problem. Instead, it would be
  ideal to write the method at a sufficient level of generality such that
  ~translate‚ÇÄ~ and ~translate‚ÇÅ~ are, say, polymorphic instances thereof. This is what
  we shall propose in a later section, section ref:sec:PF. More generally, notice that
  ~Semigroup·µ¢~ is a type constructor consuming ùíæ-many arguments, which are also
  arguments to ~translate·µ¢~. The ideal context to phrase the translation result is
  with ~ùíæ = 1~, but we also want to be able to apply it for the other possible
  values of ~ùíæ ‚à∂ 0..3~.

  :Relocate_yoneda:
  Moreover, as a stylistic decision, implementers may prefer to view
  an object in either its predicate form ---with the constituents varying---
  or in its record form ---with the constituents fixed---, will all
  library utilities tied to a particular form.
  :End:

**** DONE COMMENT efficiency_remarks_incomplete
    CLOSED: [2020-04-10 Fri 10:42]

  *Efficiency:*

  A hallmark of computing is to reduce new problems to ones already considered.
  One realisation of this principle is found in the sharing mechanisms of
  certain lazy languages: In the expression ~let y = f(x) in g(y, y)~,
  the term ~y~ is evaluated once and the result is shared among its multiple
  call sites. This idea comes under the name of /thunks/:
  When we encounter an instance of ~y~ and we need to ‚Äòthink‚Äô
  of its value, we realise we have already ‚Äòthunk‚Äô it.

  # :What:
  Memory is tremendously difficult to reason about {{{remark(reynolds calculus)}}},
  and lazy sharing only compounds to the troubles of garbage collection
  and complexity analysis {{{remark(Haskell)}}}.
  # :End:

  Dependently-typed languages are usually not only utilised for programming
  but generally also for proof; as such, their implementations adhere to
  a particular logic.

  To be completed ‚Ä¶

**** Conclusion

  # One final benefit is exposition. It happens in academic literature, that an
  # audicance may not be familar with the rudiments of a hierarchy, nor should they
  # be forced to ...

  These features are considered ‚Äòmissing‚Äô since they are reasonably achievable in
  a dependently-typed system ---e.g., the different forms of dependently-typed
  bundling suggest a form of polymorphism. Their absence may be due to logistic
  reasons, such as no effort expedited in their direction, or due to issues
  surrounding the logical frameworks of the systems.

  We posit that the problem lies in /typing/; e.g., it is not at all clear how to
  type a generic ~translate~ function that works for all possible ~Semigroup·µ¢~. With
  the presence of metaprogramming, we could quote arguments to obtain abstract
  syntax, ~Term~, and so define the following.
 #+BEGIN_SRC haskell
 translate : (ùíæ : Fin 4)
             {A B : Set} (f : A ‚Üí B) (inj : Injection f) (surj : Surjection f)
             ‚Üí (args : Vec ùíæ Term)
             ‚Üí Œ£ S ‚à∂ Semigroup·µ¢ args ‚Ä¢ Carrier·µ¢ S ‚â° A
             ‚Üí Œ£ T ‚à∂ Semigroup·µ¢ args ‚Ä¢ Carrier·µ¢ S ‚â° B
 translate = ‚ãØ
 #+END_SRC

 Notice that unlike ~translate‚ÇÄ~, this form is more useful since it relates the
 output semigroup with the input semigroup via the function ~f~ ---in contrast,
 ~semigroup‚ÇÄ~ could have simply returned the input semigroup and still typecheck.
 Even though the need to quote and unquote terms is not ideal, there is a more
 processing concern: With the exception of ~ùíæ = 0~, the Œ£ constraints will all be
 tedious =refl=-exivity proofs that will mention ~A~ before and after the bullet, ~‚Ä¢~.
 Instead, it would be preferable to declare the carrier ~A~ of the input semigroup
 as was done in ~translate‚ÇÅ~ ---namely, directly in the type application of
 ~Semigroup·µ¢~. That is, we would like an operation =_with-carrier_= so that ~translate~
 could drop the Œ£'s and instead conclude with ~Semigroup·µ¢ args with-carrier A ‚Üí
 Semigroup·µ¢ args with-carrier B~. Such an infix operation would require decidable
 equality on syntax. It seems that metaprogramming is necessary ---at least from
 the library builder's perspective.

 Going forward, we will thus use metaprogramming /on the implementation side/,
 but try to hide it from the user as much as possible.

**** Con
   These features are desirable for working with modules, yet raise a number of
   immediate concerns. For example, uniformity may lead to ambiguous parsing,
   genericity may lead to inefficient execution, and extensibility borders on
   meta-programming thereby leaving the realm of types altogether.
   Possible limitations on these features may result in the thesis efforts
   to implement them in a dependently-typed system, such as Agda.
** ‚ü®ùëµùë∂‚ü© Semantics Continued ‚Üê the second choice

 *Intuitively, the nature of the meta-primitives:*
 1. A ~PackageFormer~ is a context, a signature, an essentially algebraic theory of Freyd, or a generalised algebraic theory of Cartmell.
    Moreover, it is tagged by some values for practical purposes; e.g., the kind of concrete realisation that is possible in Agda ---namely, ~record, data, module,~ or
    the abstract ~PackageFormer~.
 2. A ‚Äòvariational‚Äô is a morphism between PackageFormers ---taking signatures to signatures.

    Built up from the grammar:
    #+BEGIN_SRC haskell :tangle no
ùìã ‚à∑=                   -- empty, identity, variational
   | ùìã ‚ü¥ ùìã            -- composition
   | :kind  ùìÄ          -- ùìÄ ‚àà {record, data, module, PackageFormer}
   | :waist ùìÉ          -- n ‚àà ‚Ñï, number of initial items to be considered as ‚Äòparameters‚Äô
   | :alter-elements ùíª -- f : List Elements ‚Üí List Elements
    #+END_SRC

    ~:alter-elements~ is a sledgehammer that may result in ill-formed signatures, but we leave it in the system due to its power.
    Instead, we recommend using the following derivied primitives for signature catenation, map, and filter:
    #+BEGIN_SRC haskell :tangle no
   | extended-by ds  -- Adjoin declarations ds, ‚Äúname : type‚Äù, to a PackageFormer
   | map         f   -- Alter each element by f : Element ‚Üí Element
   | generated   f   -- Keep the largest well-formed PackageFormer whose elements satisfy predicate f
 #+END_SRC

    Why are these sufficient? The first homomorphism theorem of lists ---i.e., the fact that lists are free monoids---
    informs us that all well-behaved functions from a list monoid are determined as folds after maps. Since our signatures
    are essentially free monoids and the target of our functions are again the same free monoids, the fold is determined and only
    the map remains. We conjecture this is enough; we are not yet certain.

    Interestingly, we are mostly generic over the underlying type theory.

    #  Œì extended-by x‚ÇÄ:œÑ‚ÇÄ,‚Ä¶,x‚Çô:œÑ‚Çô  -- where Œì,x‚ÇÄ:œÑ‚ÇÄ,‚Ä¶,x‚Çñ‚Çã‚ÇÅ:œÑ‚Çñ‚Çã‚ÇÅ ‚ä¢ œÑ‚Çñ Type

    Since a ~PackageFormer~ corresponds to a signature, then these variationals
    ---at least the well-behaved ones--- correspond to signature morphisms.
    Great difficulty lies in providing semantics for ~alter-elements~; if
    we demand a well-typedness judgement, ‚Äú‚ä¢‚Äù, from our underlying type theory
    then we could define ~(x‚ÇÄ : œÑ‚ÇÄ, ‚Ä¶, x‚Çô ‚à∂ œÑ‚Çô) = Œì :alter-elements f~ to be well-typed iff
    ~f : List Elements ‚Üí List Elements~ and ~x‚ÇÄ:œÑ‚ÇÄ,‚Ä¶,x‚Çñ‚Çã‚ÇÅ:œÑ‚Çñ‚Çã‚ÇÅ ‚ä¢ œÑ‚Çñ Type~ for ~k : 0..n~;
    likewise if we admit defined constants in our contexts.

    :functorial_semantics:
 Object-level Semantics -- ‚Äúfunctorial semantics‚Äù
 - ‚ü¶_‚üß : PF ‚ü∂ |‚ÑÇ|
 - ‚ü¶Empty‚üß = ()  -- the empty context
 - ‚ü¶Œì extended-by Œî‚üß = ‚ü¶Œì‚üß ++ Œî
 - ‚ü¶Œì :waist n‚üß = ???
 - ‚ü¶Œì :kind k‚üß  = ???
 - ‚ü¶Œì :map f‚üß   = map f ‚ü¶Œì‚üß
 - ‚ü¶Œì :filter p‚üß = filter p ‚ü¶Œì‚üß
 - ‚ü¶Œì A ‚ü¥ B‚üß = ‚ü¶ ‚ü¶Œì A‚üß B ‚üß -- get a context, then apply B to that.
 :end:

** ‚ü®ùëµùë∂‚ü© Current Approaches             :to_be_incorporated_into_ch2:

<<sec:current_approaches>>
#+latex: \label{sec:current_approaches}

#+begin_edcomm
:ed: JC

- this clearly heavily borrows from your proposal (good), but it's also not
  clear anymore that this material 'fits' what you ended up doing. This is why
  having a very crisp "What problem am I solving", and then "Contributions" is
  so important. That will tell you what material in later sections is crucial /
  can be dumped.

- for example, the whole subsection on JSON feels like it brings nothing. I
  would delete it completely.

#+end_edcomm
#+latex: \vspace{1ex}.

*** COMMENT Who has worked on this problem and where have they gotten?
*** COMMENT What are their shortcomings and advantages wrt to our approach?
*** COMMENT Shortcomings of our approach.
*** COMMENT Missing features and next steps.
*** Intro                                                          :ignore:

Structuring mechanisms for proof assistants are seen as tools providing
administrative support for large mechanisation developments
citet:LF_practical_module_system, with support for them usually being
conservative: Support for structuring-mechanisms elaborates, or rewrites, into
the language of the ambient system's logic. Conservative extensions are
reasonable to avoid bootstrapping new foundations altogether but they come at
the cost of limiting expressiveness to the existing foundations; thereby
possibly producing awkward or unusual uses of linguistic phrases of the ambient
language.

We may use the term ‚Äòmodule‚Äô below due to its familiarity, however some of the
issues addressed also apply to other instances of grouping mechanisms ---such as
records, code blocks, methods, files, families of files, and namespaces.

In section ref:sec:module_expectations we define modularisation; in section
ref:sec:module_ad_hoc we discuss how to simulate it, and in section
ref:sec:module_existing we review what current systems can and cannot do; later
on, in section ref:sec:module_agda we provide legitimate examples of the
interdefinability of different grouping mechanisms within Agda. We conclude in
section ref:sec:module_theory by taking a look at an implementation-agnostic
representation of grouping mechanisms that is sufficiently abstract to ignore
any differences between a record and an interface but is otherwise sufficiently
useful to encapsulate what is expected of module systems. Moreover, besides
looking at the current solutions, we also briefly discuss their shortcomings.

#+begin_quote
The /purpose/ of this section is to establish a working definition of ‚Äúgrouping
mechanism‚Äù, how it can be simulated when it is not a primitive construct, and a
brief theory of their foundations which are exemplified using JavaScript.
#+end_quote

JavaScript will be the language of choice to demonstrate these ideas since it
has a primitive notion of module: Every notion of grouping mechanism boils down
to begin a list of ‚Äúkey:value‚Äù pairs, a so-called <<<JSON object>>>
#+latex: \label{<JSON object>}.


{{{localtoc}}}

*** Expectations of Module Systems
<<sec:module_expectations>>
#+latex: \label{sec:module_expectations}

# JC: 2.1 is wonderful. For your thesis, I will want this expanded (references,
# table of where the feature exists, etc), but this is enough for the proposal.

Packaging systems are not so esoteric that we need to dwell on their uses; yet
we recall primary use cases to set the stage for the rest of our discussions.

+ Namespacing :: Modules provide new unique local scopes for identifiers thereby
  permitting de-coupling ---possibly via multiple files contributing to the same
  namespace, which necessitates an independence of module names from the names
  of physical files; in turn, such de-conflation permits recursive modules.

+ Information Hiding :: Modules ought to provide the ability to enforce content
  /not/ to be accessible, or alterable, from outside of the module to enforce that
  users cannot depend on implementation design decisions.

+ Citizenship :: Grouping mechanisms need not be treated any more special than
  record types. As such, one ought to be able to operate on them and manipulate
  them like any first-class citizen.

  In particular, packages themselves have types which happen to be packages.
  Besides being the JavaScript approach, this is also the case with universal
  algebra, and OCaml, where ‚Äòstructures‚Äô are typed by ‚Äòsignatures‚Äô.
  Incidentally, OCaml and JavaScript use the same language for modules and for
  their /types/, whereas, for example, Haskell's recent retrofitting
  citet:haskell_backpack, of its weak module system to allow such interfacing, is
  not entirely in the core language since, for example, instantiating happens by
  the package manager rather than by a core language declaration.

+ Polymorphism :: Grouping mechanisms should group all kinds of things without prejudice.

  This includes ‚Äònested datatypes‚Äô: Local types introduced for implementation
  purposes, where only certain functionality is exposed. E.g., in an Agda record
  declaration, it may be nice to declare a local type where the record fields
  refer to it. This approach naturally leads into hierarchical modules as well.

  Interestingly, such nesting is expressible in [[http://fsl.cs.illinois.edu/images/5/5e/Cayenne.pdf][Cayenne]], a long-gone predecessor
  of Agda. The language lived for about 7 years and it is unclear why it is no longer
  maintained. Speculation would be that dependent types were poorly understood by
  the academics let alone the coders ---moreover, it had essentially one maintainer
  who has since moved on to other projects.

  With the metaprogramming inspired approach we are proposing, it is only
  reasonable that, for example, one be able to mechanically transform a package
  with a local type declaration into a package with the local declaration
  removed and a new component added to abstract it. That is, a particular
  implementation is no longer static, but dynamic. Real world uses cases of this
  idea can be found in the earlier section
  ref:sec:redundancy_derived_features_feature_exclusion.

It would not be unreasonable to consider adding to this enumeration:

+ Sharing :: The computation performed for a module parameter should be shared
  across its constituents, rather than inefficiently being recomputed for each
  constituent ---as is the case in the current implementation of Agda.

It is however debatable whether the following is the ‚Äòright‚Äô way to incorporate
object-oriented notions of encapsulation.

+ Generative modules :: A module, rather than being pure like a function, may
  have some local state or initial setup that is unique to each ‚Äòinstantiation‚Äô
  of the module ---rather than purely applying a module to parameters.

  #  As I remember Leroy-1995, the point was that SML's generative system is
  #  replaced in OCaml with an applicative system.
  SML supports such features. Whereas Haskell, for example, has its typeclass
  system essentially behave like an implicitly type-indexed record for the
  ‚Äòunnamed instance record‚Äô declarations; thereby rendering useless the
  interfaces supporting, say, only an integer constant.

+ Subtyping :: This gives rise to ‚Äòheterogeneous equality‚Äô where altering type
  annotations can suddenly make a well-typed expression ill-typed. E.g., any two
  record values are equal /at/ the subtype of the empty record, but may be unequal
  at any other type annotation.

  Since a package could contain anything, such as notational declarations, it is
  unclear how even homogeneous equality should be defined ---assuming notations
  are not part of a package's type.

Below is a table briefly summarising the above module features for popular
languages like C and JavaScript, and less popular languages Agda and OCaml.

#+begin_footnotesize org
#+caption: How languages support module uses
| Concept / Language  | C              | JavaScript          | Agda   | OCaml          |
|---------------------+----------------+---------------------+--------+----------------|
| Namespacing         | file dependent | functions and ~class~ | ~record~ | Signatures     |
| Encapsulation       | No             | JSON objects        | ~record~ | Modules        |
| First-class modules | No             | JSON objects        | No     | Functors       |
| Polymorphism        | Void Pointers  | Dynamic             | DTL    | Strongly typed |
|---------------------+----------------+---------------------+--------+----------------|
| Sharing             | ~#define~        | Function args       | No     | Function args  |
| Generative modules  | ~malloc~         | Constructors, ~new~   | No     | Yes            |
| Subtyping           | No             | JSON inheritance    | No     | Yes            |
#+end_footnotesize
:WithDetails:
#+begin_footnotesize org
#+caption: How languages support module uses
| Concept / Language  | C                  | JavaScript                  | Agda                   | OCaml                      |
|---------------------+--------------------+-----------------------------+------------------------+----------------------------|
| Namespacing         | file dependent     | functions and ~class~         | ~module~ and ~record~      | Signatures                 |
| Encapsulation       | No                 | Yes                         | Yes                    | Yes                        |
| First-class modules | No                 | Yes: JSON prototype objects | No                     | Yes: Functors              |
| Polymorphism        | Yes: Void Pointers | Yes: Dynamically checked    | Yes: Dependently typed | Yes: Strongly typed        |
|---------------------+--------------------+-----------------------------+------------------------+----------------------------|
| Sharing             | Yes with ~#define~   | Yes, as function arguments  | No                     | Yes, as function arguments |
| Generative modules  | ~struct, malloc~     | Constructors and ~new~        | No                     | Yes                        |
| Subtyping           | No                 | Yes, prototype inheritance  | No                     | Yes                        |
#+end_footnotesize
:End:

There are many other concerns regarding packages ---such as deriving excerpts,
decoration with higher-order utilities, literate programming support, and
matters of compilation along altered constituents--- but they serve to distract
from our core discussions and are thus omitted.

**** COMMENT ‚ü™ Originally lengthy & messy version ‚ü´ What's Expected of Module Systems?

***** Namespacing

  Modules ought to provide new unique local scopes ---say, by hiding or exporting--- wherein names are considered unique.
  Consequently, the same name declared in distinct modules ought to be considered
  distinct names. This idea permits de-coupling: Implementations are independent
  of one another, whence alterations can transpire in parallel, and development
  may proceed rapidly.
  # Maintaibility!

  Consider the case of de-coupled implementations that incidentally contain
  the exact same datatype declaration ---for example, the modules were created
  at different times by completely different people, and we cannot alter either code.
  If we could alter the code, we might factor out the similarities; otherwise,
  it would be fruitful to provide aliases to the datatype /and/ its constructors:
  The latter is usually not possible in many languages, but it is in Haskell and Agda
  for example, thereby permitting pattern matching on previously-identical constructor names.

{{{remark(WK: Interchangable? Really? Example!)}}}

***** COMMENT Separate Compilation ---WK: Why is this important? What for?

Module code is built /once/ in a while ---e..g, when it was last altered.
  As such, scripts that rely on pre-existing module code should not waste
  time rebuilding the module library. For example, in Agda, files are
  built once to produce ~agdai~ ---‚Äúinteractive Agda‚Äù--- files, which are then
  used speedily by other files. Our scripts, in Agda, go through the process
  of parsing, typechecking, and producing the ~agdai~ files ---this process
  needn't be repeated for pre-existing modules.

  Alternatively, for example, if a file contains two code blocks each referring
  to distinct namespaces and only one of them is altered, then the state of the
  other namespace ought to remain the same ---even if it indirectly refers to the
  former namespace--- and so should not require to be rebuilt.
  With sufficient care, a similar argument could be presented for methods
  and code blocks.

***** Grouping Mechanisms Should Group All Kinds Of Things!

****** Genericity ---Parameters and State

Module matter may be utilised in unimagined manners, so should be adaptable.

  - To support such adaptability, varying degrees of polymorphic, generic, programming
    should be supported ---to avoid duplicate code, if anything else.

     E.g., Agda provides a hierarchy of types which can be quantified over, yet
     there are record and module constructs that are essentially the same but
     this is inexpressible in Agda since these two grouping mechanisms have
     distinct citizenship classification in Agda.

  - Modules may require an initial communication to occur with an external
   system ---such as setting up a network connection or initialising a global
   variable---.

   To provide such support, consideration should be given to effectful module
   invocations. The distinction between effectful and pure module operations is notable
   within the OCaml and SML communities in the form of `functors',
   {{{remark(Both effectful and pure?)}}}
   even though the concepts are widely popular
   in stateful languages ---e.g., in the guise of a constructor method for a
   class in an object oriented language.

   Being total and pure, Agda currently does not support such effectful
   modules. Utilising secondary options, such as pragmas, may be one
   of the best possible approximations. In fact this is essentially what
   the C preprocessor does when it includes header files ---the preprocessor copies and pastes
   contents of other files into the current script.

  - Modules may be parameterised ---such as which network to connect to, or
    which file to read from.

    The computation performed for a parameter should be shared across its
    constituents, rather than inefficiently being recomputed by each constituent.
    Haskell, for example, forms a ‚Äòthunk‚Äô of memory that refers to the result
    of the /unevaluated/ computation such that each constituent refers to it.
    Once any constituent actually makes use of it, then it is evaluated, and
    all other constituents continue to point to the same memory location
    which now has the resulting computed value.
    However, the current implementation of Agda forces each
    constituent to re-compute the value of a parameter ---there is minimal
    sharing.

{{{remark()}}}

****** Instance-Specific Variables in Pure Languages

  Before even getting to nested type declarations, one desirable feature of any
  grouping mechanism is to contain instance specific-variables.

  For example, suppose I have a type ~t~ that is to implement an interface ~i~
  containing an integer value ~rank~.
  In Haskell, for example, ~i~ is a typeclass and its utilities are dispatched according
  to the instances declared. Even if ~t~ is declared an instance of ~i~, the invocation ~rank~
  makes no reference to ~t~ in its type and it might as well be referring to the rank
  associated with any other type!
  The problem is that the instance is unnamed and the instance dictionary is indexed by the
  name ~t~, which is not referenced at all.
  As such, one would need to produce
  the following awkward workaround.
  In ~i~, we declare ~rank :: a -> Int~, even though we do not /intend/ to make any use of the argument,
  then at the invocation site we have ~rank (undefined :: t)~.
  This is all terribly roundabout; no wonder the Haskell library does not have a
  ‚Äòpointed carrier‚Äô typeclass! ( It does have a [[http://hackage.haskell.org/package/pointed-5.0.1/docs/Data-Pointed.html][‚Äòpointed type constructor‚Äô]] typeclass. )
  In contrast, C# interfaces, for example, can only contain methods and constants
  ---not arbitrary properties--- and avoid Haskell's problem.
  Incidentally, Scala, which can be thought of as a middle ground between Haskell and C#,
  allows the C#-like trait declaration.
  # https://gist.github.com/missingfaktor/2575397

  Observe that Haskell's distinction of constructs results in distinct tools:
  It needs both a type-class checker and a type-checker.
  The former is unnecessary if typeclasses were syntactic sugar for canonical record types,
  thereby having them as ordinary types.
  Conveniently, the reduction of distinctions not only makes it easier to learn a language
  but also demands less tooling on the compiler implementers.

****** Nested Type Declarations

  A grouping mechanism ought to provide support not only for amalgamating functionality
  but also for assembling data structures.
  Moreover the access to the two forms of data
  should be uniform ---e.g., by using the popular dot notation for both.
  #   Why? For example, a type of containers, say sets, exposes a certain functionality but
  #   the implementation of the container may be altered

  # https://stackoverflow.com/questions/2287267/alternatives-to-nested-interfaces-not-possible-in-c
  Depending on /intended/ usage, some grouping mechanisms do not allow the introduction
  of data structures. For example, C# does not allow this even for the case
  of an interface containing a nested interface ---incidentally, its
  close relative VB.NET does
  support such a feature.
  Unfortunately even Agda does not allow this; e.g., the following is invalid
  {{{code(Agda does not permit ~data~ in ~record~)}}}
  #+BEGIN_SRC agda org-agda
  record TreeContainer (A : Set) : Set‚ÇÅ where

    data Rose : Set where Children : A ‚Üí List Rose ‚Üí Rose

    field
      initial  : Rose
      insert   : A ‚Üí Rose ‚Üí Rose
  #+END_SRC

  Note that the type ~Rose~ is not intended to be a field, but rather a local type that
  need not exist elsewhere. Unfortunately this is not possible for Agda records,
  but is only available at the module level ---which is not first class.
  It seems there was a proposal to include such features into
  Agda's older sibling, Haskell, some 6 years ago but the lack of dependent types
  made some features awkward, or impossible, to express, thereby leading to the abandonment
  of the project. @@latex: \iffalse ---this is merely speculation; but
  possibly related, \fi @@
  Interestingly, there is now currently
  much effort exerted into bringing dependent-types into Haskell in a
  harmonious fashion.

  :GraphsAreDTs:
  WK: What purpose does this remark serve at this location?

  For example, the ubiquitous notion of graphs is inherently
  a dependent type since the functions associating an edge with its source and target
  vertices have types depending on which type the vertices are and which type the edges are.

  {{{code(Graphs are Inherently a Dependent Type)}}}
  #+BEGIN_SRC agda org-agda
record Graph : Set‚ÇÅ where
  field
    vertices : Set
    edges    : Set
    src tgt  : edges ‚Üí vertices
#+END_SRC
:End:

  That one works /over/ some given carrier type ---the fact that indexing by type is the only
  way to distinguish instance ‚Äòrecords‚Äô--- has led the Haskell community to produce
  a number of isomorphic data types, using the ~newtype~ keyword, for the sole purpose of providing different typeclass
  instances. For example, the Booleans have the isomorphic copies [[http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html#t:All][~All~]] and [[http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html#t:Any][~Any~]]
  for which there are conjunctive and disjunctive monoid instances, respectively;
  as well as conversions to the standard Booleans.
  Besides the essential duplication, comments are the only way to communicate the desired
  behaviour of the monoid typeclass ---in contrast, the Agda compiler can check such a specification.
  Nonetheless, type classes provide for tremendously terse code and it would be nice to
  declare which instance is to be used in a given scope citet:named_instances
  ---this is doable in Agda, Idris, and PureScript, to name a few,
  and there is a proposal to bring this to Haskell.

  :WhyTCsNotEnought:
    WK: What purpose does this remark serve at this location?

  It is to be noted that a naive approach such as inserting Boolean terms expressing
  the specification of a typeclass and having, say, QuickCheck ensure they hold on randomly
  generated input does not scale. Such an approach would work for ensuring, say, that
  the additive integers yield a monoid, but would fail to show that lists produce a functor
  since the random generation of /functions/ for ~fmap~ would be rather costly, to say the least.
  Another naive approach would be to reduce the Boolean terms to normal then checking for
  reflexivity. This only works for basic concepts, but is tremendously brittle:
  Ensuring the naturals under addition form a monoid would require an inductive proof,
  thereby necessitating a proof term to begin with. As such, explicit proof is necessary
  for the large scale verification of behavioural properties of data types.
  :End:

  :Cayenne:
  WK: What purpose does this remark serve at this location?

  Perhaps more realistically, consider a container type that supports certain
  functionality yet the particular implementation, call it ~C,~ is chosen dynamically.
  {{{code(Dynamic Containers)}}}
  #+BEGIN_SRC agda org-agda
record IntegerContainer : Set‚ÇÅ where
  field
    C      : Set   {- The container implementation. -}
    empty  : C
    insert : Int ‚Üí C ‚Üí C
#+END_SRC

  However, the ~TreeContainer~ record is expressible in Cayenne, a long-gone predecessor
  of Agda. The language lived for about 7 years and it is unclear why it is no longer
  maintained. Speculation would be that dependent types were poorly understood by
  the academics let alone the coders ---a statement that remains true today as we have
  already discussed.
 # http://fsl.cs.illinois.edu/images/5/5e/Cayenne.pdf
 :End:

***** Excerpting ---Deriving Modules

  There is a tendency to depend on a particular set of modules when forming
  numerous scripts ---for example, requiring numeric, list, vector,
  and a variety of equality and isomorphism notions when working on a problem of representing bags.
  The common solution is to manually produce a module that re-exports the
  desired utilities.

  In the extreme case that we actually use one utility from each of /N/ modules,
  then our scripts will not depend on /N/ utility functions but rather on
  /N/ many modules ---which is not necessarily true. However, that is what appears
  on the surface and so those files must be built. For the sake of efficiency,
  it would be desirable to have a new module formed, say in the back-end,
  that includes only the minimum setup, from each module, needed to have the
  utility functions working. Ideally the system could be commanded to either
  produce such an amalgamated module implicitly in some local directory,
  or to weave it into the back-end ---either way, there would be side-effects.

  Besides efficiency, if this module could be presented
  by the system to the user, it would also make the resulting scripts more self-contained
  and so more re-usable. Moreover, for presentation purposes, it is convenient
  to have precisely only what is needed rather a hodge-podge of imports
  from a variety of libraries which may not even be publicly accessible
  ---as is the case with many personal libraries.

  Emacs' Org major mode provides for the ability to make such `tangling'
  happen. It has already been demonstrated that Agda code can be tangled from
  literate programming citet:knuth_lp with Org-mode documents, however the goal is to be
  able to do so directly within Agda itself.

***** Access Controls
{{{remark(Difference between this section and the next?)}}}

A key feature of grouping mechanisms is information hiding; the
ability to encapsulate data representations so that data invariants
may be maintained by the library utilities.
Thus, modules should have access controls
  ---the ability to enforce content /not/ to be accessible, or alterable, from
  outside of the module.

{{{remark(More general: To enfore that users cannot depend on implementation design decisions.)}}}

  In particular, when the implementation of a concept leaks details divergent
  from its intended interface, or if the implementation is likely to change,
  one should provide an interface and be able to make the definitions opaque
  to the system so that its normalisation is not overly aggressive.
  For example, suppose we implement bags using lists.
  Using knowledge of the implementation, users could produce methods
  that are undefinable for bags; e.g., any fold using a
  non-commutative operator. This is an opportunity to
  provide a definition and mark it as opaque.
  Agda does this with the ~abstract~ keyword
  ---which happens to be experimental since it's semantics are not
  well-understood.
  :PoorExample:
  For example, suppose we want to implement an addition algorithm over the
  natural numbers, but we have yet to settle on the implementation
  ---e.g., whether it is recursive on the first or second argument, or if it
  makes a translation to binary then back---, then this is an opportunity to
  provide a definition and mark it as opaque.
  #   Agda does this with the ~abstract~ keyword.
  :End:

  It is important to observe that many languages may hide method names, but
  this feature of Agda goes further. It hides the method implementation altogether
  from the user, so they cannot rely on it for reasoning purposes nor
  efficiency hacks. The latter being common programming tricks; e.g.,
  knowledge of ~gcc~ compiler implementations lets users favour certain constructs
  or form expressions that are considered undefined by the C language specification.

***** Representation Hiding

{{{remark(Difference between this section and the previous?)}}}

We've remarked that a module should serve multiple purposes, such as
  namespacing, but it should also provide support for creating abstract
  data types.

  For example,
  {{{remark(WK: What does this illustrate? DT? Context?)}}}
  suppose a library is intended to provide an in implementation
  for the notion of bags ---also known as multisets---, then the module would
  contain the implementation but the exported data would hide the implementation
  matter. Indeed, access to implementation matter could render dangerously incoherent
  operations to be permissible; such as deriving an order on a type by considering
  the hidden bag implementation.

  Another example of where access to an implementation radically alters
  the possibilities is in the relm of databases. A stack may be implemented
  using a linked list, but providing only a restricted core functionality.
  The latter can serve as a basic database, but the former cannot since one
  cannot implement the general ~select~ database operation on stacks
  to alter elements. {{{remark(WK: Insufficiant declaration of constraints!)}}}


  Stacks are not functorial. {{{remark(---Musa: Yes they are!)}}}
  #+begin_src haskell
---  fmap using only stack interface.

fmap f s | null s    = s
     | otherwise = let (hd, tl) = pop s in push(f hd, fmap f tl)
  #+end_src

***** Operations on grouping mechanisms ---grouping mechanisms as first-class citizens!

  A common experience is coding an algorithm along with print statements
  to keep the user notified of the events taking place, or of coding an
  algorithm and keeping track of a table of pre-computed values, i.e., memoiziation.
  The core logic of the algorithm is polluted with an extra-desirable
  functionality, which makes the core logic un-reusable when other functionality
  is desired. The solution is a ‚Äòdecorator‚Äô, a higher-order function that
  takes the core algorithm as a method and yields a method that adds the
  extra-desirable functionalities.

  {{{remark(WK: ‚Äúaspect-oriented‚Äù?)}}}
  For matters of efficiency, it may be desirable to take a module of polymorphic
  code and instantiate its variables to concrete types and values, possibly
  eliminating recursion as well to produce static code that incurs less dynamic
  penalty.

  Another common operation, which happens to be supported in OCaml, is obtaining the
  interface of a module. The manner in which code is grouped could be optimally
  aimed at maintainability or at usability. These are different problems and
  so should be decoupled.

***** Physical Independence

  In a zealous appeal to the principle of separation of concerns, some
  systems insist on only one module per file; moreover, the module's name
  must be the name of the physical file.
  However, incessant appeal to that principle results in fragmented hierarchies.
  It may be prudent to have multiple files contributing to the same module
  namespace, as in C, thereby necessitating filenames be independent from the module names.

{{{remark(WK: See also: ghc ---split-objs, ---split-sections)}}}

***** Subtyping & (Type-directed) Equality

  Subtyping is a controversial issue.
  On the one hand, it permits re-use.
  On the other hand, it makes type inference citet:type_inference_in_math rather weak.
  Its incorporation however does allow for using records for manifest fields.
  Then again, type inference is already sufficiently weak in a dependently-typed language,
  so this may not be too much of a burden.

  Moreover this now gives rise to (heterogeneous!) equality issues:
  If two records have only one common field with the same value, but otherwise have many
  other distinct fields, then they are equal only /at/ the sub-record consisting of that field,
  and are otherwise unequal /at/ any other type. Altering the type annotation can suddenly
  make a well-typed expression ill-typed.
  # This is worrisome, to say the least.
  #  This becomes more anxiety provoking when ‚Äòproof irrelevance‚Äô and term erasure enter
  #  the scene.
  #
  # Altering the type annotation can suddenly make equal items unequal.

  Powerful languages like Agda allow for the declaration of patterns, notation, and
  precedence. Modelling a module by a record would suggest module equality is structural
  record equality ---but do we really want to consider notational declarations?
  If we do not, then we are considering equality /at/ the greatest common sub-record type?

  Perhaps sub-typing should be in the background but not in the foreground?
  This may lead to a divergent treatment of first-class versus second-class grouping mechanisms.

{{{remark(WK: Look at OCaml singatures, module types, and modules. Similar in Coq?)}}}

***** COMMENT ? Hierarchical Modules
***** COMMENT ? Recursive Modules

   One potential solution would be to deconflate the unit of namespacing from the
unit of compilation (from the unit of filesystem organization).)
*** Ad hoc Grouping Mechanisms
<<sec:module_ad_hoc>>
#+latex: \label{sec:module_ad_hoc}

# ad hoc ‚à∑ created or done for a ‚Äúparticular‚Äù purpose as necessary.
# Synonyms:	impromptu, improvised, rough and ready, makeshift, make-do, cobbled together, thrown together.

Many popular coding languages do not provide top-level modularisation
mechanisms, yet users have found ways to emulate some or all of their
/requirements/. We shall emphasise a record-like embedding in this section, then
illustrate it in Agda in the next section. We shall number the required features
then illustrate their simulation in JavaScript.

‚ü®0‚ü© *Namespacing:* Ubiquitous languages, such as C, Shell, and JavaScript, that do not
have built-in support for namespaces mimic it by a consistent naming discipline
as in {{{newline}}} ~theModule_theComponent~. This way, it is clear where
~theComponent~ comes from; namely, the ‚Äòmodule‚Äô ~theModule~ which may have its
interface expressed as a C header file or as a JSON literal. This is a variation
of Hungarian Notation citet:hungarian_notation.

# https://docs.racket-lang.org/guide/macro-module.html
Incidentally, a Racket source file, module, and ‚Äòlanguage‚Äô declaration are
precisely the same. Consequently, Racket modules, like OCaml's, may contain
top-level effectful expressions. In a similar fashion, Python packages are
directories containing an ~__init__.py~ file which is used for the the same
purpose as Scala's ~package object~'s ---for package-wide definitions.

‚ü®1‚ü© *Objects:* An object can be simulated by having a record structure contain the
properties of the class which are then instantiated by record instances. Public
class methods are then normal methods whose first argument is a reference to the
structure that contains the properties. The relationship between an object
instance and its class prototype can be viewed across a number of domains, as
illustrated in the following table.

# Records, Prefixes, & Record Consuming Operations

# +LaTeX: \begin{tcolorbox}[title=\hfill Muliple Forms of the Template-Instantiation Duality]
# +BEGIN_CENTER org
#+caption: Muliple Forms of the Template-Instantiation Correspondence
| *Template*            | $\qquad\text{\emph{has a}}\qquad$ | *Instance*           |
| ‚âà class             |                                   | ‚âà object           |
| ‚âà type              |                                   | ‚âà value            |
| ‚âà theorem statement |                                   | ‚âà witnessing proof |
| ‚âà specification     |                                   | ‚âà implementation   |
| ‚âà interface         |                                   | ‚âà implementation   |
| ‚âà signature         |                                   | ‚âà algebra          |
| ‚âà metamodel         |                                   | ‚âà model            |
# | ‚âà logic             |                                   | ‚âà theory           |
# +END_CENTER
# +LaTeX: \end{tcolorbox}

:Hide:
#+begin_edcomm org
:ed: WK
#¬† - Why do you use $\approx$ as item ``bullet''?
¬† - ``A logic has theories as instances'' sounds dubious to me.

Musa: Why is that?
#+end_edcomm
:End:

‚ü®2‚ü© *Modules:* Languages that do not support a module may mimic it by placing ‚Äúmodule
contents‚Äù within a record. Keeping all contents within one massive record also
solves the namespacing issue.

In older versions of JavaScript, for example, a module is a Gls:json literal
---i.e., a comma separated list of key-value pairs. Moreover, encapsulation is
simulated by having the module be encoded as a function that yields a record
which acts as the public contents of the module, while the non-returned matter
is considered private. Due to JavaScript's dynamic nature we can easily adjoin
functionality to such ‚Äòmodules‚Äô at any later point; however, we cannot access
any private members of the module. This inflexibility of private data is both a
heavy burden as well as a championed merit of the Object Oriented Paradigm.

‚ü®3‚ü© *Sub-Modules:* If a module is encoded as a record, then a sub-module is a
field in the record which itself happens to be a module encoding.

‚ü®4‚ü© *Parameterised Modules:* If a module can be considered as encoded as the
returned record from a function, then the arguments to such a function are the
parameters to the module.

‚ü®5‚ü© *Mixins:* A /gls:mixin is the ability to extend a datatype /X/ with functionality
/Y/ long after, and far from, its definition. Mixins ‚Äòmix in‚Äô new functionality by
permitting /X obtains traits Y/ ---unlike inheritance which declares /X is a Y/.
Examples of this include Scala's traits, Java's inheritance, Haskell's
typeclasses, and C#'s extension methods.

Let us see a concrete realisation of such a simulation of module features in
JavaScript.
#+BEGIN_SRC js :results output
// ‚ü®2‚ü© A simple unparamterised module with no private information
// ‚ü®0‚ü© The field ‚Äúname‚Äù is not global, but lives in a dedicated namespace
function Person (nom, age) { this.name = nom; this.age = age; }

// ‚ü®1‚ü© An object instance;
// i.e., the dictionary literal {name: "GoÃàdel", age: 12}
goÃàdel = new Person("GoÃàdel", 12)

// ‚ü®5‚ü© Let's mixin new functionality, say, a new method
goÃàdel.prove = () => console.log("I have an incomplete proof...")

// ‚ü®2, 4‚ü© A module parameterised by another module
// that is a ‚Äúsubmodule‚Äù of ‚ÄúPerson‚Äù.
// ‚ü®3‚ü© The non-Person parts of the parameter are in module ‚ÄúP‚Äù.
function alter_module({name, age, ...P}) {

    // ‚ÄúPrivate‚Äù fields
    information = `I am ${name}! I am ${age} years of age!`
    function speak() { console.log(information) }

    // The return value; fields that are promoted to ‚Äúpublic‚Äù
    return {name, speak}
}

// Invoking the function-on-modules ‚Äúalter_module‚Äù
// which mixes-in the ‚Äúspeak‚Äù method but drops the ‚Äúage‚Äù field
kurt  = alter_module(goÃàdel)
kurt.speak() // ‚áí I am GoÃàdel! I am 12 years of age!

// ‚ü®0‚ü© Notice that the ‚ÄúgoÃàdel‚Äù module ‚Äòlost‚Äô the ‚Äúage‚Äù field
// when it was transformed into the ‚Äúkurt‚Äù module.
console.log(kurt) // ‚áí { name: 'GoÃàdel', speak: [Function: speak] }
#+END_SRC

Typescript citet:understanding_typescript occupies an interesting position with
regards to mixins: It is one of the few languages to provide union and
intersection combinators for its ~interface~ grouping mechanism, thereby most
easily supporting the gls:little-theories citet:little_theories method and making
theories a true lattice. Interestingly, intersection of interfaces results in a
type that contains the declarations of its arguments and if a field name has
conflicting types then it is, recursively, assigned the intersection of the
distinct types ---the base cases of this recursive definition are primitive
types, for which distinct types yield an empty intersection. In contrast, its
union types are disjoint sums.
#
# https://codingblast.com/typescript-intersection-types/

In the dependently-typed setting, one also obtains so-called ‚Äòcanonical
structures‚Äô citet:coq_canonical, which not only generalise the previously
mentioned mixins but also facilitate a flexible style of logic programming by
having user-defined algorithms executed during unification; thereby permitting
one to /omit many details citet:coq_canonical_tutorial and have them inferred/. As
mentioned earlier regarding objects, we could simulate mixins by encoding a
class as a record and a mixin as a record-consuming method. Incidentally
languages admitting mixins give rise to an alternate method of module encoding:
A ‚Äòmodule /of type M‚Äô is encoded as an instantiation of the mixin trait M./

# In the sequel,
# when we discuss modules as contexts, it can be seen that the simplest form of
# mixins is context prepending.

These natural encodings only reinforce our idea that there is no real essential
difference between grouping mechanisms: Whether one uses a closure, record, or
module is a matter of preference the usage of which communicates particular
intent, as summarised briefly in the table below.

#+caption: Choice of grouping mechansims communicate intent
| Concept               | Possible Intent                                             |
|-----------------------+-------------------------------------------------------------|
| module                | Namespacing; organise related utilities under the same name |
| record                | Bundle up related features into one ‚Äòcoherent‚Äô unit         |
| tuple                 | Quickly return multiple items from a function               |
|-----------------------+-------------------------------------------------------------|
| function              | An indexed value                                            |
|-----------------------+-------------------------------------------------------------|
| parameterised modules | Namespaced utilities abstracted over other utilities        |
| parameterised record  | A semantic unit that ‚Äòbuild upon‚Äô another coherent unit     |

# | parameterised modules | Namespaced utilities abstracted over other utilities; e.g., ~sort~ indexed by ~<~. |

*** Theory Presentations: A Structuring Mechanism
 <<sec:module_theory>>
#+latex: \label{sec:module_theory}

:Hide:
 What of the most closely related theoretical work?

#+begin_edcomm org
:ed: WK

``What of the most closely related theoretical work?''
¬† Inappropriate formulation. Your PhD thesis is not the place to be sloppy in ANY way.
#+end_edcomm
:End:

 Our envisioned effort would support a ‚Äúwrite one, obtain many‚Äù approach to
 package formation. In order to get there, we must first understand what is
 currently possible. As such, we investigate how package formers are currently
 treated formally under the name of ‚Äòglspl:theory-presentation‚Äô. It is the aim of
 this section to attest that the introduction's story is not completely on shaky
 foundations, thereby asserting that the aforementioned goals of the
 introduction are not unachievable ---and the problems that posed in
 ref:sec:examples_from_the_wild are not trivial.

 As discussed, languages are usually designed with a bit more thought given to a
 first-class citizen notion of grouping than is given to second-class notions of
 packaging-up defined content. Object-oriented languages, for example, comprise
 features of both views by treating classes as external structuring mechanisms
 even though they are normal types of the type system. This internalising of
 external grouping features has not received much attention with the notable
 mentions being citet:theories_as_types,focalize. It is unclear whether there is
 any real distinction between these ‚Äòinternal, integrated‚Äô and ‚Äòexternal,
 stratified‚Äô forms of grouping, besides intended use. The two approaches to
 gls:module-systems have different advantages. Both approaches permit separation
 of concerns: The external point of view provides a high-level structuring of a
 development, the internal point of view provides essentially another type which
 can be the subject of the language's operations ---e.g., quantification or
 tactics--- thereby being more amicable to computing transformations.
 Essentially it comes down to whether we want a ‚Äòmodule parameter‚Äô or a ‚Äòrecord
 field‚Äô ---why not write it the way you like and get the other form for free.

 #+caption: Parameters ‚âà Projections
 For example, a function ~f ‚à∂ X ‚Üí Y √ó Z~ is externally /an indexed value/, a way to
 structure data ---~Y √ó Z~ pairs--- according to some *parameters* ---~X~. By a slight
 change of perspective, the /type/ ~X ‚Üí Y √ó Z~ treated internally consists of /values/
 that have *field projections* ~eval‚Çì~: For any ~x ‚à∂ X~ and ~f ‚à∂ X ‚Üí Y √ó Z~, we have
 ~eval‚Çì f ‚à∂ Y √ó Z~.

 Since external grouping mechanisms tend to allow for intra-language features
 ---e.g., imports, definitions, notation, extra-logical declarations such as
 pragmas--- their systematic internalisation necessitates expressive record
 types. As such, a labelled product type or <<</gls:context/>>>
#+latex: \label{</gls:context/>} ---being a list of
 name-type declarations with optional definitions--- is a sufficiently generic
 rendition of what it means to group matter together.

 Below is a grammar, from citet:theories_as_types, for a simple yet powerful
 module system based on theory (presentations) and [[glspl:theory-morphism][Theory Morphism]] ---which are
 merely named contexts and named substitutions between contexts, respectively.
 Both may be formed modularly by using includes to copy over declarations of
 previously named objects. Unlike theories which may include arbitrary
 declarations, theory morphisms ~(V ‚à∂ P ‚Üí Q) ‚âî Œ¥~ are well-defined if for every
 ~P~-declaration ~x ‚à∂ T~, ~Œ¥~ contains a declaration ~x ‚âî t~ where ~t~ may refer to all
 names declared in ~Q~.

 {{{code(Syntax for Dependently Typed Œª-calculus with Theories)}}}
 #+BEGIN_SRC haskell
-- Contexts
Œì  ::= ‚àÖ                       -- empty context
     | x : œÑ [:= œÑ'], Œì         -- context with declaration, optional definition
     | Includes X, Œì           -- theory inclusion

-- Terms
œÑ ::= x | œÑ‚ÇÅ œÑ‚ÇÇ | Œª x : œÑ' ‚Ä¢ œÑ -- variables, application, lambdas
    | Œ† x : œÑ' ‚Ä¢ œÑ             -- dependent product
    | [Œì] | ‚ü®Œì‚ü© | œÑ.x          -- record ‚Äú[type]‚Äù and ‚Äú‚ü®element‚ü©‚Äù formers, projections
    | Mod X                    -- contravariant ‚Äútheory to record‚Äù internalisation

-- Theory, external grouping, level
Œò ::= ‚àÖ                        -- empty theory
    | X := Œì, Œò                -- a theory can contain named contexts
    | (X : (X‚ÇÅ ‚Üí X‚ÇÇ)) := Œì     -- a theory can be a first-class theory morphism

-- Proviso: In record formers, Œì must be flat; i.e., does not contain includes.
 #+END_SRC

 #+LaTeX: \def\Mod{\mathsf{Mod}\,}

This concept of packaging indeed captures much of what's expected of grouping
mechanisms; e.g.,

 + Grouping mechanism should group all kinds of things and indeed there is no
   constraint on what a theory presentation may contain.

 + Namespacing: Every module context can be construed as a record whose contents
   can then be accessed by record field projection.

   /Theories as Types/ citet:theories_as_types presents the first formal approach
   that systematically internalises theories into record types. Their central
   idea is to introduce a new operator ~Mod~ ---read ‚Äúmodels of‚Äù--- that turns a
   theory $T$ into a type =Mod T= which /behaves/ like a record type.

 + Operations on grouping mechanisms citet:tpc.

Observe that a context is, up to syntactical differences, essentially a
JavaScript object notation literal. Consequently, the notion of a mixin as
described for JSON literals is here rendered as a theory morphism.
# ?
# ?
#+caption: Theory presentations in practice
| Theory Presentations | JavaScript                                              |
|----------------------+---------------------------------------------------------|
| Context / Record     | JSON object: ~{key‚ÇÄ‚à∂ value‚ÇÄ, ‚Ä¶, key‚Çô‚à∂ value‚Çô}~            |
| Empty context        | Empty dictionary: ~{}~                                    |
| Inclusion            | In-place syntactic unpacking: ~{...Œì, k‚ÇÄ‚à∂ v‚ÇÄ, ‚Ä¶, k‚Çô‚à∂ v‚Çô}~ |
| Theory               | A file or a JSON object or an object-returning function |
| Translation          | Function from JSON objects to JSON objects              |
| Gls:view             | Specification preserving translation                     |

For example, with the abbreviation =(Œ† x ‚à∂ A ‚Ä¢ B) = (A ‚Üí B)=, we may form a small
/theory/ hierarchy of signatures ---which is a just list of /named/ contexts.
{{{code(Example Theory Presentation ---Informal Notation)}}}
#+BEGIN_SRC haskell
  MagmaSig ‚âî Carrier ‚à∂ Set, _‚®æ_ ‚à∂ Carrier ‚Üí Carrier ‚Üí Carrier, ‚àÖ
, MonSig   ‚âî Includes MagmaSig, Id ‚à∂ Carrier, ‚àÖ
, Forget ‚à∂ MagmaSig ‚Üí MonSig ‚âî (Carrier ‚âî Carrier, Id ‚âî Id, ‚àÖ)
, ‚àÖ
#+END_SRC
This theory is then realised as follows in JavaScript ---ignoring the types.
{{{code(Example Theory Presentation ---Executable JavaScript)}}}
#+BEGIN_SRC js :results output
let MagmaSig = {Carrier: undefined, op: undefined}
let MonSig   = {...MagmaSig, id: undefined}
let Forget   = (Mon) => ({Carrier: Mon.Carrier, op: Mon.op})
#+END_SRC

In practice, an object's features behave, to some degree, in a /known/ fashion;
e.g., what operators may be applied or how the object's features interact with
one another. For instance, a <<</monoid/>>>
#+latex: \label{</monoid/>} is an object consisting of a set
~Carrier~, a value ~Id~ of that set, and a binary operation ~_‚®æ_~ on the set;
moreover, the interaction of the latter two is specified by requesting that the
operation is associative and ~Id~ is the identity element for the binary
operation. In contrast, a <<</magma/>>>
#+latex: \label{</magma/>} is simply a set along with a binary
operation. As such, the translation ~Forget~, above, not only gives us a
translation of features, but it also satisfies all zero coherence laws of a
magma.

 As mentioned earlier, a theory morphism, also known as a <<</view/>>>
#+latex: \label{</view/>}, or
 gls:substitution, is a map between contexts that implements the interface of
 the source using utilities of the target; whence results about specific
 structures can be constructed by transport along views citet:little_theories: A
 view =V ‚à∂ ùíÆ ‚Üí ùíØ= gives rise to a term homomorphism ~ùí±~ from ~P~-terms to ~Q~-terms that
 is type-preserving in that whenever =Œò, ùíÆ ‚ä¢ e ‚à∂ œÑ= then =Œò, ùíØ ‚ä¢ ùí± e : ùí± œÑ=. Thus,
 views preserve judgements and, via the propositions-as-types representations,
 also preserve truth.

 # Theory interpretations are also called translations, theory morphisms, immersions, and realisations.
 More concretely, a view =V = (U, Œ≤) ‚à∂ ùíÆ ‚Üí ùíØ= is essentially a predicate $U$, of
 the target theory, denoting a /universe of discourse/ along with an
 arity-preserving mapping =Œ≤= of ùíÆ-symbols, or declarations, to ùíØ-expressions
 ---by itself, =Œ≤= is called a <<</translation/>>>
#+latex: \label{</translation/>}. It is lifted to terms as
 follows ---notice that the translated variable-binders are relativised to the
 new domain.
 #+latex:  \begin{tcolorbox}[title=\hfill ùí± Extended to Terms]
 | ~ùí± x ‚âà x~                              | If ~x~ is an ùíÆ-variable symbol       |
 | ~ùí±(f e‚ÇÅ ‚Ä¶ e‚Çô) ‚âà (Œ≤ f) (ùí± e‚ÇÅ) ‚Ä¶ (ùí± e‚Çô)~ | If ~f~ is an ~n~-ary ùíÆ-function symbol |
 | ~ùí±(ùí¨ x ‚Ä¢ P) ‚âà (ùí¨ x ‚à£ U x ‚Ä¢ ùí± P)~       | If ~ùí¨~ is a variable-binder ~‚àÄ, ‚àÉ, Œª~  |
#+latex:  \end{tcolorbox}
:Alternate_LaTeX_Form:
 #+BEGIN_EXPORT latex
 \begin{tcolorbox}[title=\hfill $\Phi$ Extended to Terms]
 \vspace{-1em}
 \begin{align*}
 \Phi(x) &= x  & & \text{ Provided $x$ is an $\mathcal{S}$-variable symbol }
 \\
 \Phi\left( f(t_1, \ldots, t_n) \right)
 &= \beta(f) \left(\Phi\, t_1, \ldots, \Phi\, t_n\right)
 & & \text{ Provided $f$ is a $n$-ary $\mathcal{S}$-function symbol}
 \\
 \Phi\left(\mathcal{Q}\, x \;\bullet\; P\right)
 &= \left(\mathcal{Q}\, x \;‚ùô\; U\, \;x \bullet\; \Phi(P) \right)
 & & \text{ Provided $\mathcal{Q}$ is a variable-binder $\forall, \exists, \lambda$ }
 \end{align*}
 \end{tcolorbox}
 #+END_EXPORT
:End:

 The /Standard Interpretation Theorem/ citet:theory_interpretations_farmer provides
 sufficient conditions for a translation to be an ‚Äògls:interpretation‚Äô which
 transports results between formalisations. It states: A translation is an
 interpretation provided ùíÆ-axioms =P= are lifted to theorems =ùí± P=, the universe of
 discourse is non-empty =‚àÉ x ‚Ä¢ U x=, and the interpretation of the universe
 contains the interpretations of the symbols; i.e., for each ùíÆ-symbol =f= of arity
 =n=, {{{newline}}} ~ùí±(‚àÄ x‚ÇÅ, ‚Ä¶, x‚Çô ‚Ä¢ ‚àÉ y ‚Ä¢ f x‚ÇÅ ‚Ä¶ x‚Çô = y)~ holds.

 # Standard interpreations are used to compare the strength of theories: ùíØ is at
 # least as strong as ùíÆ provided ùì¢ is interpretable in ùíØ --indeed, that's why
 # every model of the latter gives rise to a model of the former! Also, standard
 # interpretations have long been used in logic to prove meta-mathematical
 # properties baout first-order theories, mainly rel;atoive consisitency,
 # decidiabilkity, and undecidiability.

 By virtue of being a validity preserving homomorphism, a standard
 interpretation syntactically and semantically embeds its source theory in its
 target theory. The most important consequence of interpretability is the
 /Standard Relative Satisfiability/ citet:theory_interpretations_farmer which says
 that a theory which is interpretable in a satisfiable theory is itself
 satisfiable; in programming terms this amount to: /If $X$ is an implementation/
 /of *interface* ùíØ and ùíÆ is interpretable in ùíØ then $X$ can be transformed into an
 implementation of ùíÆ./ Interestingly such ‚Äòsubtyping‚Äô can be derived in a
 mechanical fashion, but it can force the subtype relation to be cyclic.
 However, it is unclear under which conditions translations automatically give
 rise to interpretations: Can the issue be relegated to syntactic manipulation
 only?

 Theory interpretation has been studied for first-order predicate logic then
 extended to higher-order logic citet:theory_interpretations_farmer. The advent
 of dependent-types, in particular the blurring of operations and formulae
 citet:wiki_curry_howard, means that propositions of a language can be encoded
 into it as other sorts, dependent on existing sorts, thereby questioning /what
 it means to have a validity-preserving morphism/ when the axioms can be encoded
 as operations? As far as we can tell, it seems very little work regarding
 theory interpretations has been conducted in dependently-typed settings
 citet:mlt_partial,higher_order_interpretations,institution_interpretations,dtl_interpretations.

 #  {{{remark(WK: Then you should discuss it in more detail.)}}}

 In subsequent sections, ref:sec:prototype:morphisms and ref:sec:PF:extension,
 we shall identify a number of views that are formed /syntactically/ and the fact
 that they are indeed views then becomes the need to mechanically provide
 certain values ---which by the propositions-as-types view means we mechanically
 provide certain ‚Äúproofs of propositions‚Äù. Incidentally, moving forward, we
 shall consider an essentially untyped setting in which to perform such syntax
 shuffling ---that is, even though we are tackling DTLs, we shall follow a
 JavaScript-like approach with essentially /one/ notion of grouping rather than a
 theory presentation approach with two notions.

 :Irrelevant:
 Notice that records play dual roles. They not only serve as an internal form of grouping
 mechanisms, but inspired by the previous Agda renditions, also serve the purpose of
 forming dependent sum types.

 What about the presence of non-termination or inheritance
 ---i.e., partial functions and subtypes?
 The subject is only beginning to
 be seriously explored in higher-order logic and type theory.
 cite{theory_interpretations_farmer}.
 Views associating base types with subtypes get complicated since functions must now
 deal with restricted domains, consequently necessitating that all predicates on functions
 also be relativised.
 :End:
*** ‚ÄúJSON is Foundational‚Äù: From Prototypes to Classes

   In the previous section, we indicated that going forward, we will be taking a
   JSON-like approach to working with modules. JavaScript has the reputation of
   being non-academic, along with its dynamically type-checked nature it is not
   surprising that the reader may take pause to consider whether our inclination
   is, plainly put, ‚Äòwrong‚Äô. To reassure the reader, we will show how JSON
   objects are a foundational way to group data by deriving the notion of a
   ~class~ from object-oriented programming. In fact, recent implementations of
   JavaScript have a ~class~ keyword which, for the most part, is syntactic sugar
   for JSON objects.

   We shall arrive at the ~class~ keyword as a means of moving away from design
   patterns and going to mechanical constructs.

**** Prototypical Concepts

 In English, /prototype/ means a preliminary model of something from which
 other forms are developed or /copied/. As such, a /prototypical/ object
 is an object denoting the original or typical form of something.

 In addition to their properties, JavaScript objects also have a prototype
 ---i.e., another object that is used as a source of additional properties. When
 an object gets a request for a property that it does not have, its prototype
 will be searched for the property, then the prototype‚Äôs prototype, and so on.

 | A <<</prototype/>>>
#+latex: \label{</prototype/>} is another object that is used as a fallback source of properties. |

 Adding new features or overriding methods are another primary use for
 prototypes. E.g., to attach a new property to a ‚Äòkind‚Äô of object, we simply
 need to attach it to the prototype ---since all those ‚Äòkinds‚Äô of objects use
 the prototype's properties. In this way, we overload a method by attaching it
 to prototypes. If, instead, we add the property to an object, rather than to
 its prototype, then the property is attached directly to the object and
 possibly shadowing the property of the same name that the prototype has, whence
 overriding.

***** Prototype Example

  Prototypes let us define properties that are the same for all instances, but
  properties that differ per instance are stored directly in the objects
  themselves. E.g., the prototypical person acts as a container for the
  properties that are shared by all people. An individual person object, like
  ~kathy~ below, contains properties that apply only to itself, such as its name,
  and derives shared properties from its prototype.

  {{{code(Painfully Initialising the Infrastructure of an Instance)}}}
  #+BEGIN_SRC js
// An example object prototype
let prototypicalPerson    = {};
prototypicalPerson._world = 0;
prototypicalPerson.speak  = function () {
  console.log(`I am ${this.name}, a ${this.job}, in a world of `
               + `${prototypicalPerson._world} people.`) }
prototypicalPerson.job = `farmer`;

// Example use: Manually ensure the necessary properties are setup
// and then manually increment the number of people in the world.
let person = Object.create(prototypicalPerson);
person.name = `jasim`;
prototypicalPerson._world++;
person.speak() // ‚áí I am jasim, a farmer, in a world of 1 people.

// Another person requires just as much setup
let kathy = { ...prototypicalPerson }; // Same as ‚ÄúObject.create(‚ãØ)‚Äù
kathy.name = `kathy`;
prototypicalPerson._world++;
kathy.speak() // ‚áí I am kathy, a farmer, in a world of 2 people.
  #+END_SRC

  You can use ~Object.create~ to create an object with a specific prototype. The
  default prototype is ~Object.prototype~. For the most part,
  ~Object.create(someObject) ‚âà { ...someObject }~; i.e., we /copy/ the properties of
  ~someObject~ into an empty object, thereby treating ~someObject~ as a prototype
  from which we will build more sophisticated objects.

  Notice that we have to manually update the ‚Äòclass variable‚Äô ~_world~ each time a
  new person instance is created.

***** Manual Constructor Functions

  | /Classes are prototypes along with constructor functions!/ |

  A /class/ defines the shape of a kind of object; i.e., what properties it has;
  e.g., a Person can ~speak~, as all people can, but should have its own ~name~
  property to speak of. This idea is realised as a prototype along with a
  /constructor/ function that ensures an instance object not only derives from the
  proper prototype but also ensures it, itself, has the properties that instances
  of the class are supposed to have.

  {{{code(Using a Function to Initialise the Infrastructure of an Instance)}}}
  #+BEGIN_SRC js
let prototypicalPerson    = {};
prototypicalPerson._world = 0;
prototypicalPerson.speak  = function () {
  console.log(`I am ${this.name}, a ${this.job}, in a world of `
               + `${prototypicalPerson._world} people.`) }

function makePerson(name, job = `farmer`) {
  let person  = Object.create(prototypicalPerson);
  person.name = name;
  person.job  = job;
  prototypicalPerson._world++;
  return person;
}

// Example use
let jasim = makePerson(`jasim`);
jasim.speak() // ‚áí I am jasim, a farmer, in a world of 1 people.

makePerson(`kathy`).speak()
// ‚áí I am kathy, a farmer, in a world of 2 people.
  #+END_SRC

  Notice that we did not have to manually update the ~_world~ variable
  each time a new person instance is created.

***** Constructor Functions with ~new~
   We can fuse the previous two approaches under one name by making the prototype
   a part of the constructor.

   {{{code(Constructor Functions)}}}
  #+BEGIN_SRC js
function Person(name, job = `farmer`) {
 this.name = name;
 this.job  = job;
 Person.prototype._world++;
}

Person.prototype._world = 0;
Person.prototype.speak = function () {
  console.log(`I am ${this.name}, a ${this.job}, in a world of `
               + `${Person.prototype._world} people.`) }

// Example use
let jasim = Object.create(Person.prototype)
Person.call(jasim, `jasim`)
jasim.speak() // ‚áí I am jasim, a farmer, in a world of 1 people.

// Example using shorthand
let kasim = new Person (`kathy`)
kasim.speak()  // ‚áí I am kathy, a farmer, in a world of 2 people.
  #+END_SRC

  If you put the keyword ~new~ in front of a function call, the function is
  treated as a constructor. This means that an object with the right prototype is
  automatically created, bound to ~this~ in the function, and returned at the end
  of the function.

  {{{code(Definition of ‚Äònew‚Äô)}}}
  #+BEGIN_SRC js
  new f(args)
‚âà (_ => let THIS = Object.create(f.prototype);
        f.call(THIS, args); return THIS;) ()
  #+END_SRC

  All functions automatically get a property named ~prototype~, which by default
  holds a plain, empty object that derives from ~Object.prototype~. You can
  overwrite it with a new object if you want. Or you can add properties to the
  existing object, as the example does.

  Notice that the ~Person~ object /derives/ from ~Function.prototype~,
  but also has a /property/ named ~prototype~ which is used for instances
  created through it.
  {{{code(Sanity Checks)}}}
  #+BEGIN_SRC js
console.log( Object.getPrototypeOf(Person) == Function.prototype
           , Person instanceof Function
           , jasim  instanceof Person
           , Object.getPrototypeOf(jasim) == Person.prototype)
  #+END_SRC

  Hence, we can update our motto:
  | /Classes are constructor functions with a prototype property!/ |

***** ~class~ Notation
  Rather than declaring a constructor, /then/ attaching properties to its prototype,
  we may perform both steps together using ~class~ notation shorthand.

  {{{code(Classes as Syntactic Convenience)}}}
  #+BEGIN_SRC js
class Person {
  static #world = 0
  constructor(name, job = `farmer`) {
    this.name = name;
    this.job  = job;
    Person.#world++;
  }
  speak() {
    console.log(`I am ${this.name}, a ${this.job}, in a world of `
               + `${Person.#world} people.`)
  }
}

// Example use

let jasim = new Person(`jasim`)
jasim.speak()
// ‚áí I am jasim, a farmer, in a world of 1 people.

new Person(`kathy`).speak()
// ‚áí I am kathy, a farmer, in a world of 2 people.
  #+END_SRC

  :Hide:
  #+BEGIN_SRC js
// ‚Äúclass‚Äù is just a shorthand
console.log( Object.getPrototypeOf(Person) == Function.prototype
           , Person instanceof Function
           , jasim  instanceof Person
           , Object.getPrototypeOf(jasim) == Person.prototype)
  #+END_SRC
  :End:

  Notice that there is a special function named ~constructor~ which is
  bound to the class name, ~Person~, outside the class. The remainder of the
  class declarations are bound to the constructor's prototype.
  Thus, the earlier class declaration is equivalent to the constructor
  definition from the previous section. It just looks nicer.
  - Actually, this is even better: The ~static #world = 0~ declaration makes the
    property ~world~ /private/, completely inaccessible from the outside the
    class. The ~static~ keyword attaches the name not to particular instances
    (~this~) but rather to the constructor/class name (~Person~).
  - Indeed, in the previous examples we could have accidentally messed-up our world count.
    Now, we get an error if we write ~Person.#world~ outside of the class.

**** Conclusion

   Historically, physicists believed that matter was built from indivisible
   building blocks called /atoms/, then some hundred years later it was discovered
   that atoms are in-fact not atomic but are built from /neutrons, protons/, and
   /electrons/, then some fifty years later it was discovered that neutrons and
   protons are built from so called /quarks/. Similarly, albeit ironically, early
   versions of JavaScript were considered incomplete from an object-oriented
   perspective since they did not have a primitive, atomic, ~class~ construct.
   Akin to physicists, we have seen how JavaScript indeed has classes and is
   thus a full-fledged object-oriented language, only unlike other languages,
   they are not a primitive but a derived construct.

   Unsurprisingly, other features of object-oriented programming can also be
   derived ---and possibly more flexibly than their counterparts in languages
   that take them as primitive. For example, it can be useful to know whether an
   object ùîÅ was derived from a specific class ùìé and so there is the
   abbreviation: {{{newline}}} ~ùìç instanceof ùìé ‚âà Object.getPrototypeOf(ùìç) == ùìé.prototype~.
   Inheritance is then an abbreviation for using the previously discussed
   ~Object.create(parentPrototype)~ method. Finally, It can be pragmatic to have a
   few technical methods show up in all objects, such as ~toString~, which
   converts an object to a string representation. To accomplish this,
   JavaScript's /standard library/ objects have ~Object.prototype~ as their great
   ancestral prototype. In languages were classes are primitive, ~Object~ is the
   top of the class hierarchy.
   {{{code(Maximal Elements in the Class Hierarchy)}}}
   #+BEGIN_SRC js
// ‚ÄúObject‚Äù is maximal
console.log(Object.getPrototypeOf(Object.prototype)); // ‚áí null

// Empty object that *does* derive from ‚ÄúObject‚Äù
let basic = {}
console.log( basic instanceof Object // ‚áí true
           , "toString" in basic)    // ‚áí true

// Empty object that does not derive from ‚ÄúObject‚Äù
let maximal = Object.create(null);
console.log( maximal instanceof Object // ‚áí false
           , "toString" in maximal)    // ‚áí false
 #+END_SRC
 However, since JavaScript's classes are a derived concept, ~Object~ is not the
 /maximum/ class but rather a /maximal/ class: It has no parent class, but is not
 necessarily the parent of all other classes. Indeed, a declaration ~let basic =
 {}~, by default, creates an empty object whose parent is ~Object~ ---so as to have
 the aforementioned useful technical methods. If you pass ~null~ to ~Object.create~,
 as shown above, the resulting object will not derive from ~Object~. This is
 exhilarating.

  So objects do more than just hold their own properties. They have prototypes,
  which are other objects. They‚Äôll act as if they have properties they don‚Äôt have
  as long as their prototype has that property.
** ‚ü®ùëµùë∂‚ü© more TODOs

+ Perhaps explain why we care about DTLs?

#+begin_rule org
:multiple-rules: yes

+ Base Type :: œÑ : Type
  - œÑ ‚àà ùíÆ

+ Type-in-Type :: Type : Type
#+end_rule

?? Why are we interests in such a dependency ??  We
solve it by generalising ‚Üí to Œ† and √ó to Œ£.  ---note that sums are derivable
from Œ£ and the Booleans, or any two-valued type: ~Œ± + Œ≤ := Œ£ t : ùîπ ‚Ä¢ if t then ùüô
√ó Œ± else Œ≤ √ó ùüô~ where the ùüô values serve to tag the elements of ~Œ± + Œ≤~ so that any
element can be traced back to /either/ Œ± or Œ≤, but not both.

Now that we have formal underpinnings for opaque elements,
we turn to permitting definitions alongside typing declarations
then to semantics.

** ‚ü®ùëµùë∂‚ü© Diagrams
The concepts related to this thesis include:
#+begin_center latex
\smartdiagram[bubble diagram]{this thesis,
dependent-types, first-class citizens, pragmatic syntax, metaprogramming,
unbundling problem, module combinators}
#+end_center

For PackageFormer, this was the general plan:
#+begin_center latex
\tikzset{my decoration/.style={decorate,decoration=zigzag}}
\smartdiagramset{module shape=rectangle,
insert decoration={my decoration},
uniform arrow color=true,
arrow color=gray!50!black,
}

\smartdiagram[priority descriptive diagram]{
  Find real-world examples of manual package manipulation
 ,Identify and implement the underlying syntactic transformations
 ,Factor-out similarities from the implementations
 ,Fine-tune the essence of a package
 }
#+end_center

** ‚ü®ùëµùë∂‚ü© [OLD] Introduction
  :PROPERTIES:
  :CUSTOM_ID: Introduction-new
  :END:

*** Intro                                                          :ignore:
   :PROPERTIES:
   :CUSTOM_ID: Intro-new
   :END:

The composition of heterogeneous components, consisting of various types and
values, leads to large-scale, maintainable, software systems.  The components
are often of a domain-specific nature, packed-up using a module system that
exists only in the periphery.  The computations therein may themselves involve
‚Äòfirst-class modules‚Äô, for which there usually is only a limited,
non-extensible, number of operators that can be applied ---with =new, open,
import, using= being the common suspects.  The rising popularity of functional
programming and dependently-typed languages has contributed to the
‚Äòinternalisation‚Äô of what were once considered ‚Äòsecond-class‚Äô citizens in a
language.  For example, method blocks becomes functional values, and types
become values inhabiting larger types. Consequently, this has prompted a search
for a minimal number of primitives that provide a rich and expressive language
that not only accounts for inter-language operations but also intra-language
concepts, such as first-class modules.  Therefore, an effort needs to be made in
order to design and implement systems which cut-away unnecessary clutter and
provide a core kernel that is powerful enough to support existing pragmatic use
cases.  In particular, /the goal is to use a/ /dependently-typed language to
implement the ‚Äòmissing‚Äô module system features directly inside the language./

# inter ‚âà intermediate, between, among
# intra ‚âà on the inside, within

This chapter introduces the context and problem domain of this thesis and
motivates the need for a framework for a first-class treatment of modules in
dependently typed languages. More precisely, Section ref:sec:DTLs_overview gives
an overview of dependently-typed languages and Section ref:sec:DTLs_burdens
discusses the burdens of moving to expressive type systems.  Section
ref:sec:many_tongues provides a shallow motivation for the internalising of modules
as a natural progression of dependently-typed languages.  Section
ref:sec:module_interdefinability demonstrates the interdefinability of three
prominent structuring mechanisms with the context of a dependently-typed
language, thereby outlining the specific context of this thesis.  Section
ref:sec:research_problem_statement states the proposed research problem, outlines
the objectives of this thesis, and discusses the highlights of the approach
taken to achieve each objective.  Section ref:sec:contributions summarises the
contributions of this thesis to the enhanced understanding of modular module
systems within dependently-typed languages. Section ref:sec:publications notes
the publications related to the work presented in this thesis. Finally, Section
ref:sec:thesis_structure outlines the structure of the remainder of this thesis.

*** COMMENT What setting are we targeting, why?                    :ignore:
   :PROPERTIES:
   :CUSTOM_ID: COMMENT-What-setting-are-we-targeting-why
   :END:

Programming language communities whose language has a powerful type system, such
as Haskell's, have proverbs such as ‚Äúif it typechecks, ship it!‚Äù Such phrases
are mostly in praise of the language's impressive type system. However, the
motto is not flawless; e.g., consider citet:DBLP:conf/afp/McBride04 the Haskell
term src_haskell[:exports code]{if null xs then tail xs else xs} ---it
typechecks, but crashes at run time since empty lists have no (strictly smaller)
tail. Dependently typed languages (DTLs) provide a static means of expressing
the significance of particular values in legitimising some computations rather
than others.

Dependent-types provide an immense level of expressivity thereby allowing
varying degrees of precision to be embedded, or omitted, from the type of a
declaration. This overwhelming degree of freedom comes at the cost of common
albeit non-orthogonal styles of coding and compilation, which remain as open
problems that are only mitigated by awkward workarounds such as Coq's
distinction of types and propositions for compilation efficiency. The
difficulties presented by DTLs are outweighed by the opportunities they provide
citet:dtl_why ---of central importance is that they blur distinctions between
usual programming constructs citet:dtls_give_modules, which is in alignment with
our thesis.

#+begin_quote
The /purpose/ of this section is to establish the necessary foundational aspects
of dependently-typed languages (DTLs) by reviewing the existing DTLs and
narrowing on Agda in particular.
#+end_quote

# Finally, we close with a look at actively
# developed dependently-typed programming languages.
# #
Rather than dictatorially declare that Agda is the ideal setting for our
research, we shall consider the possible candidates ---only after arguing that
dependently-typed languages provide power, and complexity, for our tasks. Having
decided to use Agda, we provide a quick tutorial on the language and on
dependent types. Finally, we conclude with demonstrating our observation of ‚Äúall
packaging mechanisms are essentially the same‚Äù formally through Agda examples by
simulating different grouping constructs in the language.

*** Overview of Dependently-Typed Languages (DTLs)
  :PROPERTIES:
  :CUSTOM_ID: Overview-of-Dependently-Typed-Languages-DTLs
  :END:
<<sec:DTLs_overview>>

Software systems typically consist of numerous components whose constituent data
may be parameterised or accessed without qualifiers or have a corresponding
descriptive syntax type for serialisation and metaprogramming. Ensuring that the
diverse variations on a component of grouped data ---parameterised, namespace,
description--- remain in sync is a challenging task. Generally speaking, this
thesis explores the area of library development and focuses on two issues: /Write
once, generate many/ approach to modules, and /a practical interface for module
users/ to ‚Äòhoist up‚Äô module constituents as opaque parameters which can then be
fixed ‚Äòonce and for all‚Äô to provide a new product type.

# Why DTLs?
<<sec:what_is_DTL_informal>>
#+latex: \label{sec:what_is_DTL_informal}
#+latex: \label{sec:what_is_DTL_informal}

:Hide:
In this section, we argue that dependently-typed languages constitute a poorly
understood domain in comparison to their more popular counterparts, such as the
functional language Haskell and the imperative language JavaScript. To keep the
discussion self-contained, we first provide a quick, informal, overview of the
power allotted by dependent types ---a more formal introduction, backed by
typechecked code, is presented later in section ref:sec:what_is_DTL.
:End:

:OldIntro:
Is there any actual /need/ for the proposed research?
Are the goals easily adaptable from the simply-typed settings?
Is the declared arena of dependently-typed languages
sufficiently intricate to warrant this much attention?

In this section, we shall outline that DTLs constitute a difficult
and poorly understood domain in comparison to conventional programming
languages, such as the purely functional Haskell or the imperative Java.
Then we outline the merits of including dependent types.
Finally, we close with a comparison of some of the most popular DTLs.
:End:

# The New World, afforded by DTLs
**** Introduction                                                 :ignore:
    :PROPERTIES:
    :CUSTOM_ID: Introduction
    :END:

# We have thus far discussed the burdens of programming with dependent
# types ---perhaps so much so, that it seems like they should be avoided
# altogether. Our aim was to demonstrate that DTLs present a new and difficult
# domain, but we shall now briefly discuss their merits and the opportunities they
# provide \cite{dtl_why} ---of central importance is that they blur distinctions between
# usual programming constructs, which is in alignment with our thesis.
# #
# In particular certain function
# arguments only serve to ensure that all client calls are coherent
# in some fashion, but otherwise are not part of the resulting
# computation.
# #


Dependent-types allow us to encode properties of data /within the structure/ of
the data itself, and so all the data we consider is necessarily ‚Äòwell-formed‚Äô.
In contrast, without dependent types, one would (1) declare a data structure,
/then/ (2) define the subclass of such data that is ‚Äòwell-formed‚Äô in some sense;
/then/, (3) to work with this data, one provides an interface that only produces
well-formed data, a so-called ‚Äòsmart constructor‚Äô, /finally/, one needs to test
that their smart constructor actually only forms well-defined data elements. For
instance, raw untyped Œª-terms are not all sensible, and so one introduces types
to organise them into sensible classes, then introduces inference rules that
ensure only sensible terms are constructed.
#+begin_quote
DTLs flatten the conventional four-stage process of declaring raw data,
selecting a coherent subclass, providing a smart constructor, and proving the
constructor is valid.
#+end_quote

#+latex: \noindent
We shall explain this idea more concretely via two examples, below
in Sections ref:sec:DTL:sanitising_raw_data, ref:sec:DTL:correct_by_construction. The Agda
fragments presented will be explained in the accompanying text ---an
introduction to Agda is given in Appendix ref:sec:what_is_DTL. Afterword, we conclude by
briefly mentioning theoretical concerns when working with DTLs and, more
importantly for topic on modularisation, issues of a more practical nature
involving library development.
 #
 # For more on the motivation of DTs, take a look at
 # http://www.cis.upenn.edu/~sweirich/papers/eisenberg-thesis.pdf
 #
 # I might have this in my references?

#+caption: Why we are interested in DTLs?
|-----------------+-----------------------------------------------------------------------|
| Types           | Machine check-able ‚Äòcomments‚Äô; coherent expressions                   |
|-----------------+-----------------------------------------------------------------------|
| Polymorphism    | Uniform definitions; avoiding repetition                              |
|-----------------+-----------------------------------------------------------------------|
| Dependent types | Uniform treatment of values and types, section ref:sec:DTL:uniformity |
|                 | and increased expressivity of ‚Äòcomments‚Äô                              |
|-----------------+-----------------------------------------------------------------------|

# , section ref:sec:curry_howard |

 The above table tersely summarises our desire for powerful type systems. In
 particular, type polymorphism permits us to produce functions written once with
 type variables and have them applied to radically different types. Likewise, it
 would be desirable to write once a generic function on a kind of package and
 have it operate on the many variations of packaging. An example of this idea is
 presented in Section ref:sec:PF_scrap_repetition.
 # Moreover, we demonstrate a
 # novel form of generic programming, /package polymorphism/: A method is written
 # against a generic notion of container and is then applied to derived notions
# ---such as the =Semigroup·µ¢= forms from the previous section, see Section ref:sec:PF:extracting_little_theories.

**** Uniformity
    :PROPERTIES:
    :CUSTOM_ID: Uniformity
    :END:

<<sec:DTL:uniformity>>
#+latex: \label{sec:DTL:uniformity}
#+latex: \label{sec:DTL:uniformity}

 A type alias and a value alias are merely aliases at the end of the day, so
 unlike Haskell, for example, which distinguishes the two, Agda, for example,
 does not. More generally, type families, simple types, type constructors,
 dependent types, etc, collapse into a single category: Dependent types.

 In particular, recall the canonical definition of ‚Äòterm‚Äô:
 {{{code(Grammar for Terms)}}}
 #+begin_src haskell
term ::=  x                   {- variable             -}
      |   f(term‚ÇÄ, ‚Ä¶, term‚Çô) {- function application -}
 #+end_src

 In pedestrian languages, one distinguishes between /value/ terms and /type/ terms,
 whence the ~term·µ¢~ are constrained to be homogeneously all values or all types.
 In contrast, a dependently-typed languages makes no such limitation, thereby
 allowing the ~term·µ¢~ to be heterogeneous. For example, in a simple type system,
 ~Maybe (A √ó List B)~ is a term where all variables, ~term‚ÇÄ, term‚ÇÅ = A, B~, are of
 the same kind ---types. This is not so with the term[fn:16]  ~Maybe (A √ó Vec B n)~ ---~A~
 and ~B~ are types while ~n~ is a number. This is the essence of DTLs, and a primary
 reason we want to use them.
# #
# Our aim is not to educate the reader on the power and utility of dependent types;
# we invite the reader to consult any of the existing material citet:dtl_why,agda_overview.
# #
 # This is akin to forming English sentences using only noun phrases,
 # as in ‚ÄúI thanked the man‚Äù, or sentences where the clauses may be of different
 # kinds, as in ‚ÄúI thanked the man who directed me‚Äù which contains noun and adjective
 # clauses.
 # #
 # WK: ‚Äúthanked the man‚Äù is a verb phrase.
 # #
 # ‚ÄúThe man knows much.‚Äù
 # vs. ‚ÄúThe man who introduced me to Emacs knows much.‚Äù
 # #
 # since terms/values and types are in the same syntactic category, all these
 # things really are the same.

 In the same vein, the varying notions of packaging are treated differently
 even though they are isomorphic in certain scenarios or interdefinable in others.
 As such, it would be useful to reduce the syntactic distinction between them.

**** Example 1: Sanitising raw data
    :PROPERTIES:
    :CUSTOM_ID: Example-1-Sanitising-raw-data
    :END:
<<sec:DTL:sanitising_raw_data>>
#+latex: \label{sec:DTL:sanitising_raw_data}
#+latex: \label{sec:DTL:sanitising_raw_data}

 When interacting with users, a system receives raw data then ‚Äòsanitises‚Äô it, or
 ensures it is ‚Äòsanitised‚Äô. For instance, to subscribe to a mailing list, a user
 provides a string of symbols which the program then ensures is a
 well-formatted email address. Below is a possible implementation of the email
 address portion within Haskell ---the comments are a designer's thought process
 as /allowed/ by the coding language.

{{{code(Traditional Four Stages to Structuring Data)}}}
#+BEGIN_SRC haskell :tangle email.hs
{- (1) An email address is just a raw string -}
data Email = MkEmail String  deriving Show

{- (2) Actually, it has some structure -}
isValid :: Email -> Bool
isValid (MkEmail s) = let pre_rest = splitOn "@" s
                      in length pre_rest == 2
                      && length (splitOn ".com" (pre_rest !! 1)) == 1

{- (3) Given two strings, we can form an email address -}
mkEmail :: String -> String -> Email
mkEmail pre post = MkEmail (pre ++ "@" ++ post ".com")

{- (4) Also, mkEmail is a smart constructor for Email -}
{- ‚àÄ pre post ‚Ä¢ isValid (mkEmail pre post)        -}
 #+END_SRC

 With dependent types, we can /encode/ structural[fn:1] properties: We can declare
 a type of strings necessarily of the form ~‚ü®string‚ü©@‚ü®string‚ü©.com~, thereby
 dispensing with any sanitation phase. In particular, in this style, a parser is
 essentially a type-checker. Moreover such checks happen at compile time since
 these are just like any other type.

 {{{code(Parsing ‚âà Typechecking)}}}
 #+BEGIN_SRC agda
data Email : String ‚Üí Set where
  MkEmail : (pre post : String) ‚Üí Email (pre ++ "@" ++ post ++ ".com")
 #+END_SRC

 The above declaration defines a new type ~Email s~ with values ~MkEmail pre post~
 /precisely when/ ~s ‚âà pre ++ "@" ++ post ++ ".com"~. Hence, any value of =Email s= is, by
 its very construction, a pair of strings, say, =pre= and =post= that compose to
 give the original address =s=. The above four steps in Haskell have been reduced
 to a single declaration in Agda.

 What happened exactly? Where are the dependent-types? Let ~X~ denote the type of
 strings, ~Y~ the type of pairs of strings, ~P~ the property ‚Äú$x$ is composed of the
 pair $y$‚Äù, and the lower-case ~p~ is the proviso in the Haskell code above. Let ~ùí¥~
 absorp the proviso property ~p~ ---in the Agda code, this amounts to ‚Äúbuilding ~p~
 into the type‚Äù--- so that ~y¬†‚àà¬†ùí¥(x)¬†‚â°¬†p(x,¬†y)~.  The type =ùí¥= is a dependent type:
 It is a type that /depends/ on a term; namely, ~x~.  Then the transition from
 specification, to Haskell implementation, to Agda code can be summarised in the
 following chain of equalities.

 #+caption: Dependent types ‚Äòabsorp‚Äô preconditions
 |   | /Every email address decomposes into a pair of strings/ |
 | ‚âà | =‚àÄ x ‚à∂ X ‚Ä¢ ‚àÉ y ‚à∂ Y ‚Ä¢ p(x, y) ‚àß P(x, y)=                  |
 | ‚âà | =‚àÄ x ‚à∂ X ‚Ä¢ ‚àÉ y ‚à∂ ùí¥(x) ‚Ä¢ P(x, y)=                        |

 # The precondition to ~P~ has been incorporated into the type ùí¥.

 # This can be done in FOL, namel in Z.

 When claims only hold under certain expected premises, it would be easier to
 reason and state the claims if such preconditions were incorporated into the
 types. This is common practice in mathematics ---e.g., ‚Äúthe maximum operation
 over real numbers has a least element when /only considering/ non-negative whole
 numbers‚Äù versus ‚Äúthe maximum operation /on naturals/ has a least element‚Äù; i.e.,
 mathematicians /declare a new set/ \\ $‚Ñï¬†=¬†\{r¬†‚à∂¬†‚Ñù¬†‚ùô¬†r¬†‚â•¬†0¬†‚àß¬†‚åàr‚åâ¬†=¬†r\}$. However, in
 conventional programming, there is no way to /form such a new type/ denoting ‚Äúthe
 values of type $A$ that satisfy property $B$‚Äù; unless you have access to
 dependent types, which call this type ~Œ£ a ‚à∂ A ‚Ä¢ B(a)~.

**** Example 2: Correct-by-Construction Programming
    :PROPERTIES:
    :CUSTOM_ID: Example-2-Correct-by-Construction-Programming
    :END:

<<sec:DTL:correct_by_construction>>
#+latex: \label{sec:DTL:correct_by_construction}
#+latex: \label{sec:DTL:correct_by_construction}

 Program verification is an `after the fact' activity, like documentation; yet
 when a project behaves as desired, programmers seldom willingly go back to clean
 up and instead prefer a new project. This dissociation of concerns is remedied
 by enabling program verification to proceed side-by-side with development
 citet:sop,sop_cohen,ewd_discipline: Each proof of a program property acts as
 exhaustive test cases for that property.

 #+begin_center
 /With a careful specification of the type, there is only one[fn:15] program!/
 #+end_center

 #+latex: \noindent
 For example, suppose we want an implementation of a function $f$ specified by
 the property ~f 0 = 1 ‚àß f (n + 1) = n √ó f n~, for any =n=. The first conjunct
 completely determines ~f~ on input ~0~, however an inattentive implementer may
 decide to define \\ ~f n := f (n + 1) / n.~ The resulting ‚Äòdefinition‚Äô clearly
 satisfies the specification, but it does not terminate on any positive input
 since it recursively calls itself on ever increasing arguments.

 In comparison, since Agda requires all its functions to be terminating,
 after insisting the specification obligations hold by definition, ~refl~,
 we turn to defining ~f~ by pattern matching and its implementation from
 there is fully forced: There are no more choices in implementation.
 Then, Agda's Emacs ‚Äòproof finder‚Äô Agsy automates the definition of ~f~:
 There is only one road to defining ~f~ so that the constraints hold by
 ‚Äòrefl‚Äôexivity ---i.e., by definition.

{{{code(Correct-by-Construction Programming)}}}
 #+BEGIN_SRC agda
factorial :  Œ£ f ‚à∂ (‚Ñï ‚Üí ‚Ñï) ‚Ä¢  f 0 ‚â° 1 √ó (‚àÄ {n} ‚Üí  f (1 + n)  ‚â°  n * f n)
factorial = f , refl , refl
  where f : ‚Ñï ‚Üí ‚Ñï
        f zero    = 1
        f (suc n) = n * f n
 #+END_SRC
 # LaTeX: \centerline{\emph{Agda Code for Factorial Function}}

 By utilising dependent types, run time errors ---failures occurring during
 program execution, such as non-emptiness or well-formedness conditions--- are
 transported to compile time, which are errors caught during typechecking. This
 is in itself a tremendously amazing feature.

 #+latex: \vspace{-2em}
 | /Dependent types enable all errors, including logical errors, to become type checking errors!/ |

 #+latex: \vspace{-1em} \noindent
 Regarding the middle clause, /including logical errors/, suppose we are
 interested in a utility function whose inputs must be even numbers, or rather
 any computable precondition ~p~. In simpler type systems, such as JavaScript's,
 we could throw an exception if the input does not satisfy it or simply return a
 =null=, which then needs to be handled at the call site by using conditionals
 or try-catch blocks. Instead of all of this explicit plumbing, DTLs allow us to
 define types and let the compiler handle the grunt work. That is, in a DTL we
 could encode the precondition directly into the function's type.

**** COMMENT The Curry-Howard Correspondence ---‚ÄúPropositions as Types‚Äù
    :PROPERTIES:
    :CUSTOM_ID: The-Curry-Howard-Correspondence-Propositions-as-Types
    :END:

     <<sec:curry_howard>>
#+latex: \label{sec:curry_howard}
#+latex: \label{sec:curry_howard}

     Types provide machine check-able comments of a simple type; whereas DTLs
     extend the language of these comments to serve as arbitrary specifications.
     The [[gls:curry-howard][Curry-Howard Correspondence]] makes a dependently-typed programming
     language also a proof assistant: A proposition is proved by writing a
     program of the corresponding type.

     #+macro: twolines @@latex:\begin{tabular}[l]{@{}l@{}}$1\\$2\end{tabular}@@
     #+macro: hfill @@latex:\hfill@@

     # +latex: \vspace{-1em}
     #+caption: Programming and proving are two sides of the same coin
     | *Logic*                  | *Programming*                           | Example Use in Programming                                                  |
     |------------------------+---------------------------------------+-----------------------------------------------------------------------------|
     | proof / proposition    | element / type                        | ‚Äú$p$ is a proof of $P$‚Äù ‚âà ‚Äú$p$ is of type $P$‚Äù                              |
     |------------------------+---------------------------------------+-----------------------------------------------------------------------------|
     | $true$                 | singleton type                        | return type of side-effect only methods                                     |
     | $false$                | empty type                            | return type for non-terminating methods                                     |
     |------------------------+---------------------------------------+-----------------------------------------------------------------------------|
     | ‚áí                      | function type  {{{hfill}}}   ‚Üí        | methods with an input and output type                                       |
     | ‚àß                      | product type   {{{hfill}}}  √ó         | simple records of data and methods                                          |
     | ‚à®                      | sum type       {{{hfill}}} +          | enumerations or tagged unions                                               |
     |------------------------+---------------------------------------+-----------------------------------------------------------------------------|
     | ‚àÄ                      | dependent function type {{{hfill}}} Œ† | return type varies according to input /value/                           |
     | ‚àÉ                      | dependent product type {{{hfill}}}  Œ£ | record fields depend on each other's /values/                               |
     |------------------------+---------------------------------------+-----------------------------------------------------------------------------|
     | natural deduction      | type system                           | ensuring only ‚Äúmeaningful‚Äù programs                                         |
     | hypothesis             | free variable                         | global variables, closures                                                  |
     |------------------------+---------------------------------------+-----------------------------------------------------------------------------|
     | modus ponens           | function application                  | executing methods on arguments                                              |
     | ‚áí-introduction         | Œª-abstraction                         | {{{twolines(parameters acting as local variables, to method definitions)}}} |
     |------------------------+---------------------------------------+-----------------------------------------------------------------------------|
     | {{{twolines(induction;, elimination rules)}}} | Structural recursion                  | ~for~-loops are precisely ‚Ñï-induction |

     Let's augment the table a bit to relate concepts that we shall refer to in
     later sections.
     #+caption: Programming and proving are two sides of the same coin ---Extended
     | *Logic*                   | *Programming*                                 |
     | Signature, term         | Syntax; interface, record type, ~class~       |
     | Algebra, Interpretation | Semantics; implementation, instance, object |
     | Free Theory             | Data structure                              |
     | Inference rule          | Algebraic datatype constructor              |
     | Monoid                  | Untyped programming / composition           |
     | Category                | Typed programming / composition             |
**** The Syntax of DTLs

 Let us conclude with the minimalist's syntax[fn:13] for dependently-typed
 languages.

{{{code(DTL Syntax)}}}
#+attr_latex: :options xleftmargin=6pt
 #+begin_src haskell +n 0
-- Terms: Expressions and Types
e, œÑ ::= Œ±          -- base type and constants
    | Type·µ¢         -- ‚Äútype of types‚Äù; Universe of types at level i : ‚Ñï
    | ‚Ñï             -- ‚ÄúLevels‚Äù for the type hierarchy
    | Œ† x : œÑ ‚Ä¢ œÑ   -- ‚ÄòPi‚Äô, dependent-function type
    | Œ£ x : œÑ ‚Ä¢ œÑ   -- ‚ÄòSigma‚Äô, dependent-sum type
    | x             -- Variable
    | e e           -- Application; Œ†-elimination
    | Œª x : œÑ ‚Ä¢ e   -- Abstraction; Œ†-introduction
    | (e , e)       -- Pairing; Œ£-introduction
    | fst e | snd e -- Projections; Œ£-elimination
    | Fix ùë≠         -- Fixpoints for ùë≠ : Type·µ¢ ‚Üí Type·µ¢

-- Abbreviation: Provided Œ≤ does not refer to variable ‚Äò_‚Äô,
(Œ± ‚Üí Œ≤) :=  (Œ† _ : Œ± ‚Ä¢ Œ≤)
 #+end_src

 The Simply Typed (non-polymorphic) Œª-Calculus is obtained by splitting the sole
 term syntactic category into two categories, the ‚Äòtypes‚Äô being the first two
 clauses, and the ‚Äòexpressions‚Äô being clauses 6-8, with all other clauses dropped
 and taking ‚Äò‚Üí‚Äô as a primitive type constructor. If only ~Type‚ÇÄ~ and Œ† are then
 admitted with the proviso that its bound variable ~x~ ranges only over types
 ---values of ~Type‚ÇÄ~--- then we obtain the Polymorphic Œª-Calculus. Notice how the
 elusive notion of polymorphism is captured explicitly as ‚Äòtype abstraction‚Äô in a
 DTL ---with the ‚Äòvarying type argument‚Äô becoming a legitimate and necessary
 argument that must be provided in function calls.  For families of types[fn:14],
 such as =Vec œÑ n= consisting of those lists of œÑ elements of length =n=, we must not
 only abstract over /types/ œÑ but also over /values/ =n=; hence, the /dependent function
 space/ constructor Œ† generalises the usual function space ‚Äò‚Üí‚Äô. Indeed, ~Vec~ is
 only typeable in the presence of dependent-types. With intricate type class
 masochism citet:DBLP:conf/haskell/LindleyM13, under the constraint that types are
 /not/ terms, one is forced to duplicate term-level definitions at the type-level
 and thereby mimic dependent-types; albeit in a difficult fashion.

 Traditionally, types constrain terms but by allowing terms to occur in types
 we now have /terms constraining types/; hence, there is no real distinction
 between the two. *Everything is a term!*
 In the phrase ~e ‚à∂ œÑ~ there is no syntactic constraint forcing ~e~ to be a non-type term;
 the symbol ‚Äò‚à∂‚Äô thus relates two terms. However, it is conventional to use
 the word /type/ to refer to terms ~œÑ~ with ~œÑ ‚à∂ Type·µ¢~ for some level $i ‚à∂ ‚Ñï$,
 and one calls ~Type·µ¢~ a /kind/ or a /universe of (types of) level i/.

 Below are the typing rules. Notice that there is only one family of rules;
 whereas the simply typed Œª-calculus with its two syntactic categories, for
 expressions and terms, must have a set of rules for well-formed types then a set
 of rules for how to type values. Since everything is a term in a DTL, there is
 only one set of rules.
{{{code(DTL Typing Rules)}}}
 #+begin_src haskell
-- Typing Rules: ‚ÄúŒì ‚ä¢ e : œÑ‚Äù indicates term e is of type œÑ in (valid) context Œì
-- The context Œì documents the types of the variables that may appear in e and œÑ
Œì ::= Œµ | Œì, x : œÑ  {- Empty context; adding an identifier -}

-- Well formed contexts
(0) Valid Œµ
(1) Valid (Œì, x : œÑ)  ‚áê  Valid Œì  ‚àß  Œì ‚ä¢ œÑ : Type·µ¢  for some i : ‚Ñï

-- Typing Rules
Œì ‚ä¢ x : œÑ  ‚áê  Œì(x) = œÑ  {- Œì(x) is the information assocaited with name x in Œì -}
Œì ‚ä¢ Œ± : Type‚ÇÄ {- For brevity, base types are all ‚Äúsmall types‚Äù -}
Œì ‚ä¢ (Œ† x : œÑ ‚Ä¢ œÑ') : Type‚Çñ  ‚áê  Œì ‚ä¢ œÑ : Type·µ¢
                            ‚àß  Œì, x : œÑ ‚ä¢ œÑ' : Type‚±º for some i,j : ‚Ñï
                            ‚àß  k = max{i, j}
Œì ‚ä¢ Type·µ¢ : Type·µ¢‚Çä‚ÇÅ  for all i : ‚Ñï
Œì ‚ä¢ (Œª x : œÑ ‚Ä¢ e) : (Œ† x : œÑ ‚Ä¢ œÑ')  ‚áê  Œì, x : œÑ ‚ä¢ e : œÑ'
Œì ‚ä¢ e e' : œÑ[x ‚âî e']  ‚áê  Œì ‚ä¢ e : (Œ† x : œÑ ‚Ä¢ œÑ')  ‚àß  Œì ‚ä¢ e' : œÑ

Œì ‚ä¢ Fix ùë≠ : Type·µ¢  ‚áê  Œì ‚ä¢ ùë≠ : Type·µ¢ ‚Üí Type·µ¢
 #+end_src

 It is important to note that some type formers do not have fixed points such as
 ~ùë≠ X = X~. This does not matter, all we request is that /some/ type is assigned to
 such type formers; it may not necessarily be a least fixed point but possibly,
 say, an empty type.

 Note that Œ£ is included for convenience, since it could have been introduced as an
 abbreviation for its Church encoding; i.e., its elimination rule.  That is
{{{code(Œ£-contexts from Œ†-contexts)}}}
 #+BEGIN_SRC haskell
(Œ£ x ‚à∂ œÑ ‚Ä¢ œÑ') ‚âÖ  Œ† œÅ ‚à∂ (Œ† x ‚à∂ œÑ ‚Ä¢ Œ† w ‚à∂ œÑ' ‚Ä¢ Type·µ¢) ‚Ä¢ Œ† x ‚à∂ œÑ ‚Ä¢ Œ† w ‚à∂ œÑ' ‚Ä¢ œÅ x w
fst            ‚âÖ  Œ† e ‚à∂ (Œ£ x ‚à∂ œÑ ‚Ä¢ œÑ') ‚Ä¢ e (Œª x ‚à∂ œÑ ‚Ä¢ Œª w ‚à∂ œÑ' ‚Ä¢ x)
snd            ‚âÖ  Œ† e ‚à∂ (Œ£ x ‚à∂ œÑ ‚Ä¢ œÑ') ‚Ä¢ e (Œª x ‚à∂ œÑ ‚Ä¢ Œª w ‚à∂ œÑ' ‚Ä¢ w)
 #+END_SRC

 /This/ is already illuminating for our thesis: *The record structuring mechanism Œ£
 can be captured using the function mechanism Œ†.*

*** Burdens of DTLs: The Paralysing Paradox of Choice
  :PROPERTIES:
  :CUSTOM_ID: Burdens-of-DTLs-The-Paralysing-Paradox-of-Choice
  :END:
<<sec:DTLs_burdens>>
#+latex: \label{sec:DTLs_burdens}
#+latex: \label{sec:DTLs_burdens}

# The trials and tribulations of working with dependent types

 Since a /dependently-typed language/ is a typed language ---i.e., a formal
 syntactic grammar and associated type system--- where we can write /types/ that
 depend on /terms/; consequently types may require non-trivial term calculation in
 order to be determined citet:why_dependent_types_matter. A glaring drawback is
 that types now depend on term calculations thereby rendering type checking, and
 type inference, to be difficult if not impossible
 citet:undecidability_of_typing. E.g., ~Vec String (factorial 100)~ is the type of
 really long lists of strings ---the length will take some time to calculate.

:Comparision:
 #+BEGIN_EXPORT latex
 \begin{tcolorbox}[title=\hfill Comparision of Some Popular Languages]
 \[ \xrightarrow[\text{Programming Language \hspace{25em} Proof Assistant}]
 {\text{
                  Haskell
     \hspace{5em} Idris
     \hspace{5em} Agda
     \hspace{5em} Coq
 }}
 \]
 \end{tcolorbox}
 #+END_EXPORT
 :End:

Unsurprisingly, ‚Äúdoing‚Äù dependent typing ‚Äúright‚Äù is still an open issue
 citet:dtl_implementation_practical,dtl_implementation_simple,dtl_implementation_tutorial,dtl_implementation_idris,dtl_implementation_lectures_and_code,citet:DBLP:conf/haskell/LindleyM13.
 In particular, after more than 30 years after Martin-{{{lof}}}'s work on the
 type theory citet:lof_constructive_math,lof_itt, it is still unclear how such
 typing should be implemented so that the result is usable and well-founded. Of
 interest is Agda which claims to have achieved this desired ground but, in
 reality, it is seldom used as a programming language due to efficiency issues;
 in contrast, Idris aims at efficiency but its use as a proof assistant is
 somewhat lacking in comparison to Agda. Below are a few other issues that
 demonstrate the non-triviality of problems in dependently-typed languages.

 1. Should programs be total for the sake of consistency or can they be partially defined?

 2. Do we allow the ‚ÄúType in Type‚Äù axiom
     citet:russell_type_hierarchy,agda_type_in_type_contradiction,system_F_with_type_in_type,extended_cic?

 3. What about ‚ÄúAxiom K‚Äù expressing /almost/ the recursion scheme of identity types
    citet:uip_streicher,dependent_matching_is_just_K,matching_without_K,eliminating_dependent_matching,elimination_with_motive,uip_problem,uip_strength}?

 4. Should dependent pattern matching give us more information about a type?
    How does this interact with side effects?
    # citet:dtl_effectful

 5. Should unification be proof-relevant; i.e., to consider the /ways/ in which
    terms can be made equal citet:proof_relevant_unification?

 6. How do subtypes, which classically require proof irrelevance,
    tie into the paradigm?

 7. How does proof-term erasure work citet:dtl_practical_erasure,dtl_index_erasure,erasure_type_systems,proof_irrelevant_cic}?

 8. When are two values, or programs, or types equal: When they have the same type?

 9. Should a language permit non-termination or require explicit co-data?

 Besides technical concerns, there are also pressing practical concerns. Since
 dependent types blur the distinction between value and type ---thereby
 conflating many traditional programming concepts--- library design becomes
 pretty delicate.

 - For example, the method that extracts the first element of a list can in
   traditional languages be assigned usually two types ---one with an explicit
   exception decoration such as Haskell's ~Maybe~ or C#'s ~Nullable~, or without
   this and instead throwing an (implicit) exception. In addition, in a DTL, we
   can instead decorate the list with a positive length to avoid exceptions
   altogether, or request a non-emptiness proof, or output a dependent pair
   consisting of a proof that the input list is non-empty and, if so, an element
   of that list, or do we request as input a dependent pair consisting of a list
   and a non-emptiness proof ---note that this is a Œ£-type, in contrast to the
   curried form from earlier---, or ‚ãØ.

 - Moreover, when a function is written /which/ properties should be attached to
   the resulting type and which should be stated separately?

   For example, if we write an append function for lists, do we separately prove
   that the length of an append is the sum of the lengths of its arguments, or
   do we encode that information into the return type by means of a dependent
   pair?

 /Hence programming style becomes vastly more important in DTLs since simple
 functions can have a diverse set of typings./ In particular, this can lead to
 `duplication' of code: Dependently-typed and simply typed variants of the
 ‚Äòsame‚Äô concept, as well as the methods & proofs that operate on them; e.g.,
 ‚Ñï-indexed vectors vs.{{{null}}} lists,
 citet:ornaments_relationally,tt_in_colour,ornaments. So much for the DRY[fn:2]
 Principle. Since in a DTL records and modules are conflated, perhaps the
 structuring-mechanism combinators resulting from this research could reduce
 some of the ‚Äòduplication‚Äô.

 #    - Not many good ‚Äúdesign patterns‚Äù for DTLs! [CITATION]

 :Nick:
       #+LaTeX: \fbox{\LARGE Nick}

 + Check out redux
 + Check out LanguageEXT for C#
 + Maybe mention newtypes, for example String vs ValidationString ;-)
    - Often consider making such `typed' strings which are basically just a compiler level label.
       :End:

 #+LaTeX: \vspace{1ex}
 #+begin_center
 /We, as a community, are decidedly still learning about the role of dependent
 types in programming!/
 #+end_center

*** A Language Has Many Tongues
  :PROPERTIES:
  :CUSTOM_ID: A-Language-Has-Many-Tongues
  :END:
<<sec:many_tongues>>
#+latex: \label{sec:many_tongues}
#+latex: \label{sec:many_tongues}

A programming language is actually many languages working together.

The most basic of imperative languages comes with a notion of ‚Äòstatement‚Äô that
is executed by the computer to alter ‚Äòstate‚Äô and a notion of ‚Äòvalue‚Äô that can be
assigned to memory locations. Statements may be sequenced or looped, whereas
values may be added or multiplied, for example. In general, the operations on
one linguistic category cannot be applied to the other. Unfortunately, a rigid
separation between the two sub-languages means that binary choice, for example,
conventionally invites two notations with identical semantics ---e.g.; in ~C~ one
writes src_C[:exports code]{if (cond) clause‚ÇÅ else clause‚ÇÇ} for statements but
must use the notation =cond ? term‚ÇÅ : term‚ÇÇ= for values.
Hence, there are value and statement languages.

Let us continue using the ~C~ language for our examples since it is so ubiquitous
and has influenced many languages. Such a choice has the benefit of referring to
a concrete language, rather than speaking in vague generalities. Besides Agda
---our language of choice--- we shall also refer to Haskell as a representative
of the functional side of programming. For example, in Haskell there is no
distinction between values and statements ---the latter being a particular
instance of the former--- and so it uses the same notation src_haskell[:exports
code]{if ‚Ä¶ then ‚Ä¶ else ‚Ä¶ } for both. However, in practice, statements in Haskell are
more pragmatically used as a body of a src_haskell[:exports code]{do} block for
which the rules of conditionals and local variables change ---hence, Haskell is
not as uniform as it initially appears.

In ~C~, one declares an integer value by src_C[:exports code]{int x;} but a value
of a user-defined type ~T~ is declared src_C[:exports code]{struct T x;} since,
for simplicity, one may think of ~C~ having an array named src_C[:exports
code]{struct} that contains the definitions of user-defined types ~T~ and the
notation ~struct T~ acts as an array access. Since this is a clunky notation, we
can provide an alias using the declaration src_C[:exports code]{typedef
existing-name new-name;}. Unfortunately, the existing name must necessarily be a
type, such as src_C[:exports code]{struct T} or src_C[:exports code]{int}, and
cannot be an arbitrary term. One must use src_C[:exports code]{#define} to
produce term aliases, which are handled by the ~C~ preprocessor, which also
provides src_C[:exports code]{#include} to ‚Äòcopy-paste import‚Äô existing libraries. Hence, the
type language is distinct from the libraries language, which is part of the
preprocessor language.

In contrast, Haskell has a pragma language for enabling certain features of the
compiler. Unlike ~C~, it has an interface language using type-src_haskell[:exports
code]{class}-es which differs from its src_haskell[:exports code]{module}
language
citet:haskell_modules_formally,haskell_in_haskell,classic_haskell_genericity
since the former's names may be qualified by the names of the latter but not the
other way around. In turn,  type-src_haskell[:exports
code]{class} names may be used as constraints on types,
but not so with src_haskell[:exports code]{module} names. It may be argued that this interface language is
part of the type language, but it is sufficiently different that it could be
thought of as its own language citet:modular_modules ---for example, it comes
with keywords src_haskell[:exports code]{class, instance, =>} that can only
appear in special phrases. In addition, by default, variable declarations are
the same for built-in and user-defined types ---whereas ~C~ requires using
src_C[:exports code]{typedef} to mimic such behaviour. However, Haskell
distinguishes between term and type aliases. In contrast, Agda treats aliasing
as nothing more than a normal definition.

Certain application domains require high degrees of confidence in the
correctness of software. Such program verification settings may thus have an
additional specification language. For ~C~, perhaps the most popular is the ANSI C
Specification Language, ACSL citet:acsl. Besides the ~C~ types, ACSL
provides a type ~integer~ for specifications referring to unbounded integers as
well as numerous other notions and notations not part of the ~C~ language. Hence,
the specification language generally differs from the implementation language.
In contrast, Haskell's specifications are generally citet:programatica in
comments but its relative Agda allows specifications to occur at the type level.

# When working with ACSL, or JML, or SPARK
Whether programs actually meet their specifications ultimately requires a proof
language. For example, using the Frama-C tool citet:frama_c, ACSL
specifications can be supported by Isabelle or Coq proofs. In contrast, being
dependently-typed, Agda allows us to use the implementation language also as a
proof language ---/the only distinction is a shift in our perspective; the syntax
is the same./ Tools such as Idris and Coq come with ‚Äòtactics‚Äô ---algorithms which
one may invoke to produce proofs--- and may combine them using specific
operations that only act on tactics, whence yet another tongue.

Hence, even the simplest of programming languages contain the first three of the
following sub-languages ---types may be treated at runtime.

1. Expression language;
  #   (Expressions are syntax; values are semantics (most of the time...).)
2. Statement, or control flow, language;
3. Type language;
4. Specification language;
5. Proof language;
6. Module language;
7. Meta-programming languages ---including Coq tactics, C preprocessor, Haskell
   pragmas, Template Haskell's various quotation brackets ~[x| ... ]~, Idris
   directives, etc.

As briefly discussed, the first five languages telescope down into one uniform
language within the dependently-typed language Agda. So why not the module
language?

*** Related Publications
  :PROPERTIES:
  :CUSTOM_ID: 1-6j
  :END:
<<sec:publications>>
#+latex: \label{sec:publications}
#+latex: \label{sec:publications}

Below are works related to the research presented in this thesis.

+ Publication :: M. Al-hassy, J. Carette, and W. Kahl.
  A language feature to unbundle data at will (short paper).
  /The 18th International Conference on Generative Programming/,
  (Submitted 2019).
+ Conference :: M. Al-hassy, J. Carette, W. Kahl, and Y. Sharoda.
  Metaprogramming Agda. /The 19th IFIP Conference on Program Generation./
  # https://wiki.hh.se/wg211/index.php/WG211/M19Schedule
+ Draft :: M. Al-hassy, J. Carette, and W. Kahl.
  Functional Pearl: Do-it-yourself module types.
  (Rejected from /The 19th International Conference on Functional Programming/)
  # https://alhassy.github.io/next-700-module-systems/papers/icfp20_do_it_yourself_module_systems.pdf
+ Technical Report :: M. Al-hassy.  Making Modules with Meta-Programmed
  Meta-Primitives: Liberating Package Formation from the Backend.  Available:
  https://alhassy.github.io/next-700-module-systems/prototype/package-former

*** Structure of the Thesis
  :PROPERTIES:
  :CUSTOM_ID: 1-7j
  :END:
<<sec:thesis_structure>>
#+latex: \label{sec:thesis_structure}
#+latex: \label{sec:thesis_structure}

The remainder of this thesis is organised as follows.

+ Chapter 2 :: Survey existing DTL libraries to find /actual/ problems with
  module systems that people want to solve.
+ Chapter 3 :: Survey the current state-of-the-art in literature with respect
  to first-class module systems in DTLs.
+ Chapter 4 :: Implementations make subtle issues less subtle, and this chapter
  discusses a rapid prototype for the intended framework.  Besides the
  operational Lisp semantics, a preliminary rewrite-system semantics is given
  for the intended syntactic framework.
+ Chapter 5 :: With the lessons learned from the prototype, an in-language
  framework is developed.  It is better than the prototype in some respects, but
  weaker in others.
+ Chapter 6 :: The contributions made by this thesis are highlighted and
  assessed. Conclusions are drawn and avenues for future work are suggested.

** ‚ü®ùëµùë∂‚ü© latex-as-png
#+latex: \begin{tcolorbox}[title = ?, colback=red!5!white, colframe=red!75!black]
 #+latex: \tcblower
 #+latex: \end{tcolorbox}

(add-hook 'org-babel-after-execute-hook 'org-redisplay-inline-images)

  #+begin_src latex-as-png :file put-lifting :exports results
\usepackage{tikz-cd} % ùíü‚ÇÅùíü‚ÇÇar specfies an arrow going direction ùíü‚ÇÅ then ùíü‚ÇÇ; the ùíü·µ¢ must be unique.
\usepackage{amssymb} % green!70!black ‚áí The colour obtained by mixing 70% green and the remaining 30% black.
\usepackage{amsmath} % Need to use a ‚Äúbend‚Äù to have arrows between arrows!
\usepackage{mathtools}

\usepackage{ stmaryrd }

\def\PB{ \arrow[dr, phantom, "\lrcorner", very near start] }
\def\get{\mathsf{get}}
\def\put{\mathsf{put}}
\def\dg{green!70!black}
\usetikzlibrary{decorations.pathmorphing} % to use squiggly arrows
\usetikzlibrary{arrows.meta}
\def\midtxt#1{ \arrow[dr, phantom, "#1"] } % text to go in the middle of a square

\usepackage{tikz}
\usetikzlibrary{decorations.text,calc,arrows.meta}

\usetikzlibrary{shapes,snakes}

% Extensible mapsto, with text on top
\makeatletter
\newcommand{\xMapsto}[2][]{\ext@arrow 0599{\Mapstofill@}{#1}{#2}}
\def\Mapstofill@{\arrowfill@{\Mapstochar\Relbar}\Relbar\Rightarrow}
\makeatother

\usepackage{my-tikz-cats}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% in
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{tikzcd}
% \end{tikzcd}

\begin{figure}
  \label{fig:renaming-example}
  \caption{Given green, derive cyan candidate constructions, require red relationships}
\begin{center}
  \begin{tikzpicture}
\setlength{\unit}{4cm}
\def\arrowthickness{thick}
\def\nodethickness{thick}
\def\textoffset{0cm}
\def\arrowtype{<->}

\mknode{Num}{x = 1, y = 1, candidate color, text = \texttt{Numeric \\  \_{}+\_{}}}
\mknode{Set}{x = 3, y = 1, candidate color, text = \texttt{Sets \\  $\_{}\cup\_{}$}}
\mknode{Lis}{x = 2, y = 0, candidate color, text = \texttt{Lists \\ \_{}++\_{} \\[-0.2ex] {\footnotesize (Catenation)} }}
\mknode{Pro}{x = 2, y = 2, candidate color,
  text =  \texttt{Programs \\ \_{};\_{} \\[-0.2ex] {\footnotesize (Sequencing)} }}
\mknode{Mag}{x = 2, y = 1, given color, text = \fbox{Magma} \\[0.8ex] \texttt{Carrier \\ op}}


\mkline{left = Mag}{right = Num, required color, label = ???, location = above}
\mkline{right = Mag}{left = Set, required color, label = ???, location = below}

\mkline[bend left]{left = Lis}{bot = Num, label = ???, sloped, location = below,   required color}
\mkline[bend right]{right = Lis}{bot = Set, label = ???, sloped, location = below, required color}

\mkline[bend left]{top = Num}{left = Pro, required color, label = ???, sloped, location = above}
\mkline[bend right]{top = Set}{right = Pro, required color, label = ???, sloped, location = above}
\mkline{bot = Pro}{top = Mag, label = ???, location = right,  required color}
\mkline{bot = Mag}{top = Lis, label = ???, location = left,  required color}
\end{tikzpicture}
\end{center}
\end{figure}

#+end_src

#+RESULTS:
[[file:put-lifting.png]]

*** my-tikz-cats.sty
#+begin_src latex :tangle "my-tikz-cats.sty"
\usepackage{tikz}
\usetikzlibrary{decorations.text,calc,arrows.meta}

\usetikzlibrary{shapes,snakes}

% \usepackage{pgffor} % key-value management system, p974 of tikz manual

\usetikzlibrary[fpu]
%
% Example: \numCase{7*3 - 4}{neg}{zer}{pos} % ‚áí pos
%
\def\numCase#1#2#3#4{
\pgfmathparse{#1}
\pgfmathfloatparsenumber{\pgfmathresult}
\pgfmathfloatifflags{\pgfmathresult}{-}{#2}{
  \pgfmathfloatifflags{\pgfmathresult}{0}{#3}{#4}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{pgfkeys} % key-value management system, p974 of tikz manual

% \pgfkeys{/my cool key/.code   = The value is '#1'.}
% \pgfkeys{/my cool key/.default = woah}
% \pgfkeys{/my cool key = hi!, /my cool key}

\iffalse
 Super simple key-management system, abstracting \pgfkeys{}

 #1 is the namespace, and #2 is {key·µ¢ = value·µ¢}
 where each value·µ¢ may contain a ‚Äú#1‚Äù

 Example use:

 \makekeys{it}{x = here, f = ``#1''}
 \callkeys{it}{x, f = 3} % ‚áí here‚Äú3‚Äù

 In particular, this allows us to make a record ‚ÄúR‚Äù
 with a number fields ‚Äúk·µ¢‚Äù, which can be used with
 ‚Äúcallkeys{R}{k·µ¢}‚Äù.

 (The name ‚Äú\setkeys‚Äù is already defined.)

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Any whitespace before \endcsname is part of the name!
\def\set#1#2#3{ \expandafter\edef\csname #1#2\endcsname{#3} }
\def\get#1#2{ \expandafter\csname #1#2\endcsname }
%
% \set{R}{f}{1}
% \get{R}{f} % i.e., ‚Äú\Rf‚Äù

% \def\unit{3cm}
\newlength{\unit}
\setlength{\unit}{2cm}

% ‚Äú‚Äù ‚â§ thick ‚â§ very thick ‚â§ ultra thick
\def\arrowthickness{}
\def\nodethickness{} % {ultra thick}
\def\textoffset{0.9\unit}

\definecolor{umber}{rgb}{.99,.81,.71}
% Add colour keys to a given namespace; use ‚Äú\mycolor‚Äù to access the color.
\def\adjoincolorkeys#1{
  \pgfkeys{/#1/.cd,
                   color/.code  = \def\mycolor{##1},
                   given color/.code  = \def\mycolor{green!50!black},
                   required color/.code  = \def\mycolor{red!50!black},
                   candidate color/.code  = \def\mycolor{cyan!80!black},
                   unique color/.code  = \def\mycolor{umber!50!black}
              }}

\def\adjoinddkeys#1{\pgfkeys{/#1/.cd, dx/.initial = 0cm, dy/.initial = 0cm}}


\def\mknode#1#2{

\pgfkeys{/#1/.cd, x/.initial = 0, y/.initial = 0, text/.initial =, thickness/.initial = \nodethickness}
\adjoincolorkeys{#1}
\adjoinddkeys{#1}
\pgfkeys{/#1/.cd, #2}

\def\x{\pgfkeysvalueof{/#1/x}}
\def\y{\pgfkeysvalueof{/#1/y}}
% \def\color{\pgfkeysvalueof{/#1/color}} % whitespace causes color name error!
\def\text{\pgfkeysvalueof{/#1/text}}
\def\thickness{\pgfkeysvalueof{/#1/thickness}}

\filldraw[color=\mycolor!60, fill=\mycolor!5, \thickness] (\x * \unit, \y * \unit) ellipse ({\unit/3} and {\unit/3});
\node at (\x * \unit, \y * \unit) {\hspace{\textoffset}\begin{minipage}{\unit} \centering \text
%    \pgfkeys{/#1/.cd, color}
  \end{minipage}};
}


\def\resetLocals{
  \def\dx{0cm} \def\dxx{0cm}
  \def\dy{0cm} \def\dyy{0cm}
  \def\mylabel{}
  \def\mylabelsettings{right, sloped}
  \def\mylabellocation{right}
  \def\mylabelsloped{}
  \def\arrowdashed{}}
\resetLocals

\adjoinddkeys{src}
\adjoinddkeys{tgt}
\pgfkeys{/src/.cd,
                   right/.code = \def\dx{+\the\unit/3} \def\src{#1},
                   top/.code   = \def\dy{+\the\unit/3} \def\src{#1},
                   bot/.code      = \def\src{#1} \def\dy{-\the\unit/3},
                   dx/.code    = \def\dx{#1}, % disjoint with ‚Äúleft, right‚Äù
                   dy/.code    = \def\dy{#1} % disjoint with ‚Äúleft, right‚Äù
                 }
\pgfkeys{/tgt/.cd, left/.code     = \def\dxx{-\the\unit/3} \def\tgt{#1},
                   right/.code    = \def\dxx{+\the\unit/3} \def\tgt{#1},
                   top/.code   = \def\dyy{+\the\unit/3} \def\tgt{#1},
                   bot/.code      = \def\tgt{#1} \def\dyy{-\the\unit/3},
                   dx/.code    = \def\dxx{#1}, % disjoint with ‚Äúleft, right‚Äù
                   dy/.code    = \def\dyy{#1}, % disjoint with ‚Äúleft, right‚Äù
                   dashed/.code   = \def\arrowdashed{dashed},
                   label/.code    = \def\mylabel{#1},
                   location/.code = \def\mylabellocation{#1},
                   sloped/.code   =  \def\mylabelsloped{sloped},
                   }
\adjoincolorkeys{tgt}

% Read ‚Äúl = n‚Äù as ‚Äúlocation l *OF* node n‚Äù
% \mkline{loc‚ÇÅ = Src}{loc‚ÇÇ = Tgt}
% At any point we may prefix \mkline with calls ‚Äú\def\dùë®ùë®{‚ãØ}‚Äù
% where ùë® is either x,y,xx,yy to denote offsets to source x,y or target x,y.
\def\arrowtype{->}
\newcommand{\mkline}[3][]{
  % execute the calls in 2 and 4
  \pgfkeys{/src/.cd, left/.code  = \def\src{##1} \def\dx{-\the\unit/3},
                     #2,
          /tgt/.cd, #3}

%  \draw[\arrowthickness, ->, \arrowdashed, \mycolor]  (\pgfkeysvalueof{/\src/x} * \unit + \pgfkeysvalueof{/\src/dx}, \pgfkeysvalueof{/\src/y} * \unit + \pgfkeysvalueof{/\src/dy})  to  [#1] node[\mylabellocation, \mylabelsloped, \mycolor] {\mylabel} (\pgfkeysvalueof{/\tgt/x} * \the\unit + \dxx, \pgfkeysvalueof{/\tgt/y} * \the\unit + \dyy) ;
  \def\x{\pgfkeysvalueof{/\src/x}}   % \def\dx{\pgfkeysvalueof{/src/dx}}
  \def\y{\pgfkeysvalueof{/\src/y}}   % \def\dy{\pgfkeysvalueof{/src/dy}}
  \def\xx{\pgfkeysvalueof{/\tgt/x}}
  \def\yy{\pgfkeysvalueof{/\tgt/y}}
  \draw[\arrowthickness, \arrowtype, \arrowdashed, \mycolor]
    (\x * \unit + \dx, \y * \unit + \dy)
    to  [#1] node[\mylabellocation, \mylabelsloped, \mycolor] {\mylabel}
    (\xx * \the\unit + \dxx, \yy * \the\unit + \dyy);
\resetLocals
}

% example
% \mkline[bend right]{top = Y}{right = Z, label = inclusion,  location = below, sloped}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\iffalse EXAMPLE Use, pushouts (generalised lubs)

\begin{tikzpicture}
\setlength{\unit}{3cm}
\def\arrowthickness{thick}
\def\nodethickness{thick}

\mknode{X}{x = 1, y = 1, given color, text = $X$}
\mknode{Y}{x = 3, y = 1, given color, text = $Y$}
\mknode{Z}{x = 2, y = 0, given color, text = $Z$}
\mknode{P}{x = 2, y = 2, required color, text = $P$}
\mknode{PP}{x = 2, y = 3, candidate color, text = $P'$}

% Given green,
\mkline[bend left]{left = Z}{bot = X, given color}
\mkline[bend right]{right = Z}{bot = Y, given color}
% Require red,
\mkline[bend left]{top = X}{left = P, required color}
\mkline[bend right]{top = Y}{right = P, required color}
% such that for any candidate cyan,
\mkline[bend left]{top = X, dx = -0.2cm}{left = PP, candidate color}
\mkline[bend right]{top = Y, dx = +0.2cm}{right = PP, candidate color}
% there is a unique umber
\mkline{top = P}{bot = PP,  label = unique, location = left, dashed, unique color}
\end{tikzpicture}
% umber
\fi
#+end_src

+ Set: \pgfkeys{/my cool key/.code = The function, on arg #1, associated with this key}
+ Call:  \pgfkeys{/my cool key = the argument here}
+ Setting a default value: \pgfkeys{/my cool key/.default = the default here}
+ You can also have multi-arg code blocks; see p975/985 of [[https://muug.ca/mirror/ctan/graphics/pgf/base/doc/pgfmanual.pdf][the manual]].
+ In either case, the syntax is \pgfkeys{k‚ÇÅ = v‚ÇÅ, ‚Ä¶, k‚Çô = v‚Çô}
  where the values v·µ¢ are optional.
** COMMENT OLD Introduction ---The Thesis‚Äô ‚ÄúStory‚Äù
  :PROPERTIES:
  :CUSTOM_ID: introduction
  :END:

*** Intro                                                          :ignore:

#+begin_edcomm org
:ed: JC

"that demonstrates the distinction between what can currently be accomplished
  and what is desired when working with composition of software units." this is
  overly broad. Your thesis does not accomplish that, nor should it try. Focus!
#+end_edcomm

In this chapter we aim to present the narrative that demonstrates the
distinction between what can currently be accomplished and what is desired when
working with composition of software units. We arrive at the observation that
packaging concepts differ only in their use ---for example, a [[gls:typeclass][typeclass]] and a
[[gls:record][record]] are both sequences of declarations that only differ in that the former is
used for polymorphism with instance search whereas the latter is used as a
structure, grouping related items together. In turn, we are led to propose that
the various packaging concepts ought to have a uniform syntax. Moreover, since
records are a particular notion of packaging, the commitment to syntactic
similarity gives rise to a [[https://en.wikipedia.org/wiki/Homoiconicity][homoiconic]] nature to the host language.

#+begin_edcomm
:ed: JC

the whole first paragraph is quite vague. It's not false, but it's also not
  helpful. You should try to remember your audience, which is your committee
  (Emil, Ridha, and an external person).
#+end_edcomm

Within this work we refer to a /simple type theory/ as a language that contains
typed lambda terms for terms and formuale; if in addition it contains lambda
terms whose types are indexed by values then we say it is a /dependently-typed
language/, or ‚ÄòDTL‚Äô for short ---depending on intent, value-indexed types could
be interpreted as /propositions/ and their terms as /proofs/. With the exception of
declarations and ephemeral notions, nearly everything in a DTL is a typed lambda
term. Just as Lisp's [[gls:homoiconic][homoiconic]] nature blurs data and code leaving it not as a
language with primitives but rather a language with meta-primitives, so too the
lack of distinction between term and type lends itself to generic and uniform
concepts in DTLs thereby leaving no syntactic distinction between a constructive
proof and an algorithm.

#+begin_edcomm
:ed: JC

what is the message of your second paragraph? It says all sorts of things that
  are barely connected to each other. It doesn't say any of those things
  crisply. I'm not sure which of the things it communicates are clearly
  important for the rest of the thesis.
#+end_edcomm

| /An introduction to Agda and dependent types can be found in section ref:sec:what_is_DTL/ |

The sections below explore our primary observation. Section 1 demonstrates the
variety of ‚Äòtongues‚Äô present in a single language which are conflated in a DTL,
section 2 discusses that such conflation should by necessity apply to notions of
packaging, section 3 contains contributed work to ensure that happens. Finally,
section 4 concludes by outlining the remainder of the thesis.

#+begin_edcomm
:ed: JC

"The sections below explore our primary observation". By this point in the
  introduction, I should have an idea of what the thesis is about - I don't. I'm
  not even quite sure what the 'primary observation' is. I certainly don't know
  why NOW is a good time to explore it.
#+end_edcomm

# #
#+begin_edcomm
:ed: JC

"The goal is to use a dependently-typed language to implement the
‚Äòmissing‚Äô module system features directly inside the language." is the first
sentence, 7 pages in, that gets to the heart of the problem you have really
worked hard on.
#+end_edcomm

*** tongues -moved
*** Needless Distinctions for Containers

#+begin_edcomm
:ed: JC

I don't really think that 1.1 and 1.2 really help the reader understand your
thesis. They are too unfocused. This story might belong in the thesis, but not
in the introduction.
#+end_edcomm

Computing is compositionality. Large mind-bending software developments are
formed by composing smaller, much more manageable, pieces together. How? In the
previous section we outlined a number of languages equipped with term
constructors, yet we did not indicate which were more primitive and which could
be derived.

#+macro: uber @@latex:\"uber@@ @@html: uÃàber@@

The methods currently utilised are ad hoc, e.g., ‚Äúdump the contents of packages
into a new {{{uber}}} package‚Äù. What about when the packages contain conflicting
names? ‚ÄúMake an {{{uber}}} package with field names for each package's
contents‚Äù. What about viewing the new {{{uber}}} package as a hierarchy of its
packages? ‚ÄúMake conversion methods between the two representations.‚Äù These
tedious and error-prone operations /should be/ mechanically derivable.

In general, there are special-purpose constructs specifically for working with
packages of ‚Äúusual‚Äù, or ‚Äúday-to-day‚Äù expression- or statement-level code. That
is, a language for working with containers whose contents live in another
language. This forces the users to think of these constructs as rare notions
that are seldom needed ---since they belong to an ephemeral language. They are
only useful when connecting packages together and otherwise need not be learned.

When working with mutually dependent modules, a simple workaround to cyclic
typechecking and loading is to create an interface file containing the
declarations that dependents require. To mitigate such error-prone duplication
of declarations, one may utilise literate programming citet:knuth_lp to tangle
the declarations to multiple files ---the actual parent module and the interface
module. This was the situation with Haskell before its recent module signature
mechanism citet:haskell_backpack. Being a purely functional language, it is
unsurprising that Haskell treats nested record field updates awkwardly: Where a
C-like language may have {{{newline}}} ~a.b.c := d~, Haskell requires ~a { b = b a
{c = d}}~ which necessarily has field names ~b, c~ polluting the global function
namespace as field projections. Since a record is a possibly deeply nested list
of declarations, it is trivial to flatten such a list to mechanically generate
the names ~‚Äúa-b-c‚Äù~ ---since the dot is reserved--- unfortunately this is not
possible in the core language thereby forcing users to employ ‚Äòlenses‚Äô
citet:roman20:profun:lenses:prisms:optics to generate such accessors by
compile-time meta-programming. In the setting of DTLs, records in the form of
nested Œ£-types tend to have tremendously poor performance ---in existing
implementations of Coq citet:coq_cat_experiences and Agda citet:perna, the culprit
generally being projections. More generally, what if we wanted to do something
with packages that the host language does not support? ‚ÄúUse a pre-processor,
approximate packaging at a different language level, or simply settle with what
you have.‚Äù

*Main Observation* Packages, modules, theories, contexts, traits, typeclasses,
interfaces, what have you all boil down to dependent records at the end of the
day and /really differ/ in /how/ they are used or implemented. At the end of section
ref:sec:PF:practicality we demonstrate various distinct presentations of such
notions of packaging arising from a single package declaration.

   # After discussing existing approach and foundations, along with the minimal
   # requirements of a candidate solution, we then present our preliminary findings
   # in section 3. In particular,

*** Novel Contributions

#+begin_edcomm
:ed: JC

1.3 really mixes Related Work and Contributions. It does not even state a
crisp "Research Problem" that you are investigating. The outcomes reads like
"stuff I've done", rather than "contributions worth of a PhD".
#+end_edcomm

The thesis investigates the current state of the art of grouping mechanisms
{{{newline}}} ---sometimes referred to as modules or packages---, their
shortcomings, and implementing candidate solutions based upon a
dependently-typed language.

The introduction of first-class structuring mechanisms drastically changes the
situation by allowing the composition and manipulation of structuring mechanisms
within the language itself. Granted, languages providing combinators for
structuring mechanisms are not new; e.g., such notions already exist for Full
Maude citet:maude_module_algebra and B citet:B_reuse. The former is closer in
spirit to our work, but it differs from ours in that it is based on a /reflective
logic/: A logic where certain aspects of its metatheory can be faithfully
represented within the logic itself. Not only does the meta-theory of our effort
not involve reflection, but our distinctive attribute is that our aim is to form
powerful module system features for Dependently-Typed Languages (DTLs).

To the uninitiated, the shift to DTLs may not appear useful, or at least would
not differ much from existing approaches. We believe otherwise; indeed, in
programming and, more generally, in mathematics, there are three ---below: 1,
2a, 2b--- essentially equivalent perspectives to understanding a concept. Even
though they are equivalent, each perspective has prompted numerous programming
languages; as such, the equivalence does not make the selection of a perspective
irrelevant. The perspectives are below, and examples in the subsequent table.

1. ‚ÄúPoint-wise‚Äù or ‚ÄúConstituent-Based‚Äù:
   A concept is understood by studying the concepts it is ‚Äúmade out of‚Äù.

   Common examples include:
   - /Extensionality/: A mathematical set is determined by the elements it contains.
   - A method is determined by the sequence of statements or expressions it is
     composed from.
   - A package ---such as a record or data declaration--- is determined by
     its components, which may be /thought of/ as fields or constructors.

   Object-oriented programming is based on the notion of inheritance which
   is founded on the ‚Äúhas a‚Äù and ‚Äúis a‚Äù relationships.

2. ‚ÄúPoint-free‚Äù or Relationship Based:
   A concept is understood by its relationship to other concepts in the domain
   of discourse.

   This approach comes into two sub-classifications:

   a. ‚ÄúFirst Class Citizen‚Äù or ‚ÄúConcept as Data‚Äù:
      The concept is treated as a static entity and is
      identified by applying operations /onto it/ in order to observe its nature.

      Common examples include:
      - A singleton set is a set whose cardinality is 1.
      - A method, in any coding language, is a value with the ability to act on
        other values of a particular type.
      - A renaming scheme to provide different names for a given package; more
        generally, applicative modules.

   b. ‚ÄúSecond Class Citizen‚Äù or ‚ÄúConcept as Method‚Äù:
      The concept is treated as a dynamic entity that
      is fed input stimuli and is understood by its emitted observational output.

      Common examples include:
      - A singleton set is a set for which there is a unique mapping to it from
        any other set. Input any set, obtain a map from it to the singleton set.
      - A method, in any coding language, is unique up to observational
        equality: Feed it arguments, check its behaviour. Realistically, one may
        want to also consider efficiency matters.
      - Generative modules as in the ~new~ keyword from object-oriented
        programming: Basic construction arguments are provided and a container
        object is produced.

   Observing such a sub-classification as distinct led to traditional structural
   programming languages, whereas blurring the distinction somewhat led to
   functional programming.

#+latex: \vspace{-1em}
#+caption: Four ways to percieve ‚Äòthe‚Äô empty collection ‚àÖ, and associated theory
|------+-------------+------------------------------------+-----------------|
| (1)  | Extensional | ~X = ‚àÖ ‚â° (‚àÄ e ‚Ä¢ e ‚àà X ‚â° false)~      | Predicate Logic |
| (2)  | Intensional | ~X = ‚àÖ ‚â° (‚àÄ Y ‚Ä¢ X ‚äÜ Y)~              | Set Theory      |
| (2a) | Data        | ~X = ‚àÖ ‚â° #X = 0~                     | Numbers-as-Sets |
| (2b) | Method      | ~X = ‚àÖ ‚â° (‚àÄ Y ‚Ä¢ ‚àÉ‚ÇÅ f ‚Ä¢ f ‚àà (X ‚Üí Y))~ | Function Theory |
|------+-------------+------------------------------------+-----------------|

A simple selection of equivalent perspectives leads to wholly distinct paradigms
of thought. It is with this idea that we seek to implement first-class grouping
mechanisms in a dependently typed language ---theories have been proposed, on
paper, but as just discussed /actual design decisions may have challenging
impacts on the overall system/. Most importantly, this is a /requirements driven/
approach to coherent modularisation constructs in dependently typed languages.

Later on, we shall demonstrate that with a sufficiently expressive type system,
a number of traditional programming notions regarding ‚Äòpackaging up data‚Äô become
conflated ---in particular: Records and modules; which for the most part can all
be thought of as ‚Äúdependent products with named components‚Äù. Languages without
such expressive type systems necessitate certain constraints on these concepts
according to their intended usage ---e.g., no multiple inheritance for Java's
classes and only one instance for Haskell's typeclasses. It is not clear whether
such constraints have been brought to more expressive languages out of
necessity, convention, or convenience. Hence, in Section
ref:sec:current_approaches, we perform a systematic exploration of the
structuring-mechanism design space for DTLs as a starting point for the design
of an appropriate dependently-typed module system (Section ref:sec:contexts). Along
the way, we intend to provide a set of atomic combinators that suffice as
building blocks for generally desirable features of grouping mechanisms, and
moreover we intend to provide an analyses of their interactions.

That is, we want to look at the edge cases of the design space for
structuring-mechanism /systems/, not only what is considered convenient or
conventional. Along the way, we will undoubtedly encounter useless or
non-feasible approaches. The systems we intend to consider would account for,
say, module structures with intrinsic types ---hence treating them as first
class concepts--- so that our examination is based on sound principles.

Understandably, some of the traditional constraints have to do with
implementations. For example, a Haskell typeclass is generally implemented as a
dictionary that can, for the most part, be inlined whereas a record is, in some
languages, a contiguous memory block: They can be identified in a DTL, but their
uses force different implementation methodologies and consequently they are
segregated under different names.

In summary, our research builds upon the existing state of module systems
citet:types_for_modules in a dependently-typed setting citet:dtls_give_modules
which is substantiated by developing practical and pragmatic tools. Our outcomes
include:
  1. A clean module system for DTLs that treats modules uniformly as any other
     value type.
  2. A variety of use-cases contrasting the resulting system with previous
     approaches.
     - We solve the so-called unbundling problem and demonstrate ---using our
       implemented tools--- how pushout and homomorphisms constructions, among
       many others, can be /mechanically/ obtained.
  3. A module system that enables rather than inhibits efficiency.
  4. Demonstrate that module features traditionally handled using
     meta-programming can be brought to the data-value level; thereby not
     actually requiring the immense power and complexity of meta-programming.

Most importantly, we have implemented our theory thereby obtaining validation
that it ‚Äòworks‚Äô. We provide an extensible Emacs interface as well as
an Agda library for forming module constructions.

*** Overview of the Remaining Chapters

When a programming languages does not provide sufficiently expressive primitives
for a concept ---such as typeclass derivation citet:deriving_via--- users use
some form of pre-processing to accomplish their tasks. In our case, the
insufficient primitives are regarding the creation and manipulation of theories
---i.e., records, classes, packages, modules. In section
ref:sec:metaprogramming_module_meta_primitives , we will demonstrate an
prototype that clarified the requirements of our envisioned system. Even though
the prototype appears to be metaprogramming, the aim is not to force users
interested in manipulating packages to worry about the intricacies of
representations; that is, the end goal is to avoid metaprogramming ---which is
an over-glorified form of preprocessing. The goal is to /use a dependently-typed
language to implement/ /the ‚Äòmissing‚Äô module system features directly inside the
language./

#+begin_edcomm
:ed: JC

"The goal is to use a dependently-typed language to implement the
‚Äòmissing‚Äô module system features directly inside the language." is the first
sentence, 7 pages in, that gets to the heart of the problem you have really
worked hard on.
#+end_edcomm

An important design decision is whether the resulting development is intended to
be reasoned about or not. If reasoning is important, then a language that better
supports it is ideal. That is why we are using Agda ---using a simpler language
and maintaining data invariants eventually becomes much harder citet:hasochism.

The remainder of the thesis is organised as follows.

:Outline:
+ Chapter II discusses what is expected of modularisation mechanisms,
  how they could be simulated, their interdefinability in Agda, and
  discuss a theoretical basis for modularisation.

+ Chapter III outlines missing features from current modularisation systems,
  their use cases, and provides a checklist for a candidate module
  system for DTLs.

+ Chapter IV discusses issues regarding implementation matter and the next steps
  in this research, along with a proposed timeline.

+ Chapter V outlines the intended outcomes of this research effort.
:End:

+ *section ref:sec:examples_from_the_wild Examples from the wild*

   There are a host of repeated module patterns since modules are not a
   first-class construct. We look at three Agda libraries and extract ‚Äúmodule
   design patterns for dependently-typed programming‚Äù. To the best of our
   knowledge, we are the first to formalise such design patterns for
   dependently-typed languages. Three other, non-module, design patterns are
   discussed in citet:10.1145/1411204.1411213.

   :RoughOutline:
   - E.g., IsX and X in Agda's standard library.
   - E.g., Hom, and universal algebra constructs, /for/ a paraticular theory.
   - E.g., common renaming patterns such as X_i or X' or etc for a theory X.
     - Cannot do this in Context due to Agda's limited support for fresh names.
     - Doable in PF.
   :End:

+ *section ref:sec:metaprogramming_module_meta_primitives Metaprogramming Module Meta-primitives*

   To show that first-class modules are /reasonable/, we begin by providing
   ~PackageFormer~ citet:DBLP:conf/gpce/Al-hassyCK19: A specfication and
   manipulation language for modules, for Agda.
   To show that the approach is promising, we demonstrate how some problems
   from section ref:sec:examples_from_the_wild can be tackled.

   # - Emacs Lisp is used as an implementation language since Emacs is the de
   #   facto editor for Agda.

   - The tool is a *practical* sandbox for exploring do-it-yourself grouping mechanisms:
     From pushouts and pullbacks, to forming homomorphism types over a given theory.

+ *section ref:sec:module_meta_primitives_as_library_methods Module Meta-primitives as Library Methods*

   The ideas learned from making the powerful ~PackageFormer~ prototype lead us to
   form the less-powerful ~Context~ framework, which has the orthogonal benefit of
   being an Agda library rather than an external pre-processing tool.
   :RoughOutline:
   - E.g., a termtype arises by keeping only the fields that target the elected
     ADT carrier.
   - Ideas of :waist!
   :End:

   - Along the way, we solve the *unbundling problem*: Features of a structure may be
     exposed at the type level as-needed.

+ *section ref:sec:conclusion Conclusion: The lingua franca dream as reality*

   We compare the external ~PackageFormer~ tool with the ~Context~ library, and
   discuss how the latter has brought us closer to our original goal of having a
   single language for expressing values, types, and modules.

# ^_^
It has been an exciting journey, I hope you enjoy the ride!


** COMMENT Proposed Outline
1. Motivating the problem
   - Where has this problem been encountered in the wild?
   - What benefits would there be to solving this problem?
   - Mention ~1 * x + 0 = x~ problem from the ICFP20 paper.
     * Two monoidal units on the same carrier satisfy this law.

   Here is where the "STORY" is placed.

2. Background: What's necessary to solve this problem?
   - What is needed to just understand this problem?
   - Agda
   - System F
   - Monads
   - Metaprogramming

   Maybe tackle this "as needed", rather than upfront.

3. PackageFormer
   - Why an editor extension? Why Lisp is reasonable?
   - Utility of a protottype?
   - Things learned from making a protottype?
     * Perhaps show the minimal code needed to get PF working; <= 300 lines?
     * Much more Lisp for implementing common grouping mechanisms; e.g., pushouts.
   - How usable is it?
   - What exotic notions of grouping mechanisms can be coded-up? Utilit!?
   - [Disadvantages of PackageFormer?
   - Comparision to other systems.

4. Contexts
   - Why PackageFormer is not enough.
   - Discuss Agda macros ---need to be self-contained.
   - Motivate the need for a practical syntax.
   - The reason it's a "do it yourself" system is that the semantics, >>=,
     can be tweaked easily for other forms of grouping besides Pi/Sigma ;-)
   - Current limitations; e.g., lack of termination/positivity of certain constructs;
     or how termtype generation requires the ADT carrier to be the first element
     of the sequence/context, whereas a DAG interpretation of Contexts would be better?
   - How does this compare with PF?
   - What are the benefits of Context?
   - Concrete problems its usage can solve.

5. Related works
   - Who has worked on this problem and where have they gotten?
   - What are their shortcomings and advantages wrt to our approach?
   - Shortcomings of our approach.
   - Missing features and next steps.

6. Conclusion
   - What we have done
   - How it is useful to others, now.
** COMMENT Part                                                     :ignore:

#+begin_export latex
\pagelayout{wide} % No margins
\addpart{Linguistics, Type Theory, and Agda}
\pagelayout{margin} % Restore margins
#+end_export
** COMMENT src_haskell[:exports code]{Context} Implementation
#+latex_header: \usepackage[toc,page]{appendix}

# Appendices are for the details, and so have a smaller font.
#+LaTeX: \setminted[agda]{fontsize=\footnotesize} \clearpage\clearpage

Below is the entirety of the =Context= library.

{{{code(The Context Library)}}}
#+begin_src agda :tangle Context.agda
-- Agda version 2.6.0.1
-- Standard library version 1.2

module Context where
#+end_src

Also included are unit tests, evidence for claims made in the thesis proper, and
a brief case-study on graphs to demonstrate some features of the Context library
that are necessary for practical use, such as field projections, but which did
not receive attention in the paper proper.

*** Imports
#+begin_src agda :tangle Context.agda
open import Level renaming (_‚äî_ to _‚äç_; suc to ‚Ñìsuc; zero to ‚Ñì‚ÇÄ)
open import Relation.Binary.PropositionalEquality
open import Relation.Nullary

open import Data.Nat
open import Data.Fin  as Fin using (Fin)
open import Data.Maybe  hiding (_>>=_)

open import Data.Bool using (Bool ; true ; false)
open import Data.List as List using (List ; [] ; _‚à∑_ ; _‚à∑ ≥_; sum)

‚Ñì‚ÇÅ   = Level.suc ‚Ñì‚ÇÄ
#+end_src

*** Quantifiers Œ†‚à∂‚Ä¢/Œ£‚à∂‚Ä¢ and Products/Sums

  We shall using Z-style quantifier notation citet:10.5555/235337 in which the
  quantifier dummy variables are separated from the body by a large bullet.

  In Agda, we use ~\:~ to obtain the ‚Äúghost colon‚Äù since standard colon ~:~ is an
  Agda operator.

  Even though Agda provides ~‚àÄ (x : œÑ) ‚Üí fx~ as a built-in syntax for Œ†-types, we
  have chosen the Z-style one below to mirror the notation for Œ£-types, which
  Agda provides as src_agda[:exports code]{record} declarations.  In the paper
  proper, in the definition of bind, the subtle shift between Œ£-types and
  Œ†-types is easier to notice when the notations are so similar that only the
  quantifier symbol changes.

#+begin_src agda :tangle Context.agda
open import Data.Empty using (‚ä•)
open import Data.Sum
open import Data.Product
open import Function using (_‚àò_)

Œ£‚à∂‚Ä¢ : ‚àÄ {a b} (A : Set a) (B : A ‚Üí Set b) ‚Üí Set _
Œ£‚à∂‚Ä¢ = Œ£

infix -666 Œ£‚à∂‚Ä¢
syntax Œ£‚à∂‚Ä¢ A (Œª x ‚Üí B) = Œ£ x ‚à∂ A ‚Ä¢ B

Œ†‚à∂‚Ä¢ : ‚àÄ {a b} (A : Set a) (B : A ‚Üí Set b) ‚Üí Set _
Œ†‚à∂‚Ä¢ A B = (x : A) ‚Üí B x

infix -666 Œ†‚à∂‚Ä¢
syntax Œ†‚à∂‚Ä¢ A (Œª x ‚Üí B) = Œ† x ‚à∂ A ‚Ä¢ B

record ‚ä§ {‚Ñì} : Set ‚Ñì where
  constructor tt

ùüô = ‚ä§ {‚Ñì‚ÇÄ}
ùüò = ‚ä•
#+end_src
#+latex: \noindent
*** Reflection

We form a few metaprogramming utilities we would have expected to be in the
standard library.

#+begin_src agda :tangle Context.agda
import Data.Unit as Unit
open import Reflection hiding (name; Type) renaming (_>>=_ to _>>=‚Çò_)
#+end_src

Before continuing, there are a few difficulties about Agda's metaprogramming
capabilities that should be mentioned:
1. Even when recursion is on structurally smaller terms of abstract syntax
   trees, termination cannot be automatically deduced. As such, we request Agda
   to believe us that certain definitions are terminating.
2. Since Agda macros cannot be recursive ---possibly due to issues of
   termination--- an idiom we use to define a recursive operation on terms then
   wrap that in Agda's typechecking monad to form macros.
3. Sometimes, no matter how explicit we make certain affairs, macro invocations
   will complain about being unable to infer certain details. As a workaround,
   we type any declaration involving a macro invocation before using it
   ---inference is difficult in dependently-typed settings and even worse in the
   presence of metaprogramming.

**** Single argument application
#+begin_src agda :tangle Context.agda
_app_ : Term ‚Üí Term ‚Üí Term
(def f args) app arg' = def f (args ‚à∑ ≥ arg (arg-info visible relevant) arg')
(con f args) app arg' = con f (args ‚à∑ ≥ arg (arg-info visible relevant) arg')
{-# CATCHALL #-}
tm app arg' = tm
#+end_src

#+latex: \noindent
Notice that we maintain existing applications:
| ~quoteTerm (f x) app quoteTerm y~ | ‚âà | ~quoteTerm (f x y)~ |

**** Reify ‚Ñï term encodings as ‚Ñï values
#+begin_src agda :tangle Context.agda
to‚Ñï : Term ‚Üí ‚Ñï
to‚Ñï (lit (nat n)) = n
{-# CATCHALL #-}
to‚Ñï _ = 0
#+end_src
**** The Length of a Term
#+begin_src agda :tangle Context.agda
arg-term : ‚àÄ {‚Ñì} {A : Set ‚Ñì} ‚Üí (Term ‚Üí A) ‚Üí Arg Term ‚Üí A
arg-term f (arg i x) = f x

{-# TERMINATING #-}
length‚Çú : Term ‚Üí ‚Ñï
length‚Çú (var x args)      = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (con c args)      = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (def f args)      = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (lam v (abs s x)) = 1 + length‚Çú x
length‚Çú (pat-lam cs args) = 1 + sum (List.map (arg-term length‚Çú ) args)
length‚Çú (Œ†[ x ‚à∂ A ] Bx)   = 1 + length‚Çú Bx
{-# CATCHALL #-}
-- sort, lit, meta, unknown
length‚Çú t = 0
#+end_src
#+latex: \noindent
Here is an example use:
#+begin_src agda :tangle Context.agda
_ : length‚Çú (quoteTerm (Œ£ x ‚à∂ ‚Ñï ‚Ä¢ x ‚â° x)) ‚â° 10
_ = refl
#+end_src

*** Context Monad
#+begin_src agda :tangle Context.agda
Context = Œª ‚Ñì ‚Üí ‚Ñï ‚Üí Set ‚Ñì

infix -1000 ‚Äµ_
‚Äµ_ : ‚àÄ {‚Ñì} ‚Üí Set ‚Ñì ‚Üí Context ‚Ñì
‚Äµ S = Œª _ ‚Üí S

End : ‚àÄ {‚Ñì} ‚Üí Context ‚Ñì
End = ‚Äµ ‚ä§

End‚ÇÄ = End {‚Ñì‚ÇÄ}

_>>=_ : ‚àÄ {a b}
      ‚Üí (Œì : Set a)  -- Main diference
      ‚Üí (Œì ‚Üí Context b)
      ‚Üí Context (a ‚äç b)
(Œì >>= f) ‚Ñï.zero  = Œ£ Œ≥ ‚à∂ Œì ‚Ä¢ f Œ≥ 0
(Œì >>= f) (suc n) = (Œ≥ : Œì) ‚Üí f Œ≥ n
#+end_src

*** ‚ü®‚ü© Notation

# As mentioned, grouping mechanisms are declared with ~do ‚Ä¶ End~, and instances of
# them are constructed using ~‚ü® ‚Ä¶ ‚ü©~.
#+begin_src agda :tangle Context.agda
-- Expressions of the form ‚Äú‚ãØ , tt‚Äù may now be written ‚Äú‚ü® ‚ãØ ‚ü©‚Äù
infixr 5 ‚ü® _‚ü©
‚ü®‚ü© : ‚àÄ {‚Ñì} ‚Üí ‚ä§ {‚Ñì}
‚ü®‚ü© = tt

‚ü® : ‚àÄ {‚Ñì} {S : Set ‚Ñì} ‚Üí S ‚Üí S
‚ü® s = s

_‚ü© : ‚àÄ {‚Ñì} {S : Set ‚Ñì} ‚Üí S ‚Üí S √ó ‚ä§ {‚Ñì}
s ‚ü© = s , tt
#+end_src

*** DynamicSystem Context
#+begin_src agda  :tangle Context_examples.agda
DynamicSystem : Context (‚Ñìsuc Level.zero)
DynamicSystem = do X ‚Üê Set
                   z ‚Üê X
                   s ‚Üê (X ‚Üí X)
                   End {Level.zero}

-- Records with ùìÉ-Parameters, ùìÉ : 0..3
A B C D : Set‚ÇÅ
A = DynamicSystem 0 -- Œ£ X ‚à∂ Set  ‚Ä¢ Œ£ z ‚à∂ X  ‚Ä¢ Œ£ s ‚à∂ X ‚Üí X  ‚Ä¢ ‚ä§
B = DynamicSystem 1 --  (X ‚à∂ Set) ‚Üí Œ£ z ‚à∂ X  ‚Ä¢ Œ£ s ‚à∂ X ‚Üí X  ‚Ä¢ ‚ä§
C = DynamicSystem 2 --  (X ‚à∂ Set)    (z ‚à∂ X) ‚Üí Œ£ s ‚à∂ X ‚Üí X  ‚Ä¢ ‚ä§
D = DynamicSystem 3 --  (X ‚à∂ Set)    (z ‚à∂ X) ‚Üí  (s ‚à∂ X ‚Üí X) ‚Üí ‚ä§

_ : A ‚â° (Œ£ X ‚à∂ Set  ‚Ä¢ Œ£ z ‚à∂ X  ‚Ä¢ Œ£ s ‚à∂ (X ‚Üí X)  ‚Ä¢ ‚ä§) ; _ = refl
_ : B ‚â° (Œ† X ‚à∂ Set  ‚Ä¢ Œ£ z ‚à∂ X  ‚Ä¢ Œ£ s ‚à∂ (X ‚Üí X)  ‚Ä¢ ‚ä§) ; _ = refl
_ : C ‚â° (Œ† X ‚à∂ Set  ‚Ä¢ Œ† z ‚à∂ X  ‚Ä¢ Œ£ s ‚à∂ (X ‚Üí X)  ‚Ä¢ ‚ä§) ; _ = refl
_ : D ‚â° (Œ† X ‚à∂ Set  ‚Ä¢ Œ† z ‚à∂ X  ‚Ä¢ Œ† s ‚à∂ (X ‚Üí X)  ‚Ä¢ ‚ä§) ; _ = refl

stability : ‚àÄ {n} ‚Üí   DynamicSystem (3 + n)
                   ‚â° DynamicSystem  3
stability = refl

B-is-empty : ¬¨ B
B-is-empty b = proj‚ÇÅ( b ‚ä•)

ùí©‚ÇÄ : DynamicSystem 0
ùí©‚ÇÄ = ‚Ñï , 0 , suc , tt

ùí© : DynamicSystem 0
ùí© = ‚ü® ‚Ñï , 0 , suc ‚ü©

B-on-‚Ñï : Set
B-on-‚Ñï = let X = ‚Ñï in Œ£ z ‚à∂ X  ‚Ä¢ Œ£ s ‚à∂ (X ‚Üí X)  ‚Ä¢ ‚ä§

ex : B-on-‚Ñï
ex = ‚ü® 0 , suc ‚ü©
#+end_src

*** DynamicSystem :waist ùíæ
#+begin_src agda  :tangle Context_examples.agda
A' : Set‚ÇÅ
B' : ‚àÄ (X : Set) ‚Üí Set
C' : ‚àÄ (X : Set) (x : X) ‚Üí Set
D' : ‚àÄ (X : Set) (x : X) (s : X ‚Üí X) ‚Üí Set

A' = DynamicSystem :waist 0
B' = DynamicSystem :waist 1
C' = DynamicSystem :waist 2
D' = DynamicSystem :waist 3

ùí©‚Å∞ : A'
ùí©‚Å∞ = ‚ü® ‚Ñï , 0 , suc ‚ü©

ùí©¬π : B' ‚Ñï
ùí©¬π = ‚ü® 0 , suc ‚ü©

ùí©¬≤ : C' ‚Ñï 0
ùí©¬≤ = ‚ü® suc ‚ü©

ùí©¬≥ : D' ‚Ñï 0 suc
ùí©¬≥ = ‚ü®‚ü©
#+end_src
#+latex: \noindent
It may be the case that ~Œì 0 ‚â° Œì :waist 0~ for every context Œì.
#+begin_src agda  :tangle Context_examples.agda
_ : DynamicSystem 0 ‚â° DynamicSystem :waist 0
_ = refl
#+end_src

*** Field projections
#+begin_src agda :tangle Context.agda
Field‚ÇÄ : ‚Ñï ‚Üí Term ‚Üí Term
Field‚ÇÄ zero c    = def (quote proj‚ÇÅ) (arg (arg-info visible relevant) c ‚à∑ [])
Field‚ÇÄ (suc n) c = Field‚ÇÄ n (def (quote proj‚ÇÇ) (arg (arg-info visible relevant) c ‚à∑ []))

macro
  Field : ‚Ñï ‚Üí Term ‚Üí Term ‚Üí TC Unit.‚ä§
  Field n t goal = unify goal (Field‚ÇÄ n t)
#+end_src

An example usage can be found below in the setting of graphs.

*** COMMENT :NO: No ‚Äòconstants‚Äô, whence a type of inifinitely branching terms
#+begin_src agda :tangle Context.agda
PointedOver‚ÇÉ  : Set ‚Üí Context (‚Ñì‚ÇÄ)
PointedOver‚ÇÉ Œû    = do relation ‚Üê (Œû ‚Üí Œû ‚Üí Œû)
                       End {‚Ñì‚ÇÄ}

‚Ñô‚ÇÉ : Set
‚Ñô‚ÇÉ = termtype (Œª X ‚Üí PointedOver‚ÇÉ X 0)
#+end_src

*** COMMENT  :NO: Other experiments
#+begin_src agda :tangle Context.agda
{- Yellow:

PointedOver‚ÇÖ  : Context (‚Ñìsuc ‚Ñì‚ÇÄ)
PointedOver‚ÇÖ   = do One ‚Üê Set
                    Two ‚Üê Set
                    Three ‚Üê (One ‚Üí Two ‚Üí Set)
                    End {‚Ñì‚ÇÄ}

‚Ñô‚ÇÖ : Set ‚Üí Set‚ÇÅ
‚Ñô‚ÇÖ X = termtype ((PointedOver‚ÇÖ :waist 2) X)
-- Fix (Œª Two ‚Üí One √ó Two)

pattern _‚à∑‚ÇÖ_ x y = Œº (inj‚ÇÅ (x , y , tt))

case‚ÇÖ : ‚àÄ {X} ‚Üí ‚Ñô‚ÇÖ X ‚Üí Set‚ÇÅ
case‚ÇÖ (x ‚à∑‚ÇÖ xs) = Set

-}

--------------------------------------------------------------------------------

{-- Dependent sums

PointedOver‚ÇÜ  : Context ‚Ñì‚ÇÅ
PointedOver‚ÇÜ = do Sort ‚Üê Set
                  Carrier ‚Üê (Sort ‚Üí Set)
                  End {‚Ñì‚ÇÄ}

‚Ñô‚ÇÜ : Set‚ÇÅ
‚Ñô‚ÇÜ = termtype ((PointedOver‚ÇÜ :waist 1) )
-- Fix (Œª X ‚Üí X)

-}

--------------------------------------------------------------------------------

-- Distinuighed subset algebra

open import Data.Bool renaming (Bool to ùîπ)

{-
PointedOver‚Çá  : Context (‚Ñìsuc ‚Ñì‚ÇÄ)
PointedOver‚Çá       = do Index ‚Üê Set
                        Is    ‚Üê (Index ‚Üí ùîπ)
                        End {‚Ñì‚ÇÄ}

-- The current implementation of ‚Äútermtype‚Äù only allows for one ‚ÄúSet‚Äù in the body.
-- So we lift both out; thereby regaining ‚Ñô‚ÇÇ!

‚Ñô‚Çá : Set ‚Üí Set
‚Ñô‚Çá X = termtype (Œª (_ : Set) ‚Üí (PointedOver‚Çá :waist 1) X)
-- ‚Ñô‚ÇÅ X ‚âÖ X

pattern _‚áå_ x y = Œº (inj‚ÇÅ (x , y , tt))

case‚Çá : ‚àÄ {X} ‚Üí ‚Ñô‚Çá X ‚Üí Set
case‚Çá {X} (Œº (inj‚ÇÅ x)) = X

-}

--------------------------------------------------------------------------------

{-
PointedOver‚Çâ  : Context ‚Ñì‚ÇÅ
PointedOver‚Çâ       = do Carrier ‚Üê Set
                        End {‚Ñì‚ÇÄ}

-- The current implementation of ‚Äútermtype‚Äù only allows for one ‚ÄúSet‚Äù in the body.
-- So we lift both out; thereby regaining ‚Ñô‚ÇÇ!

‚Ñô‚Çâ : Set
‚Ñô‚Çâ = termtype (Œª (X : Set) ‚Üí (PointedOver‚Çâ :waist 1) X)
-- ‚âÖ ùüò ‚âÖ Fix (Œª X ‚Üí ùüò)
-}

#+end_src
*** COMMENT  :NO: ~Fix Id~
#+begin_src agda :tangle Context.agda
PointedOver‚ÇÅ‚ÇÄ  : Context ‚Ñì‚ÇÅ
PointedOver‚ÇÅ‚ÇÄ       = do Carrier ‚Üê Set
                         next    ‚Üê (Carrier ‚Üí Carrier)
                         End {‚Ñì‚ÇÄ}

-- The current implementation of ‚Äútermtype‚Äù only allows for one ‚ÄúSet‚Äù in the body.
-- So we lift both out; thereby regaining ‚Ñô‚ÇÇ!

‚Ñô‚ÇÅ‚ÇÄ : Set
‚Ñô‚ÇÅ‚ÇÄ = termtype (Œª (X : Set) ‚Üí (PointedOver‚ÇÅ‚ÇÄ :waist 1) X)
-- Fix (Œª X ‚Üí X), which does not exist.

#+end_src

*** TODO COMMENT  :NO: What about the meta-language's parameters?

 Besides ~:waist~, another way to introduce parameters into a context grouping
 mechanism is to use the language's existing utility of parameterising a context
 by another type ---as was done earlier in ~PointedOver~.

 For example, a pointed set needn't necessarily be termined with ~End~.
 #+begin_src agda
PointedSet : Context ‚Ñì‚ÇÅ
PointedSet = do Carrier ‚Üê Set
                point   ‚Üê Carrier
                End {‚Ñì‚ÇÅ}
 #+end_src
 We instead form a grouping consisting of a single type and a value of that type,
 along with an instance of the parameter type =Œû=.
 #+begin_src agda
PointedPF : (Œû : Set‚ÇÅ) ‚Üí Context ‚Ñì‚ÇÅ
PointedPF Œû = do Carrier ‚Üê Set
                 point   ‚Üê Carrier
                 ‚Äµ Œû
 #+end_src
 Clearly ~PointedPF ùüô ‚âà PointedSet~, so we have a more generic grouping mechanism.
 The natural next step is to consider other parameters such as ~PointedSet~
 in-place of =Œû=.
 :AgdaCheckedEvidence:
 #+begin_src agda
_ : ‚àÄ {n} ‚Üí PointedPF ùüô n ‚â° PointedSet n
_ = refl
 #+end_src
 :End:
 #+begin_src agda
-- Convenience names
PointedSet·µ£ = PointedSet        :kind ‚Äµrecord
PointedPF·µ£  = Œª Œû ‚Üí PointedPF Œû :kind ‚Äµrecord

-- An extended record type: Two types with a point of each.
TwoPointedSets = PointedPF·µ£ PointedSet·µ£

_ :   TwoPointedSets
    ‚â° ( Œ£ Carrier‚ÇÅ ‚à∂ Set ‚Ä¢ Œ£ point‚ÇÅ ‚à∂ Carrier‚ÇÅ
      ‚Ä¢ Œ£ Carrier‚ÇÇ ‚à∂ Set ‚Ä¢ Œ£ point‚ÇÇ ‚à∂ Carrier‚ÇÇ ‚Ä¢ ùüô)
_ = refl

-- Here's an instance
one : PointedSet :kind ‚Äµrecord
one = ùîπ , false , tt

-- Another; a pointed natural extended by a pointed bool,
-- with particular choices for both.
two : TwoPointedSets
two = ‚Ñï , 0 , one
 #+end_src
 More generally, /record *structure* can be dependent on values:/
 #+begin_src agda
_PointedSets : ‚Ñï ‚Üí Set‚ÇÅ
zero  PointedSets = ùüô
suc n PointedSets = PointedPF·µ£ (n PointedSets)

_ :   4 PointedSets
    ‚â° (Œ£ Carrier‚ÇÅ ‚à∂ Set ‚Ä¢ Œ£ point‚ÇÅ ‚à∂ Carrier‚ÇÅ
      ‚Ä¢ Œ£ Carrier‚ÇÇ ‚à∂ Set ‚Ä¢ Œ£ point‚ÇÇ ‚à∂ Carrier‚ÇÇ
      ‚Ä¢ Œ£ Carrier‚ÇÉ ‚à∂ Set ‚Ä¢ Œ£ point‚ÇÉ ‚à∂ Carrier‚ÇÉ
      ‚Ä¢ Œ£ Carrier‚ÇÑ ‚à∂ Set ‚Ä¢ Œ£ point‚ÇÑ ‚à∂ Carrier‚ÇÑ ‚Ä¢ ùüô)
_ = refl
 #+end_src
 Using traditional grouping mechanisms, it is difficult to create the family of
 types =n PointedSets= since the number of fields, $2 √ó n$, depends on $n$.

 It is interesting to note that the termtype of ~PointedPF~ is the same as the
 termtype of ~PointedOver~, the ~Maybe~ type constructor!
 #+begin_src agda :tangle no
PointedD : (X : Set) ‚Üí Set‚ÇÅ
PointedD X = termtype (PointedPF (Lift _ X) :waist 1)

-- Pattern synonyms for more compact presentation
pattern nothingP = Œº (inj‚ÇÅ tt)
pattern justP x  = Œº (inj‚ÇÇ (lift x))

casingP : ‚àÄ {X} (e : PointedD X)
        ‚Üí (e ‚â° nothingP) ‚äé (Œ£ x ‚à∂ X ‚Ä¢ e ‚â° justP x)
casingP nothingP  = inj‚ÇÅ refl
casingP (justP x) = inj‚ÇÇ (x , refl)
 #+end_src

*** COMMENT  :NO: Example: Vector Spaces

 Consider the signature of vector spaces ~V~ over a field ~F~.
 #+begin_src agda  :tangle Context_examples.agda
VecSpcSig : Context ‚Ñì‚ÇÅ
VecSpcSig = do F   ‚Üê Set
               V   ‚Üê Set
               ùüò   ‚Üê F
               ùüô   ‚Üê F
               _+_ ‚Üê (F ‚Üí F ‚Üí F)
               o   ‚Üê V
               _*_ ‚Üê (F ‚Üí V ‚Üí V)
               _¬∑_ ‚Üê (V ‚Üí V ‚Üí F)
               End‚ÇÄ
 #+end_src
 We can expose ~V~ and ~F~ so that they can be varied.
 #+begin_src agda :tangle Context_examples.agda
VSInterface : (Field Vectors : Set) ‚Üí Set
VSInterface F V = (VecSpcSig :waist 2) F V
 #+end_src

 We conjecture that the terms over such vector space signatures
 are similar to lists (vectors) consisting of elements (field scalars),
 but we also have two additional nullary constructors, a pairing constructor,
 and a branching constructor. That is, we have a structure amalgamating
 both lists and binary trees.
 #+begin_src agda :tangle Context_examples.agda
data ‚Ñùùïöùïüùïò (Scalar : Set) : Set where
  zero‚Çõ : ‚Ñùùïöùïüùïò Scalar
  one‚Çõ  : ‚Ñùùïöùïüùïò Scalar
  plus‚Çõ : Scalar ‚Üí Scalar ‚Üí ‚Ñùùïöùïüùïò Scalar
  zero·µ• : ‚Ñùùïöùïüùïò Scalar
  prod  : Scalar ‚Üí ‚Ñùùïöùïüùïò Scalar ‚Üí ‚Ñùùïöùïüùïò Scalar
  dot   : ‚Ñùùïöùïüùïò Scalar ‚Üí ‚Ñùùïöùïüùïò Scalar ‚Üí ‚Ñùùïöùïüùïò Scalar
 #+end_src

 We confirm this claim by relying on the mechanical approach to forming term
 types, then witnessing a view between the two.
 #+begin_src agda :tangle Context_examples.agda
VSTerm : (Field : Set) ‚Üí Set
VSTerm = Œª F ‚Üí termtype ((VecSpcSig :waist 2) F)
{- ‚âÖ  Fix (Œª X ‚Üí ùüô     -- Representation of additive unit, zero
               ‚äé ùüô     -- Representation of multiplicative unit, one
               ‚äé F √ó F -- Pair of scalars to be summed
               ‚äé ùüô     -- Representation of the zero vector
               ‚äé F √ó X -- Pair of arguments to be scalar-producted
               ‚äé X √ó X -- Pair of vectors to be dot-producted
-}

-- Convenience synonyms for more compact presentation & meaningful names
pattern ùüò‚Çõ         = Œº (inj‚ÇÅ tt)
pattern ùüô‚Çõ         = Œº (inj‚ÇÇ (inj‚ÇÅ tt))
pattern _+‚Çõ_ x y   = Œº (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÅ (x , (y , tt)))))
pattern ùüò·µ•         = Œº (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÅ tt))))
pattern _*·µ•_ x xs  = Œº (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÅ (x , (xs , tt)))))))
pattern _¬∑·µ•_ xs ys = Œº (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÇ (inj‚ÇÅ (xs , (ys , tt))))))))
 #+end_src

 Now the view: It simply associated constructors of the same shape, recursively.
 #+begin_src agda :tangle Context_examples.agda
view : ‚àÄ {F} ‚Üí VSTerm F ‚Üí ‚Ñùùïöùïüùïò F
view ùüò‚Çõ         = zero‚Çõ
view ùüô‚Çõ         = one‚Çõ
view (x +‚Çõ y)   = plus‚Çõ x y
view ùüò·µ•         = zero·µ•
view (x *·µ• xs)  = prod x (view xs)
view (xs ¬∑·µ• ys) = dot (view xs) (view ys)
 #+end_src

 Neato.

*** COMMENT Example: Graphs in Two Ways

  There are two ways to implement the type of graphs in the
  dependently-typed language Agda: Having the vertices be a parameter or having
  them be a field of the record. Then there is also the syntax for graph vertex
  relationships. Suppose a library designer decides to work with fully bundled
  graphs, ~Graph‚ÇÄ~ below, then a user decides to write the function ~comap~, which
  relabels the vertices of a graph, using a function ~f~ to transform vertices.

:Hide:
#+begin_src agda
data ùîæùï£ùïíùï°ùïô (Vertex : Set) : Set where
  ‚ü®_,_‚ü©‚Çõ : Vertex ‚Üí Vertex ‚Üí ùîæùï£ùïíùï°ùïô Vertex
#+end_src
:End:

#+begin_src agda :tangle Context_examples.agda
record Graph‚ÇÄ : Set‚ÇÅ where
  constructor ‚ü®_,_‚ü©‚ÇÄ
  field
    Vertex : Set
    Edges : Vertex ‚Üí Vertex ‚Üí Set

open Graph‚ÇÄ

comap‚ÇÄ : {A B : Set}
       ‚Üí (f : A ‚Üí B)
       ‚Üí (Œ£ G ‚à∂ Graph‚ÇÄ ‚Ä¢ Vertex G ‚â° B)
       ‚Üí (Œ£ H ‚à∂ Graph‚ÇÄ ‚Ä¢ Vertex H ‚â° A)
comap‚ÇÄ {A} f (G , refl) = ‚ü® A , (Œª x y ‚Üí Edges G (f x) (f y)) ‚ü©‚ÇÄ , refl
#+end_src
  #+latex: \noindent
  Since the vertices are packed away as components of the records, the only way
  for ~f~ to refer to them is to awkwardly refer to seemingly arbitrary types,
  only then to have the vertices of the input graph ~G~ and the output graph ~H~ be
  constrained to match the type of the relabelling function ~f~.  Without the
  constraints, we could not even write the function for ~Graph‚ÇÄ~.  With such an
  importance, it is surprising to see that the occurrences of the constraint
  obligations are uninsightful ~refl~-exivity proofs.

  What the user would really want is to unbundle ~Graph‚ÇÄ~ at will, to expose the
  first argument, to obtain ~Graph‚ÇÅ~ below. Then, in stark contrast, the
  implementation ~comap‚ÇÅ~ does not carry any excesses baggage at the type level
  nor at the implementation level.
#+latex: \newpage
  #+begin_src agda  :tangle Context_examples.agda
record Graph‚ÇÅ (Vertex : Set) : Set‚ÇÅ where
  constructor ‚ü®_‚ü©‚ÇÅ
  field
    Edges : Vertex ‚Üí Vertex ‚Üí Set

comap‚ÇÅ : {A B : Set}
       ‚Üí (f : A ‚Üí B)
       ‚Üí Graph‚ÇÅ B
       ‚Üí Graph‚ÇÅ A
comap‚ÇÅ f ‚ü® edges ‚ü©‚ÇÅ = ‚ü® (Œª x y ‚Üí edges (f x) (f y)) ‚ü©‚ÇÅ
  #+end_src
  #+latex: \noindent
  With ~Graph‚ÇÅ~, one immediately sees that the ~comap~ operation ‚Äúpulls back‚Äù the
    vertex type. Such an observation for ~Graph‚ÇÄ~ is not as easy; requiring
    familiarity with quantifier laws such as the one-point rule and quantifier
    distributivity.

*** COMMENT Example: Graphs with Delayed Unbundling
The ubiquitous graph structure
    is contravariant in its collection of vertices. Recall that a multi-graph, or
    quiver, is a collection of vertices along with a collection of edges between
    any two vertices; here's the traditional record form:
    #+begin_src agda  :tangle Context_examples.agda
Graph  : Context ‚Ñì‚ÇÅ
Graph  = do Vertex ‚Üê Set
            Edges  ‚Üê (Vertex ‚Üí Vertex ‚Üí Set)
            End {‚Ñì‚ÇÄ}
 #+end_src

    Using the record form, it is awkward to phrase contravariance, which simply
    ‚Äúrelabels the vertices‚Äù. Even worse, the awkward phrasing only serves to
    ensure certain constraints hold ---which are reified at the value level via
    the uninsightful ~refl~-exivity proof.
    #+begin_src agda  :tangle Context_examples.agda
pattern ‚ü®_,_‚ü© V E = (V , E , tt)

comap‚ÇÄ' : ‚àÄ {A B : Set}
      ‚Üí (f : A ‚Üí B)
      ‚Üí Œ£ G ‚à∂ Graph :kind ‚Äµrecord ‚Ä¢ Field 0 G ‚â° B
      ‚Üí Œ£ G ‚à∂ Graph :kind ‚Äµrecord ‚Ä¢ Field 0 G ‚â° A
comap‚ÇÄ' {A} {B} f (‚ü® .B , edgs ‚ü© , refl) = (A , (Œª a‚ÇÅ a‚ÇÇ ‚Üí edgs (f a‚ÇÅ) (f a‚ÇÇ)) , tt) , refl
        #+end_src
    /Without redefining graphs/, we can phrase the definition at the ‚Äòtypeclass‚Äô
    level ---i.e., records parameterised by the vertices. This form is not only
    clearer and easier to implement at the value-level, it also makes it clear
    that we are ‚Äúpulling back‚Äù the vertex type and so have also shown graphs are
    closed under reducts.
        #+begin_src agda   :tangle Context_examples.agda
pattern ‚ü®_‚ü©¬π E = (E , tt)

-- Way better and less awkward!
comap' : ‚àÄ {A B : Set}
     ‚Üí (f : A ‚Üí B)
     ‚Üí (Graph :kind ‚Äµtypeclass) B
     ‚Üí (Graph :kind ‚Äµtypeclass) A
comap' f ‚ü® edgs ‚ü©¬π = ‚ü® (Œª a‚ÇÅ a‚ÇÇ ‚Üí edgs (f a‚ÇÅ) (f a‚ÇÇ)) ‚ü©¬π
    #+end_src

    #+latex: \vspace{1ex}\noindent

    Excellent, we can unbundle at will.
** more Agda
*** COMMENT ‚ü®ùëµùë∂‚ü© Calculational Proofs ---Making Use of Unicode Mixfix Lexemes
   School math classes show calculations as follows.
   # #
   #+begin_parallel
   #+BEGIN_EXAMPLE agda
  p
‚â°‚ü® reason why p ‚â° q ‚ü©
  q
‚â°‚ü® reason why q ‚â° r ‚ü©
  r
‚àé
   #+END_EXAMPLE

 {{{code( Calculational Proof Syntax Embedded As Proof Forming Functions )}}}
   #+BEGIN_SRC agda
infixr 5 _‚â°‚ü®_‚ü©_
infix  6 _‚àé

_‚àé : {A : Set} (a : A) ‚Üí a ‚â° a
_ ‚àé = refl

_‚â°‚ü®_‚ü©_ : {A : Set} (p {q r} : A)
     ‚Üí p ‚â° q ‚Üí q ‚â° r ‚Üí p ‚â° r
_ ‚â°‚ü® refl ‚ü© refl = refl
   #+END_SRC
   #+end_parallel
   #+latex: \vspace{-1em}
   # #
   We can treat these pieces as Agda /mixfix/ identifiers and associate to the
   right to obtain: ~p ‚â°‚ü® reason‚ÇÅ ‚ü© (q ‚â°‚ü® reason‚ÇÇ ‚ü© (r ‚àé))~. We can code this up,
   as show above on the right.

*** COMMENT ‚ü®ùëµùë∂‚ü© Interacting with the real world ---Compilation, Haskell, and IO
    :PROPERTIES:
    :header-args: :tangle "CompilingAgda.agda" :comments org
    :CUSTOM_ID: agda-interacting-with-the-real-world
    :END:

   # C-c C-v C-t tangles the following code into CompilingAgda.agda.
   # Then we may compile the result using:
   # (shell-command "NAME=CompilingAgda; time agda --compile $NAME.agda; ./$NAME")
   #
   # Btw: (find-file "./MAlonzo/Code/CompilingAgda.hs")

   In order to be useful, a program must interact with the real world. Agda
   relegates the work to Haskell. The only concept here that is used in later
   sections will be Agda's [[gls:do-notation][do-notation]], and so the purpose of this section is to
   demonstrate how to use it in a real scenario.

   An Agda program module containing a ~main~ function is compiled into a standalone
   executable with ~agda --compile myfile.agda~. If the module has no main file, use
   the flag ~--no-main~. If you only want the resulting Haskell, not necessarily an
   executable program, then use the flag ~--ghc-dont-call-ghc~.

   The type of ~main~ should be ~Agda.Builtin.IO.IO A~, for some ~A~; this is just a
   proxy to Haskell's ~IO~. We may ~open import IO.Primitive~ to get /this/ ~IO~, but this
   one works with costrings, which are a bit awkward. Instead, we use the standard
   library's wrapper type, also named ~IO~. Then we use ~run~ to move from ~IO~ to
   ~Primitive.IO~; conversely one uses ~lift~.

   # +latex: \begin{minipage}[c]{0.45\linewidth}
 {{{code( Necessary Imports )}}}
 #+ATTR_LATEX: :options fontsize=\tiny
   #+BEGIN_SRC agda
open import Data.Nat                 using (‚Ñï; suc)
open import Data.Nat.Show            using (show)
open import Data.Char                using (Char)
open import Data.List as L           using (map; sum; upTo)
open import Function                 using (_$_; const; _‚àò_)
open import Data.String as S         using (String; _++_; fromList)
open import Agda.Builtin.Unit        using (‚ä§)
open import Codata.Musical.Colist    using (take)
open import Codata.Musical.Costring  using (Costring)
open import Data.BoundedVec.Inefficient as B using (toList)
open import Agda.Builtin.Coinduction using (‚ôØ_)
open import IO as IO                 using (run ; putStrLn ; IO)
import IO.Primitive as Primitive
   #+END_SRC
   # +latex: \end{minipage} % no space if you would like to put them side by side
   # +latex: \begin{minipage}[c]{0.35\linewidth}
   #+begin_quote org
   /Agda has *no* primitives for side-effects, instead it allows arbitrary/
   /Haskell functions to be imported as axioms, whose definitions are only/
   /used at run-time./
   #+end_quote
   # +latex: \end{minipage}

   Agda lets us use ~do~-notation as in Haskell. To do so, methods named ~_>>_~ and
   ~_>>=_~ need to be in scope ---that is all. The type of ~IO._>>_~ takes two ‚Äúlazy‚Äù
   IO actions and yield a non-lazy IO action. The one below is a homogeneously
   typed version.
 {{{code( Non-lazy Do-combinators )}}}
   #+BEGIN_SRC agda
infixr 1 _>>=_ _>>_

_>>=_ : ‚àÄ {‚Ñì} {Œ± Œ≤ : Set ‚Ñì} ‚Üí IO Œ± ‚Üí (Œ± ‚Üí IO Œ≤) ‚Üí IO Œ≤
this >>= f = ‚ôØ this IO.>>= Œª x ‚Üí ‚ôØ f x

_>>_ : ‚àÄ{‚Ñì} {Œ± Œ≤ : Set ‚Ñì} ‚Üí IO Œ± ‚Üí IO Œ≤ ‚Üí IO Œ≤
x >> y = x >>= const y
   #+END_SRC

   Oddly, Agda's standard library comes with ~readFile~ and ~writeFile~, but the
   symmetry ends there since it provides ~putStrLn~ but not [[https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#v:getLine][~getLine~]]. Mimicking
   the ~IO.Primitive~ module, we define /two/ versions ourselves as proxies for
   Haskell's ~getLine~ ---the second one below is bounded by 100 characters,
   whereas the first is not.
   {{{code( Postulating Foreign Haskell Functions )}}}
   #+BEGIN_SRC agda
postulate
  getLine‚àû : Primitive.IO Costring

{-# FOREIGN GHC
  toColist :: [a] -> MAlonzo.Code.Codata.Musical.Colist.AgdaColist a
  toColist []       = MAlonzo.Code.Codata.Musical.Colist.Nil
  toColist (x : xs) =
    MAlonzo.Code.Codata.Musical.Colist.Cons x (MAlonzo.RTE.Sharp (toColist xs))
#-}

{- Haskell's prelude is implicitly available; this is for demonstration. -}
{-# FOREIGN GHC import Prelude as Haskell #-}
{-# COMPILE GHC getLine‚àû  = fmap toColist Haskell.getLine #-}

-- (1)
-- getLine : IO Costring
-- getLine = IO.lift getLine‚àû

getLine : IO String
getLine = IO.lift
  $ getLine‚àû Primitive.>>= (Primitive.return ‚àò S.fromList ‚àò B.toList ‚àò take 100)
   #+END_SRC
   We obtain ~MAlonzo~ strings, then convert those to colists, then eventually lift
   those to the wrapper ~IO~ type.

   Let's also give ourselves Haskell's ~read~ method.
 {{{code( Postulating Haskell's ‚Äòread‚Äô )}}}
   #+BEGIN_SRC agda
postulate readInt  : L.List Char ‚Üí ‚Ñï
{-# COMPILE GHC readInt = \x -> read x :: Integer  #-}
   #+END_SRC

   Now we write our ~main~ method.
 {{{code( An Agda Program: Triangle Numbers with IO )}}}
   #+BEGIN_SRC agda
main : Primitive.IO ‚ä§
main = run do putStrLn "Hello, world! I'm a compiled Agda program!"

              putStrLn "What is your name?"
              name ‚Üê getLine

              putStrLn "Please enter a number."
              num ‚Üê getLine
              let tri = show $ sum $ upTo $ suc $ readInt $ S.toList num
              putStrLn $ "The triangle number of " ++ num ++ " is " ++ tri

              putStrLn "Bye, "
              -- IO.putStrLn‚àû name  {- If we use approach (1) above. -}
              putStrLn $ "\t" ++ name
   #+END_SRC
   For example, the 12·µó ∞ [[https://en.wikipedia.org/wiki/Triangular_number][triangle number]] is $\sum_{i=0}^{12} i = 78$.
   Interestingly, when an integer parse fails, the program just crashes.

   Calling this file ~CompilingAgda.agda~, we may compile then run it with:
 {{{code( Compiling The Program )}}}
   #+BEGIN_SRC shell :tangle no
NAME=CompilingAgda; time agda --compile $NAME.agda; ./$NAME
   #+END_SRC

   The very first time you compile may take ‚àº80 seconds since some prerequisites
   need to be compiled, but future compilations are within ‚àº10 seconds. The
   generated Haskell source lives under the newly created MAlonzo directory;
   namely ~./MAlonzo/Code/CompilingAgda.hs~.

**** COMMENT *Debugging*
   - When compiling you may see an error ~Could not find module ‚ÄòNumeric.IEEE‚Äô~.
   - Simply open a terminal and install the necessary Haskell library:
 {{{code( ??? )}}}
     #+BEGIN_SRC shell :tangle no
cabal install ieee754
   #+END_SRC

*** COMMENT ‚ü®ùëµùë∂‚ü© Absurd Patterns

    <<sec:absurd_pattern>>
 #+latex: \label{sec:absurd_pattern}

    When there are no possible constructor patterns, we may match on the pattern
    ~()~ and provide no right hand side ---since there is no way anyone could
    provide an argument to the function. For example, here we define the datatype
    family of numbers smaller than a given natural number: ~fzero~ is smaller than
    ~suc n~ for any ~n~, and if ~i~ is smaller than ~n~ then ~fsuc i~ is smaller than ~suc
    n~.

    #+begin_parallel
 {{{code( Finite Types )}}}
    #+BEGIN_SRC agda
{- Fin n  ‚âÖ  numbers i with i < n -}
data Fin : ‚Ñï ‚Üí Set where
  fzero : {n : ‚Ñï} ‚Üí Fin (suc n)
  fsuc  : {n : ‚Ñï}
        ‚Üí Fin n ‚Üí Fin (suc n)
    #+END_SRC
    #+latex: \columnbreak

    For each $n$, the type ~Fin n~ contains $n$ elements;
    e.g., ~Fin 2~ has elements ~fsuc fzero~ and ~fzero~,
    whereas ~Fin 0~ has no elements at all.

    #+end_parallel
    #+latex:  \vspace{-1em}

    Using this type, we can write a safe indexing function that never ‚Äúgoes out
 of bounds‚Äù.
 {{{code( Safe Indexing )}}}
    #+BEGIN_SRC agda
_‚Äº_ : {A : Set} {n : ‚Ñï} ‚Üí Vec A n ‚Üí Fin n ‚Üí A
[] ‚Äº ()
(x ‚à∑ xs) ‚Äº fzero  = x
(x ‚à∑ xs) ‚Äº fsuc i = xs ‚Äº i
    #+END_SRC

    When we are given the empty list, ~[]~, then ~n~ is necessarily ~0~, but there is
    no way to make an element of type ~Fin 0~ and so we have the absurd pattern.
    That is, since the empty type ~Fin 0~ has no elements there is nothing to
    define ---we have a definition by /no cases/.

    Logically [[https://en.wikipedia.org/wiki/Principle_of_explosion][‚Äúanything follows from false‚Äù]] becomes the following program[fn:6]:
 {{{code( Ex Falso Quod Libet )}}}
    #+BEGIN_SRC agda
data False : Set where

magic : {Anything-you-want : Set} ‚Üí False ‚Üí Anything-you-want
magic ()
    #+END_SRC

    Starting with ~magic x = ?~ then casing on ~x~ yields the program above since
    there is no way to make an element of ~False~ ---we needn't bother with a
    result(ing right side), since there's no way to make an element of an empty
    type.

*** COMMENT ‚ü®ùëµùë∂‚ü© Other Agda features

   #+begin_tiny
 {{{code( ??? )}}}
   #+BEGIN_SRC agda :tangle AgdaReview.agda
module AgdaReview where

open import Level using (Level)
open import Data.Nat
open import Data.Bool hiding (_<?_)
open import Data.List using (List; []; _‚à∑_; length)
   #+END_SRC
   #+end_tiny
   #+latex: \columnbreak

   + Different types can have the same constructor names.

   + Mixifx operators can be written prefix by having all underscores mentioned; e.g.,
     ~x ‚à∑ xs~ is the same as ~_‚à∑_ x xs~.

   + In a function definition, if you don't care about an argument
     and don't want to bother naming it, use ~_~ with whitespace around it.
     This is the ‚Äúwildcard pattern‚Äù.

**** Mechanically Moving from ~Bool~ to ~Set~ ---Avoiding ‚ÄúBoolean Blindness‚Äù

      #+latex: \hspace{-1.3em}
    In Agda we can represent a proposition as a type whose elements denote proofs
    of that proposition. Why would you want this? Recall how awkward it was to request
    an index be ‚Äúin bounds‚Äù in the ~find~ method, but it's much easier to encode this
    using ~Fin~ ---likewise, ~head'~ obtains a more elegant type when the non-empty precondition
    is part of the datatype definition, as in ~head~.

    Here is a simple recipe to go from Boolean functions to inductive datatype families.
    0. Write the Boolean function.
    1. Throw away all the cases with right side ~false~.
    2. Every case that has right side ~true~ corresponds to a new nullary constructor.
    3. Every case that has $n$ recursive calls corresponds to an ~n~-ary constructor.

    Following these steps for ~_<‚ÇÄ_~, from the left side of the page, gives us:

 {{{code( ??? )}}}
    #+BEGIN_SRC agda
data _<‚ÇÅ_ : ‚Ñï ‚Üí ‚Ñï ‚Üí Set where
  z< : {y : ‚Ñï} ‚Üí zero <‚ÇÅ y
  s< : {x y : ‚Ñï} ‚Üí x <‚ÇÅ y ‚Üí suc x <‚ÇÅ suc y
    #+END_SRC

    To convince yourself you did this correctly, you can prove ‚Äúsoundness‚Äù
    ---constructed values correspond to Boolean-true statements---
    and ‚Äúcompleteness‚Äù ---true things correspond to terms formed from constructors.
    The former is ensured by the second step in our recipe!

 {{{code( ??? )}}}
    #+BEGIN_SRC agda
completeness : {x y : ‚Ñï} ‚Üí isTrue (x <‚ÇÄ y) ‚Üí x <‚ÇÅ y
completeness {x}     {zero}  ()
completeness {zero}  {suc y} p = z<
completeness {suc x} {suc y} p = s< (completeness p)
    #+END_SRC

    We began with ~completeness {x} {y} p = ?~, then we wanted to case on ~p~
    but that requires evaluating ~x <‚ÇÄ y~ which requires we know the shapes of ~x~ and ~y~.
    /The shape of proofs usually mimics the shape of definitions they use/; e.g., ~_<‚ÇÄ_~ here.

**** Preconditions as proof-object arguments

    Sometimes it is not easy to capture a desired precondition in the types, and
    an alternative is to use the following ~isTrue~-approach of passing around
    explicit proof objects.

    #+begin_parallel
 {{{code( ??? )}}}
    #+BEGIN_SRC agda
{- An empty record has only
   one value: record {} -}
record True : Set where

isTrue : Bool ‚Üí Set
isTrue true  = True
isTrue false = False
    #+END_SRC
    #+latex: \columnbreak
 {{{code( ??? )}}}
    #+BEGIN_SRC agda
_<‚ÇÄ_ : ‚Ñï ‚Üí ‚Ñï ‚Üí Bool
_ <‚ÇÄ zero      = false
zero <‚ÇÄ suc y  = true
suc x <‚ÇÄ suc y = x <‚ÇÄ y
    #+END_SRC
    #+end_parallel
    #+latex: \vspace{-1em}

 {{{code( ??? )}}}
    #+BEGIN_SRC agda
find : {A : Set} (xs : List A) (i : ‚Ñï) ‚Üí isTrue (i <‚ÇÄ length xs) ‚Üí A
find [] i ()
find (x ‚à∑ xs) zero pf    = x
find (x ‚à∑ xs) (suc i) pf = find xs i pf

head' : {A : Set} (xs : List A) ‚Üí isTrue (0 <‚ÇÄ length xs) ‚Üí A
head' [] ()
head' (x ‚à∑ xs) _ = x
    #+END_SRC

    Unlike the ~_‚Äº_~ definition, rather than there being no index into the empty list,
    there is no proof that a natural number ~i~ is smaller than 0.
** COMMENT ‚ü®Incorporate-parts/delete‚ü© Preliminary Research

 The homogeneous treatment of structuring mechanisms is herein presented using a prototype
 developed using the user-friendly Emacs application framework by means of textual expansion,
 the details of which are largely uninteresting ---suffice it to say, the code is tremendously terse.
 In this section we demonstrates that packaging concepts differ only in their use, leading to a uniform
 syntax of which first-class records are an instance and so the resulting system is homoiconic in nature.
 We introduce fictitious syntax, mostly in red, with its intended Agda elaboration in blue
 ---the users write the red and expect it to behave like the blue; no ‚Äúcode generation‚Äù transpires.

 The reader is advised to remember that the value of a prototype is in the guidance it provides,
 not the implementation itself nor any of its design decisions ---such as using strings in meta-programming
 scenarios. In other words, for the reader, portions of this section may serve as an exercise in foresight and patience.
 ( A brief demonstration of the prototype may be viewed at https://www.youtube.com/watch?v=NYOOF9xKBz8 .)

 :Minimality:
 A prime guiding design decision is
 /try to avoid making any decisions, including unconscious restrictions, unless deemed necessary!/
 :End:

 The initiated reader will quickly notice that our package formers are just theory presentations
 ---a list of name-type pairs. The chosen phrasing is due to the target audience, DTL programmers.
 We are not committed to the name, but unlike the overloaded ‚Äòmodule‚Äô, ‚Äòpackage former‚Äô is a good
 new name without too many meanings. We have not provided full semantics for package formers, but
 we have provided concrete well-defined elaborations to communicate the intent: A package former
 is akin to a type former, it is ‚Äòincomplete‚Äô and does not define a concrete package until a certain
 tag is provided.
 It is part of the thesis effort to investigate which features of our proposed package formers
 break, or become limited, when considered with other language constructs.

 The uniformity in syntax reduces the variety of sub-languages in a dependently-typed language
 by eliminating needless distinctions for notions of containers. The first subsection below
 addresses syntactic similarity, whereas the second tackles computing similarity,
 and we conclude with a brief discussion on foundational concerns.

*** First Observation: Syntactic Similarity for Containers

 Since the prototypical notion of packaging is that of records,
 which are value terms, all, necessarily succeeding, notions of packaging
 ought to be treated uniformly as value types.
 Consequently, variations on packaging should only be signalled by necessary
 keywords, and otherwise should be syntactically indistinguishable.
 That is to say, a ‚Äòvariation‚Äô is a tag identifying what particular
 form of module is desired, such as ~datatype~ for an algebraic data type
 with the declared fields as constructors, or as ~record~ to yield a record structure
 with constituents being the declared fields.

 For example, just as ~List~ is a type-former, we may declare a ‚Äòpackage former‚Äô:
 {{{code(Our first package former)}}}
 #+begin_src haskell
 PackageFormer TermP (v : Variation) : Set where
    Var : Int ‚Üí TermP v
    Add : TermP v ‚Üí TermP v ‚Üí TermP v
  #+end_src

 Note that a package former is just a sequence of names with types and,
 as will be demonstrated later, optional default types.
 It requires a particular ‚Äúinterpretation‚Äù ---possibly user-defined---,
 to produce some notion of package. This is signalled by the ~Variation~
 type, which for brevity contains ~data, record, typeclass~, and a few more
 that we will meet below.

 For example, the ~data~ variation of packaging gives us a
 free data type.
 {{{code(Free data type: Terms are integer variables and addition of terms)}}}
 #+begin_src haskell
TermData = TermP data
{-
‚âÖ  data TermData : Set where
     Var : Int ‚Üí TermData
     Add : TermData ‚Üí TermData ‚Üí TermData
-}
 #+end_src
 In the comment above, we indicate how our fictitious syntax is intended to be elaborated
 into current Agda syntax. Besides syntax, induction principles are also derived:
 Our envisioned system would be able to derive simple, tedious, uninteresting concepts;
 leaving difficult, interesting, ones  for humans to solve.
 For this type, below is the dependently typed eliminator, which in a DTL, corresponds to an induction
 principle.
 {{{code(Free data types also come with an induction principle)}}}
 #+begin_src haskell
{-
   term-data-elim : ‚àÄ {‚Ñì} {R : TermData ‚Üí Set ‚Ñì}
          ‚Üí (base : (n : Int) ‚Üí R (Var n))
          ‚Üí (ind  : ‚àÄ {s t} ‚Üí R s ‚Üí R t ‚Üí R (Add s t))
          ‚Üí (t : TermData) ‚Üí R t

   term-data-elim base ind (Var n)   = base n
   term-data-elim base ind (Add s t) = ind rs rt
      where rs = term-data-elim base ind s
        rt = term-data-elim base ind t
-}
 #+end_src

 The type of the package former, for now, could simply be ~Set~
 ---c.f., the commented-out elaboration which declares ~TermData ‚à∂ Set~.
 However, if we permit a sufficiently small subtyping system, we
 may find it desirable to have the type of a package former be itself
 a package former! Moreover, if package former ~t~ has type package former ~t'~,
 then the user should be able to use ~t~ at the levels ~t ‚à∂ s~
 without too much overhead, where ~s~ is any subtype of ~t~ with ~Set~ being a minimal
 such subtype. These thoughts are hurried and it is the purpose of the thesis
 to investigate what is the appropriate route.

 It is often the case that one begins working with a ~record~ of useful semantic
 data, but then, say, for proof automation, may want to use the associated ~datatype~
 for syntax. The latter should be mechanically derivable, and this is what we aim
 provide with our package formers.
 We will not delve into the relationship between free data types and how, for example,
 their associated catamorphism is necessarily also an interpreter
 ---in the programming languages sense.
 The reader is invited to consult a reference citet:cats_logic_shulman.

 We shall not discuss polymorphism along variations, the ~v~ components above,
 as it is orthogonal to our immediate goals. For example, ~TermP~ could have a field typed
 {{{newline}}} \texttt{TermP (f v) ‚Üí TermP (g v) ‚Üí TermP v},
 where ~f~ and ~g~ are operations on variations.
 Nonetheless, this is a feature that one should be aware of.

 The remaining items instantiate package formers for the usual
 common uses. Including notions of records in item 1;
 an algorithmic sketch underlying the examples of item 1 is presented in item2;
 union types and external, second-class, modules in item 3;
 package former polymorphism in item 4;
 operating on package formers and inheritance in items 5 and 6; then discuss
 how package formers handle the diamond problem in item 7.
 Finally, we close in item 8 by discussing a problem not generally found
 in pedestrian languages and how it is solved using package formers.

**** The Generality of Package Formers ---Products

 To demonstrate the generality of the notion of package formers we shall demonstrate
 how other common forms could be ‚Äòderived‚Äô from the single declaration above.
 It is to be noted that for such a small example, such derived code may be taken for
 granted, however for much larger theories ---for example, a ‚Äúfield‚Äù comes with more than
 20 fields--- the ability to derive different perspectives in a consistent fashion
 is indispensable; especially when the package is refactored.
 More realistically, a symmetric rig groupoid uses about 212 coherence laws citet:rig_computation,
 for which case-splitting, to perform proofs, yields [[https://github.com/JacquesCarette/pi-dual][over 200 goals]] thereby making
 metaprogramming a tempting approach.

 :counting_field_componenets:
 field ‚âÖ ablean group ‚ü∂ Carrier, op, inv, unit, assoc, 2 unit-laws, 2 inverse-laws, comm-law ‚ü∂ 10 laws
       multiplicative monoid ‚ü∂ Carrier, op, unit, assoc, 2 unit-laws ‚ü∂ 6 laws
       the above two carries are identical  ‚ü∂ 1 law
       distributively laws   ‚ü∂ 2 laws
       integrity & div-op & non-zero division ‚ü∂ 3 laws

 Total ‚ü∂ 22 laws
 :end:

 # {{{code(Records; a magma with the integers)}}}
 {{{code(Records)}}}
 #+begin_src haskell
-- An instance of  TermRecord should have a carrier type
-- containing the integers, ‚ÄòVar‚Äô, and supports some binary operation, ‚ÄòAdd‚Äô.
TermRecord = TermP record
{-
‚âÖ   record TermRecord  : Set where
      field
    Carrier : Set
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier
-}
 #+end_src
 In the previous  and following invocations, the name ~Carrier~ is a system internal, for now,
 and can easily be ~renamed~ ---as will be demonstrated later on.
 For now, we adhere to a single-sorted stance: Unless indicated otherwise, a ~Carrier~ will always
 be included. An example of a two-sorted algebraic structure, graphs, is demonstrated at the end of this subsection.

 Built-in names, such as ~Carrier~, are generally not ideal. For example, a machine may provide the
 names ~FourLeggedFeline~ and ~CommutativeIdempotentMonoid~ where a human may prefer ~Cat~ and ~JoinSemilattice~ instead.
 As such, the resulting system, would accept ‚Äòrenaming‚Äô functions to generate names. For now, we mostly limit
 such an approach for brevity.

 {{{code(Haskell-style typeclasses ---or Scala-like traits)}}}
 #+begin_src haskell
TermOn = TermP typeclass
{-
‚âÖ   record TermOn (Carrier : Set) : Set where
      field
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier
-}
 #+end_src
 {{{code(A pair of functions \emph{on} a declared carrier type)}}}
 #+begin_src haskell
TermFunctionsOn = TermP tuples
{-
TermFunctionsOn : Set ‚Üí Set
TermFunctionsOn C = (Int ‚Üí C) √ó (C ‚Üí C ‚Üí C)
-}
 #+end_src
 {{{code(Or the carrier is existential)}}}
 #+begin_src haskell
TermFunctions = TermP Œ£
-- ‚âÖ  TermFunctions  =  Œ£ C ‚à∂ Set  ‚Ä¢  Œ£ Var : Int ‚Üí C  ‚Ä¢  (C ‚Üí C ‚Üí C)
 #+end_src

 Let's show a more intricate yet desirable use.
 {{{code(The interface of non-empty lists, with a dedicated list)}}}
 #+begin_src haskell
PointedSemigroup = TermP record hiding (Var) renaming (Add to _‚®æ_)
             field
               Id     : Carrier
               ‚®æ-assoc : ‚àÄ x y z ‚Üí x ‚®æ (y ‚®æ z) ‚â° (x ‚®æ y) ‚®æ z
{-
‚âÖ   record PointedSemigroup  : Set‚ÇÅ where
      field
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    Id      : Carrier
    ‚®æ-assoc : ‚àÄ x y z ‚Üí x ‚®æ (y ‚®æ z) ‚â° (x ‚®æ y) ‚®æ z
-}
 #+end_src

**** Algorithmically Obtaining Elaborated Types
 We have discussed how the generic package formers elaborate
 ---each blue comment indicates a standalone isomorphic Agda rendition---,
 as such it should be unsurprising that the constituents of a package former
 are dependently typed functions /consuming/ each concrete variation in
 its traditional fashion. Let's clarify this idea further.

 {{{code(Our example package former)}}}
 #+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
   Var : Int ‚Üí TermP v
   Add : TermP v ‚Üí TermP v ‚Üí TermP v
 #+end_src

 The ‚Äòtype‚Äô of the first item, for example, is as follows
 ---where ~TermP v~ is rewritten using the above introduced names
 for the sake of clarity.
 {{{code(The types of a constituents of a package former)}}}
 #+begin_src haskell
Var : (v : Variation) ‚Üí Set

{- Datatype constructor -}
Var datatype   =  Int ‚Üí TermData
{- Dependent projection -}
Var record     =  (œÑ : TermRecord) ‚Üí Int ‚Üí TermRecord.Carrier œÑ
Var Œ£          =  (œÑ : TermFunctions) ‚Üí Int ‚Üí proj‚ÇÅ œÑ
{- Parameter of a constraint -}
Var typeclass  =  ‚àÄ{C} {{_ : TermOn C}} ‚Üí Int ‚Üí C
Var tuples     =  ‚àÄ{C} ‚Üí TermFunctionsOn C ‚Üí Int ‚Üí C
‚ãØ
 #+end_src

 An initial glance suggests that this is all ad-hoc; let us demonstrate that
 this is not the case. Suppose there were a method ~ùíØ~ to obtain the user-provided types of
 constituents; e.g., the given ~Var ‚à∂ Int ‚Üí TermP v~ is indistinguishable from {{{newline}}}  ~Var ‚à∂ ùíØ ‚ÄúVar‚Äù (TermP v)~.
 {{{code( Obtaining User-Provided Types ---Under the hood )}}}
 #+begin_src haskell
Constituent = String -- Draft idea, not ideal.

-- ‚ÄúA ‚ü®n‚ü©‚Üí B  ‚âà  A ‚Üí ‚ãØ ‚Üí A ‚Üí B‚Äù with n-many A's.
_‚ü®_‚ü©‚Üí_ : Set ‚Üí ‚Ñï ‚Üí Set ‚Üí Set
A ‚ü® zero   ‚ü©‚Üí B  =  B
A ‚ü® succ n ‚ü©‚Üí B  =  A ‚Üí (A ‚ü® n ‚ü©‚Üí B)

-- Constituents of package formers give rise to ‚ÄúSet ‚ü®n‚ü©‚Üí Set‚Äù functions.
ùíØ : {P : PackageFormer} ‚Üí Constituent P ‚Üí Set ‚ü® arity P ‚ü©‚Üí Set
ùíØ ‚ÄúVar‚Äù X  =  Int ‚Üí X
ùíØ ‚ÄúAdd‚Äù X  =  X ‚Üí X ‚Üí X
 #+end_src
 It is now trivial to reify the above prescription for ~Var~ in a uniformly fashion
 ---namely, ~Var = ùìâùìéùìÖùíÜ ‚ÄúVar‚Äù~.
 {{{code( Providing User-Facing Types ---Under the hood )}}}
 #+begin_src haskell
ùìâùìéùìÖùíÜ : Constituent ‚Üí Variation ‚Üí Set
ùìâùìéùìÖùíÜ c v@datatype  = ùíØ c (TermP v)
ùìâùìéùìÖùíÜ c v@record    = (œÑ : TermP v) ‚Üí ùíØ c ((TermP v).Carrier œÑ)
ùìâùìéùìÖùíÜ c v@Œ£         = (œÑ : TermP v) ‚Üí ùíØ c (proj‚ÇÅ œÑ)
ùìâùìéùìÖùíÜ c v@typeclass = ‚àÄ{C} {{_ : TermP v C}} ‚Üí ùíØ c C
ùìâùìéùìÖùíÜ c v@tuples    = ‚àÄ{C} ‚Üí TermP v C ‚Üí ùíØ c C
‚ãØ
 #+end_src
 For example, invoking this approach we find that ~Add~, on ~TermRecord~'s, is typed {{{newline}}}
 ~ùìâùìéùìÖùíÜ ‚ÄúAdd‚Äù record~, which may be rewritten as {{{newline}}}
 ~(œÑ ‚à∂ TermRecord) ‚Üí TermRecord.Carrier œÑ ‚Üí TermRecord.Carrier œÑ ‚Üí TermRecord.Carrier œÑ~.
 That is, as expected, ~Add~ on records consumes a record value then acts as a binary
 operation on the carrier of said record value. Likewise, we invite the reader
 to check that ~Add~ on algebraic datatype ~TermData~ is typed as a binary constructor.

 Users have access to the elaborated types.
 {{{code(Providing User-Facing Types)}}}
 #+begin_src haskell
 TermP.Var : ‚àÄ{v} ‚Üí ùìâùìéùìÖùíÜ ‚ÄúVar‚Äù v
 TermP.Add : ‚àÄ{v} ‚Üí ùìâùìéùìÖùíÜ ‚ÄúAdd‚Äù v
 #+end_src
 This is particularly useful when one wants to extract such types for re-use elsewhere.
 {{{code(Extracting a single ---possibly complicated--- signature)}}}
 #+begin_src haskell
ListBop = TermP.Add datatype ‚àò List
{-
‚âÖ  ListBop : Set ‚Üí Set
   ListBop C = (List C ‚Üí List C ‚Üí List C)
-}

ConstrainedBop : (Set ‚Üí Set) ‚Üí Set
ConstrainedBop constraint  = TermP.Add typeclass using constraint
{-
‚âÖ ConstrainedBop constraint  =  ‚àÄ{C} ‚Üí constraint C ‚Üí C ‚Üí C ‚Üí C

-- N.B., this would not elaborate without the ‚Äúusing‚Äù.
-- Semantically, ‚ÄúP.x y using z = (P.x y)[P v ‚âî z]‚Äù
-- ‚îÄthe ‚Äúv‚Äù appears from ‚Äú‚àÄ{v}‚Äù above.
-}

SetoidBop = TermP.Add record using Setoid
{-
‚âÖ SetoidBop : Setoid ‚Ñì‚ÇÄ ‚Ñì‚ÇÄ ‚Üí Set
  SetoidBop S = Setoid.Carrier C ‚Üí Setoid.Carrier C ‚Üí Setoid.Carrier C

-- N.B., this would not elaborate if ‚ÄúSectoid.Carrier‚Äù were undefiend.
-}
 #+end_src
 These examples open a flurry of problems.

 At this stage, it is sufficient to have observed what could possibly
 be performed and that it is not without burden.
 We will not attempt to clarify any problem nor propose any solution;
 the thesis effort will contend with these matters further.

**** The Generality of Package Formers ---Sums & Modules

 Thus far we have only discussed products; however
 the proposed general notion of containers should also produce sum types
 and be used in modules ---which are just packages.
 {{{code(At ‚Äúleast one‚Äù of the operations is desired on a declared carrier type)}}}
 #+begin_src haskell
TermFunctionsSumOn = TermP sum
-- ‚âÖ  TermFunctionsSumOn C  =  (Int ‚Üí C) ‚äé (C ‚Üí C ‚Üí C)
 #+end_src

 In general, this yields a disjoint collection of declarations
 where each declaration is itself a Œ£ consisting of the context necessary
 to ensure that the operations are well-defined.

 For modules,
 {{{code(Using our package former \emph{within} another package)}}}
 #+begin_src haskell
  PackageFormer MyDriver (t : TermP record renaming (Carrier to C)) : Set where ‚ãØ
-- ‚âÖ module MyDriver (t : TermRecord[Carrier ‚âî C]) where ‚ãØ
-- ‚âÖ module MyDriver (C : Set) (Var : Int ‚Üí C) (Add : C ‚Üí C ‚Üí C) where ‚ãØ
 #+end_src
 At least two ‚Äòfree‚Äô invocation notations ought to be supplied:
 1. ~MyDriver t~
 2. ~MyDriver type varOp addOp~

 Multifaceted invocations provide a common use case: No overhead to pack or unpack
 the constituents of a type former so the sole purpose of an invocation.
 However, the pragmatic feasibility of such an approach is unclear at this stage.

**** Novel Genericity: ‚ÄòPackage Polymorphism‚Äô

 We have a sufficient number of elaborations thus far to demonstrate
 that the notion of package formers is not without merit.
 It is now an appropriate moment to address an elephant in the room:
 /The phrase ~TermP v~ semantically refers to which type?/

 If ~v = datatype~ then ~TermP v~
 refers to the associated algebraic datatype.
 If ~v = record~, then there are at least two ways to interpret ~TermP v~:
 As either the record type or as the carrier of a record value.
 Likewise for other variations. For now, we settle with a monadic-like interpretation:
 We write ~do œÑ ‚Üê TermP v; ‚ãØ~ whenever we wish to refer to the underlying carrier of a concrete
 package former. Loosely put,
 {{{code(Syntax ---Under the hood )}}}
 #+begin_src haskell
do œÑ ‚Üê TermP v; b  ‚âà  v ‚ï± (Œª œÑ ‚Üí b)

v@datatype  ‚ï± f  =  f (TermP v)
v@record    ‚ï± f  =  ‚àÄ(œÑ : TermP v) ‚Üí f ((TermP v).Carrier œÑ)
v@Œ£         ‚ï± f  =  ‚àÄ(œÑ : TermP v) ‚Üí f (proj‚ÇÅ œÑ)
v@typeclass ‚ï± f  =  ‚àÄ{œÑ} {{_ : TermP v œÑ}} ‚Üí f œÑ
v@tuples    ‚ï± f  =  ‚àÄ{œÑ} ‚Üí TermP v œÑ ‚Üí f œÑ
 #+end_src
 The ‚Äòover‚Äô notation, ~_‚ï±_~, assumes ~f~ is a function acting on types;
 however, this is not necessary, if the ~‚àÄ~ were replaced with ~Œª~, then
 the result would be a term expression. This is yet another opportunity for investigation
 during the thesis effort. Moreover, there is the possibility of providing
 ‚Äúimplicit counterparts‚Äù to these variations,; e.g., for ~tuples~ one may want
 ~‚àÄ{œÑ} {_ ‚à∂ TermP v œÑ} ‚Üí f œÑ~ instead, which could be variation, say, ~tuples-imp~.
 Likewise, we may want notation ~do-Œ£~ to replace {{{newline}}} ~‚àÄ ‚ãØ ‚Üí ‚ãØ~ with ~Œ£ ‚ãØ ‚Ä¢ ‚ãØ~.

 Unsurprisingly, this approach subsumes our earlier typing elaboration: {{{newline}}}
 ~ùìâùìéùìÖùíÜ c v  = do œÑ ‚Üê TermP v; ùíØ c œÑ~.
 More concretely, for example, a notion of ‚Äòdepth‚Äô for terms may have type
 ~‚àÄ {v} ‚Üí  do œÑ ‚Üê TermP v; (œÑ ‚Üí ‚Ñï)~ ---a function
 that takes a package and yields a number.
 In the case of ~v = record~, such a function actually takes /two/
 items: The first being a record value, the second being an element of
 the carrier of that record value. In the case of ~v = typeclass~,
 the function takes an argument found by instance search. Likewise,
 for the remaining variations.

 Let us now turn to an example of a function operating on the above many, and all, variations of such packages.
 This example may appear contrived, yet the power of this form of polymorphism
 appears at the end of this subsection where one programs towards a /particular/
 interface and has the result /generalised/ to other variations
 ---a prime use case is to code against a typeclass representation and use the
 same methods on bundled records.
 {{{code(‚ÄúTimes Loop‚Äù: Iterate an action $n$ times. )}}}
 #+begin_src haskell
-- Suppose I have the following syntactic construction.
repeat : TermData ‚Üí ‚Ñï ‚Üí TermData
repeat t Zero      =  Var 0
repeat t (Succ n)  =  Add t (repeat t n)

-- Here is its semantic counterpart.
run : (œÑ : TermRecord) ‚Üí TermRecord.Carrier œÑ ‚Üí ‚Ñï ‚Üí TermRecord.Carrier œÑ
run œÑ t Zero      =  TermRecord.Var œÑ 0
run œÑ t (Succ n)  =  TermRecord.Add œÑ t (run œÑ t n)

-- Which is merely multiplication for the naturals.
_√ó_ : ‚Ñï ‚Üí ‚Ñï ‚Üí ‚Ñï
t √ó Zero     = Zero
t √ó (Succ n) = t + (t √ó n)
 #+end_src

 The first two are instances of a package former, and it is not diffcult to construe the naturals as the carrier of a package former.
 After which, we should be able to write one generic function, by writing according to the pacakge former as the interface.
 {{{code(‚ÄúTimes Loop‚Äù: Iterate an action $n$ times. )}}}
 #+begin_src haskell
instance
  ‚ÑïTerms : TermOn ‚Ñï
  ‚ÑïTerms = record {Var = Œª n ‚Üí 0; Add = _+_}

{- IsConsumer is defined below; ignore for now. -}
exp : ‚àÄ{v} {{_ : IsConsumer v}}  ‚Üí  do œÑ ‚Üê TermP v; œÑ ‚Üí ‚Ñï ‚Üí œÑ
exp t Zero     = Var 0
exp t (Succ n) = Add t (exp t n)
 #+end_src
 For example, we immediately obtain an instance for strings.
 {{{code(‚ÄúTimes Loop‚Äù: Iterate an action $n$ times. )}}}
 #+begin_src haskell
instance
  STerms : TermOn (List Char)
  STerms = record {Var = Œª n ‚Üí []; Add = _++_}

repeat-s = exp {v = typeclass}
{- Yields a whole family, which includes:

   repeat-s0 : {{TermOn (List Char)}} ‚Üí List Char ‚Üí ‚Ñï ‚Üí List Char
   repeat-s0 c Zero = []
   repeat-s0 c (Succ n) = c ++ repeat c n
-}
 #+end_src

 Now that's re-use! One function for many semantically distinct types.
 Notice that invoking ~exp~ on ~ListBop~ or ~TermFunctionsSumOn~ values is ill-typed
 since the mechanically verifiable constraint ~IsConsumer~ fails for those variations.
 Indeed, we may utilise a number of constraints on our package variations, such as
 the following.
 {{{code(Under the hood constraints)}}}
 #+begin_src haskell
data IsConsumer : Variation ‚Üí Set where
  Prod    : IsConsumer tuples
  DepProd : IsConsumer Œ£
  Data    : IsConsumer datatype
  Rec     : IsConsumer record
 #+end_src
 When a user defines a variation, they can signal whether it is a consumer or not.
 Likewise, one can indicate whether a variation should have ~Set~-valued operations
 on not. Note that a default mechanism could be implemented, but the user should
 continue to have the ability to enforce a particular discipline
 ---c.f., how ~C#~ allows the user to enforce the subtyping variance of a type former.
 {{{code(Under the hood constraints)}}}
 #+begin_src haskell
data HasConstructiveRelations : Variation ‚Üí Set where
  Prod    : HasConstructiveRelations tuples
  DepProd : HasConstructiveRelations Œ£
  Rec     : HasConstructiveRelations record
 #+end_src
 For example, ~data~ declarations cannot contain proofs of an arbitrary, but fixed, constructive relation
 without declaring it as a parameter to the type. Nonetheless, a user may want to be
 able to express syntactic statements about such proof terms
 ---say for proof automation--- and they should have the ability to toggle such
 a feature.

 A more important concern is the type of ~exp~: The phrase ~do œÑ ‚Üê TermP v; œÑ ‚Üí ‚Ñï ‚Üí œÑ~
 elaborates to different types according to the value of ~v~, whence to define ~exp~
 it seems necessary to actually pattern match on it to obtain a concrete type, which,
 for example, may contain more arguments. Case analysis on the possible packaging variations
 is far from ideal ---one might as well re-implement the definition only on the cases they
 want rather than all cases. The aim ---to be pursued further in the full thesis effort---
 is to invert the process: /Avoid case analysis in favour of a particularly convenient view./

 This is clarified best by referring to the current prototype language: Lisp.
 Since all data and methods in a lisp are essentially lists, when one prescribes
 how to project a value from a possibly nested datatype, then the same prescription
 essentially directs how to get to the location of that value and so we obtain
 /generic setters/. The following tiny example demonstrates this idea.
 {{{code(Generic Setters in Lisp)}}}
 #+begin_src emacs-lisp
(setq xs '("a" nil (x y z) 12))  ;; Heterogenous list of 4 items.
(cadar (cdaddr xs))              ;; ‚áí y
(setf (cadar (cdaddr xs)) 'woah) ;; xs ‚áí '("a" nil (x woah z) 12))
 #+end_src
 It is this flexibility that we aim to provide to users.
 They code not against a generic variation, but rather along one that
 is the most appropriate task at hand. We would hope that it would not
 be unrealistic to then mechanically derive the other forms from it.
 For example, suppose we wish to define retracts on magmas; rather than
 define the concept for each possible view, we define it once and obtain it
 for other views.
 {{{code(Example Algebra)}}}
 #+begin_src haskell
PackageFormer MagmaP (v : Variation) : Set where
  _‚®æ_ : MagmaP v ‚Üí MagmaP v ‚Üí MagmaP v

MagmaOn = MagmaP typeclass
AMagma  = MagmaP record
 #+end_src

 The ubiquity of magmas ---literally everywhere--- lends itself to recall that
 working with structure, possibly needless structure, may usurp the goals of
 proof citet:purposes_of_proof_detailed,purposes_of_proof: No mathematician
 would naturally say /let M be an algebra on set C/ when it suffices to say /let M
 be an algebra/; yet it may be /convenient/ to phrase problems more elegantly when
 the carrier set is mentioned explicitly
 citet:packaging_mathematical_structures.  On the other hand, having the carrier
 explicit for the sake of typeclass resolution relies on decidable type
 (non)equality; which may be resonable for a simplly typed language but for a
 DTL type normalisation generally requires non-trivial, non-constant,
 computation.  Anyhow, as mentioned earlier, bundling data is akin to currying
 or nesting quantifiers, yet is vastly more expensive since library designers
 generally commit early to one form or another; in this case {{{newline}}}
 ~AMagma ‚âÖ Œ£ C : Set ‚Ä¢ MagmaOn C~ and {{{newline}}} ~MagmaOn C ‚âÖ Œ£ M : AMagma ‚Ä¢
 M.Carrier ‚â° C~.  {{{code(Example Operation)}}}
 #+begin_src haskell
retract : ‚àÄ{S T} ‚Üí (f : S ‚Üí T) ‚Üí MagmaOn T ‚Üí MagmaOn S
retract f Tgt = record {_‚®æ_ = Œª x y ‚Üí f x ‚®æ f y} where open MagmaOn Tgt
 #+end_src
 Since ~MagmaOn = MagmaP v~ where ~v = typeclass~, we would ideally be able
 to derive the generic form ---possibly via case analysis.
 {{{code(Variation Generalisation)}}}
 #+begin_src haskell
retract-v : ‚àÄ{v}
      ‚Üí ‚àÄ {S T} (f : S ‚Üí T)
      ‚Üí  do   tgt ‚Üê MagmaP v; tgt ‚â° T  -- Intentionally no parens.
      ‚Üí (do-Œ£ src ‚Üê MagmaP v; src ‚â° S)
retract-v = ‚ãØ -- Unclear at this stage.
 #+end_src
 #  {{_ : HasCarrier v}}
 The record case could, semi-algorithmically, yield:
 {{{code(Verbose Record Case)}}}
 #+begin_src haskell
retract-v {record}  :  ‚àÄ {S T} (f : S ‚Üí T)
            ‚Üí  ‚àÄ (Tgt : AMagma) ‚Üí AMagma.Carrier Tgt ‚â° T
            ‚Üí  Œ£ (Src : AMagma) ‚Ä¢ AMagma.Carrier Src ‚â° S
retract-v {record} {S} {T} f Tgt refl =  record { Carrier = S
                        ;  _‚®æ_ = Œª x y ‚Üí f x ‚®æ f y }
                       , refl
                       where open AMagma Tgt
 #+end_src
 From a usability perspective the trivial proofs should not be present
 and so we need to algorithmically rewrite the above type to omit them, as follows.
 We would like to preserve the argument syntax, ~retract f Tgt~, that was originally declared.
 Unfortunately, for the record case, the type of ~f~ must refer to the types of the other magamas
 if we eliminate the trivial equalities. One possible workaround, as follows, is thus to simply provide
 a omit the tedious equality proofs since they can be found by instance search.
 {{{code(Usable Record Case)}}}
 #+begin_src haskell
retract-v {record}  :  ‚àÄ {S T} (f : S ‚Üí T)
            ‚Üí  ‚àÄ (Tgt : AMagma) ‚¶É_ : AMagma.Carrier Tgt ‚â° T ‚¶Ñ
            ‚Üí  proj‚ÇÅ (‚¶ÉŒ£‚¶Ñ Src : AMagma ‚Ä¢ AMagma.Carrier Src ‚â° S)
retract-v {record} f Tgt  = ‚ãØ

-- ‚Äú‚¶ÉŒ£‚¶Ñ (x : A) ‚Ä¢ B x‚Äù consists of a pair
-- where the second is found by instance search.
 #+end_src
 Notice that we also project at the end since we do not care about the tedious proof;
 nor should its existence be forced upon the user.

 Before we move on, there is particular reason we have deviated from our ~TermP~ example
 to the ~MagmaP~ concept. The ~datatype~ variation for ~MagmaP~ does not provide a way
 to speak of variables of the data type ---indeed ~MagmaP datatype~ has no closed terms,
 whence no terms at all. It is thus appropriate to now introduce a variation for
 syntactic terms /over/ some variable set which is then utilised by a mechanically
 derivable semantic function that is freely homomorphic.

 {{{code(From Syntax to Semantics)}}}
 #+begin_src haskell
MagmaTermsOn = MagmaP term-typeclass
{-
‚âÖ data MagmaTermsOn (Vars : Set) : Set where
    Var : Vars ‚Üí MagmaTermsOn Vars
    _‚®æ_  : MagmaTermsOn Vars ‚Üí MagmaTermsOn Vars ‚Üí MagmaTermsOn Vars

MagmaTermsOn-sem : ‚àÄ {v} {A}  ‚Üí  do œÑ ‚Üê MagmaP v;
                 (f : A ‚Üí œÑ) ‚Üí MagmaTermsOn A ‚Üí œÑ
MagmaTermsOn-sem {record} S f (Var x) = f x
MagmaTermsOn-sem {record} S f (l ‚®æ r)  = ll s‚®æ rr
  where _‚®æs_ = AMagma._‚®æ_ S
    ll = MagmaTermsOn-sem {record} S f l
    rr = MagmaTermsOn-sem {record} S f r
‚ãØ
-}
 #+end_src

 We will return to homomorphisms later on, for now it is important to notice
 that some variations may be useless ---as in the empty datatypes.
 There is also the opportunity to explore co-inductive datatypes.
**** Common Operations on Package Formers
 It is rather common in the record variation to have multiple instances being
 mentioned and it is desirable to refer to them with syntactically distinct yet appealing
 names ---such as using subscripts, primes, or other decoration. Moreover, a notion of
 homomorphism, structure-preservation, can usually be automatically inferred.

 Here we show what such declarations looks like, later we show that such things
 could be /user defined/.

 {{{code(An example package former)}}}
 #+begin_src haskell
PackageFormer TermRelP (v : Variation) : Set where
   Var : Int ‚Üí TermRelP v
   Add : TermRelP v ‚Üí TermRelP v ‚Üí TermRelP v
   Rel : TermRelP v ‚Üí TermRelP v ‚Üí Set  -- This time we have a relation as well.
 #+end_src
 {{{code(A prime-decorated package former)}}}
 #+begin_src haskell
Declare PackageFormer TermRelP (v : Variation) decorated (Œª x ‚Üí x ++ "'")
{-
‚âÖ PackageFormer TermRelP' (v : Variation) : Set where
   Var' : Int ‚Üí TermRelP' v
   Add' : TermRelP' v ‚Üí TermRelP' v ‚Üí TermRelP' v
   Rel' : TermRelP' v ‚Üí TermRelP' v ‚Üí Set

-- Coherence Meta-property: ‚àÄ v, d  ‚Ä¢  TermRelP v decorated d  ‚âÖ  TermRelP v
-}
 #+end_src
 {{{code(Structure preserving operations)}}}
 #+begin_src haskell
Declare Homomorphism TermRelP (v : Variation)
{-
‚âÖ PackageFormer TermRelP-Homomorphism (v : Variation) : Set where

    Src : TermRelP v   decorated  (Œª x ‚Üí x ++ "‚ÇÅ")
    Tgt : TermRelP v   decorated  (Œª x ‚Üí x ++ "‚ÇÇ")

    map : Src ‚Üí Tgt
    -- Elaborates to ‚ÄúCarrier Src ‚Üí Carrier Tgt‚Äù in ‚Äúrecord‚Äù variation.

    var_preservation : ‚àÄ n   ‚Üí map (Var‚ÇÅ n) ‚â° Var‚ÇÇ n
    add_preservation : ‚àÄ x y ‚Üí map (Add‚ÇÅ x y) ‚â° Add‚ÇÇ (map x) (map y)
    rel_preservation : ‚àÄ x y ‚Üí Rel‚ÇÅ x y ‚Üí Rel‚ÇÇ (map x) (map y)

NB: The ‚Äúdecorated‚Äù annotations are local to the package.
-}
 #+end_src

**** Inheritance & Defaults for Package Formers

 Things get a bit more interesting with multiple packaging,
 fields making use of dependent types, and of (multiple) default implementations.
 Besides defaults, a desirable feature of our envisioned system is the ability to lift definitional extensions
 into fields of the package, say for more efficient implementations.

 {{{code(Recall our example package former)}}}
 #+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
   Var : Int ‚Üí TermP v
   Add : TermP v ‚Üí TermP v ‚Üí TermP v
 #+end_src

 {{{code(All the pieces of \texttt{TermP} but now with additionall new pieces)}}}
 #+begin_src haskell
PackageFormer PreOrderedTermP (v : Variation) : Set  inherits-from (TermP v) where
   Ord   : OrderedTermP v ‚Üí OrderedTermP v ‚Üí Set
   Refl  : ‚àÄ x ‚Üí Ord x x
   Trans : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z

   -- Two default ‚Äòimplementations‚Äô

   default‚ÇÅ Ord x y                =  x ‚â° y
   default‚ÇÅ Refl  x                =  refl
   default‚ÇÅ Trans _ _ _ refl refl  =  refl

   default‚ÇÇ Ord x y                =  ‚ä§
   default‚ÇÇ Refl  x                =  tt
   default‚ÇÇ Trans _ _ _ _ _        =  tt
 #+end_src

 Notice how ‚Äúfree type‚Äù formation incorporates this new open-ended
 construct, ~Ord~, as a two-value holder. An alternative interpretation would
 be to eliminate it altogether from the elaborated data declaration.
 Anyhow, since we elaborate a relation as a pair former, proofs for
 such a relation cannot be included ---otherwise it's not a ‚Äúfree‚Äù type!
 {{{code(Derivied ADT from a package former with constructive relations)}}}
 #+begin_src haskell
PreOrderedTermData = PreOrderedTermP data
{-
‚âÖ  data PreOrderedTermData : Set where
     Var : Int ‚Üí OrderedTermData
     Add : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí PreOrderedTermData
     Ord : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí PreOrderedTermData

     -- No reflexitivity axiom on ‚ÄòOrd‚Äô, nor transitivity!
-}
 #+end_src
 {{{code(Using a ~default~ implementation)}}}
 #+begin_src haskell
PreOrderedTermData = PreOrderedTermP data with-default‚ÇÅ
{-
‚âÖ  data PreOrderedTermData : Set where
     Var : Int ‚Üí OrderedTermData
     Add : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí PreOrderedTermData

     -- No ‚ÄòOrd‚Äô construction, but instead a constructive relation and properties:

     Ord : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí Set
     Ord x y  =  x ‚â° y

     Refl  : ‚àÄ x ‚Üí Ord x x
     Refl  x  =  refl

     Trans : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z
     Trans _ _ _ refl refl  =  refl
-}
 #+end_src
 The naming ~Ord, Refl, Trans~ could have been altered to refer to the newly declared data
 type, for simplicity we have avoided such a transformation.
 Moreover, we could reserve ~with-default‚ÇÄ~ to simply omit constructive relations from
 being reified as data constructors.

 {{{code(Keeping the axioms by using a record)}}}
 #+begin_src haskell
PreOrderedTermRecord = PreOrderedTermP record
{-
‚âÖ   record PreOrderedTermRecord : Set where
      field
    Carrier : Set
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier
    Ord     : Carrier ‚Üí Carrier ‚Üí Set
    Refl    : ‚àÄ x ‚Üí Ord x x
    Trans   : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z

     -- Notice that the reflexitivity & transitivity axioms are kept!
-}
 #+end_src
 Moreover, the default implementations means we also have the following
 declaration, where distinctions are made by the occurenace, or absence, of fields.
 {{{code(Defaults yield additional elaborations)}}}
 #+begin_src haskell
{-
    record PreOrderedTermRecord : Set where
      field
    Carrier : Set
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier

      Ord     : Carrier ‚Üí Carrier ‚Üí Set
      Ord x y =  x ‚â° y

      Refl    : ‚àÄ x ‚Üí Ord x x
      Refl _ = refl

      Trans   : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z
      Trans _ _ _ refl refl = refl
-}
 #+end_src
 Here is our first observation of a uniform presentation of packaging,
 where the ‚Äúintended use‚Äù differs: Whether we want axioms or not?

 Not only is the use amicable, but utilities written for the first elaboration
 effortlessly apply to instances of the second elaboration. Unfortunately,
 the relationship is not symmetric
 ---e.g., using the additional information provided by the default implementations,
  ~‚àÄ x y ‚Üí Ord x y ‚Üí Add x y ‚â° Add y x~ is provable for the latter but
 not the former. As such, there is need to be able to mark results applying
 to a subtype of a package former, or to eliminate such a desirable feature
 that reduces needless distinctions when applying utilties of the former to the
 latter. The thesis will provide a solution with a discussion of the alternatives
 and why they were not adopted.

**** Package Formers Dispense with The Diamond Problem

 Let's consider combining multiple containers.
 {{{code(A package former for unital magmas)}}}
 #+begin_src haskell
Package UnitalTermP (v : Variation) : Set inherits-from (TermP v) where
   unit : UnitalTermP v
   lid  : ‚àÄ x ‚Üí Add unit x ‚â° x
   rid  : ‚àÄ x ‚Üí Add x unit ‚â° x
 #+end_src
 # -- NB: Using ‚ÄúMaybe‚Äù, every ‚ÄúTermP record‚Äù can be converted into a ‚ÄúUnitalTermP record‚Äù.
 {{{code(Inheriting from multiple pacakage formers)}}}
 #+begin_src haskell
Package PreOrderedMonoid (v : Variation) : Set
      inherits-from (UnitalTermP v; PreOrderedTermP v)
  where
   associative : ‚àÄ x y z ‚Üí (Add x y) z ‚â° Add x (Add y z)
   monotone    : ‚àÄ x x' y y' ‚Üí Ord x x' ‚Üí Ord y y' ‚Üí Ord (Add x y) (Add x' y')
 #+end_src
 This package ought to be indistinguishable from the following, whence allowing tremendously flexible
 declarations and uses. In particular, there is no longer a need to distinguish between a hierarchical
 and a flattened perspective, since they are considered identical.
 {{{code(Equivalent backend representation)}}}
 #+begin_src haskell
Package PreOrderedMonoid (v : Variation) : Set where

   unitaltermp : UnitalTermP v
   preorderedtermp : PreOrderedTermP v

   associative : ‚àÄ x y z ‚Üí (Add x y) z ‚â° Add x (Add y z)
   monotone    : ‚àÄ x x' y y' ‚Üí Ord x x' ‚Üí Ord y y' ‚Üí Ord (Add x y) (Add x' y')

   -- From which sub-structure does the above ‚ÄúAdd‚Äù arise?
   --
   -- The ‚Äúrecord‚Äù and ‚Äútypeclass‚Äù variations elaborate with axioms declaring
   -- that identical names are indeed identical operations:
   carrier_coherence : unitaltermp.Carrier ‚â° preorderedtermp.Carrier
   var_coherence     : unitaltermp.Var     ‚â° preorderedtermp.Var
   add_coherence     : unitaltermp.Add     ‚â° preorderedtermp.Add
   --
   -- They also elaborate with default tedious implementations:
   carrier_coherence = refl; var_coherence = refl; add_coherence = refl

   -- Moreover, we can continue the ‚Äòdefault‚Äô implementation.
   default‚ÇÅ monotone _ _ _ _ refl refl = refl
   default‚ÇÇ monotone _ _ _ _ _ _       = tt
 #+end_src

**** Package Formers & Representational Shifts

 Let us close this section by demonstrating how this genericity can aid in
 ubiquitous representational shifts that appear rather often in dependently typed programming.
 In pedestrian languages, there are usually less ways to accomplish a task in
 dependently typed languages and so programming style is not of great concern.
 In contrast, in a DTL, a user could, for example, work over an abstract data type
 where a particular argument is fixed or where it is allowed to vary.
 The two approaches are a matter of style, but can lead to awkward situations.
 # The downside of the former is that we cannot vary, whereas in the latter

 # context shifting; Œª-introduction; ‚áí-theorem.
 #
 More concretely, we consider the bread and buffer of coding: Graphs.
 Without dependent types we can only speak about graphs /over/ a given vertex type,
 with dependent types we can speak about /a/ graph, irrespective of vertex type.
 The former is tantamount to the context ~Vertex ‚à∂ Type ‚ä¢ Edges ‚à∂ Vertex ‚Üí Vertex  ‚Üí Type~,
 and an empty assumption context ~‚ä¢ Vertex ‚à∂ Set, Edges ‚à∂ Vertex ‚Üí Vertex ‚Üí Type~
 for the latter.
 However, the latter form sometimes leads us into contexts where we have two
 graphs ~G~ and ~H~ for which we make the tedious constraint {{{newline}}} ~Vertex G ‚â° Vertex H~.
 It would be less clumsy to explicitly declare the two graphs to be /over/ the
 same vertex type.

 The previous paragraph mentioned a terse dependently-typed presentation of graphs,
 let us use the classic presentation as it may be more familiar to readers.
 {{{code(Graph package former)}}}
 #+begin_src haskell
PackageFormer GraphP (v : Variation) : Set where
  Vertex, Edges : Set
  src, tgt      : Edges ‚Üí Vertex

  -- The dependently typed notion of edges.
  derivied
    _‚ü∂_ : Vertex ‚Üí Vertex ‚Üí Set
    x ‚ü∂ y  =  Œ£ e : Edges  ‚Ä¢  src e ‚â° x  ‚àß  tgt e ‚â° y
 #+end_src

 {{{code(Graphs as records)}}}
 #+begin_src haskell
AGraph = GraphP record renaming (Carrier to ‚ÄúVertex‚Äù)
{-
‚âÖ   record AGraph : Set where
      field
    Vertex Edges : Set
    src    tgt   : Edges ‚Üí Vertex
-}

-- NB. The implicitly generated name ‚ÄúCarrier‚Äù has been identified with
-- the *declared* name ‚ÄúVertex‚Äù. This is acceptable since they have the same type.
-- Without the identification, the record elaboration would have provided a
-- third type field named ‚ÄúCarrier‚Äù.
 #+end_src
 {{{code(Parameterised graphs as typeclasses)}}}
 #+begin_src haskell
GraphOver = TermP typeclass renaming (Carrier to ‚ÄúVertex‚Äù)
{-
‚âÖ   record GraphOver (Vertex : Set) : Set where
       field
      Edges   : Set
      src tgt : Edges ‚Üí Vertex
-}
 #+end_src
 With these in hand, our goal is to replace the following first line with the second.
 However, since both types ~GraphOver~ and ~AGraph~ are declared as one liners,
 such a transition is a cheap as possible.
 #+begin_src haskell
(G H : AGraph) ‚Üí Vertex G ‚â° Vertex H ‚Üí ‚ãØ

(V : Set) ‚Üí (G H : GraphOver V) ‚Üí ‚ãØ
 #+end_src
 In order to /replace a semantic constraint with a syntactic constraint/
 the user simply need to use a /variant/ on packaging. Furthermore, we
 are ensured {{{newline}}} ~AGraph ‚âÖ Œ£ V ‚à∂ Set ‚Ä¢ GraphOver V~.

 Dependently-typed graphs are an curious structure. With a bit of renaming, and adding a few laws,
 we obtain a ‚Äòsetoid‚Äô --i.e., an undirected graph where every node has a self-loop, and paths
 correspond are essentially edges.
 {{{code(Setoid package former)}}}
 #+begin_src haskell
PackageFormer SetoidP (v : Variation) : Set where
  -- Graph structure
  Carrier : Set
  _‚âà_     : Carrier ‚Üí Carrier ‚Üí Set
  -- Properties
  refl  : ‚àÄ{e}     ‚Üí e ‚âà e
  sym   : ‚àÄ{d e}   ‚Üí e ‚âà d ‚Üí d ‚âà e
  trans : ‚àÄ{c d e} ‚Üí c ‚âà d ‚Üí d ‚âà e ‚Üí c ‚âà d
 #+end_src
 A non-dependently-typed ‚Äòsignature‚Äô of a structure is generally obtained by discarding the relational operators
 and all properties. For ~SetoidP~ one would immediately think the signature consists of just ~Carrier~.
 However, if we view it instead as undirected graphs with self-loops at each node and edge-transitivity, then
 one would say the signature is the vertices ~Carrier~ and the edges ~_‚âà_~. It is thus not clear when an item,
 ~_‚âà_~ or ~_‚ü∂_~, forms constructive proofs or provides a type family. As such, signature extraction thus requires
 a parameter identifying which elements constitute ‚Äòproof matter‚Äô ---then one simply filters a pacakge-former
 against this criterion to obtain the associated signature. More generally, this allows us to take an ~X~ structure
 and obtain may of its the associated views about where knowledge is consolidated citet:realms, including:
 #+BEGIN_SRC haskell
X         = ‚ü® Carrier; Operations; Properties ‚ü©     -- C.f., SetoidP
XOver C   = ‚ü® Operations; Properties ‚ü©
IsX C Ops = ‚ü® Properties ‚ü©
XSig      = ‚ü® Carrier; Operations‚ü©                  -- C.f., GraphP
 #+END_SRC
 Having the signature in hand, one can easily and mechanically generate many derivied concepts.
 For example, a ‚Äòhomomorphism‚Äô is a family of functions of the underlying sorts such that
 the given operations are preserved. Likewise, equality of homomorphisms is extensional equality of
 the underlying maps. One can then generate closed and open terms and their interpretation functions.
 With this approach to signature extraction, we can use the same algorithms
 for the production of, say homomorphisms or other constructs, on completely
 different algebraic structures, whether they be monoids or graphs.
 Moreover, this implies that concepts generally not considered for a class
 of algebras can easily be derived and experimented with; likewise for exploring
 new algebraic theories.
 These matters are an application, rather than a goal, of our envisioned system.

 :Neat_but_irrelevant:
 Sometimes constraints on an item can be derived, leaked by a signature.

 E.g., the signature of sets, on a carrier, leaks that the carrier necessary
 has decidable equality.
 :End:

 The curiosity of graphs is that they are one of the simplest /two-sorted/ structures
 and one of the most common in computing. Counter to intuition, existing packaging
 systems, namely canonical structures and typeclasses, are oriented toward having
 a distinct parameter: They cannot work well with multi-parameters; like classical
 single-sorted algebra. However, the both /aim to solve a usability problem:/
 /Having to spell out everything is too tedious./ Typeclasses are essentially dictionary look-up,
 having unicity as an issue. Whereas canonical structures require familiarity with how unifer works
 --we provide enough information to the unifer to find the desired structure-- but, in general,
 canonical structures do not scale. It is one of the thesis efforts to ensure the the unionised
 approach scales by a complex example with clear avenues of extension.

 It should be clear from these examples that package formers provide
 expectant generality, including the common uses one is mostly interested in.
 What about unexpected uses? What if a user wishes to utilise a representation
 we did not conceive of? They should be able to use the existing language to
 form it.
*** Second Observation: Computing Similarity for Containers

 By necessity of the first corollary, we are forced to utilise a uniform language
 between the varying notions of packaging thereby relegating their treatment
 to be a normal aspect of a language's core vernacular, rather than an extra-linguistic feature.
 The previous examples hint at possible issues regarding well-definedness of certain constructs.
 Moreover, we only elaborated on a few compositional operations,
 ~inherits-from, renaming, decorated~, yet users
 may well wish to utilise their own compositional schemes and so it is imperative that we allow
 them such a flexibility.
 Consequently, users ought to be able to define their own compositional mechanisms, thereby
 necessitating that they be able to manipulate package declarations themselves
 which in-turn forces the language to be somewhat homoiconic. Moreover, to avoid a hierarchy
 of languages, the facility for manipulating package declarations must itself be a part of
 the core language, rather than an extra-linguistic feature ---c.f., Coq's Ltac.

 In our envisioned setup, every ~PackageFormer~ declaration adds a clause to a special
 function,
 {{{code(Under the hood)}}}
 #+begin_src haskell
packageInfo : PackageFormer ‚Üí PackageInfo
packageInfo = ‚ü™compiler defined‚ü´
 #+end_src
 Where a ~PackageInfo~ consists of ~Name~, which is a list of parameter names and types, along with the name of the package former;
 and ~Declarations~, a list of name-type pairs whose last element is the target type.
 {{{code(PackageInfo: Just another package ---for ‚Äúsignatures‚Äù)}}}
 #+begin_src haskell
{- Draft: Lots of string manipulation, not ideal. -}
record PackageInfo : Set where
  field
    Name         : List (String √ó String) √ó String
    Declarations : List (String √ó List String)
--
-- This is just another package,
-- it incidentally happens to be the representation of packages!
 #+end_src

 #+RESULTS:
 #+begin_example
 <interactive>:6:5-16: error:
     Data constructor not in scope: Declarations

 <interactive>:6:20-23: error:
     Data constructor not in scope: List :: t0 -> [a]

 <interactive>:6:26-31: error: Data constructor not in scope: String

 <interactive>:6:33: error:
     Variable not in scope: (√ó) :: t1 -> t2 -> t0

 <interactive>:6:35-38: error:
     Data constructor not in scope: List :: t3 -> t2

 <interactive>:6:40-45: error: Data constructor not in scope: String
 #+end_example

 It is to be noted that there is no commitment to a string-based representation.
 It is only a prototype and the thesis will likely move to a better typed
 representation ---otherwise, we may run into too many problems of ill-formed
 package formers.

 {{{code(Recall our example package former)}}}
 #+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
  Var : Int ‚Üí TermP v
  Add : TermP v ‚Üí TermP v ‚Üí TermP v
 #+end_src
 The above declaration provides, under the hood, the following clause to ~packageInfo~.
 {{{code(Under the hood)}}}
 #+begin_src haskell
packageInfo TermP = record { Name         = ["v", Variation] , "TermP"
               ; Declarations = [ ("Var", ["Int", "TermP v"])
                        , ("Add", ["TermP v", "TermP v", "TermP v"])
                        ]
               }
 #+end_src
 # Note the ‚Äòv‚Äô, whence String not Set in the defn of PackageInfo.

 We are now in a position to provide the semantics for the keyword ~Declare~,
 from the previous section. It takes a ~PackageInfo~ and declares a ~PackageFormer~.
 There should be a compile-time warning if such declarations are meaningless, ill-formed.

 For example, the previous {{{newline}}} ~Declare PackageFormer TermRelP (v ‚à∂ Variation) decorated (Œª x ‚Üí x ++ "'")~
 can thus be obtained by a user by defining ~decorated~ as an operation on packages!
 {{{code(User-defined composition scheme)}}}
 #+begin_src haskell
_decorated_ : PackageInfo ‚Üí (String ‚Üí String) ‚Üí PackageInfo
pk decorated f = record { Name         = bimap id f pk.Name
            ; Declarations = fmap (bimap f id) pk.Declarations
            }
 #+end_src

 To rectify the seemingly wild mixfix notions, we request from the compiler
 the following suitably general syntactic sugar.
 An operation, call it, ~altered-by~ of the type ~PackageInfo ‚Üí List PackageInfo ‚Üí List X ‚Üí PackageInfo~
 automatically obtains the syntactic sugar ~p altered-by (q0; ‚Ä¶; qk) with (f0; ...; fN)~ ---c.f., the ~inherits-from~ syntax above.

 # Woah! Look at how easy that was, no need to build it in!

 With such terse functional programs for forming composition schemes,
 there is no need to build much into the compiler.

 Users can define other similar operations, such as ~decorated-rounded~
 which replaces the first two binary relations' names with ~‚äÜ~ and ~‚äÇ~;
 or ~decorated-square~ to make the renamings ~‚äë~ and ~‚äè~.
 Additionally, such renames would propagate into any axioms or derived laws.
 Moreover, the flexibility to invoke such operations in complex ways allows for
 intricate renamings to be generated at tremendous scale without worry that
 future renames would need to be made if the orginal packages included new items.
 Numerous examples of such renaming transpire manually in the impressive
 RATH citet:RATH development, as well as in Agda's standard library.

 When working with multiple values of the same record type, for example,
 one encounters a usability problem: Refereeing to the constituents without being verbose.
 The simplest solution is to qualify each invocation, as in ~instance.field~, however this
 is rather cumbersome, inelegant, and is awkward for mixfix names. An alternative is to
 locally rename the fields according to a scheme reflecting their use. For example, in
 a produce construction of 5 items, the field names would be renamed to have a subscript number.
 In a setting of two instances, a user may instead prefer a primed and an undecorated version
 of field names. Thus far, by hand we have created these tedious subscript and primed renamings,
 with our envisioned systems, we need no longer worry about such boilerplate.

 In nearly the same fashion, a user could have defined the ~inherits-from~ compositional scheme.
 Such a scheme may assume that all identically named items have the same types, and crash otherwise.
 A user could define a better scheme that takes a renaming function, or another function to handle
 the crash, or simply omitt conflicting names altogether.
 The examples suggest that many commonly occurring compositional mechanisms citet:tpc
 can be directly provided by a library, rather than by a particular compiler
 ---this includes the ability to hide fragments, expose the largest well-defined fragment,
 and to combine packages along a given substructure.

 Rather than select what we think is best, we can simply provide the general mechanism to the
 library designer and allow them the freedom to provide their own schemes.

*** Next Steps

 Our brief examples demonstrate that the less design decisions about packaging
 made by language designers, the more general, applicable, and, most importantly, increased homogeneity
 in the resulting datatype language without becoming unityped but rather thanks to being dependently-typed.
 As mentioned in the previous section on existing approaches, one formalism for
 packages is that of theories and theory combinators; below we thus draw on some problems from theory combinators
 rendered toward packaging systems.

 We have mentioned that the ~record~ and ~typeclass~ perspectives solve the common requirement of
 structures sharing an identical field. Other than that, we have essentially only
 outlined a general mechanism for declaring packages and compositional schemes, but have not
 discussed which are the most common and most useful packaging combinators.
 It is also desirable to discuss the formal properties of such combinators
 ---if anything, to ensure they are sensible and behave as expected.
 Moreover, which combinators act as a basis for all packaging combinators?
 Whence their use ensures the resulting composition is well-formed
 and they could be targeted for optimisations.
 #  Soundness & Completeness proofs?

 To make our approach accessible, the generic package operations are brought to the user
 rather than baked into the compiler ---too great a distance for most users.
 The ~Declare~ syntax reifies ~PackageInfo~'s into package declarations, but we have not mentioned
 under what constraints it can actually provide compiler-time, or typechecking-time,
 errors of ill-formedness. Moreover, how (in)efficient is this process?
 Could it be extended to work on variable, runtime provided, declarations
 for refying packages? Perhaps there is a constraint that suffices for the most common cases?
 Moreover, having observable ~PackageInfo~'s being automatically generated for every package declaration
 renders representation hiding nearly moot.

 The proposed approach boarders on meta-programming.
 Can type erasure and other compiler-specific optimisations be brought into
 the homoiconic-like setting being pursued here?
 We have mentioned a few ‚Äòbuilt in‚Äô variations for packaging; can such a feature
 be liberated from the compiler and be bent to the users' will?
 We would need the ability to explain how a package elaborates.

 Tremendous flexibility is demanded from the back-end so as to ignore needless distinctions
 at the users' level. Whereas the practicality is promising, the feasibility of an
 implementation for such ambiguous parsing citet:ambiguous_parsing is unclear.
 It is also unclear what effects identifying syntactically distinct items
 has on, say, normalisation and propositional equality.

 The numerous claims and associaited bookkeeping of details pushes us into using a proof assistant, Agda.

 Our examples have been ‚Äòvariation‚Äô polymorphic;
 we have been even more generic by defining ~decorated~.
 What are the limits of programming genericity provided by our scheme?
 It would unsurprising if this approach yields
 the next 700 module systems.
** TODO COMMENT [ReLOCATE] Disclaimer about going forward :incorporate_into_ch_1:
 #+latex: \begin{tcolorbox}[title = Prerequisite of the reader, colback=red!5!white, colframe=red!75!black]
Going forward, it is assumed that the reader is comfortable programming with
Haskell, and the associated menagerie of Category Theory concepts that are
usually present in the guise of Functional Programming.  In particular, this
includes ‚Äòpractical‚Äô notions such as typeclasses and instance search, as well as
‚Äòtheoretical‚Äô notions such categorial limits and colimits, lattices ---a kind of
category with products--- and monoids ---possibly in arbitrary monoidal
categories, as is the case with monads.
#+latex: \tcblower
Moreover, we assume the reader to have *actually* worked with a dependently-typed
language; otherwise, it /may/ be difficult to appreciate the solutions to the
problems addressed in this thesis ---since they could not be expressed in
languages without dependent-types and are thus ‚Äònot problems‚Äô.
 #+latex: \end{tcolorbox}

* Glossary                                                           :ignore:

#+LaTeX: \addcontentsline{toc}{part}{Glossary}

# placed at the top, since the entry-creation tool places new entries at the top
# +latex_header: \usepackage{glossaries}
# +latex_header: \makeglossaries

#+BEGIN_SRC emacs-lisp :exports none :results replace
(setq words '(
module-systems "Module Systems"
"Module systems parameterise programs, proofs, and tactics over structures.

They come in many flavours that each communicate a utility
difference; e.g., tuples for quickly returning multiple values
from a function, a record to treate pieces as a coherent whole, a
function as an indexed value, and paramterised modules which
‚Äòbuild upon‚Äô other coherent units
"

signature "Signature"
"A sequence of pairs of name-type declarations; an alias for
‚Äòcontext‚Äô and ‚Äòtelescope‚Äô; see also JSON Object and Theory Presentation"

context "Context"
"A sequence of ‚Äúvariable ‚à∂ type [:= definition]‚Äù declarations; a
dictionarry associating variables to types and, optionally, a
definition; c.f., record-type and object-oriented class; see ‚ÄòJSON Object‚Äô"

theory-presentation "Theory Presentation"
"A (named) list of name-type declarations, where the type may be
a formulae that governs how earlier declared names are inteded to
interact. Essentially, it is a signature in a DTL"

substitution "Substitution"
"A typed-substition of kind $P ‚Üí Q$, also known as a ‚Äòview‚Äô or ‚Äòtheory morphism‚Äô,
is a context Œ¥ such that every $P$-delcaration $x ‚à∂ œÑ$ has an
associated Œ¥-declaration $x ‚âî t$ where $t$ may refer to all names
declared in $Q$. That is, a substition is a map of contexts that
implements the interface of the source using utilities of the
target; whence it gives rise to a type-preseving homomorphism on
terms which ---using the propositions-as-types
correspondecnece--- preserves truthhood of results. For instance
if $I$ implements ‚Äòinterface‚Äô (context) $P$ which can be viewed
as $Q$, then $I$ can be viewed as an implementation of $Q$"

view "View" "See ‚ÄòSubstitution‚Äô"
theory-morphism "Theory Morphism" "See ‚ÄòSubstitution‚Äô"
interpretation "Interpretation" "See ‚ÄòSubstitution‚Äô"

json "JSON object"
"A comma-separted list of key-value pairs; an alias for
 ‚Äòdictionary‚Äô, ‚Äòhashmap‚Äô, and ‚Äòobject‚Äô"

mixin "Mixin"
"The ability to extend a datatype with additional functionality
long after, and far from, its definition. See also typeclass.
Mixins could be simulated as module-to-module functions,
which give rise to ‚Äòa module of type M‚Äô as an instance of the mixin M;
e.g., a type of type Show is an instance of the typeclass Show
"

parameters-vs-indices "Parameters and Indices"
"A parameter is an argument that can be used uniformly in a
declaration, whereas an index determines the ‚Äòshape‚Äô of the
declaration and so needs to be more ‚Äòflexible‚Äô than a parameter
in that it can vary on a case by case fashion within the
declaration"

typeclass "Typeclass"
"Essentially a dictionary that associates types with a particular
list of methods which define the typeclass. Whenever such a
method is invoked, the dictionary is accessed for the inferred
type and the appropriate definition is used, if possible. This
provides a form of ad-hoc polymorphism: We have a list of methods
that appear polymorphic, but in-fact their definitions depend on
a particular parent type"
; related to canonical structures

record "Record"
"Rather than holding a bunch of items in our hands and running
around with them, we can put them in a bag and run around with
it. That is, a record type bundles up related concepts so that
may be treated as one coherent entity. If record types can
‚Äòinherit‚Äô from one another, then we have the notion of an
‚Äòobject‚Äô"

homoiconic "Homoiconic"
"The lack of distinction between ‚Äòdata‚Äô and ‚Äòmethod‚Äô. E.g.,
\\texttt{'(+ 1 2)} is considered a list of symbols, whereas the
\\emph{unquoted} term \\texttt{(+ 1 2)} is considered a function
call that reduces to 3"

dependent-function "Dependent Function"
"A function whose result type depends on the value of the argument"

curry-howard "Curry-Howard Correspondence"
"Programming and proving are essentially the same idea"

do-notation "Do-Notation"
"Syntactic abbrevation that renders purely functional code as if
it were sequential and imperative."

little-theories "Little Theories"
"The dicipline of building a library by adding one new orthogonal feature
at each stage of the hierarchy; c.f., the Interface Segregation Principle"
))

(concat "#+latex_header_extra: "
(s-join " "
(loop for (label name description) in (-partition 3 words)
      collect (format
       "\\newglossaryentry{%s}{name={%s}, description={%s}}"
       label
       name
       (s-collapse-whitespace description)))))
#+END_SRC

# #
#+latex_header_extra: \newglossaryentry{module-systems}{name={Module Systems}, description={Module systems parameterise programs, proofs, and tactics over structures. They come in many flavours that each communicate a utility difference; e.g., tuples for quickly returning multiple values from a function, a record to treate pieces as a coherent whole, a function as an indexed value, and paramterised modules which ‚Äòbuild upon‚Äô other coherent units }} \newglossaryentry{signature}{name={Signature}, description={A sequence of pairs of name-type declarations; an alias for ‚Äòcontext‚Äô and ‚Äòtelescope‚Äô; see also JSON Object and Theory Presentation}} \newglossaryentry{context}{name={Context}, description={A sequence of ‚Äúvariable ‚à∂ type [:= definition]‚Äù declarations; a dictionarry associating variables to types and, optionally, a definition; c.f., record-type and object-oriented class; see ‚ÄòJSON Object‚Äô}} \newglossaryentry{theory-presentation}{name={Theory Presentation}, description={A (named) list of name-type declarations, where the type may be a formulae that governs how earlier declared names are inteded to interact. Essentially, it is a signature in a DTL}} \newglossaryentry{substitution}{name={Substitution}, description={A typed-substition of kind $P ‚Üí Q$, also known as a ‚Äòview‚Äô or ‚Äòtheory morphism‚Äô, is a context Œ¥ such that every $P$-delcaration $x ‚à∂ œÑ$ has an associated Œ¥-declaration $x ‚âî t$ where $t$ may refer to all names declared in $Q$. That is, a substition is a map of contexts that implements the interface of the source using utilities of the target; whence it gives rise to a type-preseving homomorphism on terms which ---using the propositions-as-types correspondecnece--- preserves truthhood of results. For instance if $I$ implements ‚Äòinterface‚Äô (context) $P$ which can be viewed as $Q$, then $I$ can be viewed as an implementation of $Q$}} \newglossaryentry{view}{name={View}, description={See ‚ÄòSubstitution‚Äô}} \newglossaryentry{theory-morphism}{name={Theory Morphism}, description={See ‚ÄòSubstitution‚Äô}} \newglossaryentry{interpretation}{name={Interpretation}, description={See ‚ÄòSubstitution‚Äô}} \newglossaryentry{json}{name={JSON object}, description={A comma-separted list of key-value pairs; an alias for ‚Äòdictionary‚Äô, ‚Äòhashmap‚Äô, and ‚Äòobject‚Äô}} \newglossaryentry{mixin}{name={Mixin}, description={The ability to extend a datatype with additional functionality long after, and far from, its definition. See also typeclass. Mixins could be simulated as module-to-module functions, which give rise to ‚Äòa module of type M‚Äô as an instance of the mixin M; e.g., a type of type Show is an instance of the typeclass Show }} \newglossaryentry{parameters-vs-indices}{name={Parameters and Indices}, description={A parameter is an argument that can be used uniformly in a declaration, whereas an index determines the ‚Äòshape‚Äô of the declaration and so needs to be more ‚Äòflexible‚Äô than a parameter in that it can vary on a case by case fashion within the declaration}} \newglossaryentry{typeclass}{name={Typeclass}, description={Essentially a dictionary that associates types with a particular list of methods which define the typeclass. Whenever such a method is invoked, the dictionary is accessed for the inferred type and the appropriate definition is used, if possible. This provides a form of ad-hoc polymorphism: We have a list of methods that appear polymorphic, but in-fact their definitions depend on a particular parent type}} \newglossaryentry{record}{name={Record}, description={Rather than holding a bunch of items in our hands and running around with them, we can put them in a bag and run around with it. That is, a record type bundles up related concepts so that may be treated as one coherent entity. If record types can ‚Äòinherit‚Äô from one another, then we have the notion of an ‚Äòobject‚Äô}} \newglossaryentry{homoiconic}{name={Homoiconic}, description={The lack of distinction between ‚Äòdata‚Äô and ‚Äòmethod‚Äô. E.g., \texttt{'(+ 1 2)} is considered a list of symbols, whereas the \emph{unquoted} term \texttt{(+ 1 2)} is considered a function call that reduces to 3}} \newglossaryentry{dependent-function}{name={Dependent Function}, description={A function whose result type depends on the value of the argument}} \newglossaryentry{curry-howard}{name={Curry-Howard Correspondence}, description={Programming and proving are essentially the same idea}} \newglossaryentry{do-notation}{name={Do-Notation}, description={Syntactic abbrevation that renders purely functional code as if it were sequential and imperative.}} \newglossaryentry{little-theories}{name={Little Theories}, description={The dicipline of building a library by adding one new orthogonal feature at each stage of the hierarchy; c.f., the Interface Segregation Principle}}

:HowToWorkWithGlossaryies:

+ org-ref-add-glossary-entry ‚áí Add a new entry to the file
+ org-ref-insert-glossary-link ‚áí Insert a particular link to a glossary entry
  - Or just write, in-place, ~gls:ùìß~ to refer to entry ùí≥.

See https://github.com/jkitchin/org-ref/blob/master/org-ref.org#glossaries
and https://tex.stackexchange.com/questions/413947/glossaries-not-showing

C-c C-c this block to ensure we have glossaries ^_^
#+BEGIN_SRC shell
pdflatex -shell-escape thesis.tex; makeglossaries thesis; pdflatex -shell-escape thesis.tex  pdflatex -shell-escape thesis.tex
#+END_SRC

Better yet, simply add it to the export process:
#+BEGIN_SRC emacs-lisp
(setq org-latex-pdf-process
      '("pdflatex -interaction nonstopmode -shell-escape -output-directory %o %f"
        "biber %b"
        "makeglossaries %f"
        "pdflatex -interaction nonstopmode -shell-escape -output-directory %o %f"
        "pdflatex -interaction nonstopmode -shell-escape -output-directory %o %f"))

(add-to-list 'org-src-lang-modes '("agda" . haskell))
(add-to-list 'org-src-lang-modes '("agda2" . haskell))
#+END_SRC

:End:

# Example
# +latex_header_extra: \newglossaryentry{computering}{name={computeringname},description={it is a thing which computers}}
# [[gls:computering][computeringname]] or gls:computering

#+latex: \printglossaries
