#+title: Do-it-yourself Module Systems
# subtitle: We can change things later, but can't change it if there's nothing to change!
# subtitle: The Next 700 Module Systems
# +DESCRIPTION: Thesis for Musa Al-hassy; McMaster University 2020.
#+AUTHOR: [[mailto:alhassm@mcmaster.ca][Musa Al-hassy]]
#+EMAIL: alhassy@gmail.com
# +OPTIONS: toc:nil d:nil title:nil
#+PROPERTY: header-args :tangle no :comments link

# At the end of a section, explain why the section is there,
# and what the reader should take away from it.

# MA: LaTeX pads colons, :, with spacing.
# For inline typing annotations, use ghost colon â€œ\:â€ to avoid this issue.

:org-ref:
(require 'org-ref)
(setq reftex-default-bibliography '("~/thesis-proposal/papers/References.bib"))
(setq org-ref-default-bibliography reftex-default-bibliography)
(org-ref)
cite:agda_overview
:End:

#+macro: {{{newline}}} @@latex: \newline@@

* COMMENT Proposed Outline

1. Motivating the problem
   - Where has this problem been encountered in the wild?
   - What benefits would there be to solving this problem?
   - Mention ~1 * x + 0 = x~ problem from the ICFP20 paper.
     * Two monoidal units on the same carrier satisfy this law.

   Here is where the "STORY" is placed.

2. Background: What's necessary to solve this problem?
   - What is needed to just understand this problem?
   - Agda
   - System F
   - Monads
   - Metaprogramming

   Maybe tackle this "as needed", rather than upfront.

3. PackageFormer
   - Why an editor extension? Why Lisp is reasonable?
   - Utility of a protottype?
   - Things learned from making a protottype?
     * Perhaps show the minimal code needed to get PF working; <= 300 lines?
     * Much more Lisp for implementing common grouping mechanisms; e.g., pushouts.
   - How usable is it?
   - What exotic notions of grouping mechanisms can be coded-up? Utilit!?
   - [Disadvantages of PackageFormer?
   - Comparision to other systems.

4. Contexts
   - Why PackageFormer is not enough.
   - Discuss Agda macros ---need to be self-contained.
   - Motivate the need for a practical syntax.
   - The reason it's a "do it yourself" system is that the semantics, >>=,
     can be tweaked easily for other forms of grouping besides Pi/Sigma ;-)
   - Current limitations; e.g., lack of termination/positivity of certain constructs;
     or how termtype generation requires the ADT carrier to be the first element
     of the sequence/context, whereas a DAG interpretation of Contexts would be better?
   - How does this compare with PF?
   - What are the benefits of Context?
   - Concrete problems its usage can solve.

5. Related works
   - Who has worked on this problem and where have they gotten?
   - What are their shortcomings and advantages wrt to our approach?
   - Shortcomings of our approach.
   - Missing features and next steps.

6. Conclusion
   - What we have done
   - How it is useful to others, now.

* Table of Contents                                    :Github:TOC_4ish:
- [[#image][Image]]
- [[#fthe-thesis-story][fThe Thesis Story]]
- [[#motivating-the-problem-----examples-from-the-wild][Motivating the problem --- Examples from the Wild]]
  - [[#introduction][Introduction]]
  - [[#adding-zero-then-multiplying-by-one-results-in-a-type-error][Adding Zero then Multiplying by One Results in a Type Error]]
  - [[#renaming][Renaming]]
    - [[#renaming-problems-from-agdas-standard-library][Renaming Problems from Agda's Standard Library]]
    - [[#renaming-problems-from-the-rath-agda-library][Renaming Problems from the RATH-Agda Library]]
    - [[#renaming-problems-from-the-agda-categories-library][Renaming Problems from the Agda-categories Library]]
  - [[#from-isğ“§-to-ğ“§----packing-away-components][From ~Isğ“§~ to ~ğ“§~ ---Packing away components]]
  - [[#redundancy-derived-features-and-feature-exclusion][Redundancy, Derived Features, and Feature Exclusion]]
  - [[#extensions][Extensions]]
  - [[#summary-of-some-design-patterns-in-dependently-typed-programming][Summary of Some Design Patterns in Dependently-Typed Programming]]

* COMMENT Abstract
* Introduction ---The Thesisâ€™ â€œStoryâ€
  :PROPERTIES:
  :CUSTOM_ID: introduction
  :END:

** Intro                                                             :ignore:
In this chapter we aim to present the narrative that demonstrates the
distinction between what can currently be accomplished and what is desired when
working with composition of software units. We arrive at the observation that
packaging concepts differ only in their use ---for example, a typeclass and a
record are both sequences of declarations that only differ in that the former is
used for polymorphism with instance search whereas the latter is used as a
structure, grouping related items together. In turn, we are led to propose that
the various packaging concepts ought to have a uniform syntax. Moreover, since
records are a particular notion of packaging, the commitment to syntactic
similarity gives rise to a [[https://en.wikipedia.org/wiki/Homoiconicity][homoiconic]] nature to the host language.

Within this work we refer to a /simple type theory/ as a language that contains
typed lambda terms for terms and formuale; if in addition it contains lambda
terms whose types are indexed by values then we say it is a /dependently-typed
language/, or â€˜DTLâ€™ for short ---depending on intent, value-indexed types could
be interpreted as /propositions/ and their terms as /proofs/. With the exception of
declarations and ephemeral notions, nearly everything in a DTL is a typed lambda
term. Just as Lisp's homoiconic nature blurs data and code leaving it not as a
language with primitives but rather a language with meta-primitives, so too the
lack of distinction between term and type lends itself to generic and uniform
concepts in DTLs thereby leaving no syntactic distinction between a constructive
proof and an algorithm.

The sections below explore our primary observation, which is discussed further
later on in Chapter ???. Section 1 demonstrates the variety of languages present in a
single system which are conflated in a DTL, section 2 discusses that such
conflation should by necessity apply to notions of packaging, and section 3
concludes with contributed work to ensure that happens.

** A Language Has Many Tongues

:Armkeh:
- In the introduction to section 1, you discuss "the variety of languages
  present in a single system". I feel this makes sense after reading "A coding
  language is actually many languages working together" below, but I found it
  confusing on first read. Maybe put languages in quotes and change system to
  language?
:End:

A programming language is actually many languages working together.

The most basic of imperative languages comes with a notion of â€˜statementâ€™ that
is executed by the computer to alter â€˜stateâ€™ and a notion of â€˜valueâ€™ that can be
assigned to memory locations. Statements may be sequenced or looped, whereas
values may be added or multiplied, for example. In general, the operations on
one linguistic category cannot be applied to the other. Unfortunately, a rigid
separation between the two sub-languages means that binary choice, for example,
conventionally invites two notations with identical semantics ---e.g.; in ~C~ one
writes ~if (cond) clauseâ‚ else clauseâ‚‚~ for statements but must use the notation
~cond?termâ‚:termâ‚‚~ for values. Hence, there are value and statement languages.

Let us continue using the ~C~ language for our examples since it is so ubiquitous
and has influenced many languages. Such a choice has the benefit of referring to
a concrete language, rather than speaking in vague generalities. Besides Agda
---our language of choice--- we shall also refer to Haskell as a representative
of the functional side of programming. For example, in Haskell there is no
distinction between values and statements ---the latter being a particular
instance of the former--- and so it uses the same notation ~if_then_else_~ for
both. However, in practice, statements in Haskell are more pragmatically used as
a body of a ~do~ block for which the rules of conditionals and local variables
change ---hence, Haskell is not as uniform as it initially appears.

In ~C~, one declares an integer value by ~int x;~ but a value of a user-defined type
~T~ is declared ~struct T x;~ since, for simplicity, one may think of ~C~ having an
array named ~struct~ that contains the definitions of user-defined types ~T~ and the
notation ~struct T~ acts as an array access. Since this is a clunky notation, we
can provide an alias using the declaration ~typedef existing-name new-name;~.
Unfortunately, the existing name must necessarily be a type, such as ~struct T~ or
~int~, and cannot be an arbitrary term. One must use ~#define~ to produce term
aliases, which are handled by the ~C~ preprocessor, which also provides ~#include~
to import existing libraries. Hence, the type language is distinct from the
libraries language, which is part of the preprocessor language.

In contrast, Haskell has a pragma language for enabling certain features of the
compiler. Unlike ~C~, it has an interface language using ~typeclass~-es which
differs from its ~module~ language
cite:haskell_modules_formally,haskell_in_haskell,classic_haskell_genericity
since the former's names may be qualified by the names of the latter but not the
other way around. In turn, ~typeclass~ names may be used as constraints on
types, but not so with ~module~ names. It may be argued that this interface
language is part of the type language, but it is sufficiently different that it
could be thought of as its own language cite:modular_modules ---for
example, it comes with keywords ~class, instance, =>~ that can only appear in
special phrases. In addition, by default, variable declarations are the same for
built-in and user-defined types ---whereas ~C~ requires using ~typedef~ to mimic such
behaviour. However, Haskell distinguishes between term and type aliases. In
contrast, Agda treats aliasing as nothing more than a normal definition.

Certain application domains require high degrees of confidence in the
correctness of software. Such program verification settings may thus have an
additional specification language. For ~C~, perhaps the most popular is the ANSI C
Specification Language, ACSL cite:acsl. Besides the ~C~ types, ACSL
provides a type ~integer~ for specifications referring to unbounded integers as
well as numerous other notions and notations not part of the ~C~ language. Hence,
the specification language generally differs from the implementation language.
In contrast, Haskell's specifications are generally cite:programatica in
comments but its relative Agda allows specifications to occur at the type level.

# When working with ACSL, or JML, or SPARK
Whether programs actually meet their specifications ultimately requires a proof
language. For example, using the Frama-C tool cite:frama_c, ACSL
specifications can be supported by Isabelle or Coq proofs. In contrast, being
dependently-typed, Agda allows us to use the implementation language also as a
proof language ---/the only distinction is a shift in our perspective; the syntax
is the same./ Tools such as Idris and Coq come with â€˜tacticsâ€™ ---algorithms which
one may invoke to produce proofs--- and may combine them using specific
operations that only act on tactics, whence yet another tongue.

Hence, even the simplest of programming languages contain the first three of the
following sub-languages ---types may be treated at runtime.

1. Expression language;
  #   (Expressions are syntax; values are semantics (most of the time...).)
2. Statement, or control flow, language;
3. Type language;
4. Specification language;
5. Proof language;
6. Module language;
7. Meta-programming languages ---including Coq tactics, C preprocessor, Haskell
   pragmas, Template Haskell's various quotation brackets ~[x| ... ]~, Idris
   directives, etc.

As briefly discussed, the first five languages telescope down into one uniform
language within the dependently-typed language Agda. So why not the module
language?

** Needless Distinctions for Containers

Computing is compositionality. Large mind-bending software developments are
formed by composing smaller, much more manageable, pieces together. How? In the
previous section we outlined a number of languages equipped with term
constructors, yet we did not indicate which were more primitive and which could
be derived.

The methods currently utilised are ad hoc, e.g., â€œdump the contents of
packages into a new uÌˆber packageâ€. What about when the packages contain
conflicting names? â€œMake an uÌˆber package with field names for each package's
contentsâ€. What about viewing the new uÌˆber package as a hierarchy of its
packages? â€œMake conversion methods between the two representations.â€ This
/should be/ mechanically derivable.

In general, there are special-purpose constructs specifically for working with
packages of â€œusualâ€, or â€œday-to-dayâ€ expression- or statement-level code. That
is, a language for working with containers whose contents live in another
language. This forces the users to think of these constructs as rare notions
that are seldom needed ---since they belong to an ephemeral language. They are
only useful when connecting packages together and otherwise need not be learned.

When working with mutually dependent modules, a simple workaround to cyclic
typechecking and loading is to create an interface file containing the
declarations that dependents require. To mitigate such error-prone duplication
of declarations, one may utilise literate programming cite:knuth_lp to tangle
the declarations to multiple files ---the actual parent module and the interface
module. This was the situation with Haskell before its recent module signature
mechanism cite:haskell_backpack. Being a purely functional language, it is
unsurprising that Haskell treats nested record field updates awkwardly: Where a
C-like language may have {{{newline}}} ~a.b.c := d~, Haskell requires ~a { b = b a
{c = d}}~ which necessarily has field names ~b, c~ polluting the global function
namespace as field projections. Since a record is a possibly deeply nested list
of declarations, it is trivial to flatten such a list to mechanically generate
the names ~â€œa-b-câ€~ ---since the dot is reserved--- unfortunately this is not
possible in the core language thereby forcing users to employ â€˜lensesâ€™
cite:lenses to generate such accessors by compile-time meta-programming. In the
setting of DTLs, records in the form of nested Î£-types tend to have tremendously
poor performance ---in existing implementations of Coq cite:coq_cat_experiences
and Agda cite:perna, the culprit generally being projections. More generally,
what if we wanted to do something with packages that the host language does not
support? â€œUse a pre-processor, approximate packaging at a different language
level, or simply settle with what you have.â€

*Main Observation* Packages, modules, theories, contexts, traits, typeclasses,
interfaces, what have you all boil down to dependent records at the end of the
day and /really differ/ in /how/ they are used or implemented. At the end of section
3 we demonstrate various distinct presentations of such notions of packaging
arising from a single package declaration.

   # After discussing existing approach and foundations, along with the minimal
   # requirements of a candidate solution, we then present our preliminary findings
   # in section 3. In particular,

** Novel Contributions

The thesis investigates the current state of the art of grouping mechanisms
{{{newline}}} ---sometimes referred to as modules or packages---, their
shortcomings, and implementing candidate solutions based upon a
dependently-typed language.

The introduction of first-class structuring mechanisms drastically changes the
situation by allowing the composition and manipulation of structuring mechanisms
within the language itself. Granted, languages providing combinators for
structuring mechanisms are not new; e.g., such notions already exist for Full
Maude cite:maude_module_algebra and B cite:B_reuse. The former is closer in
spirit to our work, but it differs from ours in that it is based on a /reflective
logic/: A logic where certain aspects of its metatheory can be faithfully
represented within the logic itself. Not only does the meta-theory of our effort
not involve reflection, but our distinctive attribute is that our aim is to form
powerful module system features for Dependently-Typed Languages (DTLs).

To the uninitiated, the shift to DTLs may not appear useful, or at least would
not differ much from existing approaches. We believe otherwise; indeed, in
programming and, more generally, in mathematics, there are three ---below: 1,
2a, 2b--- essentially equivalent perspectives to understanding a concept. Even
though they are equivalent, each perspective has prompted numerous programming
languages; as such, the equivalence does not make the selection of a perspective
irrelevant. The perspectives are as follows:

1. â€œPoint-wiseâ€ or â€œConstituent-Basedâ€:
   A concept is understood by studying the concepts it is â€œmade out ofâ€.

   Common examples include:
   - A mathematical set is determined by the elements it contains.
   - A method is determined by the sequence of statements or expressions it is
     composed from.
   - A package ---such as a record or data declaration--- is determined by
     its components, which may be /thought of/ as fields or constructors.

   Object-oriented programming is based on the notion of inheritance which
   is founded on the â€œhas aâ€ and â€œis aâ€ relationships.

2. â€œPoint-freeâ€ or Relationship Based:
   A concept is understood by its relationship to other concepts in the domain
   of discourse.

   This approach comes into two sub-classifications:

   a. â€œFirst Class Citizenâ€ or â€œConcept as Dataâ€:
      The concept is treated as a static entity and is
      identified by applying operations /onto it/ in order to observe its nature.

      Common examples include:
      - A singleton set is a set whose cardinality is 1.
      - A method, in any coding language, is a value with the ability to act on
        other values of a particular type.
      - A renaming scheme to provide different names for a given package; more
        generally, applicative modules.

   b. â€œSecond Class Citizenâ€ or â€œConcept as Methodâ€:
      The concept is treated as a dynamic entity that
      is fed input stimuli and is understood by its emitted observational output.

      Common examples include:
      - A singleton set is a set for which there is a unique mapping to it from
        any other set. Input any set, obtain a map from it to the singleton set.
      - A method, in any coding language, is unique up to observational
        equality: Feed it arguments, check its behaviour. Realistically, one may
        want to also consider efficiency matters.
      - Generative modules as in the ~new~ keyword from object-oriented
        programming: Basic construction arguments are provided and a container
        object is produced.

   Observing such a sub-classification as distinct led to traditional structural
   programming languages, whereas blurring the distinction somewhat led to
   functional programming.

A simple selection of equivalent perspectives leads to wholly distinct paradigms
of thought. It is with this idea that we seek to implement first-class grouping
mechanisms in a dependently typed language ---theories have been proposed, on
paper, but as just discussed /actual design decisions may have challenging
impacts on the overall system/. Most importantly, this is a /requirements driven/
approach to coherent modularisation constructs in dependently typed languages.

Later on, we shall demonstrate that with a sufficiently expressive type system,
a number of traditional programming notions regarding â€˜packaging up dataâ€™ become
conflated ---in particular: Records and modules; which for the most part can all
be thought of as â€œdependent products with named componentsâ€. Languages without
such expressive type systems necessitate certain constraints on these concepts
according to their intended usage ---e.g., no multiple inheritance for Java's
classes and only one instance for Haskell's typeclasses. It is not clear whether
such constraints have been brought to more expressive languages out of
necessity, convention, or convenience. Hence, in chapter cite:sec:three, we
perform a systematic exploration of the structuring-mechanism design space for
DTLs as a starting point for the design of an appropriate dependently-typed
module system (cite:sec:four). Along the way, we intend to provide a set of
atomic combinators that suffice as building blocks for generally desirable
features of grouping mechanisms, and moreover we intend to provide an analyses
of their interactions.

That is, we want to look at the edge cases of the design space for
structuring-mechanism /systems/, not only what is considered convenient or
conventional. Along the way, we will undoubtedly encounter useless or
non-feasible approaches. The systems we intend to consider would account for,
say, module structures with intrinsic types ---hence treating them as first
class concepts--- so that our examination is based on sound principles.

Understandably, some of the traditional constraints have to do with
implementations. For example, a Haskell typeclass is generally implemented as a
dictionary that can, for the most part, be inlined whereas a record is, in some
languages, a contiguous memory block: They can be identified in a DTL, but their
uses force different implementation methodologies and consequently they are
segregated under different names.

In summary, our research builds upon the existing state of module systems
cite:types_for_modules in a dependently-typed setting cite:dtls_give_modules
which is substantiated by developing practical and pragmatic tools. Our outcomes
include:
  1. A clean module system for DTLs that treats modules uniformly as any other value type.
  2. A variety of use-cases contrasting the resulting system with previous
     approaches.
  3. A module system that enables rather than inhibits efficiency.
  4. Demonstrate that module features traditionally handled using
     meta-programming can be brought to the data-value level; thereby not
     actually requiring the immense power and complexity of meta-programming.

Most importantly, we intend to implement our theory to obtain validation that it
â€˜worksâ€™.
** Overview of the Remaining Chapters

When a programming languages does not provide sufficiently expressive
primitives for a concept ---such as typeclass derivation cite:deriving_via---
users use some form of pre-processing to accomplish their tasks. In our case,
the insufficient primitives are regarding the creation and manipulation of
theories ---i.e., records, classes, packages, modules. In section 3, we will
demonstrate an undisciplined prototype that clarified the requirements of our
envisioned system. Even though the prototype appears to be metaprogramming,
the aim is not to force users interested in manipulating packages to worry
about the intricacies of representations; that is, the end goal is to avoid
metaprogramming ---which is an over-glorified form of preprocessing. The goal
is to /use a dependently-typed language to implement/ /the â€˜missingâ€™ module
system features directly inside the language./

An important design decision is whether the resulting development is intended to
be reasoned about or not. If reasoning is important, then a language that better
supports it is ideal. That is why we are using Agda ---using a simpler language
and maintaining data invariants eventually becomes much harder cite:hasochism.

The remainder of the thesis is organised as follows.

:Outline:
+ Chapter II discusses what is expected of modularisation mechanisms,
  how they could be simulated, their interdefinability in Agda, and
  discuss a theoretical basis for modularisation.

+ Chapter III outlines missing features from current modularisation systems,
  their use cases, and provides a checklist for a candidate module
  system for DTLs.

+ Chapter IV discusses issues regarding implementation matter and the next steps
  in this research, along with a proposed timeline.

+ Chapter V outlines the intended outcomes of this research effort.
:End:

+ *Â§ 2 Examples from the wild*

   There are a host of repeated module patterns since modules are not a
   first-class construct. We look at three Agda libraries and extract â€œmodule
   design patterns for dependently-typed programmingâ€ ---to the best of our
   knowledge, we are the first to formalise such design patterns for a
   dependently-typed language. Three other, non-module, design patterns are
   discussed in cite:10.1145/1411204.1411213.

   :RoughOutline:
   - E.g., IsX and X in Agda's standard library.
   - E.g., Hom, and universal algebra constructs, /for/ a paraticular theory.
   - E.g., common renaming patterns such as X_i or X' or etc for a theory X.
     - Cannot do this in Context due to Agda's limited support for fresh names.
     - Doable in PF.
   :End:

+ *Â§ 3 Metaprogramming Module Meta-primitives*

   To show that first-class modules are /reasonable/, we begin by providing
   PackageFormer cite:DBLP:conf/gpce/Al-hassyCK19: A specfication and
   manipulation language for modules, for Agda.
   To show that the approach is promising, we demonstrate how some problems
   from Â§2 can be tackled.

   # - Emacs Lisp is used as an implementation language since Emacs is the de facto
   #   editor for Agda.

   - The tool is a *practical* sandbox for exploring do-it-yourself grouping mechanisms:
     From pushouts and pullbacks, to forming homomorphism types over a given theory.

+ *Â§ 4 Module Meta-primitives as Library Methods*

   The ideas learned from making the powerful ~PackageFormer~ prototype lead us to
   form the less-powerful ~Context~ framework, which has the orthogonal benefit of
   being an Agda library rather than an external pre-processing tool.
   :RoughOutline:
   - E.g., a termtype arises by keeping only the fields that target the elected
     ADT carrier.
   - Ideas of :waist!
   :End:

   - Along the way, we solve the *unbundling problem*: Features of a structure may be
     exposed at the type level as-needed.

+ *Â§ 5 Conclusion: The lingua franca dream as reality*

   We compare the external ~PackageFormer~ tool with the ~Context~ library, and
   discuss how the latter has brought us closer to our original goal of having a
   single language for expressing values, types, and modules.

 It has been an exciting journey, I hope you enjoy the ride!

* Motivating the problem ---Examples from the Wild

** Introduction :ignore:
Tedium is for machines; interesting problems are for people.

In this section, we showcase a number of problems that occur in developing
libraries of code, with an eye to dependently-typed languages. We will refer
back to these real-world examples later on when developing our frameworks for
reducing their tedium and size.

Incidentally, the common solutions to the problems presented may be construed as
â€œdesign patterns for dependently-typed programmingâ€. Design patterns are
algorithms yearning to be formalised. The power of the host language dictates
whether design patterns remain as informal directions to be implemented in an
ad-hoc basis then checked by other humans, or as a library methods that are
written once and may be freely applied by users. For instance, [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.Morphism.html#1][Agda's
~Algebra.Morphism~ â€œlibraryâ€]] presents an example(!) of the homomorphism design
pattern ---which shows how to form operation-preserving functions for algebraic
structures. The documentation reads: ~An example showing how a morphism type can
be defined~. An example, rather than a library method, is all that can be done
since the current implementation of Agda does not have the necessary
meta-programming utilities to construct new types in a practical way ---at
least, not out of the box.
# #
# + The procedure is essentially the same for other algebraic structures.
# + It takes time to do form these explicitly, even for the common structures.

** Adding Zero then Multiplying by One Results in a Type Error

   In theory, lists and vectors are the same ---where the latter are essentially
   lists indexed by their lengths. In practice, however, the additional length
   information stated up-front as an integral part of the data structure makes
   it not only easier to write programs that would otherwise by awkward or
   impossible in the latter case. For instance, below we demonstrate that the
   function ~head~, which extracts the first element of a non-empty list, not only
   has a difficult type to read, but also requires an auxiliary relation in
   order to be expressed. In contrast, the vector variant has a much simpler
   type with the non-emptiness proviso expressed by requesting a positive
   length.

#+BEGIN_SRC agda :tangle list-is-not-vec.agda :prologue "module list-is-not-vec where \nopen import Notation \n"
data List (A : Set) : Set where
  []  : List A
  _âˆ·_ : A â†’ List A â†’ List A

data Vec (A : Set) : â„• â†’ Set where
  []  : Vec A 0
  _âˆ·_ : âˆ€ {n} â†’ A â†’ Vec A n â†’ Vec A (suc n)

data not-null {A : Set} : List A â†’ Set where
  indeed : âˆ€ {x xs} â†’ not-null (x âˆ· xs)

head : âˆ€ {A} â†’ Î£ xs âˆ¶ List A â€¢ not-null xs â†’ A
head (x âˆ· xs , indeed) = x

headâ€² : âˆ€ {A n} â†’ Vec A (suc n) â†’ A
headâ€² (x âˆ· xs) = x
#+END_SRC

This phenomena applies not only to derived concepts such as non-emptiness, but
also to explicit features of a datatype. A common scenario is when two instances
of an algebraic structure share the same carrier and thus it is reasonable to
connect the two somehow by a coherence axiom. Perhaps the most popular instance
of this scenario is in the setting of rings: There is an additive monoid ~(R, +,
0)~ and a multiplicative monoid ~(R, Ã—, 0)~ on the same underlying set, and their
interaction is dictated by two distributivity axioms, such as ~a Ã— (b + c) â‰ˆ (a
Ã— b) + (a Ã— c)~. As with ~head~ above, depending on which features of a monoid are
exposed upfront, such axioms may be either difficult to express or relatively easy.

For brevity, since our interest is in expressing the aforementioned distributivity axiom,
we shall ignore all other features of a monoid, to obtain a magma.
#+BEGIN_SRC agda :tangle list-is-not-vec.agda
record Magmaâ‚€ : Setâ‚ where
  field
    Carrier : Set
    _â¨¾_      : Carrier â†’ Carrier â†’ Carrier

module Distributivityâ‚€
    (Additive Multiplicative : Magmaâ‚€)
    (open Magmaâ‚€ Additive renaming (Carrier to Râ‚Š; _â¨¾_ to _+_))
    (open Magmaâ‚€ Multiplicative renaming (Carrier to Râ‚“; _â¨¾_ to _Ã—_))
    (shared-carrier :  Râ‚Š â‰¡ Râ‚“)
    where

  coeâ‚“ : Râ‚Š â†’ Râ‚“
  coeâ‚“ = subst id shared-carrier

  coeâ‚Š : Râ‚“ â†’ Râ‚Š
  coeâ‚Š = subst id (sym shared-carrier)

  distributeâ‚€ : âˆ€ {a : Râ‚“} {b c : Râ‚Š}
                â†’   a Ã— coeâ‚“ (b + c)
                  â‰¡ coeâ‚“ (coeâ‚Š(a Ã— coeâ‚“ b) + coeâ‚Š(a Ã— coeâ‚“ c))
  distributeâ‚€ = {!!}
#+END_SRC
It is a bit of a challenge to understand the type of ~distributeâ‚€~.
Even though the carriers of the monoids are propositionally equal, ~Râ‚Š â‰¡ Râ‚“~,
they are not the same by definition. As such, we are forced to â€œcoeâ€rce back and forth;
leaving the distributivity axiom as an exotic property of addition, multiplication, and coercions.
Even worse, without the cleverness of declaring two coercion helpers, the typing of ~distributeâ‚€~
would have been so large and confusing that the concept would be rendered near useless.

Let's clarify what equality means. One says ~ğ“ â‰¡ ğ“‡~ is <<</definitionally
equal/>>> when both sides are indistinguishable after all possible definitions
in the terms ~ğ“~ and ~ğ“‡~ have been used. In contrast, the equality is
<<</propositionally equal/>>> when one must perform actual work, such as using
inductive reasoning. In general, if there are no variables in ~ğ“ â‰¡ ğ“‡~ then we have
definitional equality ---i.e., simplify as much as possible then compare---
otherwise we have propositional equality ---real work to do. Below is an example
about the types of vectors.
#+BEGIN_SRC agda :tangle list-is-not-vec.agda
definitional : âˆ€ {A} â†’ Vec A 5 â‰¡ Vec A (2 + 3)
definitional = refl

propoistional : âˆ€ {A m n} â†’ Vec A (m + n) â‰¡ Vec A (n + m)
propoistional = {!!}
#+END_SRC

In theory, parameterised structures are no different from their unparameterised, or â€œbundledâ€, counterparts.
However, in practice, this is wholly untrue: Below we can phrase the distributivity axiom nearly as it was
stated informally earlier since the shared carrier is declared upfront.
#+BEGIN_SRC agda :tangle list-is-not-vec.agda
record Magmaâ‚ (Carrier : Set) : Setâ‚ where
  field
    _â¨¾_      : Carrier â†’ Carrier â†’ Carrier

module Distributivityâ‚
    (R : Set) {- The shared carrier -}
    (Additive Multiplicative : Magmaâ‚ R)
    (open Magmaâ‚ Additive       renaming (_â¨¾_ to _+_))
    (open Magmaâ‚ Multiplicative renaming (_â¨¾_ to _Ã—_))
    where

  distributeâ‚ : âˆ€ {a b c : R}
                â†’ a Ã— (b + c) â‰¡ (a Ã— b) + (a Ã— c)
  distributeâ‚ = {!!}
#+END_SRC
In contrast to the bundled definition of magmas, this form requires no cleverness to form coercion helpers,
and is closer to the informal and usual distributivity statement.

By the same arguments above, the simple statement relating the two units of a ring $1 Ã— r + 0 â‰ˆ r$
---or any units of monoids sharing the same carrier--- is easily phrased using an unbundled presentation
and would require coercions otherwise. We invite the reader to pause at this moment to appreciate the difficulty
in simply expressing this property.

Computing is filled with exciting problems; machines should help us reduce if
not eliminate boring tasks.

#+begin_quote
*Unbundling Design Pattern*:
If a feature of a class is shared among instances, then use an unbundled form of the class
to avoid â€œcoercion hellâ€.
#+end_quote

Observe that we assigned superficial renamings, aliases, to the prototypical
binary operation ~_â¨¾_~ so that we may phrase the distributivity axiom in its
expected notational form. This leads us to our next topic of discussion.

** Renaming

The use of an idea is generally accompanied with particular notation that is
accepted by the community. Even though the choice of bound names it
theoretically irrelevant, certain communities would consider it unacceptable to
deviate from convention. Here are a few examples:

- ~x(f)~ :: Using ~x~ as a /function/ and ~f~ as an /argument/.; likewise $\frac{\partial x}{\partial f}$.

  With the exception of people familiar with the Yoneda Lemma, or continuations,
  such a notation is simply â€œwrongâ€!

- ~a Ã— a â‰ˆ a~ :: An idempotent operation denoted by multiplication; likewise for commutative operations.

  It is more common to use addition or join, ~âŠ”~.

- ~0 Ã— a â‰ˆ a~ :: The identity of â€œmultiplicative symbolsâ€ should never resemble
  â€œ0â€; instead it should resemble â€œ1â€ or, at least, ~â€œeâ€~ ---the standard
  abbreviation of the influential algebraic works of German authors who used
  â€œEinheitâ€ which means â€œidentityâ€.

- ~f + g~ :: Even if monoids are defined with the prototypical binary operation
  denoted â€œ+â€, it would be â€œwrongâ€ to continue using it to denote functional composition.
  One would need to introduce the new name â€œâˆ˜â€ or, at least, â€œÂ·â€.

From the few examples above, it is immediate that to even present a prototypical
notation for an idea, one immediately needs auxiliary notation when specialising
to a particular instance. For example, to use â€œadditive symbolsâ€ such as ~+, âŠ”,
âŠ•~ to denote an arbitrary binary operation leads to trouble in the function
composition instance above, whereas using â€œmultiplicative symbolsâ€ such as ~Ã—,
Â·, *~ leads to trouble in the idempotent case above.

Regardless of prototypical choices, there will always be a need to rename.

#+begin_quote
*Renaming Design Pattern*:
Use superficial aliases to better communicate an idea;
especially so, when the topic domain is specialised.
#+end_quote

Let's now turn to examples of renaming from three libraries:
1. Agda's standard library,
2. The RATH-Agda library, and
3. A recent categories library.

Each will provide a workaround to the problem of renaming. In particular, the
solutions are, respectively:

1. Rename as needed.
   - There is no systematic approach to account for the many common renamings.
   - Users are encouraged to do the same, since the standard library does it this way.

2. Pack-up the /common/ renamings as modules, and invoke them when needed.
   - Which renamings are provided is left at the discretion of the designer
     ---even â€œexpectedâ€ renamings may not be there since, say, there are too many
     choices or not enough man power to produce them.
   - The pattern to pack-up renamings leads nicely to consistent naming.

3. Names don't matter.
   - Users of the library need to be intimately connected with the definitions
     are domain to use the library.
   - Consequently, there are many inconsistencies in naming.

  The ~open â‹¯ public â‹¯ renaming â‹¯~ pattern shown below will be presented in a
   future section as a library method.

*** Renaming Problems from Agda's Standard Library

[[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.Structures.html#2757][Here is an excerpt from Agda's standard library]], notice how the prototypical
notation for monoids is rename repeatedly /as needed/. Sometimes it is
relabelled with additive symbols, other times with multiplicative symbols.
#+BEGIN_SRC agda2
record IsNearSemiring {a â„“} {A : Set a} (â‰ˆ : Rel A â„“)
                      (+ * : Opâ‚‚ A) (0# : A) : Set (a âŠ” â„“) where
  open FunctionProperties â‰ˆ
  field
    +-isMonoid    : IsMonoid â‰ˆ + 0#
    *-isSemigroup : IsSemigroup â‰ˆ *
    distribÊ³      : * DistributesOverÊ³ +
    zeroË¡         : LeftZero 0# *

  open IsMonoid +-isMonoid public
         renaming ( assoc       to +-assoc
                  ; âˆ™-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  )

  open IsSemigroup *-isSemigroup public
         using ()
         renaming ( assoc    to *-assoc
                  ; âˆ™-cong   to *-cong
                  )

record IsSemiringWithoutOne {a â„“} {A : Set a} (â‰ˆ : Rel A â„“)
                            (+ * : Opâ‚‚ A) (0# : A) : Set (a âŠ” â„“) where
  open FunctionProperties â‰ˆ
  field
    +-isCommutativeMonoid : IsCommutativeMonoid â‰ˆ + 0#
    *-isSemigroup         : IsSemigroup â‰ˆ *
    distrib               : * DistributesOver +
    zero                  : Zero 0# *

  open IsCommutativeMonoid +-isCommutativeMonoid public
         hiding (identityË¡)
         renaming ( assoc       to +-assoc
                  ; âˆ™-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  ; isMonoid    to +-isMonoid
                  ; comm        to +-comm
                  )

  open IsSemigroup *-isSemigroup public
         using ()
         renaming ( assoc       to *-assoc
                  ; âˆ™-cong      to *-cong
                  )

record IsSemiringWithoutAnnihilatingZero
         {a â„“} {A : Set a} (â‰ˆ : Rel A â„“)
         (+ * : Opâ‚‚ A) (0# 1# : A) : Set (a âŠ” â„“) where
  open FunctionProperties â‰ˆ
  field
    +-isCommutativeMonoid : IsCommutativeMonoid â‰ˆ + 0#
    *-isMonoid            : IsMonoid â‰ˆ * 1#
    distrib               : * DistributesOver +

  open IsCommutativeMonoid +-isCommutativeMonoid public
         hiding (identityË¡)
         renaming ( assoc       to +-assoc
                  ; âˆ™-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  ; isMonoid    to +-isMonoid
                  ; comm        to +-comm
                  )

  open IsMonoid *-isMonoid public
         using ()
         renaming ( assoc       to *-assoc
                  ; âˆ™-cong      to *-cong
                  ; isSemigroup to *-isSemigroup
                  ; identity    to *-identity
                  )

record IsRing
         {a â„“} {A : Set a} (â‰ˆ : Rel A â„“)
         (_+_ _*_ : Opâ‚‚ A) (-_ : Opâ‚ A) (0# 1# : A) : Set (a âŠ” â„“) where
  open FunctionProperties â‰ˆ
  field
    +-isAbelianGroup : IsAbelianGroup â‰ˆ _+_ 0# -_
    *-isMonoid       : IsMonoid â‰ˆ _*_ 1#
    distrib          : _*_ DistributesOver _+_

  open IsAbelianGroup +-isAbelianGroup public
         renaming ( assoc               to +-assoc
                  ; âˆ™-cong              to +-cong
                  ; isSemigroup         to +-isSemigroup
                  ; identity            to +-identity
                  ; isMonoid            to +-isMonoid
                  ; inverse             to -â€¿inverse
                  ; â»Â¹-cong             to -â€¿cong
                  ; isGroup             to +-isGroup
                  ; comm                to +-comm
                  ; isCommutativeMonoid to +-isCommutativeMonoid
                  )

  open IsMonoid *-isMonoid public
         using ()
         renaming ( assoc       to *-assoc
                  ; âˆ™-cong      to *-cong
                  ; isSemigroup to *-isSemigroup
                  ; identity    to *-identity
                  )
#+END_SRC

At first glance, one solution would be to package up these renamings into helper modules:
#+BEGIN_SRC agda2
-- Orginal notations
--------------------------------------------------------------------------------
record IsMonoid {a â„“} {A : Set a} (â‰ˆ : Rel A â„“)
                (âˆ™ : Opâ‚‚ A) (Îµ : A) : Set (a âŠ” â„“) where
  open FunctionProperties â‰ˆ
  field
    isSemigroup : IsSemigroup â‰ˆ âˆ™
    identity    : Identity Îµ âˆ™

record IsCommutativeMonoid {a â„“} {A : Set a} (â‰ˆ : Rel A â„“)
                           (_âˆ™_ : Opâ‚‚ A) (Îµ : A) : Set (a âŠ” â„“) where
  open FunctionProperties â‰ˆ
  field
    isSemigroup : IsSemigroup â‰ˆ _âˆ™_
    identityË¡   : LeftIdentity Îµ _âˆ™_
    comm        : Commutative _âˆ™_

    â‹®
  isMonoid : IsMonoid â‰ˆ _âˆ™_ Îµ
  isMonoid = record { â‹¯ }

-- Renaming helpers
--------------------------------------------------------------------------------
module AdditiveIsMonoid {a â„“} {A : Set a} {â‰ˆ : Rel A â„“}
               {_âˆ™_ : Opâ‚‚ A} {Îµ : A} (+-isMonoid : IsMonoid â‰ˆ _âˆ™_ Îµ)  where

   open IsMonoid +-isMonoid public
         renaming ( assoc       to +-assoc
                  ; âˆ™-cong      to +-cong
                  ; isSemigroup to +-isSemigroup
                  ; identity    to +-identity
                  )

module AdditiveIsCommutativeMonoid {a â„“} {A : Set a} {â‰ˆ : Rel A â„“}
               {_âˆ™_ : Opâ‚‚ A} {Îµ : A} (+-isCommutativeMonoid : IsMonoid â‰ˆ _âˆ™_ Îµ)  where

   open AdditiveIsMonoid (CommutativeMonoid.isMonoid +-isCommutativeMonoid) public
   open IsCommutativeMonoid +-isCommutativeMonoid public using ()
      renaming ( comm to +-comm
               ; isMonoid to +-isMonoid)
#+END_SRC
However, one then needs to make similar modules for /additive notation/ for
~IsAbelianGroup, IsRing, IsCommutativeRing, â€¦~. Moreover, this still invites
repetition: Additional notations, as used in ~IsSemiring~, would require
additional helper modules.
#+BEGIN_SRC agda2
module MultiplicativeIsMonoid {a â„“} {A : Set a} {â‰ˆ : Rel A â„“}
               {_âˆ™_ : Opâ‚‚ A} {Îµ : A} (*-isMonoid : IsMonoid â‰ˆ _âˆ™_ Îµ)  where

   open IsMonoid *-isMonoid public
         renaming ( assoc       to *-assoc
                  ; âˆ™-cong      to *-cong
                  ; isSemigroup to *-isSemigroup
                  ; identity    to *-identity
                  )
#+END_SRC

Unless carefully organised, such notational modules would bloat the standard
library, resulting in difficulty when navigating the library. As it stands
however, the new algebraic structures appear large and complex due to the
â€œrenaming hellâ€ encountered to provide the expected conventional notation.

*** Renaming Problems from the RATH-Agda Library

The impressive [[http://relmics.mcmaster.ca/RATH-Agda/RATH-Agda-2.2.pdf][Relational Algebraic Theories in Agda]] library takes a disciplined
approach: Copy-paste notational modules, possibly using a find-replace mechanism
to vary the notation. The use of a find-replace mechanism leads to consistent naming
across different notations.

#+caption: Relation.Binary.Setoid.Utils
#+begin_quote
For contexts where calculation in different setoids is necessary, we provide
â€œdecoratedâ€ versions of the ~Setoidâ€²~ and ~SetoidCalc~ interfaces:
#+end_quote
#+BEGIN_SRC agda2
module SetoidA {i j : Level} (S : Setoid i j) = Setoidâ€² S renaming
    ( â„“ to â„“A ; Carrier to Aâ‚€ ; _â‰ˆ_ to _â‰ˆA_ ; â‰ˆ-isEquivalence to â‰ˆA-isEquivalence
    ; â‰ˆ-isPreorder to â‰ˆA-isPreorder ; â‰ˆ-preorder to â‰ˆA-preorder
    ; â‰ˆ-indexedSetoid to â‰ˆA-indexedSetoid
    ; â‰ˆ-refl to â‰ˆA-refl ; â‰ˆ-reflexive to â‰ˆA-reflexive ; â‰ˆ-sym to â‰ˆA-sym
    ; â‰ˆ-trans to â‰ˆA-trans ; â‰ˆ-transâ‚ to â‰ˆA-transâ‚ ; â‰ˆ-transâ‚‚ to â‰ˆA-transâ‚‚
    ; _âŸ¨â‰ˆâ‰ˆâŸ©_ to _âŸ¨â‰ˆAâ‰ˆâŸ©_ ; _âŸ¨â‰ˆâ‰ˆË˜âŸ©_ to _âŸ¨â‰ˆAâ‰ˆË˜âŸ©_ ; _âŸ¨â‰ˆË˜â‰ˆâŸ©_ to _âŸ¨â‰ˆAË˜â‰ˆâŸ©_ ; _âŸ¨â‰ˆË˜â‰ˆË˜âŸ©_ to _âŸ¨â‰ˆAË˜â‰ˆË˜âŸ©_
    ; _âŸ¨â‰¡â‰ˆâŸ©_ to _âŸ¨â‰¡â‰ˆAâŸ©_ ; _âŸ¨â‰¡â‰ˆË˜âŸ©_ to _âŸ¨â‰¡â‰ˆAË˜âŸ©_ ; _âŸ¨â‰¡Ë˜â‰ˆâŸ©_ to _âŸ¨â‰¡Ë˜â‰ˆAâŸ©_ ; _âŸ¨â‰¡Ë˜â‰ˆË˜âŸ©_ to _âŸ¨â‰¡Ë˜â‰ˆAË˜âŸ©_
    ; _âŸ¨â‰ˆâ‰¡âŸ©_ to _âŸ¨â‰ˆAâ‰¡âŸ©_ ; _âŸ¨â‰ˆâ‰¡Ë˜âŸ©_ to _âŸ¨â‰ˆAâ‰¡Ë˜âŸ©_ ; _âŸ¨â‰ˆË˜â‰¡âŸ©_ to _âŸ¨â‰ˆAË˜â‰¡âŸ©_ ; _âŸ¨â‰ˆË˜â‰¡Ë˜âŸ©_ to _âŸ¨â‰ˆAË˜â‰¡Ë˜âŸ©_
    )

module SetoidB {i j : Level} (S : Setoid i j) = Setoidâ€² S renaming
    ( â„“ to â„“B ; Carrier to Bâ‚€ ; _â‰ˆ_ to _â‰ˆB_ ; â‰ˆ-isEquivalence to â‰ˆB-isEquivalence
    ; â‰ˆ-isPreorder to â‰ˆB-isPreorder ; â‰ˆ-preorder to â‰ˆB-preorder
    ; â‰ˆ-indexedSetoid to â‰ˆB-indexedSetoid
    ; â‰ˆ-refl to â‰ˆB-refl ; â‰ˆ-reflexive to â‰ˆB-reflexive ; â‰ˆ-sym to â‰ˆB-sym
    ; â‰ˆ-trans to â‰ˆB-trans ; â‰ˆ-transâ‚ to â‰ˆB-transâ‚ ; â‰ˆ-transâ‚‚ to â‰ˆB-transâ‚‚
    ; _âŸ¨â‰ˆâ‰ˆâŸ©_ to _âŸ¨â‰ˆBâ‰ˆâŸ©_ ; _âŸ¨â‰ˆâ‰ˆË˜âŸ©_ to _âŸ¨â‰ˆBâ‰ˆË˜âŸ©_ ; _âŸ¨â‰ˆË˜â‰ˆâŸ©_ to _âŸ¨â‰ˆBË˜â‰ˆâŸ©_ ; _âŸ¨â‰ˆË˜â‰ˆË˜âŸ©_ to _âŸ¨â‰ˆBË˜â‰ˆË˜âŸ©_
    ; _âŸ¨â‰¡â‰ˆâŸ©_ to _âŸ¨â‰¡â‰ˆBâŸ©_ ; _âŸ¨â‰¡â‰ˆË˜âŸ©_ to _âŸ¨â‰¡â‰ˆBË˜âŸ©_ ; _âŸ¨â‰¡Ë˜â‰ˆâŸ©_ to _âŸ¨â‰¡Ë˜â‰ˆBâŸ©_ ; _âŸ¨â‰¡Ë˜â‰ˆË˜âŸ©_ to _âŸ¨â‰¡Ë˜â‰ˆBË˜âŸ©_
    ; _âŸ¨â‰ˆâ‰¡âŸ©_ to _âŸ¨â‰ˆBâ‰¡âŸ©_ ; _âŸ¨â‰ˆâ‰¡Ë˜âŸ©_ to _âŸ¨â‰ˆBâ‰¡Ë˜âŸ©_ ; _âŸ¨â‰ˆË˜â‰¡âŸ©_ to _âŸ¨â‰ˆBË˜â‰¡âŸ©_ ; _âŸ¨â‰ˆË˜â‰¡Ë˜âŸ©_ to _âŸ¨â‰ˆBË˜â‰¡Ë˜âŸ©_
    )

module SetoidC {i j : Level} (S : Setoid i j) = Setoidâ€² S renaming
    ( â„“ to â„“C ; Carrier to Câ‚€ ; _â‰ˆ_ to _â‰ˆC_ ; â‰ˆ-isEquivalence to â‰ˆC-isEquivalence
    ; â‰ˆ-isPreorder to â‰ˆC-isPreorder ; â‰ˆ-preorder to â‰ˆC-preorder
    ; â‰ˆ-indexedSetoid to â‰ˆC-indexedSetoid
    ; â‰ˆ-refl to â‰ˆC-refl ; â‰ˆ-reflexive to â‰ˆC-reflexive ; â‰ˆ-sym to â‰ˆC-sym
    ; â‰ˆ-trans to â‰ˆC-trans ; â‰ˆ-transâ‚ to â‰ˆC-transâ‚ ; â‰ˆ-transâ‚‚ to â‰ˆC-transâ‚‚
    ; _âŸ¨â‰ˆâ‰ˆâŸ©_ to _âŸ¨â‰ˆCâ‰ˆâŸ©_ ; _âŸ¨â‰ˆâ‰ˆË˜âŸ©_ to _âŸ¨â‰ˆCâ‰ˆË˜âŸ©_ ; _âŸ¨â‰ˆË˜â‰ˆâŸ©_ to _âŸ¨â‰ˆCË˜â‰ˆâŸ©_ ; _âŸ¨â‰ˆË˜â‰ˆË˜âŸ©_ to _âŸ¨â‰ˆCË˜â‰ˆË˜âŸ©_
    ; _âŸ¨â‰¡â‰ˆâŸ©_ to _âŸ¨â‰¡â‰ˆCâŸ©_ ; _âŸ¨â‰¡â‰ˆË˜âŸ©_ to _âŸ¨â‰¡â‰ˆCË˜âŸ©_ ; _âŸ¨â‰¡Ë˜â‰ˆâŸ©_ to _âŸ¨â‰¡Ë˜â‰ˆCâŸ©_ ; _âŸ¨â‰¡Ë˜â‰ˆË˜âŸ©_ to _âŸ¨â‰¡Ë˜â‰ˆCË˜âŸ©_
    ; _âŸ¨â‰ˆâ‰¡âŸ©_ to _âŸ¨â‰ˆCâ‰¡âŸ©_ ; _âŸ¨â‰ˆâ‰¡Ë˜âŸ©_ to _âŸ¨â‰ˆCâ‰¡Ë˜âŸ©_ ; _âŸ¨â‰ˆË˜â‰¡âŸ©_ to _âŸ¨â‰ˆCË˜â‰¡âŸ©_ ; _âŸ¨â‰ˆË˜â‰¡Ë˜âŸ©_ to _âŸ¨â‰ˆCË˜â‰¡Ë˜âŸ©_
    )
#+END_SRC

This keeps going to cover the alphabet ~SetoidD, SetoidE, SetoidF, â€¦, SetoidZ~
then we shift to subscripted versions ~Setoidâ‚€, Setoidâ‚, â€¦, Setoidâ‚„~.

Next, RATH-Agda shifts to the need to calculate with setoids:
#+BEGIN_SRC agda2
module SetoidCalcA {i j : Level} (S : Setoid i j) where
  open SetoidA S public
  open SetoidCalc S public renaming
    ( _â–¡ to _â–¡A
    ; _â‰ˆâŸ¨_âŸ©_ to _â‰ˆAâŸ¨_âŸ©_
    ; _â‰ˆË˜âŸ¨_âŸ©_ to _â‰ˆAË˜âŸ¨_âŸ©_
    ; _â‰ˆâ‰¡âŸ¨_âŸ©_ to _â‰ˆAâ‰¡âŸ¨_âŸ©_
    ; _â‰ˆâŸ¨âŸ©_ to _â‰ˆAâŸ¨âŸ©_
    ; _â‰ˆâ‰¡Ë˜âŸ¨_âŸ©_ to _â‰ˆAâ‰¡Ë˜âŸ¨_âŸ©_
    ; â‰ˆ-begin_ to â‰ˆA-begin_
    )
module SetoidCalcB {i j : Level} (S : Setoid i j) where
  open SetoidB S public
  open SetoidCalc S public renaming
    ( _â–¡ to _â–¡B
    ; _â‰ˆâŸ¨_âŸ©_ to _â‰ˆBâŸ¨_âŸ©_
    ; _â‰ˆË˜âŸ¨_âŸ©_ to _â‰ˆBË˜âŸ¨_âŸ©_
    ; _â‰ˆâ‰¡âŸ¨_âŸ©_ to _â‰ˆBâ‰¡âŸ¨_âŸ©_
    ; _â‰ˆâŸ¨âŸ©_ to _â‰ˆBâŸ¨âŸ©_
    ; _â‰ˆâ‰¡Ë˜âŸ¨_âŸ©_ to _â‰ˆBâ‰¡Ë˜âŸ¨_âŸ©_
    ; â‰ˆ-begin_ to â‰ˆB-begin_
    )
module SetoidCalcC {i j : Level} (S : Setoid i j) where
  open SetoidC S public
  open SetoidCalc S public renaming
    ( _â–¡ to _â–¡C
    ; _â‰ˆâŸ¨_âŸ©_ to _â‰ˆCâŸ¨_âŸ©_
    ; _â‰ˆË˜âŸ¨_âŸ©_ to _â‰ˆCË˜âŸ¨_âŸ©_
    ; _â‰ˆâ‰¡âŸ¨_âŸ©_ to _â‰ˆCâ‰¡âŸ¨_âŸ©_
    ; _â‰ˆâŸ¨âŸ©_ to _â‰ˆCâŸ¨âŸ©_
    ; _â‰ˆâ‰¡Ë˜âŸ¨_âŸ©_ to _â‰ˆCâ‰¡Ë˜âŸ¨_âŸ©_
    ; â‰ˆ-begin_ to â‰ˆC-begin_
    )
#+END_SRC
This keeps going to cover the alphabet ~SetoidCalcD, SetoidCalcE, SetoidCalcF, â€¦, SetoidCalcZ~
then we shift to subscripted versions ~SetoidCalcâ‚€, SetoidCalcâ‚, â€¦, SetoidCalcâ‚„~.
If we ever have more than 4 setoids in hand, or prefer other decorations, then
we would need to produce similar helper modules.
| Each ~Setoidğ’³ğ’³ğ’³~ takes 10 lines, for a total of at-least 600 lines! |

Indeed, such renamings bloat the library, but, unlike the Standard Library, they
allow new records to be declared easily ---â€œrenaming hellâ€ has been deferred
from the user to the library designer. However, later on, in ~Categoric.CompOp~,
we see the variations ~LocalEdgeSetoidğ’Ÿ~ and ~LocalSetoidCalcğ’Ÿ~ where decoration
~ğ’Ÿ~ ranges over ~â‚€, â‚, â‚‚, â‚ƒ, â‚„, R~. The inconsistency in not providing the other
decorations used for ~Setoidğ““~ earlier is understandable: These take time to
write and maintain.

Various similar decorations can be found in RATH, such as for ~Semigroupoidğ’Ÿ~ in
~Categoric.Semigroupoid~.

*** Renaming Problems from the Agda-categories Library

With RATH-Agda's focus on notational modules at one end of the spectrum, and the
Standard Library's casual do-as-needed in the middle, it is inevitable that
there are other equally popular libraries but at the other end of the spectrum.
The [[https://github.com/agda/agda-categories][Agda-categories]] library seemingly ignored the need for meaningful names
altogether! Below are a few notable instances.

+ Functors have fields named ~Fâ‚€, Fâ‚, F-resp-â‰ˆ, â€¦~.
  - This could be considered reasonable even if one has a functor named ~G~.
  - This [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/Product.agda][leads to expressions]] such as ~< F.Fâ‚€ , G.Fâ‚€ >~.
  - Incidentally, and somewhat inconsistently, a ~Pseudofunctor~ has fields ~Pâ‚€,
    Pâ‚, P-homomophism~ ---where the latter is documented /P preserves â‰ƒ/.

  On the opposite extreme, RATH-Agda's importance on naming has it functor record
  having fields named ~obj, mor, mor-cong~ instead of ~Fâ‚€, Fâ‚, F-resp-â‰ˆ~
  ---which refer to a functor's â€œobjâ€ect map, â€œmorâ€phism map, and the fact that the
  â€œmorâ€phism map is a â€œcongâ€ruence.

+ Such lack of concern for naming might be acceptable for well-known concepts
  such as functors, where some communities use ~Fáµ¢~ to denote the object/0 or
  morphism/1 operations. However, considering [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/SubCategory.agda][subcategories]] one is sees field
  names ~U, R, Rid, _âˆ˜R_~ which are wholly unhelpful. Instead, more meaningful
  names such as ~embed, keep, id-kept, keep-resp-âˆ˜~ could have been used.

+ The ~Iso, Inverse,~ and ~NaturalIsomorphism~ records have fields ~to / from, f
  / fâ»Â¹,~ and ~~Fâ‡’G / Fâ‡G~, respectively.

  #  ( ~Categories.Category~ )

  Even though some of these build on one another, with Agda's namespacing
  features, all â€œforwardâ€ and â€œbackwardâ€ morphism fields could have been named,
  say, ~to~ and ~from~. The naming may not have propagated from ~Iso~ to other
  records possibly due to the low priority for names.

  From a usability perspective, projections like ~f~ are reminiscent of the OCaml
  community and may be more acceptable there. Since Agda is more likely to attract
  Haskell programmers than OCaml ones, such a particular projection seems completely
  our of place. Likewise, the field name ~Fâ‡’G~ seems only appropriate if the
  functors involved happen to be named ~F~ and ~G~.

  These unexpected deviations are not too surprising since the Agda-categories
  library seems to give names no priority at all. Field projections are treated
  little more than classic array indexing with numbers.


By largely avoiding renaming, Agda-categories has no â€œrenaming hellâ€ anywhere at
the heavy price of being difficult to read: Any attempt to read code requires
one to â€œsquint awayâ€ the numerous projections to â€œseeâ€ the concepts of
relevance. Consider the [[https://github.com/agda/agda-categories/blob/master/src/Categories/Yoneda.agda][following excerpt]].
#+BEGIN_SRC agda
helper : âˆ€ {F : Functor (Category.op C) (Setoids â„“ e)}
                     {A B : Obj} (f : B â‡’ A)
                     (Î² Î³ : NaturalTransformation Hom[ C ][-, A ] F) â†’
                   Setoid._â‰ˆ_ (Fâ‚€ Nat[Hom[C][-,c],F] (F , A)) Î² Î³ â†’
                   Setoid._â‰ˆ_ (Fâ‚€ F B) (Î· Î² B âŸ¨$âŸ© f âˆ˜ id) (Fâ‚ F f âŸ¨$âŸ© (Î· Î³ A âŸ¨$âŸ© id))
          helper {F} {A} {B} f Î² Î³ Î²â‰ˆÎ³ = S.begin
            Î· Î² B âŸ¨$âŸ© f âˆ˜ id          S.â‰ˆâŸ¨ cong (Î· Î² B) (id-comm â—‹ (âŸº identityË¡)) âŸ©
            Î· Î² B âŸ¨$âŸ© id âˆ˜ id âˆ˜ f     S.â‰ˆâŸ¨ commute Î² f CE.refl âŸ©
            Fâ‚ F f âŸ¨$âŸ© (Î· Î² A âŸ¨$âŸ© id) S.â‰ˆâŸ¨ cong (Fâ‚ F f) (Î²â‰ˆÎ³ CE.refl) âŸ©
            Fâ‚ F f âŸ¨$âŸ© (Î· Î³ A âŸ¨$âŸ© id) S.âˆ
            where module S where
                    open Setoid (Fâ‚€ F B) public
                    open SetoidR (Fâ‚€ F B) public
#+END_SRC

Here are a few downsides of not renaming:

1. The type of the function is difficult to comprehend; though it need not be.
   - Take ~_â‰ˆâ‚€_ = Setoid._â‰ˆ_ (Fâ‚€ Nat[Hom[C][-,c],F] (F , A))~, and
   - Take ~_â‰ˆâ‚_ = Setoid._â‰ˆ_ (Fâ‚€ F B)~,
   - Then the type says: If ~Î² â‰ˆâ‚€ Î³~ then
     ~Î· Î² B âŸ¨$âŸ© f âˆ˜ id â‰ˆâ‚ Fâ‚ F f âŸ¨$âŸ© (Î· Î³ A âŸ¨$âŸ© id)~
     ---a naturality condition!

2. The short proof is difficult to read!
   - The repeated terms such as ~Î· Î² B~ and ~Î· Î² A~ could have been renamed with
     mnemoic-names such as ~Î·â‚, Î·â‚‚~ or ~Î·â‚›, Î·â‚œ~ for â€˜sâ€™ource/1 and â€˜tâ€™arget/2.

Recall that functors ~F~ have projections ~Fáµ¢~, so the â€œmorâ€phism map on a given
morphism ~f~ becomes ~Fâ‚ F f~, as in the excerpt above; however, using
RATH-Agda's naming it would have been ~mor F f~.

Since names are given a lower priority, one no longer needs to perform renaming.
Instead, one is content with projections. The downside is now there are too many
projections, leaving code difficult to comprehend. Moreover, this leads to
inconsistent renaming.

** From ~Isğ“§~ to ~ğ“§~ ---Packing away components

 The distributivity axiom from earlier required an unbundled structure /after/ a
 completely bundled structure was initially presented. Usual structure are rather
 large and have libraries built around them, so building and using an alternate form
 is not practical. However, multiple forms are usually desirable.

 To accommodate the need for both forms of structure, Agda's Standard Library
 begins with a [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.Structures.html#1][type-level predicate]] such as ~IsSemigroup~ below, then [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.html#1][packs that up
 into a record]]. Here is an instance, along with comments from the library.
 #+caption: From the [[http://www.cse.chalmers.se/~nad/listings/lib/Algebra.html#601][Agda Standard Library on Algebra]]
 #+BEGIN_SRC agda2
-- Some algebraic structures (not packed up with sets, operations, etc.
record IsSemigroup {a â„“} {A : Set a} (â‰ˆ : Rel A â„“)
                   (âˆ™ : Opâ‚‚ A) : Set (a âŠ” â„“) where
  open FunctionProperties â‰ˆ
  field
    isEquivalence : IsEquivalence â‰ˆ
    assoc         : Associative âˆ™
    âˆ™-cong        : âˆ™ Preservesâ‚‚ â‰ˆ âŸ¶ â‰ˆ âŸ¶ â‰ˆ

-- Definitions of algebraic structures like monoids and rings (packed in records
-- together with sets, operations, etc.)
record Semigroup c â„“ : Set (suc (c âŠ” â„“)) where
  infixl 7 _âˆ™_
  infix  4 _â‰ˆ_
  field
    Carrier     : Set c
    _â‰ˆ_         : Rel Carrier â„“
    _âˆ™_         : Opâ‚‚ Carrier
    isSemigroup : IsSemigroup _â‰ˆ_ _âˆ™_
 #+END_SRC

 If we refer to the former as ~IsX~ and the latter as ~X~, then we can see similar
 instances in the standard library for ~X~ being: ~Monoid, Group, AbelianGroup,
 CommutativeMonoid,~ ~SemigroupWithoutOne, NearSemiring, Semiring,
 CommutativeSemiringWithoutOne, CommutativeSemiring, CommutativeRing~.

 It thus seems that to present an idea ~X~, we require the same amount of space
 to present it unpacked or packed, and so doing both duplicates the process
 and only hints at the underlying principle: From ~IsX~ we pack away the carriers
 and function symbols to ~X~. The converse approach, starting from ~X~ and going to ~IsX~
 is not practical, as it leads to numerous unhelpful reflexivity proofs.

 #+begin_quote
 *Predicate Design Pattern:* Present a concept ğ“§ first as a predicate ~Isğ“§~ on types
 and function symbols, then as a type ~ğ’³~ consisting of types, function symbols,
 and a proof that together they satisfy the ~Isğ’³~ predicate.

 *Î£ Padding Anti-Pattern*: Starting from a bundled up type ~ğ’³~ consisting of types,
 function symbols, and how they interact, one may form the type ~Î£ X âˆ¶ ğ’³ â€¢ ğ’³.f X â‰¡
 ğ’‡~ to specialise the feature ~ğ’³.f~ to the particular choice ~ğ’‡~. However, nearly all
 uses of this type will be of the form ~(X , refl)~ where the proof is unhelpful
 noise.
 #+end_quote

 Since the standard library uses the predicate pattern, ~Isğ’³~, which requires all
 sets and function symbols, the Î£-padding anti-pattern becomes a necessary evil.
 Instead, it would be preferable to have the family ~ğ’³áµ¢~ which is the same as ~Isğ’³~
 but only takes ~ğ’¾~-many elements ---c.f., ~Magmaâ‚€~ and ~Magmaâ‚~ above. However,
 writing these variations and functions to move between them is not only tedious
 but also error prone. Later on, also demonstrated in [GPCE19], we shall show
 how the bundled form ~ğ’³~ acts as /the/ definition, with other forms being
 derived-as-needed.

 Incidentally, the particular choice ~ğ’³â‚~, a predicate on one carrier, deserves
 special attention. In Haskell, instances of such a type are generally known as
 /typeclass instances/ and ~ğ’³â‚~ is known as a /typeclass/. In Agda, we may mark such
 implementations for instance search using the keyword ~instance~.

 #+begin_quote
 *Typeclass Design Pattern*: Present a concept ğ’³ as a unary predicate ~ğ“§â‚~ that
 associates functions and properties with a given type. Then, mark all
 implementations with ~instance~ so that arbitrary ~ğ’³~-terms may be written without
 having to specify the particular instance.

 When there are multiple instance of an ğ’³-structure on a particular type, only
 one of them may be marked for instance search in a given scope.
 #+end_quote

** Redundancy, Derived Features, and Feature Exclusion

 A tenet of software development is not to over-engineer solutions; e.g., we need
 a notion of untyped composition, and so use ~Monoid~. However, at a later stage,
 we may realise that units are inappropriate and so we need to drop them to
 obtain the weaker notion of ~Semigroup~ ---for instance, if we wish to module
 finite functions as hashmaps, we need to omit the identity functions since they
 may have infinite domains; and we cannot simply enforce a convention, say, to
 treat empty hashmaps as the identities since then we would lose the empty
 functions. Incidentally, this example, among others, led to dropping the
 identity features from Categories to obtain so-called Semigroupoids.

 In weaker languages, we could continue to use the monoid interface at the cost
 of â€œthrowing an exceptionâ€ whenever the identity is used. However, this breaks
 the Interface Segregation Principle: Users should not be forced to bother with
 features they are not interested in. A prototypical scenario is exposing an
 expressive interface, possibly with redundancies, to users, but providing a
 minimal self-contained counterpart by dropping some features for the sake of
 efficiency or to act as a â€œsmart constructorâ€ that takes the least amount of
 data to reconstruct the rich interface.

 For example, in the Agda-categories library one finds concepts expressive
 interfaces, with redundant features, named ~ğ’³~, along with their minimal
 self-contained versions, named ~ğ’³Helper~. In particular, the [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/Core.agda][Category]] type and the
 [[https://github.com/agda/agda-categories/blob/master/src/Categories/NaturalTransformation/NaturalIsomorphism.agda][natural isomorphism]] type are instances of such a pattern. The redundant features
 are there to make the lives of users easier; e.g., Agda-categories states the following.
 #+begin_quote
 We add a symmetric proof of associativity so that the opposite category of the
 opposite category is definitionally equal to the original category.
 #+end_quote
 To underscore the intent, we present below a minimal setup needed to express the
 issue. The semigroup definition contains a redundant associativity axiom
 ---which can be obtained from the first one by applying symmetry of equality.
 This is done purposefully so that the â€œopposite, or dual, transformerâ€ ~_Ë˜~ is
 self-inverse on-the-nose; i.e., definitionally rather than propositionally.
 Definitionally equality does not need to be â€˜invokedâ€™, it is used silently when
 needed, thereby making the redundant setup worth it.
 #+begin_src agda2 :tangle op-involutive-on-the-nose.agda :prologue module op-involutive-on-the-nose where \nopen import Notation\n
record Semigroup : Setâ‚ where
  constructor ğ’®
  field
    Carrier : Set
    _â¨¾_     : Carrier â†’ Carrier â†’ Carrier
    assocÊ³ : âˆ€ {x y z} â†’  (x â¨¾ y) â¨¾ z  â‰¡  x â¨¾ (y â¨¾ z)
    assocË¡ : âˆ€ {x y z} â†’  x â¨¾ (y â¨¾ z)  â‰¡  (x â¨¾ y) â¨¾ z

    -- Notice:  assocË¡ â‰ˆ sym assocÊ³

_Ë˜ : Semigroup â†’ Semigroup
(ğ’® Carrier _â¨¾_ assocÊ³ assocË¡) Ë˜ = ğ’® Carrier (Î» b a â†’ a â¨¾ b)  assocË¡ assocÊ³

Ë˜Ë˜â‰ˆid : âˆ€ {S} â†’ (S Ë˜) Ë˜ â‰¡ S
Ë˜Ë˜â‰ˆid = refl
 #+end_src

 #+begin_quote
 *On-the-nose Redundancy Design Pattern* [Agda-Categories]: Include redundant
 features if they allow certain common constructions to be definitional equal,
 thereby requiring no overhead to use such an equality. Then, provide a smart
 constructor so users are not forced to produce the redundant features manually.
 #+end_quote

 Incidentally, since this is not a library method, inconsitencies are bound to
 arise; in particular, in the ~ğ’³~ and ~ğ’³Helper~ naming scheme: The ~NaturalIsomorphism~
 type has ~NIHelper~ as its minimised version, and the type of [[https://github.com/agda/agda-categories/blob/master/src/Categories/Category/Monoidal/Symmetric.agda][symmetric monoidal
 categories]] is oddly called ~Symmetricâ€²~ with its helper named ~Symmetric~. Such
 issues could be reduced, if not avoided, if library methods were used instead.

 It is interesting to note that duality forming operators, such as ~_Ë˜~ above, are
 a design pattern themselves. How? In the setting of algebraic structures, one
 picks an operation to have its arguments flipped, then systematically â€˜flipsâ€™
 all proof obligations via a user-provided symmetry operator. We shall return to
 this as a library method in a future section.

 # Since names are given a low priority, the brading operation is simply called ~B~!
 # A symbol closer to the standard model, inverses ~_â»Â¹~, such as ~_Ë˜~ may have been
 # more suggestive.

 Another example of purposefully keeping redundant features is for the sake of
 efficiency.
  #+begin_quote
 For division semi-allegories, even though right residuals, restricted residuals,
 and symmetric quotients all can be derived from left residuals, we still assume
 them all as primitive here, since this produces more readable goals, and also
 makes connecting to optimised implementations easier.

 ---RATH-Agda Â§15.13
  #+end_quote

 For instance, the above semigroup type could have been augmented with an
 ordering if we view ~_â¨¾_~ as a meet-operation. Instead, we lift such a derived
 operation as a primitive field, in case the user has a better implementation.
  #+begin_src agda2 :tangle op-involutive-on-the-nose.agda
record Order (S : Semigroup) : Setâ‚ where
  open Semigroup S public
  field
    _âŠ‘_    : Carrier â†’ Carrier â†’ Set
    âŠ‘-def  : âˆ€ {x y} â†’ (x âŠ‘ y) â‰¡ (x â¨¾ y â‰¡ x)

  {- Results about _â¨¾_ and _âŠ‘_ here â€¦ -}

defaultOrder : âˆ€ S â†’ Order S
defaultOrder S = let open Semigroup S
                 in record { _âŠ‘_ = Î» x y â†’ x â¨¾ y â‰¡ x ; âŠ‘-def = refl }
  #+end_src

  #+begin_quote
 *Efficient Redundancy Design Pattern* [RATH-Agda, Â§17.1]: To enable efficient
 implementations, replace derived operators with additional fields for them and
 for the equalities that would otherwise be used as their definitions. Then,
 provide instances of these fields as derived operators, so that in the absence
 of more efficient implementations, these default implementations can be used
 with negligible penalty over a development that defines these operators as
 derived in the first place.
  #+end_quote

 # Also
 # which RATH-Agda does a number of times ---e.g., due to the converse
 # operator, not only are division operators are inter-definable but
 # symmetric-quotient congruence laws are derivable.

** Extensions

   In our previous discussion, we needed to drop features from ~Monoid~ to get
   ~Semigroup~. However, excluding the unit element from the monoid also required
   excluding the identity laws. More generally, all features reachable, via
   occurrence relationships, must be dropped when a particular feature is
   dropped. In some sense, a generated graph of features needs to be â€œripped outâ€
   from the starting type, and the generated graph may be the whole type. As
   such, in general, we do not know if the resulting type even has any features.

   Instead, in an ideal world, it is preferable to begin with a minimal interface
   then /extend/ it with features as necessary. E.g., begin with ~Semigroup~
   then add orthogonal features until ~Monoid~ is reached. Extensions are also
   known by /subclassing/ or /inheritance/.

 #+BEGIN_SRC mermaid :file semigroup-to-monoid.png :theme default :background-color transparent  :tangle no :tangle no :exports results
graph LR                          %% A â€œLâ€eft to â€œRâ€ight graph

Semigroup[<strong>Semigroup</strong><br>carrier <br> binary operation <br> associtivity law ]
PointedSemigroup[<strong>PointedSemigroup</strong><br>carrier <br> binary operation <br> <i>unit element</i> <br> associtivity law ]
LeftUnitalSemigroup[<strong>LeftUnitalSemigroup</strong><br>carrier <br> binary operation <br> unit element <br> <i>left identity law</i> <br> associtivity law ]
RightUnitalSemigroup[<strong>RightUnitalSemigroup</strong><br>carrier <br> binary operation <br> unit element <br> <i>right identity law</i> <br> associtivity law ]
Monoid[<strong>Monoid</strong><br>carrier <br> binary operation <br> unit element <br> <i>left identity law <br> right identity law</i> <br> associtivity law ]

Semigroup --> PointedSemigroup

PointedSemigroup --> LeftUnitalSemigroup
PointedSemigroup --> RightUnitalSemigroup

LeftUnitalSemigroup --> Monoid
RightUnitalSemigroup --> Monoid
 #+END_SRC

 #+RESULTS:
 [[file:semigroup-to-monoid.png]]

 #+begin_quote
 *Extension Design Pattern:* To extend a structure ~ğ’³~ by new features ~fâ‚€, â€¦, fâ‚™~
 which may mention features of ~ğ’³~, make a new structure ~ğ’´~ with fields for ~ğ’³, fâ‚€,
 â€¦, fâ‚™~. Then publicly open ~ğ’³~ in this new structure so that the features of ~ğ’³~ are
 visible directly from ~ğ“¨~ to all users.
 #+end_quote

 The libraries mentioned thus far generally implement extensions in this way.
 By way of example, here is how monoids could be built directly from semigroups in one step.
 #+begin_src agda2 :tangle semigroups_to_monoids.agda :prologue module list-is-not-vec where \nopen import Notation\n
record Semigroup : Setâ‚ where
  field
    Carrier : Set
    _â¨¾_     : Carrier â†’ Carrier â†’ Carrier
    assoc  : âˆ€ {x y z} â†’  (x â¨¾ y) â¨¾ z  â‰¡  x â¨¾ (y â¨¾ z)

record Monoid : Setâ‚ where
  field
    semigroup : Semigroup

  open Semigroup semigroup public  {- (0) -}

  field
    Id      : Carrier
    leftId  : âˆ€ {x} â†’ Id â¨¾ x â‰¡ x
    rightId : âˆ€ {x} â†’ x â¨¾ Id â‰¡ x

open Monoid

neato : âˆ€ {M} â†’ Carrier M â†’ Carrier M â†’ Carrier M
neato {M} = _â¨¾_ M    {- Possible due to (0) above -}
 #+end_src

 Notice how we accessed the binary operation ~_â¨¾_~ feature from ~Semigroup~ as if it
 were a native feature of ~Monoid~. Unfortunately, ~_â¨¾_~ is only superficially native
 to ~Monoid~ ---any actual instance, such as ~woah~ below, needs to define the binary
 operation in a ~Semigroup~ instance first.
 #+begin_src agda2 :tangle semigroups_to_monoids.agda
woah : Monoid
woah = record { semigroup = {!!} ; Id = {!!} ; leftId = {!!} ; rightId = {!!} }
 #+end_src

 While library designers may be content to build ~Monoid~ out of ~Semigroup~, users
 should not be forced to learn about how the hierarchy was built. Even worse,
 when the library designers decide to incorporate, say, ~LeftUnitalSemigroup~ then
 all users' code would break. Instead, it would be preferable to have a
 â€˜flattenedâ€™ presentation for the users that â€œdoes not leak out implementation
 detailsâ€. We shall return to this in a future section.

** Summary of Some Design Patterns in Dependently-Typed Programming
   :PROPERTIES:
   :CUSTOM_ID: design-patterns
   :END:

 Below is a summary of the design patterns mentioned above, using monoids as the
 prototypical structure. Some patterns we did not cover, as they will be covered
 in future sections.

 #+caption: PL Research is about getting free stuff: From the left-most node, we can get a lot!
 # #+BEGIN_SRC mermaid  :file patterns.png :theme forest :background-color transparent
 #+BEGIN_SRC mermaid  :file patterns.png :theme forest :exports results
graph TD %% LR and TD are both also good!

%% A(<br><hr> Carrier : Set <br> _â¨¾_ : Carrier â†’ Carrier â†’ Carrier <br> Id : Carrier)
A(<hr> carrier <br> binary operation <br> point <br> left identity law <br> right identity law <br> associtivity law)
B(carrier <br> binary operation <br> point <br><hr> left identity law <br> right identity law <br> associtivity law)
C(carrier <br><hr> binary operation <br> point <br> left identity law <br> right identity law <br> associtivity law)

D{<hr> <pre>Branch <br>Nil </pre>}               %% Using verbatim environment
E{Variables <br><hr> <pre>Embed <br>Branch <br>Nil </pre>} %% Using verbatim environment
F((<hr> &ensp;carrier <br> &ensp;binary operation <br> &ensp;point))

A-. Predicate  &ensp;<br> .->B
B-. Î£ Padding  &ensp;<br>.->A
A-. Typeclass  &ensp;<br> .-> C
C-. Î£ Padding &ensp;<br> .-> A

A-. Closed Termtype  &ensp;<br> .-> D
D-. Interpreter &ensp;<br> .-> A
A-. Open Termtype &ensp;<br> .-> E
E-. Interpreter  &ensp;<br> .-> C
E-. Setoid &ensp;<br> .-> A
A-. Signature &ensp;<br> .-> F
E-- Instance  &ensp;<br> --> F

A-. Renaming &ensp;<br> .-> R
R-. Renaming &ensp;<br> .-> A
R(<hr> universe of discourse <br> composition <br> unit <br> left unital <br> right unital <br> parenthesis shift)

A-- Theorem Proving &ensp;<br> -->A

E-- Simplifier  &ensp;<br> -->E
E-- Metaprogramming  &ensp;<br> -->E

UA> Universal <br> Algebra ]

A-. Î» Homomorphism &nbsp;<br> Î» Kernel &nbsp;<br> Î» Products &nbsp;<br> Î» FOL termtypes &nbsp;<br> Î» etc .-> UA
C-. Î» Products &nbsp;<br> Î» Substructure &nbsp;<br> Î» etc .-> UA
UA-. Î» Pushouts / Pullbacks &nbsp;<br> Î» Extensions / Exclusions &nbsp;<br> Î» Duality / Views &nbsp;<br> Î» etc .-> UA

subgraph  %% A subgraph environment places the legend in the top left, which is better than it being in the bottom somewhere.
Legend[<center>Legend</center>0. Parameters occur above the waist line <br> 1. Fields occur below the waist line <br> 2. Dashed lines are design patterns ]
end
 #+END_SRC
 #+RESULTS:
 [[file:patterns.png]]

 Remarks:

 0. It is important to note that the ~termtype~ constructions could also be
    co-inductive, thereby yielding possibly infinitely branching syntax-trees.

    - In the â€œsimplifyâ€ pattern, one could use axioms as rewrite rules.

 1. It is more convenient to restrict a carrier or to form products along carriers using the typeclass version.

 2. As discussed earlier, the name /typeclass/ is justified not only by the fact
    that this is the shape used by typeclasses in Haskell and Coq, but also that
    instance search for such records is supported in Agda by using the ~instance~
    keyword.

 There are many more design patterns in dependently-typed programming. Since
 grouping mechanisms are our topic, we have only presented those involving
 organising data.

* COMMENT Background: What's necessary to solve this problem?
   - What is needed to just understand this problem?
   - Agda
   - System F
   - Monads
   - Metaprogramming

   Maybe tackle this "as needed", rather than upfront.

* COMMENT Current Approaches
   :PROPERTIES:
   :CUSTOM_ID: current_approaches
   :END:

** COMMENT Who has worked on this problem and where have they gotten?
** COMMENT What are their shortcomings and advantages wrt to our approach?
** COMMENT Shortcomings of our approach.
** COMMENT Missing features and next steps.

** Intro                                                             :ignore:

Structuring mechanisms for proof assistants are seen as tools providing
administrative support for large mechanisation developments
cite:LF_practical_module_system, with support for them usually
being conservative: Support for structuring-mechanisms elaborates, or rewrites,
into the language of the ambient system's logic. Conservative extensions
are reasonable to avoid bootstrapping new foundations altogether but they
come at the cost of limiting expressiveness to the existing foundations;
thereby possibly producing awkward or unusual uses of linguistic phrases
of the ambient language.

We may use the term â€˜moduleâ€™ below due to its familiarity, however some of the
issues addressed also apply to other instances of grouping mechanisms
---such as records, code blocks, methods, files, families of files, and namespaces.

In section 2.1 we define modularisation; in section 2.2 we discuss how to
simulate it, and in section 2.3 we review what current systems can and cannot do;
then in section 2.4 we provide legitimate examples of the interdefinability of
different grouping mechanisms within Agda. We conclude in section 2.5 by
taking a look at an implementation-agnostic representation of grouping mechanisms
that is sufficiently abstract to ignore any differences between a record and
an interface but is otherwise sufficiently useful to encapsulate what is expected of
module systems.
Moreover, besides looking at the current solutions, we also briefly discuss their flaws.

** Expectations of Module Systems

# JC: 2.1 is wonderful.  For your thesis, I will want this expanded (references, table of where the feature exists, etc), but this is enough for the proposal.

Packaging systems are not so esoteric that we need to dwell on their uses;
yet we recall primary use cases to set the stage for the rest of our discussions.

+ Namespacing :: Modules provide new unique local scopes for identifiers thereby permitting de-coupling.

         The ability to have multiple files contribute to the same namespace is also desirable
         for de-coupled developments. This necessitates an independence of module names from
         the names of physical files ---such de-conflation permits recursive modules.

+ Information Hiding :: Modules ought to provide the ability to enforce content /not/ to be accessible,
    or alterable, from outside of the module to enforce that users cannot depend on implementation design decisions.

+ Citizenship :: Grouping mechanisms need not be treated any more special than record types.
         As such, one ought to be able to operate on them and manipulate them
         like any first-class citizen.

         In particular, packages themselves have types which happen to be packages.
         This is the case with universal algebra, and OCaml, where
         â€˜structuresâ€™ are typed by â€˜signaturesâ€™
         ---note that OCaml's approach is within the same language, whereas, for example,
         Haskell's recent retrofitting cite:haskell_backpack,
         of its weak module system to allow such interfacing, is not
         entirely in the core language since, for example, instantiating happens
         by the package manager rather than by a core language declaration.

+ Polymorphism :: Grouping mechanisms should group all kinds of things without prejudice.

          This includes â€˜nested datatypesâ€™: Local types introduced for implementation
          purposes, where only certain functionality is exposed. E.g., in an Agda record
          declaration, it may be nice to declare a local type where the record fields refer to it.
          This approach naturally leads into hierarchical modules as well.

          Interestingly, such nesting is expressible in [[http://fsl.cs.illinois.edu/images/5/5e/Cayenne.pdf][Cayenne]], a long-gone predecessor
          of Agda. The language lived for about 7 years and it is unclear why it is no longer
          maintained. Speculation would be that dependent types were poorly understood by
          the academics let alone the coders ---moreover, it had essentially one maintainer
          who has since moved on to other projects.

          With the metaprogramming inspired approach we are proposing, it is only reasonable that, for example,
          one be able to mechanically transform a package with a local type declaration into
          a package with the local declaration removed and a new component added to abstract it.
          That is, a particular implementation is no longer static, but dynamic.

It would not be unreasonable to consider adding to this enumeration:
+ Sharing :: The computation performed for a module parameter should be
         shared across its constituents, rather than inefficiently being recomputed
         for each constituent ---as is the case in the current implementation of Agda.

It is however debatable whether the following is the â€˜rightâ€™ way to incorporate
object-oriented notions of encapsulation.
+ Generative modules :: A module, rather than being pure like a function, may have
     some local state or initial setup that is unique to each â€˜instantiationâ€™ of
     the module ---rather than being purely applying a module to parameters.

     #  As I remember Leroy-1995, the point was that SML's generative system is replaced in OCaml with an applicative system.
     SML supports such features.
     Whereas Haskell, for example,
     has its typeclass system essentially behave like an implicitly type-indexed record
     for the â€˜unnamed instance recordâ€™ declarations; thereby rendering useless
     the interfaces supporting, say, only an integer constant.
+ Subtyping :: This gives rise to â€˜heterogeneous equalityâ€™ where altering type annotations can suddenly
        make a well-typed expression ill-typed. E.g., any two record values are equal /at/ the
        subtype of the empty record, but may be unequal at any other type annotation.

        Since a package could contain anything, such as notational declarations,
        it is unclear how even homogeneous equality should be defined
        ---assuming notations are not part of a package's type.

There are many other concerns regarding packages ---such as deriving excerpts, decoration with
higher-order utilities, literate programming support, and matters of compilation along altered constituents---
but they serve to distract from our core discussions and are thus omitted.

*** COMMENT âŸª Originally lengthy & messy version âŸ« What's Expected of Module Systems?

**** Namespacing

  Modules ought to provide new unique local scopes ---say, by hiding or exporting--- wherein names are considered unique.
  Consequently, the same name declared in distinct modules ought to be considered
  distinct names. This idea permits de-coupling: Implementations are independent
  of one another, whence alterations can transpire in parallel, and development
  may proceed rapidly.
  # Maintaibility!

  Consider the case of de-coupled implementations that incidentally contain
  the exact same datatype declaration ---for example, the modules were created
  at different times by completely different people, and we cannot alter either code.
  If we could alter the code, we might factor out the similarities; otherwise,
  it would be fruitful to provide aliases to the datatype /and/ its constructors:
  The latter is usually not possible in many languages, but it is in Haskell and Agda
  for example, thereby permitting pattern matching on previously-identical constructor names.

{{{remark(WK: Interchangable? Really? Example!)}}}

**** COMMENT Separate Compilation ---WK: Why is this important? What for?

Module code is built /once/ in a while ---e..g, when it was last altered.
  As such, scripts that rely on pre-existing module code should not waste
  time rebuilding the module library. For example, in Agda, files are
  built once to produce ~agdai~ ---â€œinteractive Agdaâ€--- files, which are then
  used speedily by other files. Our scripts, in Agda, go through the process
  of parsing, typechecking, and producing the ~agdai~ files ---this process
  needn't be repeated for pre-existing modules.

  Alternatively, for example, if a file contains two code blocks each referring
  to distinct namespaces and only one of them is altered, then the state of the
  other namespace ought to remain the same ---even if it indirectly refers to the
  former namespace--- and so should not require to be rebuilt.
  With sufficient care, a similar argument could be presented for methods
  and code blocks.

**** Grouping Mechanisms Should Group All Kinds Of Things!

***** Genericity ---Parameters and State

Module matter may be utilised in unimagined manners, so should be adaptable.

  - To support such adaptability, varying degrees of polymorphic, generic, programming
    should be supported ---to avoid duplicate code, if anything else.

     E.g., Agda provides a hierarchy of types which can be quantified over, yet
     there are record and module constructs that are essentially the same but
     this is inexpressible in Agda since these two grouping mechanisms have
     distinct citizenship classification in Agda.

  - Modules may require an initial communication to occur with an external
   system ---such as setting up a network connection or initialising a global
   variable---.

   To provide such support, consideration should be given to effectful module
   invocations. The distinction between effectful and pure module operations is notable
   within the OCaml and SML communities in the form of `functors',
   {{{remark(Both effectful and pure?)}}}
   even though the concepts are widely popular
   in stateful languages ---e.g., in the guise of a constructor method for a
   class in an object oriented language.

   Being total and pure, Agda currently does not support such effectful
   modules. Utilising secondary options, such as pragmas, may be one
   of the best possible approximations. In fact this is essentially what
   the C preprocessor does when it includes header files ---the preprocessor copies and pastes
   contents of other files into the current script.

  - Modules may be parameterised ---such as which network to connect to, or
    which file to read from.

    The computation performed for a parameter should be shared across its
    constituents, rather than inefficiently being recomputed by each constituent.
    Haskell, for example, forms a â€˜thunkâ€™ of memory that refers to the result
    of the /unevaluated/ computation such that each constituent refers to it.
    Once any constituent actually makes use of it, then it is evaluated, and
    all other constituents continue to point to the same memory location
    which now has the resulting computed value.
    However, the current implementation of Agda forces each
    constituent to re-compute the value of a parameter ---there is minimal
    sharing.

{{{remark()}}}

***** Instance-Specific Variables in Pure Languages

  Before even getting to nested type declarations, one desirable feature of any
  grouping mechanism is to contain instance specific-variables.

  For example, suppose I have a type ~t~ that is to implement an interface ~i~
  containing an integer value ~rank~.
  In Haskell, for example, ~i~ is a typeclass and its utilities are dispatched according
  to the instances declared. Even if ~t~ is declared an instance of ~i~, the invocation ~rank~
  makes no reference to ~t~ in its type and it might as well be referring to the rank
  associated with any other type!
  The problem is that the instance is unnamed and the instance dictionary is indexed by the
  name ~t~, which is not referenced at all.
  As such, one would need to produce
  the following awkward workaround.
  In ~i~, we declare ~rank :: a -> Int~, even though we do not /intend/ to make any use of the argument,
  then at the invocation site we have ~rank (undefined :: t)~.
  This is all terribly roundabout; no wonder the Haskell library does not have a
  â€˜pointed carrierâ€™ typeclass! ( It does have a [[http://hackage.haskell.org/package/pointed-5.0.1/docs/Data-Pointed.html][â€˜pointed type constructorâ€™]] typeclass. )
  In contrast, C# interfaces, for example, can only contain methods and constants
  ---not arbitrary properties--- and avoid Haskell's problem.
  Incidentally, Scala, which can be thought of as a middle ground between Haskell and C#,
  allows the C#-like trait declaration.
  # https://gist.github.com/missingfaktor/2575397

  Observe that Haskell's distinction of constructs results in distinct tools:
  It needs both a type-class checker and a type-checker.
  The former is unnecessary if typeclasses were syntactic sugar for canonical record types,
  thereby having them as ordinary types.
  Conveniently, the reduction of distinctions not only makes it easier to learn a language
  but also demands less tooling on the compiler implementers.

***** Nested Type Declarations

  A grouping mechanism ought to provide support not only for amalgamating functionality
  but also for assembling data structures.
  Moreover the access to the two forms of data
  should be uniform ---e.g., by using the popular dot notation for both.
  #   Why? For example, a type of containers, say sets, exposes a certain functionality but
  #   the implementation of the container may be altered

  # https://stackoverflow.com/questions/2287267/alternatives-to-nested-interfaces-not-possible-in-c
  Depending on /intended/ usage, some grouping mechanisms do not allow the introduction
  of data structures. For example, C# does not allow this even for the case
  of an interface containing a nested interface ---incidentally, its
  close relative VB.NET does
  support such a feature.
  Unfortunately even Agda does not allow this; e.g., the following is invalid
  {{{code(Agda does not permit ~data~ in ~record~)}}}
  #+BEGIN_SRC agda org-agda
  record TreeContainer (A : Set) : Setâ‚ where

    data Rose : Set where Children : A â†’ List Rose â†’ Rose

    field
      initial  : Rose
      insert   : A â†’ Rose â†’ Rose
  #+END_SRC

  Note that the type ~Rose~ is not intended to be a field, but rather a local type that
  need not exist elsewhere. Unfortunately this is not possible for Agda records,
  but is only available at the module level ---which is not first class.
  It seems there was a proposal to include such features into
  Agda's older sibling, Haskell, some 6 years ago but the lack of dependent types
  made some features awkward, or impossible, to express, thereby leading to the abandonment
  of the project. @@latex: \iffalse ---this is merely speculation; but
  possibly related, \fi @@
  Interestingly, there is now currently
  much effort exerted into bringing dependent-types into Haskell in a
  harmonious fashion.

  :GraphsAreDTs:
  WK: What purpose does this remark serve at this location?

  For example, the ubiquitous notion of graphs is inherently
  a dependent type since the functions associating an edge with its source and target
  vertices have types depending on which type the vertices are and which type the edges are.

  {{{code(Graphs are Inherently a Dependent Type)}}}
  #+BEGIN_SRC agda org-agda
record Graph : Setâ‚ where
  field
    vertices : Set
    edges    : Set
    src tgt  : edges â†’ vertices
#+END_SRC
:End:

  That one works /over/ some given carrier type ---the fact that indexing by type is the only
  way to distinguish instance â€˜recordsâ€™--- has led the Haskell community to produce
  a number of isomorphic data types, using the ~newtype~ keyword, for the sole purpose of providing different typeclass
  instances. For example, the Booleans have the isomorphic copies [[http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html#t:All][~All~]] and [[http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Monoid.html#t:Any][~Any~]]
  for which there are conjunctive and disjunctive monoid instances, respectively;
  as well as conversions to the standard Booleans.
  Besides the essential duplication, comments are the only way to communicate the desired
  behaviour of the monoid typeclass ---in contrast, the Agda compiler can check such a specification.
  Nonetheless, type classes provide for tremendously terse code and it would be nice to
  declare which instance is to be used in a given scope cite:named_instances
  ---this is doable in Agda, Idris, and PureScript, to name a few,
  and there is a proposal to bring this to Haskell.

  :WhyTCsNotEnought:
    WK: What purpose does this remark serve at this location?

  It is to be noted that a naive approach such as inserting Boolean terms expressing
  the specification of a typeclass and having, say, QuickCheck ensure they hold on randomly
  generated input does not scale. Such an approach would work for ensuring, say, that
  the additive integers yield a monoid, but would fail to show that lists produce a functor
  since the random generation of /functions/ for ~fmap~ would be rather costly, to say the least.
  Another naive approach would be to reduce the Boolean terms to normal then checking for
  reflexivity. This only works for basic concepts, but is tremendously brittle:
  Ensuring the naturals under addition form a monoid would require an inductive proof,
  thereby necessitating a proof term to begin with. As such, explicit proof is necessary
  for the large scale verification of behavioural properties of data types.
  :End:

  :Cayenne:
  WK: What purpose does this remark serve at this location?

  Perhaps more realistically, consider a container type that supports certain
  functionality yet the particular implementation, call it ~C,~ is chosen dynamically.
  {{{code(Dynamic Containers)}}}
  #+BEGIN_SRC agda org-agda
record IntegerContainer : Setâ‚ where
  field
    C      : Set   {- The container implementation. -}
    empty  : C
    insert : Int â†’ C â†’ C
#+END_SRC

  However, the ~TreeContainer~ record is expressible in Cayenne, a long-gone predecessor
  of Agda. The language lived for about 7 years and it is unclear why it is no longer
  maintained. Speculation would be that dependent types were poorly understood by
  the academics let alone the coders ---a statement that remains true today as we have
  already discussed.
 # http://fsl.cs.illinois.edu/images/5/5e/Cayenne.pdf
 :End:

**** Excerpting ---Deriving Modules

  There is a tendency to depend on a particular set of modules when forming
  numerous scripts ---for example, requiring numeric, list, vector,
  and a variety of equality and isomorphism notions when working on a problem of representing bags.
  The common solution is to manually produce a module that re-exports the
  desired utilities.

  In the extreme case that we actually use one utility from each of /N/ modules,
  then our scripts will not depend on /N/ utility functions but rather on
  /N/ many modules ---which is not necessarily true. However, that is what appears
  on the surface and so those files must be built. For the sake of efficiency,
  it would be desirable to have a new module formed, say in the back-end,
  that includes only the minimum setup, from each module, needed to have the
  utility functions working. Ideally the system could be commanded to either
  produce such an amalgamated module implicitly in some local directory,
  or to weave it into the back-end ---either way, there would be side-effects.

  Besides efficiency, if this module could be presented
  by the system to the user, it would also make the resulting scripts more self-contained
  and so more re-usable. Moreover, for presentation purposes, it is convenient
  to have precisely only what is needed rather a hodge-podge of imports
  from a variety of libraries which may not even be publicly accessible
  ---as is the case with many personal libraries.

  Emacs' Org major mode provides for the ability to make such `tangling'
  happen. It has already been demonstrated that Agda code can be tangled from
  literate programming cite:knuth_lp with Org-mode documents, however the goal is to be
  able to do so directly within Agda itself.

**** Access Controls
{{{remark(Difference between this section and the next?)}}}

A key feature of grouping mechanisms is information hiding; the
ability to encapsulate data representations so that data invariants
may be maintained by the library utilities.
Thus, modules should have access controls
  ---the ability to enforce content /not/ to be accessible, or alterable, from
  outside of the module.

{{{remark(More general: To enfore that users cannot depend on implementation design decisions.)}}}

  In particular, when the implementation of a concept leaks details divergent
  from its intended interface, or if the implementation is likely to change,
  one should provide an interface and be able to make the definitions opaque
  to the system so that its normalisation is not overly aggressive.
  For example, suppose we implement bags using lists.
  Using knowledge of the implementation, users could produce methods
  that are undefinable for bags; e.g., any fold using a
  non-commutative operator. This is an opportunity to
  provide a definition and mark it as opaque.
  Agda does this with the ~abstract~ keyword
  ---which happens to be experimental since it's semantics are not
  well-understood.
  :PoorExample:
  For example, suppose we want to implement an addition algorithm over the
  natural numbers, but we have yet to settle on the implementation
  ---e.g., whether it is recursive on the first or second argument, or if it
  makes a translation to binary then back---, then this is an opportunity to
  provide a definition and mark it as opaque.
  #   Agda does this with the ~abstract~ keyword.
  :End:

  It is important to observe that many languages may hide method names, but
  this feature of Agda goes further. It hides the method implementation altogether
  from the user, so they cannot rely on it for reasoning purposes nor
  efficiency hacks. The latter being common programming tricks; e.g.,
  knowledge of ~gcc~ compiler implementations lets users favour certain constructs
  or form expressions that are considered undefined by the C language specification.

**** Representation Hiding

{{{remark(Difference between this section and the previous?)}}}

We've remarked that a module should serve multiple purposes, such as
  namespacing, but it should also provide support for creating abstract
  data types.

  For example,
  {{{remark(WK: What does this illustrate? DT? Context?)}}}
  suppose a library is intended to provide an in implementation
  for the notion of bags ---also known as multisets---, then the module would
  contain the implementation but the exported data would hide the implementation
  matter. Indeed, access to implementation matter could render dangerously incoherent
  operations to be permissible; such as deriving an order on a type by considering
  the hidden bag implementation.

  Another example of where access to an implementation radically alters
  the possibilities is in the relm of databases. A stack may be implemented
  using a linked list, but providing only a restricted core functionality.
  The latter can serve as a basic database, but the former cannot since one
  cannot implement the general ~select~ database operation on stacks
  to alter elements. {{{remark(WK: Insufficiant declaration of constraints!)}}}


  Stacks are not functorial. {{{remark(---Musa: Yes they are!)}}}
  #+begin_src haskell
---  fmap using only stack interface.

fmap f s | null s    = s
     | otherwise = let (hd, tl) = pop s in push(f hd, fmap f tl)
  #+end_src

**** Operations on grouping mechanisms ---grouping mechanisms as first-class citizens!

  A common experience is coding an algorithm along with print statements
  to keep the user notified of the events taking place, or of coding an
  algorithm and keeping track of a table of pre-computed values, i.e., memoiziation.
  The core logic of the algorithm is polluted with an extra-desirable
  functionality, which makes the core logic un-reusable when other functionality
  is desired. The solution is a â€˜decoratorâ€™, a higher-order function that
  takes the core algorithm as a method and yields a method that adds the
  extra-desirable functionalities.

  {{{remark(WK: â€œaspect-orientedâ€?)}}}
  For matters of efficiency, it may be desirable to take a module of polymorphic
  code and instantiate its variables to concrete types and values, possibly
  eliminating recursion as well to produce static code that incurs less dynamic
  penalty.

  Another common operation, which happens to be supported in OCaml, is obtaining the
  interface of a module. The manner in which code is grouped could be optimally
  aimed at maintainability or at usability. These are different problems and
  so should be decoupled.

**** Physical Independence

  In a zealous appeal to the principle of separation of concerns, some
  systems insist on only one module per file; moreover, the module's name
  must be the name of the physical file.
  However, incessant appeal to that principle results in fragmented hierarchies.
  It may be prudent to have multiple files contributing to the same module
  namespace, as in C, thereby necessitating filenames be independent from the module names.

{{{remark(WK: See also: ghc ---split-objs, ---split-sections)}}}

**** Subtyping & (Type-directed) Equality

  Subtyping is a controversial issue.
  On the one hand, it permits re-use.
  On the other hand, it makes type inference cite:type_inference_in_math rather weak.
  It's incorporation however does allow for using records for manifest fields.
  Then again, type inference is already sufficiently weak in a dependently-typed language,
  so this may not be too much of a burden.

  Moreover this now gives rise to (heterogeneous!) equality issues:
  If two records have only one common field with the same value, but otherwise have many
  other distinct fields, then they are equal only /at/ the sub-record consisting of that field,
  and are otherwise unequal /at/ any other type. Altering the type annotation can suddenly
  make a well-typed expression ill-typed.
  # This is worrisome, to say the least.
  #  This becomes more anxiety provoking when â€˜proof irrelevanceâ€™ and term erasure enter
  #  the scene.
  #
  # Altering the type annotation can suddenly make equal items unequal.

  Powerful languages like Agda allow for the declaration of patterns, notation, and
  precedence. Modelling a module by a record would suggest module equality is structural
  record equality ---but do we really want to consider notational declarations?
  If we do not, then we are considering equality /at/ the greatest common sub-record type?

  Perhaps sub-typing should be in the background but not in the foreground?
  This may lead to a divergent treatment of first-class versus second-class grouping mechanisms.

{{{remark(WK: Look at OCaml singatures, module types, and modules. Similar in Coq?)}}}

**** COMMENT ? Hierarchical Modules
**** COMMENT ? Recursive Modules

   One potential solution would be to deconflate the unit of namespacing from the
unit of compilation (from the unit of filesystem organization).)
** Ad hoc Grouping Mechanisms

# ad hoc âˆ· created or done for a â€œparticularâ€ purpose as necessary.
# Synonyms:	impromptu, improvised, rough and ready, makeshift, make-do, cobbled together, thrown together.

Many popular coding languages do not provide top-level modularisation mechanisms,
yet users have found ways to emulate some or all of their /requirements/.
We shall emphasise a record-like embedding in this section, then illustrate it in
Agda in the next section.

*Namespacing:* Ubiquitous languages, such as C, Shell, and JavaScript, that do not
have built-in support for namespaces mimic it by a consistent naming
discipline as in {{{newline}}} ~theModule_theComponent~. This way, it is clear where ~theComponent~
comes from; namely, the `module' ~theModule~ which may have its interface expressed as a
C header file or as a JSON literal. This is a variation of
Hungarian Notation cite{hungarian_notation}.

# https://docs.racket-lang.org/guide/macro-module.html
Incidentally, a Racket source file, module, and `language' declaration
are precisely the same.
Consequently, Racket modules, like OCaml's, may contain top-level
effectful expressions.
In a similar fashion, Python packages
are directories containing an  ~__init__.py~ file which is used for the the same
purpose as Scala's ~package object~'s ---for package-wide definitions.

*Objects:* An object can be simulated by having a record structure
contain the properties of the class which are then instantiated
by record instances. Public class methods are then normal
methods whose first argument is a reference to the structure
that contains the properties.

# Records, Prefixes, & Record Consuming Operations

#+LaTeX: \begin{tcolorbox}[title=\hfill Muliple Forms of the Template-Instantiation Duality]
#+BEGIN_CENTER
| *Template*            | $\qquad\text{has a}\qquad$ | *Instance*           |
| â‰ˆ class             |                            | â‰ˆ object           |
| â‰ˆ type              |                            | â‰ˆ value            |
| â‰ˆ theorem statement |                            | â‰ˆ witnessing proof |
| â‰ˆ specification     |                            | â‰ˆ implementation   |
| â‰ˆ interface         |                            | â‰ˆ implementation   |
| â‰ˆ signature         |                            | â‰ˆ algebra          |
| â‰ˆ logic             |                            | â‰ˆ theory           |
#+END_CENTER
#+LaTeX: \end{tcolorbox}

*Modules:* Languages that do not support a module may mimic it
by placing ``module contents'' within a record.
Keeping all contents within one massive record also solves the
namespacing issue.

In JavaScript, for example, a module is a JSON literal
---i.e., a comma separated list of key-value pairs.
Moreover, encapsulation is simulated by having the module be encoded
as a function that yields a record which acts as the public contents
of the module, while the non-returned matter is considered private.
Due to JavaScript's dynamic nature we can easily adjoin functionality to such `modules'
at any later point; however, we cannot access any private members of the module.
This inflexibility of private data is a heavy burden in an Object Oriented
Paradigm.

*Sub-Modules:* If a module is encoded as a record, then a sub-module is a
field in the record which itself happens to be a module encoding.

*Parameterised Modules:* If a module can be considered as encoded as the returned record from
a function, then the arguments to such a function are the parameters to the module.

*Mixins:* A /mixin/ is the ability to extend a datatype /X/ with functionality /Y/
long after, and far from, its definition.
Mixins â€˜mix inâ€™ new functionality by permitting /X obtains traits Y/
---unlike inheritance which declares /X is a Y/. Examples of this
include Scala's traits, Java's inheritance, Haskell's typeclasses, and C#'s extension methods.

Typescript cite:understanding_typescript
occupies an interesting position with regards to mixins: It is one of the few
languages to provide union and intersection combinators for its ~interface~ grouping mechanism,
thereby most easily supporting the little theories cite:little_theories
method and making theories a true lattice. Interestingly intersection of interfaces
results in a type that contains the declarations of its arguments and if a field
name has conflicting types then it is, recursively, assigned the intersection of the distinct types
---the base cases of this recursive definition are primitive types, for which distinct types yield an empty intersection.
In contrast, its union types are disjoint sums.
#
# https://codingblast.com/typescript-intersection-types/

In the dependently-typed setting, one also obtains so-called â€˜canonical structuresâ€™ cite:coq_canonical,
which not only generalise the previously mentioned mixins but also facilitate a flexible
style of logic programming by having user-defined algorithms executed during unification;
thereby permitting one to omit many details cite:coq_canonical_tutorial and have them inferred.
As mentioned earlier regarding objects, we could simulate mixins by encoding a class
as a record and a mixin as a record-consuming method.
Incidentally languages admitting mixins give rise to an alternate method
of module encoding:
A â€˜module /of type Mâ€™ is encoded as an instantiation
of the mixin trait M./

# In the sequel,
# when we discuss modules as contexts, it can be seen that the simplest form of
# mixins is context prepending.

These natural encodings only reinforce our idea that there is no real essential difference
between grouping mechanisms: Whether one uses a closure, record, or module
is a matter of preference the usage of which communicates particular intent.

** Existing Systems

:OldIntro:
Is there any actual /need/ for the proposed research?
Are the goals easily adaptable from the simply-typed settings?
Is the declared arena of dependently-typed languages
sufficiently intricate to warrant this much attention?

In this section, we shall outline that DTLs constitute a difficult
and poorly understood domain in comparison to conventional programming
languages, such as the purely functional Haskell or the imperative Java.
Then we outline the merits of including dependent types.
Finally, we close with a comparison of some of the most popular DTLs.
:End:

We want to implement solutions in a dependently typed
language. Let us discuss which are active and their capabilities.

Dependent-types provide an immense level of expressivity thereby
allowing varying degrees of precision to be embedded, or omitted,
from the type of a declaration. This overwhelming degree of freedom
comes at the cost of common albeit non-orthogonal styles of coding
and compilation, which remain as open problems that are only mitigated
by awkward workarounds such as Coq's distinction of types and
propositions for compilation efficiency.
The difficulties presented by DTLs are outweighed by
the opportunities they provide cite{dtl_why} ---of central importance is that they blur distinctions between
usual programming constructs, which is in alignment with our thesis.

To the best of our knowledge, as confirmed by Wikipedia in cite:wiki_proof_assistants, wiki_proof_assistants_dependent, there are currently less than 15 /actively
developed/ dependently-typed languages in-use /that are also used/ as
proof-assistants ---which are intersting to us since we aim to
mechanise all of our results: Algorithms as well as theorems.

*Agda cite:agda_overview, agda_thesis*: One of the more popular proof assistants around; possibly due to its syntactic
inheritance from Haskell ---as is the case with Idris. Its Unicode mixfix
lexemes permit somewhat faithful renditions of informal mathematics; e.g.,
calculational proofs can be encoded to be read by those unfamiliar with the system.
It also allows traditional functional programming with the ability to
`escape under the hood' and write Haskell code. The language has not been
designed solely with theorem proving in mind, as is the case for Coq, but rather
has been designed with dependently-typed programming in mind
cite:agda_web, agda_plf.

The current implementation of the Agda language has a notion of second-class modules which
may contain sub-modules along with declarations and definitions of first-class citizens.
The intimate relationship between records and modules is perhaps best exemplified here
since the current implementation provides a declaration to construe a record as if it were
a module. This change in perspective allows Agda records to act as Haskell typeclasses.
However, the relationship with Haskell is only superficial: Agda's current implementation does
not support sharing. In particular, a parameterised module is only syntactic sugar such that
each member of the module actually obtains a new functional parameter; as such, a computationally
expensive parameter provided to a module invocation may be intended to be computed only once,
but is actually computed at each call site.

*Coq cite:coq_implementation, coq_cat_experiences:* Unquestionably one of, if not, the most popular proof assistant around.
It has been used to produce mechanised proofs of the infamous Four Colour Theorem
cite:coq_four_colour}, the Feit-Thompson Theorem \parencite{coq_feit,
and an optimising compiler for the C language: CompCert cite:coq_compcert, compcert_paper.

Unlike Agda, Coq supports tactics cite:tacticstype -a brute force approach
that renders (hundredfold) case analysis as child's play:
Just refine your tactics till all the subgoals are achieved.
Ultimately the cost of utilising tactics is that a tactical proof
can only be understood with the aid of the system, and may otherwise be
un-insightful and so failing to meet most of the purposes of proof cite:purposes_of_proof
---which may well be a large barrier for mathematicians who value insightful proofs.

The current implementation of Coq provides the base features expected of any module system.
A notable difference from Agda is that it allows â€œcopy and pasteâ€
contents of modules using the include keyword. Consequently it provides a number
of module combinators, such as ~<+~ which is the infix form of module inclusion
cite:coq_manual. Since Coq module types are essentially contexts,
the module type ~X <+ Y <+ Z~ is really the catenation of contexts, where later
items may depend on former items. The Maude cite:maude, maude_module_algebra framework
contains a similar yet more comprehensive algebra of modules and how they
work with Maude theories. An important aspect of the thesis work will be to
actually investigate Maude further and attempt to reproduce and generalise
some of the use cases in â€˜the Maude bookâ€™ cite:maude using a core
set of packaging primitives for DTLs ---we will return to what such primitives may be
in a later section, on preliminary research.
The Common Algebraic Specification Language
cite:casl_overview, casl_user_manual, casl_reference_manual
will also be investigated with the aim of extracting, and generalising, useful module combinators
and their properties.
#
# Casl in general: http://www.cofi.info
# Casl tools: http://hets.dfki.de
# Casl libraries: http://www.cofi.info/Libraries
#
# Coq <+ sutff:
# See https://coq.inria.fr/distrib/V8.7.2/refman/gallina-ext.html#sec90

:WK_maude:
Maude is based on rewriting logic,
which uses term rewrite rules in two roles:
+ as equations, for algebraic specification
+ as (labelled) transitions.

In the resulting transition systems,
a ``state'' is an equivalence class of value terms
modulo the associated set of equations,
and transitions are rewrites using the second class of rules.

Theories (and functional modules fmod) can only
contain equations.
:End:

Incidentally, Coq modules are essentially
Agda records ---which is unsurprising since our thesis states packaging containers
are all essentially the same. In more detail, both notions coincide with
that of a signature ---a sequence of pairs of name-type declarations.
Where Agda users would speak of a record instance, Coq users would speak of
a module implementation. To make matters worse, Coq has a notion of records
which are far weaker than Agda's; e.g., by default all record
field names are globally exposed and records are non-recursive.

Coq's module system extends that of OCaml; a notable divergence is that Coq
permits parameterised module types ---i.e., parameterised record types, in Agda
parlance. Such module types are also known as â€˜functorsâ€™ by Coq and OCaml users; which
are â€œgenerativeâ€: Invocations generate new datatypes. Perhaps an example will
make this rather strange concept more apparent.
{{{code(Example of Generative Functors)}}}
#+begin_src haskell
-- Coq                        -- Corresponding Agda

Module Type Unit. End Unit.   -- record Unit : Set where
Module TT <: Unit. End TT.    -- tt : Unit; tt = record {}

Module F (X : Unit).          -- module F (X : Unit) where
  End F.                      --     data t : Set where C : t

Module A := F TT.             -- module A = F tt
Module B := F TT.             -- module B = F tt

Fail Check eq_refl : A.t = B.t. --  â‰    eq : A.t â‰¡ B.t ; eq = refl
#+end_src
As seen, in Coq the inductive types are different yet in Agda they are the same.
This is because Agda treats such parameterised records, or functors, as
â€˜applicativeâ€™: They can only be applied, like functions.

:Agda_code:
record Unit : Set where

tt : Unit
tt = record {}

module F (X : Unit) where
  data t : Set where C : t

module A = F tt

module B = F tt

open import Relation.Binary.PropositionalEquality

it : A.t â‰¡ B.t
it = refl
:End:

For simplicity, we may think of generative functor applications ~F X~ as actually
~F X t~ where ~t~ is an implicit tag such as textual position or clock time.
From an object-oriented programming perspective,
~F X~ for a generative functor ~F~ is like the
~new~ keyword in Java/C#: A new instance is created
which is distinct from all other instances even though
the same class is utilised. So much for the esotericity of generative functors.

Unlike Agda, which uses records to provide traditional record types, Haskell-like
typeclasses, and even a module perspective of both, Coq utilises distinct
mechanisms for typeclasses and canonical structures. In contrast, Agda allows
named instances since all instances are named and can be provided where an
implicit failed to be found. Moreover, Coq's approach demands greater familiarity
with the unifer than Agda's approach.
# Coq typeclasses are nearly the same as Haskell's.
# https://softwarefoundations.cis.upenn.edu/qc-current/Typeclasses.html

# Nifty slides: â€œWhy Applicative Functors Matterâ€
# https://www.cs.ox.ac.uk/ralf.hinze/WG2.8/24/slides/derek.pdf

*Idris cite:idris_main*: This is a general purpose, functional, programming language with dependent types; alongside ATS, below,
it is perhaps the only language in this list that can truthfully boast to being
general purpose and to have dependent types. It supports both equational
and tactic based proof styles, like Agda and Coq respectively; unlike these two
however, Idris erases unused proof-terms automatically rather than forcing
the user to declare this far in advance as is the case with Agda and Coq.
The only (negligible) downside, for us, is that the use of tactics creates
a sort of distinction between the activities of proving and programming, which
is mostly fictitious.
#
# Can tactics in Idris be used for programming?
# They can in Coq, but this is for good reasons strongly discouraged.

:Irrelevant:
Moreover, Idris compiles to C whereas Agda compiles
to Haskell thereby opening the possibility to use GHC's many optimisations without
too much translation from the source: In contrast, Idris programs must be first
transformed to their imperative counterparts
cite:idris_website, idris_tdd.
:End:

Intended to be a more accessible and practical version of Agda, Idris
implements the base module system features and includes interesting new ones.
Until [[https://agda.readthedocs.io/en/v2.6.0/language/generalization-of-declared-variables.html][recently]], in Agda, one would write ~module _ (x : â„•) where â‹¯~ to parameterise every
declaration in the block â€œâ‹¯â€ by the name ~x~; whereas in Idris, one writes
~parameters (x : â„•) â‹¯~ to obtain the [[http://docs.idris-lang.org/en/latest/tutorial/modules.html][same behaviour]]
--which Agda has since improved upon it via â€˜generalisationâ€™:
A declaration's type gets only the variables it actually uses, not
every declared parameter.

# http://docs.idris-lang.org/en/latest/tutorial/modules.html

Other than such pleasantries, Idris does not add anything of note.
However, it does provide new constraints.
As noted earlier, the current implementation of Idris attempts to erase implicits
aggressively therefore providing speedup over Agda.
In particular, Idris modules and records can be parameterised but not indexed
---a limitation not in Agda.

Unlike Coq, Idris has been designed to â€œemphasise general purpose programming
rather than theorem provingâ€ cite:idris_faq, idris_tdd.
However, like Coq, Idris provides a Haskell-looking typeclasses mechanism;
but unlike Coq, it allows named instances.
In contrast to Agda's record-instances, typeclasses result in backtracking to
resolve operator overloading thereby having a slower type checker.

# http://docs.idris-lang.org/en/latest/tutorial/interfaces.html

# https://github.com/idris-lang/Idris-dev/wiki/Egg-%234:-Agda-style-records-and-modules

# *Matita*
# last publication was 2012
# website hasn't been updated since 2016
# http://matita.cs.unibo.it/index.shtml

# Lean: lean_website,
*Lean cite:lean_system_desc, lean_formalizing_math:* This is both a theorem prover and programming language; moreover it permits
quotient types and so the usually-desired notion of extensional equality.
It is primarily tactics-based, also permitting a ~calc~-ulational proof format
not too dissimilar with the standard equational proof format utilised in Agda.

# In our opinion, it is a nice language but we will remain with Agda since it
# is a bit older, whence more stable, and it is also more syntactically pleasant.
# cite:lean_website

Lean is based on a version of the Calculus of Inductive Constructions, like
Coq. Lean is heavily aimed at metaprogramming for formal verification,
thereby bridging the gap between interactive and automated theorem proving.
Unfortunately, inspecting the language shows that its rapid development is
not backwards-compatible
---Lean 2 standard libraries have yet to be ported to Lean 3---,
and unlike, for example, Coq and Isabelle which are backed by other complete
languages, Lean is backed by Lean, which is unfortunately too young to program
various tactics, for example.

:Other_remarks_on_Lean:
The lean prover [[https://leanprover.github.io/introduction_to_lean/][tutorial]] is not even complete!

It does not seem to be well docmented; only 1 file in the docs!
It's been difficult finding anything superficially; I may need to install and try things out?
:End:

# *NuPRL*
# https://github.com/jonsterling/JonPRL
# last touched 2-3 years ago!

# *PVS*
# not modified since 2014
# http://pvs.csl.sri.com/

# *Twelf* This is a logic programming language, similar to Prolog; it has been
# used to formalise safety proofs for â€˜real worldâ€™ programming languages such
# as Standard ML. Seems like that
# Website hasn't been updated since 2009!
# http://twelf.org/wiki/Main_Page

*ATS, Applied Type System*: This language combines programming and proving, but is aimed at
unifying programming with formal specification. With the focus being more
on programming than on proving.
cite:ats_website, ats_combining

ATS is intended as an approach to practical programming with theorem proving.
Its module system is largely influenced by that of Modula-3, providing what
would today be considered the bare bones of a module system.
Advocating a programmer-centric approach to program verification that
syntactically intertwines programming and theorem proving, ATS is a more
mature relative of Idris ---whereas Idris is Haskell-based, ATS is OCaml-based.

*F^**: This language supports dependent types, refinement types,
and a weakest precondition calculus cite:fstar_website.
However it is primarily aimed
at program verification rather than general proof.
Even though this language is roughly 8 years in the making,
it is not mature ---one encounters great difficult in doing anything
past the initial language tutorial.
# Language age ~ 8 years

F^*'s module system is rather uninteresting, predominately acting as namespace
management. It has very little to offer in comparison to Agda; e.g., within
the last two years, it obtained a typeclass mechanism
---regardless, typeclasses can be implemented as dependent records.

# The offical tutorial, https://rise4fun.com/fstar/tutorial,
# gives only one syntactic item to deal with modules:
# Module       m ::= module M tl1 ... tln ;; e [end]

# http://complogic.cs.mcgill.ca/beluga/index.html
#
*Beluga*: The distinctive feature and sole reason that we mention this language
is its direct support for first-class contexts cite:beluga.
A term ~t(x)~ may have free
variables and so whether it is well-formed or what its type could be depend on the
types of its free variables, necessitating one to either declare them before hand
or to write, in Beluga, {{{newline}}} ~[ x : T  |-  t(x) ]~ for example.
As we have mentioned, and will
reiterate a few times, contexts are behaviourally indistinguishable from
dependent sums.

# Unlike the previously mentioned languages, Beluga provides a
# dependently-typed language that supports specfiying formal systems in the
# logical framework LF.

A displeasure of Beluga is that, while embracing the Curry-Howard Correspondence,
it insists on two syntactic categories: Data and computation.
This is similar to Coq's distinction of ~Prop~ and ~Type~.
Another issue is that to a large degree the terms one uses in their type
declarations are closed and so have an empty context therefore one sees
expressions of the form ~[ |- t ]~ since ~t~ is a closed term needing only the empty
context. At a first glance, this is only a minor aesthetic concern; yet after
inspection of the language's webpage, tutorials, and publication matter, it is
concerning that nearly all code makes use of empty contexts ---which are easily
spotted visually. The tremendous amount of empty contexts suggests that the language
is not actually making substantial use of the concept, or it is yet unclear what
pragmatic utility is provided by contexts, and, in either way,
they might as well be relegated to a less intrusive notation.
Finally, the language lacks any substantial standard libraries
thereby rendering it more as a proof of concept rather than a serious system
for considerable work.

:Mizar_remarks:
*Mizar*: Unlike the rest, it is based on (untyped) Tarskiâ€“Grothendieck set theory
which in some-sense has a â€˜hierarchy of setsâ€™. Being based on set theory, it is non-constructive. It has a large library of formalised mathematics; like Coq.
cite:mizar_website, mizar_overview, mizar_library.

Like Idris, it provide a â€˜reservationâ€™ mechanism to name parameters for a block
of code. Mizar ~environ~-ments are generally difficult to work with due to
multiple namespaces for articles and vocabularies.
There is otherwise nothing interesting to say regarding its module system.
:End:

*Notable Mentions*: The following are not actively being developed, as far we can
tell from their websites or source repositories,
but are interesting or have made useful contributions.
In contrast to Beluga, Isabelle is a full-featured language and logical framework that also provides
support for named contexts in the form of â€˜localesâ€™ cite:locales, isabelle_locales;
unfortunately it is not a dependently-typed language --though DTLs can be implemented in it.
Mizar, unlike the above, is based on (untyped) Tarskiâ€“Grothendieck set theory
which in some-sense has a hierarchy of sets. Like Coq, it has a large library of formalised mathematics
cite:mizar_website, mizar_overview, mizar_library.
Developed in the early 1980s, Nuprl cite:prl_site is constructive with a
refinement-style logic; besides being a mature language, it has been used to provide
proofs of problems related to Girard's Paradox cite:girard_paradox.
PVS, Prototype Verification System cite:pvs_prover, differs from other DTLs
in its support for subset types; however, the language seems to be unmaintained as of 2014.
Twelf cite:twelf_site is a logic programming language
implementing Edinburgh's Logical Framework cite:lf_meta_mechanisation, lf_has_isabelle, lf_fast_proof_checking
and has been used to prove safety properties of â€˜real languagesâ€™ such as SML.
A notable practical module system cite:lf_practical_modules for Twelf has been implemented using signatures and signature morphisms.
Matita cite:matita_main, matita_site} is a Coq-like system that is much lighter \parencite{matita_is_coq_light;
it is been used for the verification of a complexity-preserving C compiler.
# Matita home page last updated 2017! *Eek!*
# Twelf home page last updated 2015! *Eek!*

# https://github.com/jonsterling/JonPRL

Dependent types are mostly visible within the functional community, however
   this is a matter of taste and culture as they can also be found in imperative
   settings, cite:dtl_imperative, albeit less prominently.
** Facets of Structuring Mechanisms: An Agda Rendition
   :PROPERTIES:
   :header-args: :tangle monoid_renditions.agda :comments link
   :END:

# JC: - 2.4 really helps situate things, and is in the proper place in the proposal
# - ditto for 2.5

:Setup:
#+begin_src haskell
open import Relation.Binary.PropositionalEquality
open â‰¡-Reasoning

-- Z-notation for sums
open import Level
open import Data.Product using (Î£ ; projâ‚ ; projâ‚‚ ; _Ã—_ ; _,_)
Î£âˆ¶â€¢ : {a b : Level} (A : Set a) (B : A â†’ Set b) â†’ Set (a âŠ” b)
Î£âˆ¶â€¢ = Î£
infix -666 Î£âˆ¶â€¢
syntax Î£âˆ¶â€¢ A (Î» x â†’ B) = Î£ x âˆ¶ A â€¢ B

open import Data.Nat
open import Data.Nat.Properties
#+end_src
:End:

In this section we provide a demonstration that with dependent-types we can show records, direct dependent types, and
contexts ---which in Agda may be thought of as parameters to a module---
are interdefinable.
Consequently, we observe that the structuring mechanisms provided by the current
implementation of Agda --and other DTLs-- have no real differences aside from those imposed by the language
and how they are generally utilised.
More importantly, this demonstration indicates our proposed direction of identifying
notions of packages is on the right track.

Our example will be implementing a monoidal interface in each format,
then presenting /views/ between each format and that of the ~record~ format.
Furthermore, we shall also construe each as a typeclass,
thereby demonstrating that typeclasses are, essentially, not only a
selected record but also a selected /value/ of a dependent type
---incidentally this follows from the previous claim that records
and direct dependent types are essentially the same.

Recall that the signature of a monoid consists of
a type ~Carrier~ with a method ~_â¨¾_~ that composes values
and an ~Id~-entity value.
With Agda's lack of type-proof discrimination, i.e., its support for the
Curry-Howard Correspondence, the â€œpropositions as typesâ€ interpretation, we can encode the signature as well as the
axioms of monoids to yield their theory presentation in the following two ways.
Additionally, we have the derived result:
~Id~-entity can be popped-in and out as desired.

The following code blocks contain essentially the same content, but
presented using different notions of packaging. Even though both
use the ~record~ keyword, the latter is treated as a typeclass
since the carrier of the monoid is given â€˜staticallyâ€™ and instance
search is used to invoke such instances.
{{{code(Monoids as Agda Records)}}}
#+BEGIN_SRC haskell
record Monoid-Record : Setâ‚ where
  infixl 5 _â¨¾_
  field
    -- Interface
    Carrier  : Set
    Id       : Carrier
    _â¨¾_      : Carrier â†’ Carrier â†’ Carrier

    -- Constraints
    lid   : âˆ€{x} â†’ (Id â¨¾ x) â‰¡ x
    rid   : âˆ€{x} â†’ (x â¨¾ Id) â‰¡ x
    assoc : âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z  â‰¡  x â¨¾ (y â¨¾ z)

  -- derived result
  pop-Idáµ£ : âˆ€ x y  â†’  x â¨¾ Id â¨¾ y  â‰¡  x â¨¾ y
  pop-Idáµ£ x y = cong (_â¨¾ y) rid

open Monoid-Record {{...}} using (pop-Idáµ£)
#+END_SRC

{{{code(Monoids as Typeclasses)}}}
#+BEGIN_SRC haskell
record HasMonoid (Carrier : Set) : Setâ‚ where
  infixl 5 _â¨¾_
  field
    Id    : Carrier
    _â¨¾_   : Carrier â†’ Carrier â†’ Carrier
    lid   : âˆ€{x} â†’ (Id â¨¾ x) â‰¡ x
    rid   : âˆ€{x} â†’ (x â¨¾ Id) â‰¡ x
    assoc : âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z â‰¡ x â¨¾ (y â¨¾ z)

  pop-Id-tc : âˆ€ x y â†’  x â¨¾ Id â¨¾ y  â‰¡  x â¨¾ y
  pop-Id-tc x y = cong (_â¨¾ y) rid

open HasMonoid {{...}} using (pop-Id-tc)
#+END_SRC

The double curly-braces ~{{...}}~ serve to indicate that
the given argument is to be found by instance resolution:
The results for ~Monoid-Record~ and ~HasMonoid~ can be invoked without having to mention a monoid on
a particular carrier, provided there exists one unique record value
having it as carrier ---otherwise one must use named instances cite:named_instances.
Notice that the carrier argument in the typeclasses approach, â€œstructure on a carrierâ€, is
an (undeclared) implicit argument to the ~pop-Id-tc~ operation.

Alternatively, in a DTL we may encode the monoidal interface using dependent products
*directly* rather than use the syntactic sugar of records.
The notation ~Î£ x âˆ¶ A â€¢ B x~ denotes the type of pairs ~(x , pf)~ where ~x âˆ¶ A~ and ~pf âˆ¶ B x~
---i.e., a record consisting of two fields.
It may be thought of as a constructive analogue to the classical set comprehension {{{newline}}} ~{ x âˆ¶ Aâ™B x}~.

{{{code(Monoids as Dependent Sums)}}}
# ATTR_LATEX: :options fontsize={\fontsize{10}{11}\selectfont}
#+BEGIN_SRC haskell
-- Type alias
Monoid-Î£  :  Setâ‚
Monoid-Î£  =    Î£ Carrier âˆ¶ Set
         â€¢ Î£ Id âˆ¶ Carrier
         â€¢ Î£ _â¨¾_ âˆ¶ (Carrier â†’ Carrier â†’ Carrier)
         â€¢ Î£ lid âˆ¶ (âˆ€{x} â†’ Id â¨¾ x â‰¡ x)
         â€¢ Î£ rid âˆ¶ (âˆ€{x} â†’ x â¨¾ Id â‰¡ x)
         â€¢ (âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z â‰¡ x â¨¾ (y â¨¾ z))

pop-Id-Î£ : âˆ€{{M : Monoid-Î£}}
               (let Id  = projâ‚ (projâ‚‚ M))
               (let _â¨¾_ = projâ‚ (projâ‚‚ (projâ‚‚ M)))
           â†’  âˆ€ (x y : projâ‚ M)  â†’  (x â¨¾ Id) â¨¾ y  â‰¡  x â¨¾ y
pop-Id-Î£ {{M}} x y = cong (_â¨¾ y) (rid {x})
             where  _â¨¾_    = projâ‚ (projâ‚‚ (projâ‚‚ M))
                rid    = projâ‚ (projâ‚‚ (projâ‚‚ (projâ‚‚ (projâ‚‚ M))))
#+END_SRC

Of the renditions thus far, the ~Î£~ rendering makes it clear that a monoid could have
any subpart as a record with the rest being dependent upon said record.
For example, if we had a semigroup type, we could have declared {{{newline}}}
~Monoid-Î£ = Î£ S âˆ¶ Semigroup â€¢ Î£ Id âˆ¶ Semigroup.Carrier S~.
There are a large number of such hyper-graphs, we have only presented a stratified view
for brevity. In particular, ~Monoid-Î£~ is the extreme unbundled version, whereas
~Monoid-Record~ is the other extreme, and there is a large spectrum in between --all of which are
somehow isomorphic; e.g., ~Monoid-Record â‰… Î£ C âˆ¶ Set â€¢ HasMonoid C~.
Our envisioned system would be able to derive any such view at will cite:casl_overview
and so programs may be written according to one view, but easily repurposed for other
view with little human intervention.

:Irrelevant:
Like a Java ~class~, within the ~record~ we may include derived results
that are then available to all values, `instances', of the record type.
Outside the ~record~, further properties may be added, though they now
require an actual value, instance, to be given.
:End:

Instances and their use are as follows.
One may realise that ~pop-0~ proofs as a form of polymorphism
---we will return to package former polymorphism when discussing preliminary research.
{{{code(Instance Declarations)}}}
#+BEGIN_SRC haskell
instance
   â„•-record = record { Carrier = â„• ; Id = 0 ; _â¨¾_ = _+_
             ; lid =  +-identityË¡ _  ; rid = +-identityÊ³ _ ; assoc = +-assoc }

   â„•-tc : HasMonoid â„•
   â„•-tc = record { Id = 0; _â¨¾_ = _+_
         ; lid = +-identityË¡ _ ; rid = +-identityÊ³ _ ; assoc = +-assoc }

   â„•-Î£ : Monoid-Î£
   â„•-Î£ = â„• , 0 , _+_ , +-identityË¡ _ , +-identityÊ³ _ , +-assoc
#+END_SRC
{{{code(No Monoids Mentioned at Use Sites)}}}
#+BEGIN_SRC haskell
â„•-pop-0áµ£ : âˆ€ (x y : â„•) â†’ x + 0 + y  â‰¡  x + y
â„•-pop-0áµ£ = pop-Idáµ£

â„•-pop-0-tc : âˆ€ (x y : â„•) â†’ x + 0 + y  â‰¡  x + y
â„•-pop-0-tc = pop-Id-tc

â„•-pop-0â‚œ : âˆ€ (x y : â„•) â†’ x + 0 + y  â‰¡  x + y
â„•-pop-0â‚œ = pop-Id-Î£
#+END_SRC

Interestingly, notice that the grouping in ~â„•-Î£~ is just an unlabelled (dependent) product,
and so when it is used in ~pop-Id-Î£~ we project to the desired components.
Whereas in the ~Monoid-Record~ case we could have projected the carrier by
~Carrier M~, now we would write ~projâ‚ M~.

:Irrelevant:
This is nearly identical to the previous implementation and possibly
simpler due to the lack of the ~record { â‹¯ }~ clutter required of /labelled products/.
However, said clutter could have been removed by providing
a ~constructor~ declaration in the definition of ~Monoid-Record~
but we have decided not to do so, to make the labelling clear
and distinct from the unlabelled product presentations.
:End:

Observe the lack of informational
difference between the presentations, yet there is a
/Utility Difference: Records give us the power to name our projections _*directly*_ with possibly meaningful names./
Of course this could be achieved indirectly by declaring extra functions; e.g.,
#+LaTeX: \def\mytitle{Agda}
#+BEGIN_SRC haskell :tangle no
Carrierâ‚œ : Monoid-Î£ â†’ Set
Carrierâ‚œ = projâ‚
#+END_SRC
We will refrain from creating such boiler plate ---that is,
/records allow us to omit such mechanical boilerplate./

Finally, let us exhibit views between this form and the ~record~ form.
#+LaTeX: \def\mytitle{Agda}
#+BEGIN_SRC haskell
-- Following proves: Monoid-Record  â‰…  Î£ Set HasMonoid.

to-record-from-usual-type : Monoid-Î£ â†’ Monoid-Record
to-record-from-usual-type (c , id , op , lid , rid , assoc)
  = record { Carrier = c ; Id = id ; _â¨¾_ = op
       ; lid = lid ; rid = rid ; assoc = assoc
       } -- Term construed by â€˜Agsyâ€™,
         -- Agda's mechanical proof search.

from-record-to-usual-type : Monoid-Record â†’ Monoid-Î£
from-record-to-usual-type M =
  let open Monoid-Record M
  in Carrier , Id , _â¨¾_ , lid , rid , assoc

  {- Essentially moved from record{â‹¯} to product listing -}
#+END_SRC

Furthermore, by definition chasing, ~refl~-exivity, these operations are seen to be inverse of
each other. Hence we have two faithful non-lossy protocols for reshaping our grouped data.

In our final presentation, we construe the grouping of the monoidal interface
as a sequence of â€œvariable : typeâ€ declarations ---i.e., a â€˜contextâ€™ or â€˜telescopeâ€™.
Since these are not top level items by themselves, in Agda, we take a purely syntactic route
by positioning them in a ~module~ declaration as follows.

#+LaTeX: \def\mytitle{Agda}
#+BEGIN_SRC haskell
module Monoid-Telescope-User
  (Carrier : Set) (Id : Carrier) (_â¨¾_ : Carrier â†’ Carrier â†’ Carrier)
  (lid   : âˆ€{x} â†’ Id â¨¾ x â‰¡ x) (rid : âˆ€{x} â†’ x â¨¾ Id â‰¡ x)
  (assoc : âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z â‰¡ x â¨¾ (y â¨¾ z))
  where

  pop-Idâ‚˜ : âˆ€(x y : Carrier)  â†’  (x â¨¾ Id) â¨¾ y  â‰¡  x â¨¾ y
  pop-Idâ‚˜ x y = cong (_â¨¾ y) (rid {x})
#+END_SRC

Notice that this is nothing more than the named fields of ~Monoid-Record~
squished into six lines. Additionally, if we insert a Î£ before each name
we essentially regain the ~Monoid-Î£~ formulation.
It seems contexts, at least superficially, are a nice middle ground between
the previous two formulations.

As promised earlier, we can regard the above telescope as a record:
#+LaTeX: \def\mytitle{Agda}
#+BEGIN_SRC haskell
  record-from-telescope : Monoid-Record
  record-from-telescope
    = record { Carrier = Carrier ; Id = Id ; _â¨¾_ = _â¨¾_
         ; lid = lid ; rid = rid ; assoc = assoc }
#+END_SRC

The structuring mechanism ~module~ is not a first class citizen in Agda.
As such, to obtain the converse view, we work in a parameterised module.
#+LaTeX: \def\mytitle{Agda}
#+BEGIN_SRC haskell
module record-to-telescope (M : Monoid-Record) where

  open Monoid-Record M
  -- Treat record type as if it were a parameterised module type,
  -- instantiated with M.

  open Monoid-Telescope-User Carrier Id _â¨¾_ lid rid assoc
#+END_SRC

Notice that we just listed the components out ---rather reminiscent of the formulation
~Monoid-Î£~. This observation only increases confidence in our thesis that there is no
real distinctions of packaging mechanisms in DTLs.

Undeniably instantiating the telescope approach to monoids for the natural number
is nothing more than listing the required components.
#+LaTeX: \def\mytitle{Agda}
#+BEGIN_SRC haskell
open Monoid-Telescope-User â„• 0 _+_ (+-identityË¡ _) (+-identityÊ³ _) +-assoc
#+END_SRC

C.f., the definition of ~â„•-Î£~: This is nearly the same instantiation with the primary
syntactical difference being that this form had its arguments separated by spaces rather than commas!
#+LaTeX: \def\mytitle{Agda}
#+BEGIN_SRC haskell
â„•-popâ‚˜  : âˆ€(x y : â„•)  â†’  x + 0 + y  â‰¡  x + y
â„•-popâ‚˜  =   pop-Idâ‚˜
#+END_SRC

Notice how this presentation makes it explicitly clear why we cannot have multiple instances:
There would be name clashes. Even if the data we used had distinct names, the derived result
may utilise data having the same name thereby admitting name clashes elsewhere.
---This could be avoided in Agda by qualifying names and/or renaming.

It is interesting to note that this presentation is akin to that of ~class~-es in C#/Java languages:
The interface is declared in one place, monolithic-ly, as well as all
derived operations there; if we want additional operations, we create
another module that  takes that given module as an argument in the
same way we create a class that inherits from that given class.

Demonstrating the interdefinablity of different notions
of packaging cements our thesis that it is essentially utility
that distinguishes packages more than anything else.
In particular, explicit distinctions have lead
to a duplication of work where the same structure is formalised
using different notions of packaging. In chapter 3 we will show how to avoid
duplication by coding against a particular â€˜package formerâ€™ rather than a
particular variation thereof --this is akin to a type former.

** Theory Presentations: A Structuring Mechanism

What of the most closely related theoretical work?

Our envisioned effort would support a â€œwrite one, obtain manyâ€ approach to package formation.
We now turn to mentioning how package formers are currently treated
formally under the name of â€˜theory presentationsâ€™. It is the aim of this section
to attest that the introduction's story is not completely on shaky foundations,
thereby asserting that the aforementioned goals of the introduction are not
unachievable ---and the problems that will be posed in chapter 3 are not trivial.

As discussed, languages are usually designed with a bit more thought given to a first-class
citizen notion of grouping than is given to second-class notions of
packaging up defined content.
Object-oriented languages, for example, comprise features of both views
by treating classes as external structuring mechanisms even though they
are normal types of the type system. This internalising of external grouping
features has not received much attention with the notable mentions being
cite:theories_as_types, focalize.
It is unclear whether there is any real distinction
between these `internal, integrated' and `external, stratified'
forms of grouping, besides intended use.
The two approaches have different advantages.
Both approaches permit separation of concerns: The external point of view
provides a high-level structuring of a development, the internal point of
view provides essentially another type which can be the subject of the
language's operations ---e.g., quantification or tactics--- thereby being
more amicable to computing transformations.
Essentially it comes down to whether we want a `module parameter' or a `record field'
---why not write it the way you like and get the other form for free.

Since external grouping mechanisms tend to allow for intra-language features
---e.g., imports, definitions, notation, extra-logical declarations such as pragmas---
their systematic internalisation necessitates expressive record types.
As such, a labelled product type or /context/
---being a list of name-type declarations with optional definitions---
is a sufficiently generic rendition of what it means to group matter together.

Below is a grammar, from cite:theories_as_types, for a simple yet powerful
module system based on theory (presentations) and theory morphisms --which are merely named contexts and named substitutions between contexts, respectively.
Both may be formed modularly by using includes to copy over declarations of previously named objects.
Unlike theories which may include arbitrary declarations, theory morphisms \texttt{(V : P â†’ Q) := Î´}
are well-defined if for every ~P~-declaration ~x âˆ¶ T~, ~Î´~ contains a declaration ~x = t~ where ~t~ may refer to all names declared in ~Q~.
Observe that a context is, up to syntactical differences,
essentially JavaScript object notation literal.
Consequently, the notion of a mixin as described for JSON literals is here
rendered as a theory morphism.
{{{code(Syntax for Dependently Typed Î»-calculus with Theories)}}}
#+BEGIN_SRC haskell
-- Contexts
Î“  ::= Â·                       -- empty context
     | x : Ï„ [:= Ï„â€²], Î“         -- context with declaration, optional definition
     | includes X, Î“           -- theory inclusion

-- Terms
Ï„ ::= x | Ï„â‚ Ï„â‚‚ | Î» x : Ï„â€² â€¢ Ï„ -- variables, application, lambdas
    | Î  x : Ï„â€² â€¢ Ï„             -- dependent product
    | [Î“] | âŸ¨Î“âŸ© | Ï„.x          -- record â€œ[type]â€ and â€œâŸ¨elementâŸ©â€ formers, projections
    | Mod X                    -- contravariant â€œtheory to recordâ€ internalisation

-- Theory, external grouping, level
Î˜ ::= .                        -- empty theory
    | X := Î“, Î˜                -- a theory can contain named contexts
    | (X : (Xâ‚ â†’ Xâ‚‚)) := Î“     -- a theory can be a first-class theory morphism

-- Proviso: In record formers, Î“ must be flat; i.e., does not contain includes.

-- Example theory hierarchy of signatures, abbrevating â€œ(Î  x : A â€¢ B) = (A â†’ B)â€.
, MagmaSig := Carrier : Set,  _â¨¾_ : Carrier â†’ Carrier â†’ Carrier, .
, MonSig   := includes MagmaSig, Id : Carrier, .
, .
#+END_SRC

#+LaTeX: \def\Mod{\mathsf{Mod}\,}

This concept of packaging indeed captures much of what's expected of grouping mechanisms; e.g.,

+ Grouping mechanism should group all kinds of things and indeed there is no
  constraint on what a theory presentation may contain.
+ Namespacing: Every module context can be construed as a record whose contents
  can then be accessed by record field projection.

  /Theories as Types/ cite:theories_as_types presents the first formal
  approach that systematically internalises theories into record types.
  Their central idea is to introduce a new operator ~Mod~ â€“read â€œmodels ofâ€â€”
  that turns a theory $T$ into a type $\Mod T$ which /behaves/ like a record type.

+ Operations on grouping mechanisms cite:tpc.

As mentioned earlier, a theory morphism, also known as a â€˜viewâ€™,
is a map between contexts that implements the interface of the source
using utilities of the target; whence results about specific structures can be
constructed by transport along views cite:little_theories:
A view \texttt{V : P â†’ Q} gives rise to a term homomorphism ~ğ’±~ from ~P~-terms to ~Q~-terms
that is type-preserving in that whenever \texttt{Î˜, P âŠ¢ t : T} then \texttt{Î˜, Q âŠ¢ ğ’± t : ğ’± T}.
Thus, views preserve judgements and, via the propositions-as-types representations,
also preserve truth.

# Theory interpretations are also called translations, theory morphisms, immersions, and realisations.
For example, a view $\Phi = (U, \beta) : \mathcal{S} \to \mathcal{T}$
is essentially a predicate $U$, of the target theory, denoting a /universe of discourse/
along with an  arity-preserving mapping $\beta$ of ğ’®-symbols, or declarations, to ğ’¯-expressions.
It is lifted to terms as follows
--- notice translated variable-binders are relativised to the new domain.
#+BEGIN_EXPORT latex
\begin{tcolorbox}[title=\hfill $\Phi$ Extended to Terms]
\vspace{-1em}
\begin{align*}
\Phi(x) &= x  & & \text{ Provided $x$ is an $\mathcal{S}$-variable symbol }
\\
\Phi\left( f(t_1, \ldots, t_n) \right)
&= \beta(f) \left(\Phi\, t_1, \ldots, \Phi\, t_n\right)
& & \text{ Provided $f$ is a $n$-ary $\mathcal{S}$-function symbol}
\\
\Phi\left(\mathcal{Q}\, x \;\bullet\; P\right)
&= \left(\mathcal{Q}\, x \;â™\; U\, \;x \bullet\; \Phi(P) \right)
& & \text{ Provided $\mathcal{Q}$ is a variable-binder $\forall, \exists, \lambda$ }
\end{align*}
\end{tcolorbox}
#+END_EXPORT

The /Standard Interpretation Theorem/ cite:theory_interpretations_farmer
provides sufficient conditions for a translation to be an â€˜interpretationâ€™
which transports results between formalisations. It states:
A translation is an interpretation provided ğ’®-axioms $P$ are lifted to
theorems $\Phi(P)$, the universe of discourse is non-empty
$(\exists x \bullet U\, x)$, and the interpretation of the universe
contains the interpretations of the symbols;
i.e., for each ğ’®-symbol $f$ of arity $n$, {{{newline}}}
$\Phi(âˆ€ xâ‚, â€¦, xâ‚™ â€¢ âˆƒ y \,â€¢\, f\, xâ‚\, â€¦\, x\,â‚™ = \,y)$.

# Standard interpreations are used to compare tthe strength of theories: ğ’¯ is at least as strong as ğ’® provided ğ“¢ is interpretable in ğ’¯ --indeed, that's why every model of the latter gives rise to a model of the former!
# Also, standard interpretations have long been used in logic to prove meta-mathematical properties baout first-order theories, mainly rel;atoive consisitency, decidiabilkity, and undecidiability.
By virtue of being a validity preserving homomorphism,
a standard interpretation syntactically and semantically
embeds its source theory in its target theory.
The most important consequence of interpretability is the
/Standard Relative Satisfiability/ cite:theory_interpretations_farmer
which says that a theory which is interpretable in a satisfiable theory is itself satisfiable;
in programming terms this amount to: If $X$ is an implementation of `interface' ğ’¯
and ğ’® is interpretable in ğ’¯ then $X$ can be transformed into an implementation of ğ’®.
Interestingly such â€˜subtypingâ€™ can be derived in a mechanical fashion, but it can leave
the subtype relation to be cyclic.
However, it is unclear under which conditions translations automatically
give rise to interpretations: Can the issue be relegated to syntactic
manipulation only?

Theory interpretation has been studied for first-order predicate logic
then extended to higher-order logic cite{theory_interpretations_farmer}.
The advent of dependent-types, in particular the blurring of operations and formulae
cite{wiki_curry_howard}, means that propositions of a language can be encoded into it as other
sorts, dependent on existing sorts, thereby questioning
/what it means to have a validity-preserving morphism/ when the axioms can be
encoded as operations? As far as we can tell, it seems very little work
regarding theory interpretations has been conducted in dependently-typed
settings cite:mlt_partial, higher_order_interpretations, institution_interpretations, dtl_interpretations.
# {{{remark(WK: Then you should discuss it in more detail.)}}}

:Irrelevant:
Notice that records play dual roles. They not only serve as an internal form of grouping
mechanisms, but inspired by the previous Agda renditions, also serve the purpose of
forming dependent sum types.

What about the presence of non-termination or inheritance
---i.e., partial functions and subtypes?
The subject is only beginning to
be seriously explored in higher-order logic and type theory.
cite{theory_interpretations_farmer}.
Views associating base types with subtypes get complicated since functions must now
deal with restricted domains, consequently necessitating that all predicates on functions
also be relativised.
:End:
* COMMENT PackageFormer

   # I'm trying to do things with one language, in a DTL, and about being first-class.
   # What I currently have is to approximate what it could look like.
   #
   # I'm not actually generating any external code.
   # It's all in the same language.

** Why an editor extension? Why Lisp is reasonable?
** Utility of a protottype?
** Things learned from making a protottype?
     * Perhaps show the minimal code needed to get PF working; <= 300 lines?
     * Much more Lisp for implementing common grouping mechanisms; e.g., pushouts.
** How usable is it?
** What exotic notions of grouping mechanisms can be coded-up? Utilit!?
** [Disadvantages of PackageFormer?
** Comparision to other systems.

** TODO COMMENT Two
 Design patterns for theories become library methods! An interesting side-effect
 of having meta-primitives for packages is that traditional patterns for theories
 â€”e.g., homomorphisms, syntax, interpretation functionsâ€” can now be codified as
 general re-usable methods.

** TODO One

 Think of a language that does not support currying and you need to have a
 function of 10 arguments that needs to support accepting any number of arguments
 less than 10, say for partial application. In such languages, one must utilise
 the builder design pattern, or quickly copy-paste the function 10 times,
 altering it slightly each time. In general, if such a function definition
 requires N lines and M forms of the function are needed, then nearly N Ã— M lines
 of code are written manually.

* COMMENT Contexts
** Why PackageFormer is not enough.
** Discuss Agda macros ---need to be self-contained.
** Motivate the need for a practical syntax.
** The reason it's a "do it yourself" system is that the semantics, >>=,
     can be tweaked easily for other forms of grouping besides Pi/Sigma ;-)
** Current limitations; e.g., lack of termination/positivity of certain constructs;
     or how termtype generation requires the ADT carrier to be the first element
     of the sequence/context, whereas a DAG interpretation of Contexts would be better?
** How does this compare with PF?
** What are the benefits of Context?
** Concrete problems its usage can solve.

* COMMENT Conclusion
** What we have done
** How it is useful to others, now.
* COMMENT Thesis Checklist
** What's a thesis? [0%]
   + [ ] The argument
     - What is it? Is it being argued clearly?
     - What's the plan?
   + [ ] An exposition of an orginal piece of research.
   + [ ] Distinctive contribution to the knowledge of the subject?
   + [ ] Evidence of orginality shown by the discovery of new facts?
   + [ ] How is the research best appreciated?
   + [ ] Ideas not mentioned in the thesis might as well not exist! Mention ideas.

** Planning an Argument [0%]
   One sentence for each:
   + [ ] Introduction to the area of study.
   + [ ] The problem being tackled.
   + [ ] What the literature says about the problem.
     - A review of previous work shows you know the subject.
     - Besides being descriptive, the review needs to be critical.
     - Summary of the essential features of other work as it relates to this study.
   + [ ] How /I/ tackle this problem.
     - What is the philosophy of approach?
     - How were you systematic?
     - How is this linked back to the literature review?
   + [ ] How /I/ implement my solution.
     - Provide details so that others can follow what was done.
     - Justify the approach taken.
     - Does the software appear to work satisfcatorily?
   + [ ] The result.
     - Application of the approach reduces thousands of lines of code to
       human-readable specfications with an extensible system?
     - *Link back to how the solutions obtained relate to the questions posed?*
     - Accurately identitfy & summarise patterns or trends in the results.
     - Provide a critical analysis to show you know its limitations.
     - â€˜Future Workâ€™ to show what's missing.
     - Beware of specfulations not grounded in the results.
   + [ ] Conclusion ---repetition of the intro, but with reference to the detail.

   An outline acts as a workplan for which the entire research process is an
   exercise addressing each item. Each item becomes at least one section in
   the writeup.

   + [ ] Set out clearly what each chapter should say.

** Say everything thrice [0%]

   It's not repetition, but linking and rationale.

   + [ ] In the thesis as a whole.
     - [ ] Introduction - What the thesis will say.
     - [ ] Body - Details of the work.
     - [ ] Conclusion - What the thesis said.

   + [ ] Within each chapter/section.
     - [ ] Signposting - What this section says.
     - [ ] Body - The details.
     - [ ] Summary - What this section has said.

   + [ ] Within each paragraph.
     - [ ] Each paragraph describes a single idea.
     - [ ] The first sentence introduces the idea ---linking it with the previous one.
     - [ ] The last sentence concludes the idea ---linking it with the next one.

   Signposts ensure it's clear what's being discussed and why
   ---from a writer's perspective, they help get the contents right.

** The Examiner's View

   They'll read it in meetings, trains, or planes.
   They're busy and an initial scan may be:

   1. abstract - what's it about?
   2. bibliography - Does it cite the right stuff? Has it been published already?
   3. conclusions - What was achieved? Do I believe it?
   4. contents listing - Is everything there? Is the argument clear?

   Weakeness in these locations might suggest large corrections.

   + [ ] Run spellchecking everywhere.
   + [ ] Run the grammar checker as well.

** What If I'm stuck?

   1. The task at hand may be too difficult.
   2. *Ask for help!*
   3. Change the plan.
   4. Cut away irrelevant bits.

** COMMENT Our Approach [0%]
  --Remaining Tasks--
  + [ ] Plan of Attack
  + [ ] Implementation Details
  + [ ] Discussion of Results
  + [ ] Future Work

* COMMENT PROPOSAL âˆ· The Next 700 Module Systems

** Preamble & title page                                             :ignore:

 # Top level editorial comments.
 #+MACRO: remark  @@latex: \fbox{\textbf{Comment: $1 }}@@

*** Minted setup -- colouring code blocks                            :ignore:

 #+LATEX_HEADER: \usepackage[]{minted}
 #+LATEX_HEADER: \usepackage{tcolorbox}
 #+LATEX_HEADER: \usepackage{etoolbox}
 #+LATEX_HEADER: \def\mytitle{??? Program Code ???}
 #+LATEX_HEADER: \BeforeBeginEnvironment{minted}{\begin{tcolorbox}[title=\hfill \mytitle]}%
 #+LATEX_HEADER: \AfterEndEnvironment{minted}{\end{tcolorbox}}%

 # Before a code block, write {{{code(title-of-block)}}}
 #
 #+MACRO: code     #+LaTeX: \def\mytitle{$1}

 #+LaTeX: \setminted[haskell]{fontsize=\footnotesize}
 #+LaTeX: \setminted[agda]{fontsize=\footnotesize}

 # Removing the red box that appears in "minted" when using unicode.
 # Src: https://tex.stackexchange.com/questions/343494/minted-red-box-around-greek-characters
 #
 #+LATEX_HEADER: \makeatletter
 #+LATEX_HEADER: \AtBeginEnvironment{minted}{\dontdofcolorbox}
 #+LATEX_HEADER: \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
 #+LATEX_HEADER: \makeatother
*** LaTeX setup                                                      :ignore:

 # Hijacking \date to add addtional text to the frontmatter of a â€˜reportâ€™.
 #
 #
 # DATE: \today\vfill \centerline{---Supervisors---} {{{newline}}} [[mailto:carette@mcmaster.ca][Jacques Carette]] and [[mailto:kahl@cas.mcmaster.ca][Wolfram Kahl]]

 #+LATEX_HEADER: \usepackage[hmargin=25mm,vmargin=25mm]{geometry}
 #+LaTeX_HEADER: \setlength{\parskip}{1em}
 #+latex_class_options: [12pt]
 #+LATEX_CLASS: report-noparts
 # Defined below.
 #
 # Double spacing:
 # LaTeX: \setlength{\parskip}{3em}\renewcommand{\baselinestretch}{2.0}
 #
 #+LATEX_HEADER: \setlength{\parskip}{1em}

 #+LATEX_HEADER: \usepackage[backend=biber,style=alphabetic]{biblatex}
 #+LATEX_HEADER: \addbibresource{References.bib}

 #+LATEX_HEADER: \usepackage{UnicodeSymbols}

 #+LATEX_HEADER: \usepackage[dvipsnames]{xcolor} % named colours
 #+LATEX_HEADER: \usepackage{color}
 #+LATEX_HEADER: \definecolor{darkred}{rgb}{0.3, 0.0, 0.0}
 #+LATEX_HEADER: \definecolor{darkgreen}{rgb}{0.0, 0.3, 0.1}
 #+LATEX_HEADER: \definecolor{darkblue}{rgb}{0.0, 0.1, 0.3}
 #+LATEX_HEADER: \definecolor{darkorange}{rgb}{1.0, 0.55, 0.0}
 #+LATEX_HEADER: \definecolor{sienna}{rgb}{0.53, 0.18, 0.09}
 #+LATEX_HEADER: \hypersetup{colorlinks,linkcolor=darkblue,citecolor=darkblue,urlcolor=darkgreen}

 #+NAME: symbols for itemisation environment
 #+BEGIN_EXPORT latex
 \def\labelitemi{$\diamond$}
 \def\labelitemii{$\circ$}
 \def\labelitemiii{$\star$}

 % Level 0                 Level 0
 % + Level 1               â‹„ Level 1
 %   - Level 2       --->      âˆ˜ Level 2
 %     * Level 3                   â‹† Level 3
 %
 #+END_EXPORT

 # Having small-font code blocks.
 # LATEX_HEADER: \RequirePackage{fancyvrb}
 # LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}

*** ~reports-noparts~ LaTeX Class                                  :noexport:

 A custom version of the reports class which makes the outermost headings
 chapters, rather than parts.
 #+NAME: make-reports-class
 #+BEGIN_SRC emacs-lisp :results none
(add-to-list
  'org-latex-classes
    '("report-noparts"
      "\\documentclass{report}"
      ("\\chapter{%s}" . "\\chapter*{%s}")
      ("\\section{%s}" . "\\section*{%s}")
      ("\\subsection{%s}" . "\\subsection*{%s}")
      ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
      ("\\paragraph{%s}" . "\\paragraph*{%s}")
      ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
 #+END_SRC

*** Personal title page                                              :ignore:

 #+begin_center org

 #+begin_export latex
 \thispagestyle{empty}

 {\color{white}{.}}

 \vspace{5em}

 {\Huge The Next 700 Module Systems}

 \vspace{1em}

 {\Large Extending Dependently-Typed Languages to Implement
 \\ Module System Features In The Core Language}

 \vspace{2em}

 Department of Computing and Software

 McMaster University

 \vspace{2em}
 \href{mailto:alhassy@gmail.com}{Musa Al-hassy}

 \vspace{2em}
 \today
 #+end_export

 \vfill

 {{{code({\sc Thesis Proposal \hspace{12em} \color{grey}{.} })}}}
 #+begin_src haskell
-- Supervisors                                       -- Emails
Jacques Carette                                      carette@mcmaster.ca
Wolfram Kahl                                         kahl@cas.mcmaster.ca
 #+end_src
 #+end_center

 # LaTeX: \centerline{\sc Draft}

** Abstract and toc                                                  :ignore:
   :PROPERTIES:
   :CUSTOM_ID: abstract
   :END:

 # Use:  x vs.{{{null}}} ys
 # This informs LaTeX not to put the normal space necessary after a period.
 #
 #+MACRO: null  @@latex:\null{}@@

 #+begin_abstract

 Structuring-mechanisms, such as Java's ~package~ and Haskell's ~module~, are often
 afterthought secondary citizens whose primary purpose is to act as namespace delimiters,
 while relatively more effort is given to their abstraction encapsulation counterparts,
 e.g., Java's classes and Haskell's typeclasses.
 A /dependently-typed language/ (DTL) is a typed language
 where we can write /types/ that depend on /terms/; thereby blurring conventional
 distinctions between a variety of concepts.
 In contrast, languages with non-dependent type systems tend to distinguish
 /external vs.{{{null}}} internal/ structuring-mechanisms ---as in
 Java's ~package~ for namespacing vs.{{{null}}} ~class~ for abstraction encapsulation---
 with more dedicated attention and power for the internal case ---as it is
 expressible within the type theory.

 \vspace{1em}

 # cite:ocaml_website, maude_module_algebra, B_reuse
 To our knowledge, relatively few languages ---such as OCaml, Maude, and the B Method---
 allow for the manipulation of
 external structuring-mechanisms as they do for internal ones.
 Sufficiently expressive type systems, such as those of dependently typed
 languages, allow for the internalisation of many concepts
 thereby conflating a number of traditional programming notions.
 Since DTLs permit types that depend on terms, the types may require
 non-trivial term calculation in order to be determined.
 Languages without such expressive type systems necessitate certain constraints
 on its constructs according to their intended usage.
 It is not clear whether such constraints have been brought to more expressive
 languages out of necessity or out of convention.
 Hence we propose a systematic exploration of the structuring-mechanism
 design space for dependently typed languages to understand
 /what are the module systems for DTLs?/

 \vspace{1em}

 First-class structuring-mechanisms have values and types of their own
 which need to be subject to manipulation by the user, so it is reasonable
 to consider manipulation combinators for them from the beginning.
 Such combinators would correspond to the many generic operations that one
 naturally wants to perform on structuring-mechanisms
 ---e.g., combining them, hiding components, renaming components---
 some of which, in the external case, are impossible to perform in any DTL
 without resorting to third-party tools for pre-processing.
 Our aim is to provide a sound footing for systems of structuring-mechanisms
 so that structuring-mechanisms become another common feature in dependently typed languages.
 An important contribution
 of this work will be an implementation, as an extension of the current Agda implementation, of our module combinators
 ---which we hope to be accepted into a future release of Agda.

 If anything, our aim is practical ---to save developers from ad hoc copy-paste
 preprocessing hacks.
 #+begin_center org
 #+begin_small
 ---Source: https://github.com/alhassy/next-700-module-systems-proposal---
 #+end_small
 #+end_center
 #+end_abstract

 \newpage
 \thispagestyle{empty}
 \tableofcontents
 \newpage

** Solution Requirements
   :PROPERTIES:
   :CUSTOM_ID: solution_requirements
   :END:


 From the outset we have proposed a particular approach to resolving
 the needless duplication present in current module systems that are
 utilised in non-dependently-typed languages. Up to this point, we have
 only discussed how our approach could mitigate certain troubles;
 such as a difference of perspectives of modules, or of equivalent
 operations acting on different perspectives of modules.
 We now turn to discussing, in the following subsections, what it is that
 is missing from existing module systems, what one actually wants to
 do with modules, and conclude with a checklist of features that our
 proposed system should meet in order to be considered usable
 and adequate as a thesis-level effort.

*** Missing Features
    :PROPERTIES:
    :header-args: :tangle translate_functions.agda :comments link
    :END:

 Certain mechanically-derivable concepts, such as different perspectives,
 are needlessly delegated to the user by pedestrian packaging systems.
 Besides being tedious and error-prone, the inexpressibility of derivates
 obscures the corresponding general principles underlying them, thus foregoing
 any machine assistance in ensuring any correctness or safety-ness guarantees.
 The desire to pursue a more economical yet powerful packaging system
 follows from our research team's expedited efforts that could have been mechanised .
 We will only mention two such use cases.

 # [[https://www.google.com/search?ei=MeLSXLaTIuqN5wLSsaTwDw&q=derivate&oq=derivate&gs_l=psy-ab.3..0i67j0i10j0j0i10l7.27397.29434..29651...0.0..0.100.195.1j1......0....1..gws-wiz.......0i71j0i7i10i30.ZZBrC21FopE][define derivate]] :: something derived, especially a product obtained chemically from a raw material.
 #
 #
 #       derivates
 #  or   what could be considered as derived views

 \noindent
 *Expressivity:*

 \noindent
 A common pattern that can be seen, for example, in the Agda standard library,
 is of a predicate ensuring desirable properties
 OF its inputs, then of a record containing the inputs as fields along
 with a proof of said predicate. More concretely, suppose we have a binary predicate
 named ~IsSemi~ and the record is named ~Semi~; the predicate form allows us to
 quantify over inputs as in ~âˆ€ x y â†’ IsSemi x y â†’ â‹¯~, in contrast the latter
 approach is intrinsic in nature: ~âˆ€ (s âˆ¶ Semi) â†’ â‹¯~
 ---contrast this with a mathematician naturally declaring â€œlet ~s~ be a semigroupâ€,
 whereas almost never do mathematicians say â€œlet ~x~ be a set and ~y~ be an operation on it that together constitute a semigroupâ€.

 At a first glance, it does not seem too troublesome to produce the record
 presentation from the predicate presentation: Simply /repeat all/ the inputs
 under a record declaration along with a proof obligation. However, the
 word â€˜repeatâ€™ already suggests a problem, and â€˜allâ€™ suggests another one.
 What if one desires to
 utilise the record associated to the predicate by only packaging certain
 inputs but not others? This is akin to the problem of constructors
 in object-oriented languages: In Java, for example, one uses overloading
 to provide a number of user-written constructors for only a few resonable
 input invocations to construct an object; in contrast, Common Lisp permits
 optional named arguments, and so in one fell swoop, with one user-written,
 constructor, provides all possible combinations of constructor invocations
 ---we are aiming at this level of power and flexibility.
 #
 # WK: [OCaml] permits optional named arguments.

 Lest it's unclear, let's elaborate slightly on the idea.
 :Setup:
 #+begin_src haskell
open import Relation.Binary.PropositionalEquality
open â‰¡-Reasoning

-- Z-notation for sums
open import Level
open import Data.Product using (Î£ ; projâ‚ ; projâ‚‚ ; _Ã—_ ; _,_)
Î£âˆ¶â€¢ : {a b : Level} (A : Set a) (B : A â†’ Set b) â†’ Set (a âŠ” b)
Î£âˆ¶â€¢ = Î£
infix -666 Î£âˆ¶â€¢
syntax Î£âˆ¶â€¢ A (Î» x â†’ B) = Î£ x âˆ¶ A â€¢ B
 #+end_src
 :End:

 A semigroup is an algebraic structure that models (untyped) compositionality:
 It consists of a collection of objects of interests called the ~Carrier~ set,
 and an operation ~_â¨¾_~ to compose existing items to produce new items, and the operation
 is associative.
 Below is a spectrum of ways to bundle up such a structure
 --starting from being completely bundled up all the way to being
 completely exposed.
 {{{code(A value of â€œSemigroup0â€ is an arbitrary semigroup.)}}}
 #+begin_src haskell
-- One extreme: Completely bundled up
record Semigroup0 : Setâ‚ where
  field
    Carrier : Set
    _â¨¾_     : Carrier â†’ Carrier â†’ Carrier
    assoc   : âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z â‰¡ x â¨¾ (y â¨¾ z)
 #+end_src
 {{{code(A value of â€œSemigroup1 Câ€ is a semigroup â€œstructure onâ€ type â€œC.â€)}}}
 #+begin_src haskell
-- â€˜Typeclassâ€™ on a given Carrier
-- Alternatively: Carrier is known as runtime.
record Semigroup1 (Carrier : Set): Setâ‚ where
  field
    _â¨¾_   : Carrier â†’ Carrier â†’ Carrier
    assoc : âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z â‰¡ x â¨¾ (y â¨¾ z)
 #+end_src
 {{{code(A value of â€œSemigroup2 C opâ€ is a â€œproofâ€ that â€˜Câ€™ with â€˜opâ€™ forms a semigroup.)}}}
 #+begin_src haskell
-- Two items known at run time --c.f., â€œIsSemiâ€ above.
record Semigroup2
 (Carrier : Set)
 (_â¨¾_     : Carrier â†’ Carrier â†’ Carrier) : Set where
  field
    assoc : âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z â‰¡ x â¨¾ (y â¨¾ z)
 #+end_src
 {{{code(The other extreme: Completely unbundled.)}}}
 #+begin_src haskell
-- A value of â€œSemigroup3 C op pfâ€ is trivially the empty record, if any,
-- provided â€˜pfâ€™ is a proof that â€˜Câ€™ forms a semigroup with â€˜opâ€™.
-- This type is usualy written â€œÎ£ C âˆ¶ Set â€¢ Î£ _â¨¾_ âˆ¶ C â†’ C â†’ C â€¢ Î£ assoc âˆ¶ â‹¯â€.
record Semigroup3
 (Carrier : Set)
 (_â¨¾_ : Carrier â†’ Carrier â†’ Carrier)
 (assoc : âˆ€ x y z â†’ (x â¨¾ y) â¨¾ z â‰¡ x â¨¾ (y â¨¾ z)) : Set where
  -- no fields
 #+end_src
 Depending on the user's needs, it may be useful to have one form or another.
 Unfortunately they are enslaved to the choices of the library designer,
 or if they deviate then they must produce tedious conversion methods and use
 them to pad all the library methods for the structures.
 Even worse, such back and forth conversions will not only be representation
 shuffling but also wasteful of resources.

 For example, every bijective function $f : A \to B$ furnishes its target $B$ with a semigroup
 structure provided its source $A$ has the structure to begin with.
 Since the statement mentions the carriers of semigroups, it is only natural
 to formulate it an prove it using presentation ~Semigroup1~.
 {{{code(Elementary Properties of Functions)}}}
 #+begin_src haskell
Surjection : âˆ€{A B : Set} â†’ (A â†’ B) â†’ Set
Surjection {A} {B} f = âˆ€ (b : B) â†’ Î£ a âˆ¶ A â€¢ b â‰¡ f a
-- (Î£ a âˆ¶ A â€¢ P a) â‰ˆ { (a, proof) â™ a âˆˆ A âˆ§ pf is a proof of P(a) }

Injection : âˆ€{A B : Set} â†’ (A â†’ B) â†’ Set
Injection {A} {B} f = âˆ€ {x y} â†’  f x â‰¡ f y â†’ x â‰¡ y
 #+end_src
 {{{code(An Involved Proof That We Would Like to Reuse)}}}
 #+begin_src haskell
translate1 : âˆ€{A B} â†’ (f : A â†’ B) â†’ Surjection f â†’ Injection f
       â†’ Semigroup1 A â†’ Semigroup1 B
translate1 f surj inj AS =
  let
    open Semigroup1 AS

    -- x â¨¾â€² y is obtained by applying f to the â¨¾-composition of the pre-images of x and y.
    infix 5 _â¨¾â€²_
    _â¨¾â€²_ = Î» x y â†’ let a0 = projâ‚ (surj x); a1 = projâ‚ (surj y) in f (a0 â¨¾ a1)

    -- f distributes over â¨¾ turning it into â¨¾â€².
    factor : âˆ€ {a aâ€²} â†’ f a â¨¾â€² f aâ€² â‰¡ f (a â¨¾ aâ€²)
    factor {a} {aâ€²} =
           let ğ’¶  , m  = surj (f a)
           ğ’¶â€² , w  = surj (f aâ€²)
           in
           begin
         f a â¨¾â€² f aâ€²
           â‰¡âŸ¨ refl âŸ©
         f (ğ’¶ â¨¾ ğ’¶â€²)
           â‰¡âŸ¨ cong f (congâ‚‚ _â¨¾_ (inj (sym m)) (inj (sym w)))  âŸ©
         f (a â¨¾ aâ€²)
           âˆ

    distribute : âˆ€ {a aâ€²} â†’ f (a â¨¾ aâ€²) â‰¡ f a â¨¾â€² f aâ€²
    distribute {a} {aâ€²} = sym (factor {a} {aâ€²})

  in -- Bundle up â¨¾â€² along with a proof of associtivity
    record { _â¨¾_ = _â¨¾â€²_; assoc = Î» x y z â†’
     let
    -- Obtain f-pre-images
    aâ‚€ , xâ‰ˆfaâ‚€  =  surj x
    aâ‚ , yâ‰ˆfaâ‚  =  surj y
    aâ‚‚ , zâ‰ˆfaâ‚‚  =  surj z
     in
      {- Tersely, we rewrite along the pre-images,
     factor f, perform the associativity of â¨¾,
     then distribute f and rewrite along the pre-images.
      -}
       begin
     (x â¨¾â€² y) â¨¾â€² z
       â‰¡âŸ¨ congâ‚‚ _â¨¾â€²_ (congâ‚‚ _â¨¾â€²_ xâ‰ˆfaâ‚€ yâ‰ˆfaâ‚) zâ‰ˆfaâ‚‚ âŸ©
     (f aâ‚€ â¨¾â€² f aâ‚) â¨¾â€² f aâ‚‚
       â‰¡âŸ¨ cong (_â¨¾â€² f aâ‚‚) factor âŸ©
     f (aâ‚€ â¨¾ aâ‚) â¨¾â€² f aâ‚‚
       â‰¡âŸ¨ factor âŸ©
     f ((aâ‚€ â¨¾ aâ‚) â¨¾ aâ‚‚)
       â‰¡âŸ¨ cong f (assoc _ _ _)  âŸ©
     f (aâ‚€ â¨¾ (aâ‚ â¨¾ aâ‚‚))
       â‰¡âŸ¨ distribute âŸ©
     f aâ‚€ â¨¾â€² f (aâ‚ â¨¾ aâ‚‚)
       â‰¡âŸ¨ cong (f aâ‚€ â¨¾â€²_) distribute âŸ©
     f aâ‚€ â¨¾â€² (f aâ‚ â¨¾â€² f aâ‚‚)
       â‰¡âŸ¨ sym (congâ‚‚ _â¨¾â€²_ xâ‰ˆfaâ‚€ (congâ‚‚ _â¨¾â€²_ yâ‰ˆfaâ‚ zâ‰ˆfaâ‚‚))  âŸ©
     x â¨¾â€² (y â¨¾â€² z)
       âˆ
  }
 #+end_src
 ~translate1~ is a lengthy proof, we could repeat it, or invoke it.
 Since duplication with alteration is error-prone and non-generic,
 we shall aim for the latter.
 {{{code(Conversions are a Nuisance)}}}
 #+begin_src haskell
translate0 : âˆ€{B : Set} (AS : Semigroup0) (f : Semigroup0.Carrier AS â†’ B)
       â†’ Surjection f â†’ Injection f
       â†’ Semigroup0
translate0 {B} AS f surj inj = record { Carrier = B ; _â¨¾_ = _â¨¾_ ; assoc = assoc }
  where

       -- Repackage â€˜ASâ€™ from a â€˜Semigroup0â€™ to a â€˜Semigroup1â€™
       -- only to immediatley unpack it, so that its contents
       -- are available to be repacked above as a â€˜Semigroup0â€™.

       pack : Semigroup1 (Semigroup0.Carrier AS)
       pack = let open Semigroup0 AS
           in record {_â¨¾_ = _â¨¾_; assoc = assoc }

       open Semigroup1 (translate1 f surj inj pack)
 #+end_src
 Observe that ~translate0~ repackages ~AS~ via ~pack~,
 then passes that as an argument to ~translate1~, which in turn unpacks it
 to form a new ~Semigroup0~, which is then unpacked in the
 last line above.
 Regardless of any possible wasteful amount of packing and unpacking of records
 --which may be mitigated via inlining--
 the way ~translate0~ is written is far from ideal;
 whereas ~translate1~ is the appropriate level of abstraction to pose the problem.
 Instead, it would be ideal to write the method at a sufficient level of generality
 such that ~translate0~ and ~translate1~ are, say, polymorphic instances thereof.
 This is what we shall propose in a later section.

 :Relocate_yoneda:
 Moreover, as a stylistic decision, implementers may prefer to view
 an object in either its predicate form ---with the constituents varying---
 or in its record form ---with the constituents fixed---, will all
 library utilities tied to a particular form.
 :End:

 :efficiency_remarks_incomplete:

 *Efficiency:*

 A hallmark of computing is to reduce new problems to ones already considered.
 One realisation of this principle is found in the sharing mechanisms of
 certain lazy languages: In the expression ~let y = f(x) in g(y, y)~,
 the term ~y~ is evaluated once and the result is shared among its multiple
 call sites. This idea comes under the name of /thunks/:
 When we encounter an instance of ~y~ and we need to â€˜thinkâ€™
 of its value, we realise we have already â€˜thunkâ€™ it.

 # :What:
 Memory is tremendously difficult to reason about {{{remark(reynolds calculus)}}},
 and lazy sharing only compounds to the troubles of garbage collection
 and complexity analysis {{{remark(Haskell)}}}.
 # :End:

 Dependently-typed languages are usually not only utilised for programming
 but generally also for proof; as such, their implementations adhere to
 a particular logic.

 To be completed â€¦

 :End:

 *Excerption:*

 In order to produce reusable components, theories ---i.e., packages--- are formed
 from existing theories by adding only one new concept at a time. Such an approach
 reduces the possibility of missing a useful structure in the hierarchy, as well
 as provides tremendous generality ---operations can be rendered using the minimal
 interface required rather than one that is overly expressive. This is a common
 scheme when formalising mathematics cite:typeclasses_for_maths,coq_cat_experiences.

 Unfortunately, a common scenario is when one wants to /instantiate/ such a deeply
 nested theory. More concretely, suppose we have the following fine-grained
 hierarchy.
 #+begin_src plantuml :file example_hierarchy.png :exports results :tangle (org-display-inline-images t t)
skinparam defaultTextAlignment center

[*] -> Empty
Empty -> Type
Type -down-> Pointed
Type -> Magma
Magma -> Semigroup
Pointed   -down-> Pointed_Semigroup
Semigroup -down-> Pointed_Semigroup
Pointed_Semigroup -down-> Left_Unital_Semigroup
Pointed_Semigroup -down-> Right_Unital_Semigroup
Left_Unital_Semigroup -down-> Monoid
Right_Unital_Semigroup -down-> Monoid

Type : Carrier
Pointed : Carrier, point
Magma : Carrier, binary_op
Semigroup : Carrier, binary_op, associativity

Pointed_Semigroup : Carrier, point, binary_op, associativity
Left_Unital_Semigroup : âŸªinherit aboveâŸ«, left_identity_law
Right_Unital_Semigroup : âŸªinherit aboveâŸ«, right_identity_law

Monoid : Carrier, point, binary_op, associativity, identity_laws

center footer  Example Hierarchy
 #+end_src
 #+RESULTS:
 [[file:example_hierarchy_10.png]]

 If we have the ingredients for a monoid in hand, we are unfortunately first
 required to produce a left or right unital semigroup, which requires us to produce
 a pointed semigroup first, and this regress continues to the base theory, ~Type~.
 Building on semigroups, monoids are a ubiquitous model of compositionality,
 and so this scenario
 happens rather often, in one guise or another. The amount of syntactic noise
 required to produce a simple instantiation is unreasonable: One should not be forced
 to work through the hierarchy if it provides no immediate benefit.
 It is to be noted that this issue does not generally apply to implementations of
 object-oriented class supporting multiple interfaces.
 # or rephrasing the hierarchy to be horizontal and unrelated,
 # so each piece is a typeclass, and we then use multiple class constraints.
 #
 # What about OCaml, F#, F*?

 Even worse, pragmatically speaking, to access a field deep down in a nested structure
 results in overtly lengthy and verbose names. Indeed, in the above example, the monoid
 operation lives at the bottom-most level, we would need to access all the intermediary
 levels to simply refer to it. Such verbose invocations would immediately give way to
 helper functions to refer to fields lower in the hierarchy; yet another opportunity
 for boilerplate to leak in.

 It is interesting to note that diamond hierarchies cannot be trivially eliminated
 when providing fine-grained hierarchies. As such, we make no rash decisions
 regarding limiting them ---and completely forgoe the unreasonable
 possibility of forbidding them.

 A more common example from programming is that of providing monad instances
 in Haskell. Most often users want to avoid tedious case analysis or prefer a
 sequential-style approach to producing programs, so they want to furnish a
 type constructor with a monad instance in order to utilise Haskell's ~do~-notation.
 Unfortunately, this requires an applicative instances, which in turn requires
 a functor instance. However, providing the return-and-bind interface for monads
 allows us to obtain functor and applicative instances.
 Consequently, many users simply provide local names for the return-and-bind
 interface then use that to provide the default implementations for the other
 interfaces. In this scenario, the standard approach is side-stepped by manually
 carrying out a mechanical and tedious set of steps that not only wastes time
 but obscures the generic process and could be error-prone.

 Instead, it would be desirable to â€˜flattenâ€™ the hierarchy into a single package,
 consisting of the fields throughout the hierarchy, possibly with default
 implementations, yet still be able to view
 the resulting package at base levels in the hierarchy.
 Another benefit of this approach is that it allows users to utilise the package
 without consideration of how the hierarchy was formed, thereby providing library
 designers with the freedom to alter it in the future.

 # One final benefit is exposition. It happens in academic literature, that an
 # audicance may not be familar with the rudiments of a hierarchy, nor should they
 # be forced to ...

 These features are considered â€˜missingâ€™ since they are reasonably achievable
 in a dependently-typed system ---e.g., the different forms of dependently-typed
 bundling suggest a form of polymorphism.
 Their absence may be due to logistic reasons,
 such as no effort expedited in their direction, or due to issues surrounding
 the logical frameworks of the systems. Which is to blame is an investigation
 matter left to the thesis research.
*** Desirable Features

 Our preliminary research, and personal use with dependently-typed systems,
 has yielded three strongly desirable features of a module system for DTLs.

 *Uniformity:*

 A type alias and a value alias are merely aliases at the end of the day,
 so unlike Haskell, for example, which distinguishes the two, Agda, for example,
 does not. More generally, type families, simple types, type constructors,
 dependent types, etc, collapse into a single category: Dependent types.

 In particular, recall the canonical definition of â€˜termâ€™:
 {{{code(Grammar for Terms)}}}
 #+begin_src haskell
term ::=  x                    -- variable
      |   f(term_0, â€¦, term_N) -- function application
 #+end_src
 In pedestrian languages, one distinguishes between /value/ terms and /type/ terms,
 whence the ~t_i~ are constrained to be homogeneously all values or all types.
 In contrast, a dependently-typed languages makes no such limitation, thereby allowing
 the ~t_i~ to be heterogeneous. For example, in a simple type system, ~Maybe (A Ã— List B)~
 is a term where all variables, $t_0, t_1 = A, B$, are of the same kind ---types.
 This is not so with the term {{{newline}}} ~Maybe (A Ã— Vec B n)~ ---~A~ and ~B~ are types while ~n~ is a number.
 Our aim is not to educate the reader on the power and utility of dependent types;
 we invite the reader to consult any of the existing material cite:dtl_why, agda_overview.
 # This is akin to forming English sentences using only noun phrases,
 # as in â€œI thanked the manâ€, or sentences where the clauses may be of different
 # kinds, as in â€œI thanked the man who directed meâ€ which contains noun and adjective
 # clauses.
 #
 # WK: â€œthanked the manâ€ is a verb phrase.
 #
 # â€œThe man knows much.â€
 # vs. â€œThe man who introduced me to Emacs knows much.â€
 #
 # since terms/values and types are in the same syntactic category, all these things really are the same.

 In the same vein, the varying notions of packaging are treated differently
 even though they are isomorphic in certain scenarios or interdefinable in others.
 As such, it would be useful to reduce the syntactic distinction between them.

 *Genericity:*

 Type polymorphism permits us to produce functions written once with type variables
 and have them applied to radically different types. Likewise, it would be desirable
 to write once a generic function on a kind of package and have it operate on
 the many variations of packaging.

 An example of this idea is presented at
 the end of this section, as part of preliminary research.
 In particular, we demonstrate a novel form of generic programming,
 /package polymorphism/: A method is written against a generic notion of container
 and is then applied to derived notions
 ---such as the \texttt{Semigroup}$i$ forms from the previous section.

 *Extensiblity:*

 Systems tend to come with a pre-defined set of operations for built-in constructs;
 the user is left to utilise third-party pre-processing tools, for example, to
 provide extra-linguistic support for common repetitive scenarios they encounter.

 More concretely, a large number of proofs can be discharged by merely pattern
 matching on variables ---this works since the case analysis reduces the proof goal
 into a trivial reflexitivity obligation, for example. The number of cases can
 quickly grow thereby taking up space, which is unfortunate since the proof has
 very little to offer besides verifying the claim. In such cases, a pre-process,
 perhaps an â€œeditor tacticâ€, could be utilised to produce the proof in an auxiliary
 file, and reference it in the current file.

 Perhaps more common is the renaming of package contents, by hand.
 For example, when a notion of preorder is defined with relation named ~_â‰¤_~,
 one may rename it and all references to it by, say, ~_âŠ‘_~. Again, a pre-processor
 or editor-tactic could be utilised, but many simply perform the re-write by hand
 ---which is tedious, error prone, and obscures the generic rewriting method.

 It would be desirable to allow packages to be treated as first-class concepts
 that could be acted upon, in order to avoid third-party tools that obscure
 generic operations and leave them out of reach for the powerful typechecker of
 a dependently typed system.

 These features are desirable for working with modules, yet raise a number of
 immediate concerns. For example, uniformity may lead to ambiguous parsing,
 genericity may lead to inefficient execution, and extensibility borders on
 meta-programming thereby leaving the realm of types altogether.
 Possible limitations on these features may result in the thesis efforts
 to implement them in a dependently-typed system, such as Agda.

*** One-Item Checklist for a Candidate Solution

 # WK: 3.3: This section is actually good! ;-)

 An adequate module system for dependently-typed languages should make
 use of dependent-types as much as possible. As such, there is essentially
 one and only one primary goal for a module system to be considered
 reasonable for dependently-typed languages: Needless distinctions should be
 eliminated as much as possible.

 The â€œwrite once, instantiate manyâ€ attitude is well-promoted in functional
 communities predominately for /functions/, but we will take this approach to
 modules as well, beyond the features of, e.g., *ML functors.
 With one package declaration, one should be able to mechanically
 derive data, record, typeclass, product, sum formulations, among many others.
 All operations on the generic package then should also apply to the particular
 package instantiations.

 This one goal for a reasonable solution has a number of important and difficult
 subgoals. The resulting system should be well-defined with a coherent semantic
 underpinning ---possibly being a conservative extension---; it should support the elementary uses
 of pedestrian module systems;
 the algorithms utilised need to be proven correct with a mechanical proof assistant,
 considerations for efficiency cannot be dismissed if the system is to be usable;
 the interface for modules should be as minimal as possible,
 and, finally, a large number of existing use-cases must be rendered tersely
 using the resulting system without jeopardising runtime performance in order to demonstrate its success.
 #
 # At least a convincing case must be made that overhead can be
 # ``compiled away''.

 During the research stage of the thesis, some of the sub-goals may be altered
 radically, dismissed altogether, or new ones brought forth due to implementation
 considerations. However, the one main goal will remain unchanged as it is how
 we have chosen to measure the minimal adequacy for a module system for rich
 settings that include dependent-types.
*** Preliminary Research

 The homogeneous treatment of structuring mechanisms is herein presented using a prototype
 developed using the user-friendly Emacs application framework by means of textual expansion,
 the details of which are largely uninteresting ---suffice it to say, the code is tremendously terse.
 In this section we demonstrates that packaging concepts differ only in their use, leading to a uniform
 syntax of which first-class records are an instance and so the resulting system is homoiconic in nature.
 We introduce fictitious syntax, mostly in red, with its intended Agda elaboration in blue
 ---the users write the red and expect it to behave like the blue; no â€œcode generationâ€ transpires.

 The reader is advised to remember that the value of a prototype is in the guidance it provides,
 not the implementation itself nor any of its design decisions ---such as using strings in meta-programming
 scenarios. In other words, for the reader, portions of this section may serve as an exercise in foresight and patience.
 ( A brief demonstration of the prototype may be viewed at https://www.youtube.com/watch?v=NYOOF9xKBz8 .)

 :Minimality:
 A prime guiding design decision is
 /try to avoid making any decisions, including unconscious restrictions, unless deemed necessary!/
 :End:

 The initiated reader will quickly notice that our package formers are just theory presentations
 ---a list of name-type pairs. The chosen phrasing is due to the target audience, DTL programmers.
 We are not committed to the name, but unlike the overloaded â€˜moduleâ€™, â€˜package formerâ€™ is a good
 new name without too many meanings. We have not provided full semantics for package formers, but
 we have provided concrete well-defined elaborations to communicate the intent: A package former
 is akin to a type former, it is â€˜incompleteâ€™ and does not define a concrete package until a certain
 tag is provided.
 It is part of the thesis effort to investigate which features of our proposed package formers
 break, or become limited, when considered with other language constructs.

 The uniformity in syntax reduces the variety of sub-languages in a dependently-typed language
 by eliminating needless distinctions for notions of containers. The first subsection below
 addresses syntactic similarity, whereas the second tackles computing similarity,
 and we conclude with a brief discussion on foundational concerns.

**** First Observation: Syntactic Similarity for Containers

 Since the prototypical notion of packaging is that of records,
 which are value terms, all, necessarily succeeding, notions of packaging
 ought to be treated uniformly as value types.
 Consequently, variations on packaging should only be signalled by necessary
 keywords, and otherwise should be syntactically indistinguishable.
 That is to say, a â€˜variationâ€™ is a tag identifying what particular
 form of module is desired, such as ~datatype~ for an algebraic data type
 with the declared fields as constructors, or as ~record~ to yield a record structure
 with constituents being the declared fields.

 For example, just as ~List~ is a type-former, we may declare a â€˜package formerâ€™:
 {{{code(Our first package former)}}}
 #+begin_src haskell
 PackageFormer TermP (v : Variation) : Set where
    Var : Int â†’ TermP v
    Add : TermP v â†’ TermP v â†’ TermP v
  #+end_src

 Note that a package former is just a sequence of names with types and,
 as will be demonstrated later, optional default types.
 It requires a particular â€œinterpretationâ€ ---possibly user-defined---,
 to produce some notion of package. This is signalled by the ~Variation~
 type, which for brevity contains ~data, record, typeclass~, and a few more
 that we will meet below.

 For example, the ~data~ variation of packaging gives us a
 free data type.
 {{{code(Free data type: Terms are integer variables and addition of terms)}}}
 #+begin_src haskell
TermData = TermP data
{-
â‰…  data TermData : Set where
     Var : Int â†’ TermData
     Add : TermData â†’ TermData â†’ TermData
-}
 #+end_src
 In the comment above, we indicate how our fictitious syntax is intended to be elaborated
 into current Agda syntax. Besides syntax, induction principles are also derived:
 Our envisioned system would be able to derive simple, tedious, uninteresting concepts;
 leaving difficult, interesting, ones  for humans to solve.
 For this type, below is the dependently typed eliminator, which in a DTL, corresponds to an induction
 principle.
 {{{code(Free data types also come with an induction principle)}}}
 #+begin_src haskell
{-
   term-data-elim : âˆ€ {â„“} {R : TermData â†’ Set â„“}
          â†’ (base : (n : Int) â†’ R (Var n))
          â†’ (ind  : âˆ€ {s t} â†’ R s â†’ R t â†’ R (Add s t))
          â†’ (t : TermData) â†’ R t

   term-data-elim base ind (Var n)   = base n
   term-data-elim base ind (Add s t) = ind rs rt
      where rs = term-data-elim base ind s
        rt = term-data-elim base ind t
-}
 #+end_src

 The type of the package former, for now, could simply be ~Set~
 ---c.f., the commented-out elaboration which declares ~TermData âˆ¶ Set~.
 However, if we permit a sufficiently small subtyping system, we
 may find it desirable to have the type of a package former be itself
 a package former! Moreover, if package former ~t~ has type package former ~tâ€²~,
 then the user should be able to use ~t~ at the levels ~t âˆ¶ s~
 without too much overhead, where ~s~ is any subtype of ~t~ with ~Set~ being a minimal
 such subtype. These thoughts are hurried and it is the purpose of the thesis
 to investigate what is the appropriate route.

 It is often the case that one begins working with a ~record~ of useful semantic
 data, but then, say, for proof automation, may want to use the associated ~datatype~
 for syntax. The latter should be mechanically derivable, and this is what we aim
 provide with our package formers.
 We will not delve into the relationship between free data types and how, for example,
 their associated catamorphism is necessarily also an interpreter
 ---in the programming languages sense.
 The reader is invited to consult a reference cite:cats_logic_shulman.

 We shall not discuss polymorphism along variations, the ~v~ components above,
 as it is orthogonal to our immediate goals. For example, ~TermP~ could have a field typed
 {{{newline}}} \texttt{TermP (f v) â†’ TermP (g v) â†’ TermP v},
 where ~f~ and ~g~ are operations on variations.
 Nonetheless, this is a feature that one should be aware of.

 The remaining items instantiate package formers for the usual
 common uses. Including notions of records in item 1;
 an algorithmic sketch underlying the examples of item 1 is presented in item2;
 union types and external, second-class, modules in item 3;
 package former polymorphism in item 4;
 operating on package formers and inheritance in items 5 and 6; then discuss
 how package formers handle the diamond problem in item 7.
 Finally, we close in item 8 by discussing a problem not generally found
 in pedestrian languages and how it is solved using package formers.

***** The Generality of Package Formers ---Products

 To demonstrate the generality of the notion of package formers we shall demonstrate
 how other common forms could be â€˜derivedâ€™ from the single declaration above.
 It is to be noted that for such a small example, such derived code may be taken for
 granted, however for much larger theories ---for example, a â€œfieldâ€ comes with more than
 20 fields--- the ability to derive different perspectives in a consistent fashion
 is indispensable; especially when the package is refactored.
 More realistically, a symmetric rig groupoid uses about 212 coherence laws cite:rig_computation,
 for which case-splitting, to perform proofs, yields [[https://github.com/JacquesCarette/pi-dual][over 200 goals]] thereby making
 metaprogramming a tempting approach.

 :counting_field_componenets:
 field â‰… ablean group âŸ¶ Carrier, op, inv, unit, assoc, 2 unit-laws, 2 inverse-laws, comm-law âŸ¶ 10 laws
       multiplicative monoid âŸ¶ Carrier, op, unit, assoc, 2 unit-laws âŸ¶ 6 laws
       the above two carries are identical  âŸ¶ 1 law
       distributively laws   âŸ¶ 2 laws
       integrity & div-op & non-zero division âŸ¶ 3 laws

 Total âŸ¶ 22 laws
 :end:

 # {{{code(Records; a magma with the integers)}}}
 {{{code(Records)}}}
 #+begin_src haskell
-- An instance of  TermRecord should have a carrier type
-- containing the integers, â€˜Varâ€™, and supports some binary operation, â€˜Addâ€™.
TermRecord = TermP record
{-
â‰…   record TermRecord  : Set where
      field
    Carrier : Set
    Var     : Int â†’ Carrier
    Add     : Carrier â†’ Carrier â†’ Carrier
-}
 #+end_src
 In the previous  and following invocations, the name ~Carrier~ is a system internal, for now,
 and can easily be ~renamed~ ---as will be demonstrated later on.
 For now, we adhere to a single-sorted stance: Unless indicated otherwise, a ~Carrier~ will always
 be included. An example of a two-sorted algebraic structure, graphs, is demonstrated at the end of this subsection.

 Built-in names, such as ~Carrier~, are generally not ideal. For example, a machine may provide the
 names ~FourLeggedFeline~ and ~CommutativeIdempotentMonoid~ where a human may prefer ~Cat~ and ~JoinSemilattice~ instead.
 As such, the resulting system, would accept â€˜renamingâ€™ functions to generate names. For now, we mostly limit
 such an approach for brevity.

 {{{code(Haskell-style typeclasses ---or Scala-like traits)}}}
 #+begin_src haskell
TermOn = TermP typeclass
{-
â‰…   record TermOn (Carrier : Set) : Set where
      field
    Var     : Int â†’ Carrier
    Add     : Carrier â†’ Carrier â†’ Carrier
-}
 #+end_src
 {{{code(A pair of functions \emph{on} a declared carrier type)}}}
 #+begin_src haskell
TermFunctionsOn = TermP tuples
{-
TermFunctionsOn : Set â†’ Set
TermFunctionsOn C = (Int â†’ C) Ã— (C â†’ C â†’ C)
-}
 #+end_src
 {{{code(Or the carrier is existential)}}}
 #+begin_src haskell
TermFunctions = TermP Î£
-- â‰…  TermFunctions  =  Î£ C âˆ¶ Set  â€¢  Î£ Var : Int â†’ C  â€¢  (C â†’ C â†’ C)
 #+end_src

 Let's show a more intricate yet desirable use.
 {{{code(The interface of non-empty lists, with a dedicated list)}}}
 #+begin_src haskell
PointedSemigroup = TermP record hiding (Var) renaming (Add to _â¨¾_)
             field
               Id     : Carrier
               â¨¾-assoc : âˆ€ x y z â†’ x â¨¾ (y â¨¾ z) â‰¡ (x â¨¾ y) â¨¾ z
{-
â‰…   record PointedSemigroup  : Setâ‚ where
      field
    Carrier : Set
    _â¨¾_     : Carrier â†’ Carrier â†’ Carrier
    Id      : Carrier
    â¨¾-assoc : âˆ€ x y z â†’ x â¨¾ (y â¨¾ z) â‰¡ (x â¨¾ y) â¨¾ z
-}
 #+end_src

***** Algorithmically Obtaining Elaborated Types
 We have discussed how the generic package formers elaborate
 ---each blue comment indicates a standalone isomorphic Agda rendition---,
 as such it should be unsurprising that the constituents of a package former
 are dependently typed functions /consuming/ each concrete variation in
 its traditional fashion. Let's clarify this idea further.

 {{{code(Our example package former)}}}
 #+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
   Var : Int â†’ TermP v
   Add : TermP v â†’ TermP v â†’ TermP v
 #+end_src

 The â€˜typeâ€™ of the first item, for example, is as follows
 ---where ~TermP v~ is rewritten using the above introduced names
 for the sake of clarity.
 {{{code(The types of a constituents of a package former)}}}
 #+begin_src haskell
Var : (v : Variation) â†’ Set

{- Datatype constructor -}
Var datatype   =  Int â†’ TermData
{- Dependent projection -}
Var record     =  (Ï„ : TermRecord) â†’ Int â†’ TermRecord.Carrier Ï„
Var Î£          =  (Ï„ : TermFunctions) â†’ Int â†’ projâ‚ Ï„
{- Parameter of a constraint -}
Var typeclass  =  âˆ€{C} {{_ : TermOn C}} â†’ Int â†’ C
Var tuples     =  âˆ€{C} â†’ TermFunctionsOn C â†’ Int â†’ C
â‹¯
 #+end_src

 An initial glance suggests that this is all ad-hoc; let us demonstrate that
 this is not the case. Suppose there were a method ~ğ’¯~ to obtain the user-provided types of
 constituents; e.g., the given ~Var âˆ¶ Int â†’ TermP v~ is indistinguishable from {{{newline}}}  ~Var âˆ¶ ğ’¯ â€œVarâ€ (TermP v)~.
 {{{code( Obtaining User-Provided Types ---Under the hood )}}}
 #+begin_src haskell
Constituent = String -- Draft idea, not ideal.

-- â€œA âŸ¨nâŸ©â†’ B  â‰ˆ  A â†’ â‹¯ â†’ A â†’ Bâ€ with n-many A's.
_âŸ¨_âŸ©â†’_ : Set â†’ â„• â†’ Set â†’ Set
A âŸ¨ zero   âŸ©â†’ B  =  B
A âŸ¨ succ n âŸ©â†’ B  =  A â†’ (A âŸ¨ n âŸ©â†’ B)

-- Constituents of package formers give rise to â€œSet âŸ¨nâŸ©â†’ Setâ€ functions.
ğ’¯ : {P : PackageFormer} â†’ Constituent P â†’ Set âŸ¨ arity P âŸ©â†’ Set
ğ’¯ â€œVarâ€ X  =  Int â†’ X
ğ’¯ â€œAddâ€ X  =  X â†’ X â†’ X
 #+end_src
 It is now trivial to reify the above prescription for ~Var~ in a uniformly fashion
 ---namely, ~Var = ğ“‰ğ“ğ“…ğ’† â€œVarâ€~.
 {{{code( Providing User-Facing Types ---Under the hood )}}}
 #+begin_src haskell
ğ“‰ğ“ğ“…ğ’† : Constituent â†’ Variation â†’ Set
ğ“‰ğ“ğ“…ğ’† c v@datatype  = ğ’¯ c (TermP v)
ğ“‰ğ“ğ“…ğ’† c v@record    = (Ï„ : TermP v) â†’ ğ’¯ c ((TermP v).Carrier Ï„)
ğ“‰ğ“ğ“…ğ’† c v@Î£         = (Ï„ : TermP v) â†’ ğ’¯ c (projâ‚ Ï„)
ğ“‰ğ“ğ“…ğ’† c v@typeclass = âˆ€{C} {{_ : TermP v C}} â†’ ğ’¯ c C
ğ“‰ğ“ğ“…ğ’† c v@tuples    = âˆ€{C} â†’ TermP v C â†’ ğ’¯ c C
â‹¯
 #+end_src
 For example, invoking this approach we find that ~Add~, on ~TermRecord~'s, is typed {{{newline}}}
 ~ğ“‰ğ“ğ“…ğ’† â€œAddâ€ record~, which may be rewritten as {{{newline}}}
 ~(Ï„ âˆ¶ TermRecord) â†’ TermRecord.Carrier Ï„ â†’ TermRecord.Carrier Ï„ â†’ TermRecord.Carrier Ï„~.
 That is, as expected, ~Add~ on records consumes a record value then acts as a binary
 operation on the carrier of said record value. Likewise, we invite the reader
 to check that ~Add~ on algebraic datatype ~TermData~ is typed as a binary constructor.

 Users have access to the elaborated types.
 {{{code(Providing User-Facing Types)}}}
 #+begin_src haskell
 TermP.Var : âˆ€{v} â†’ ğ“‰ğ“ğ“…ğ’† â€œVarâ€ v
 TermP.Add : âˆ€{v} â†’ ğ“‰ğ“ğ“…ğ’† â€œAddâ€ v
 #+end_src
 This is particularly useful when one wants to extract such types for re-use elsewhere.
 {{{code(Extracting a single ---possibly complicated--- signature)}}}
 #+begin_src haskell
ListBop = TermP.Add datatype âˆ˜ List
{-
â‰…  ListBop : Set â†’ Set
   ListBop C = (List C â†’ List C â†’ List C)
-}

ConstrainedBop : (Set â†’ Set) â†’ Set
ConstrainedBop constraint  = TermP.Add typeclass using constraint
{-
â‰… ConstrainedBop constraint  =  âˆ€{C} â†’ constraint C â†’ C â†’ C â†’ C

-- N.B., this would not elaborate without the â€œusingâ€.
-- Semantically, â€œP.x y using z = (P.x y)[P v â‰” z]â€
-- â”€the â€œvâ€ appears from â€œâˆ€{v}â€ above.
-}

SetoidBop = TermP.Add record using Setoid
{-
â‰… SetoidBop : Setoid â„“â‚€ â„“â‚€ â†’ Set
  SetoidBop S = Setoid.Carrier C â†’ Setoid.Carrier C â†’ Setoid.Carrier C

-- N.B., this would not elaborate if â€œSectoid.Carrierâ€ were undefiend.
-}
 #+end_src
 These examples open a flurry of problems.

 At this stage, it is sufficient to have observed what could possibly
 be performed and that it is not without burden.
 We will not attempt to clarify any problem nor propose any solution;
 the thesis effort will contend with these matters further.

***** The Generality of Package Formers ---Sums & Modules

 Thus far we have only discussed products; however
 the proposed general notion of containers should also produce sum types
 and be used in modules ---which are just packages.
 {{{code(At â€œleast oneâ€ of the operations is desired on a declared carrier type)}}}
 #+begin_src haskell
TermFunctionsSumOn = TermP sum
-- â‰…  TermFunctionsSumOn C  =  (Int â†’ C) âŠ (C â†’ C â†’ C)
 #+end_src

 In general, this yields a disjoint collection of declarations
 where each declaration is itself a Î£ consisting of the context necessary
 to ensure that the operations are well-defined.

 For modules,
 {{{code(Using our package former \emph{within} another package)}}}
 #+begin_src haskell
  PackageFormer MyDriver (t : TermP record renaming (Carrier to C)) : Set where â‹¯
-- â‰… module MyDriver (t : TermRecord[Carrier â‰” C]) where â‹¯
-- â‰… module MyDriver (C : Set) (Var : Int â†’ C) (Add : C â†’ C â†’ C) where â‹¯
 #+end_src
 At least two â€˜freeâ€™ invocation notations ought to be supplied:
 1. ~MyDriver t~
 2. ~MyDriver type varOp addOp~

 Multifaceted invocations provide a common use case: No overhead to pack or unpack
 the constituents of a type former so the sole purpose of an invocation.
 However, the pragmatic feasibility of such an approach is unclear at this stage.

***** Novel Genericity: â€˜Package Polymorphismâ€™

 We have a sufficient number of elaborations thus far to demonstrate
 that the notion of package formers is not without merit.
 It is now an appropriate moment to address an elephant in the room:
 /The phrase ~TermP v~ semantically refers to which type?/

 If ~v = datatype~ then ~TermP v~
 refers to the associated algebraic datatype.
 If ~v = record~, then there are at least two ways to interpret ~TermP v~:
 As either the record type or as the carrier of a record value.
 Likewise for other variations. For now, we settle with a monadic-like interpretation:
 We write ~do Ï„ â† TermP v; â‹¯~ whenever we wish to refer to the underlying carrier of a concrete
 package former. Loosely put,
 {{{code(Syntax ---Under the hood )}}}
 #+begin_src haskell
do Ï„ â† TermP v; b  â‰ˆ  v â•± (Î» Ï„ â†’ b)

v@datatype  â•± f  =  f (TermP v)
v@record    â•± f  =  âˆ€(Ï„ : TermP v) â†’ f ((TermP v).Carrier Ï„)
v@Î£         â•± f  =  âˆ€(Ï„ : TermP v) â†’ f (projâ‚ Ï„)
v@typeclass â•± f  =  âˆ€{Ï„} {{_ : TermP v Ï„}} â†’ f Ï„
v@tuples    â•± f  =  âˆ€{Ï„} â†’ TermP v Ï„ â†’ f Ï„
 #+end_src
 The â€˜overâ€™ notation, ~_â•±_~, assumes ~f~ is a function acting on types;
 however, this is not necessary, if the ~âˆ€~ were replaced with ~Î»~, then
 the result would be a term expression. This is yet another opportunity for investigation
 during the thesis effort. Moreover, there is the possibility of providing
 â€œimplicit counterpartsâ€ to these variations,; e.g., for ~tuples~ one may want
 ~âˆ€{Ï„} {_ âˆ¶ TermP v Ï„} â†’ f Ï„~ instead, which could be variation, say, ~tuples-imp~.
 Likewise, we may want notation ~do-Î£~ to replace {{{newline}}} ~âˆ€ â‹¯ â†’ â‹¯~ with ~Î£ â‹¯ â€¢ â‹¯~.

 Unsurprisingly, this approach subsumes our earlier typing elaboration: {{{newline}}}
 ~ğ“‰ğ“ğ“…ğ’† c v  = do Ï„ â† TermP v; ğ’¯ c Ï„~.
 More concretely, for example, a notion of â€˜depthâ€™ for terms may have type
 ~âˆ€ {v} â†’  do Ï„ â† TermP v; (Ï„ â†’ â„•)~ ---a function
 that takes a package and yields a number.
 In the case of ~v = record~, such a function actually takes /two/
 items: The first being a record value, the second being an element of
 the carrier of that record value. In the case of ~v = typeclass~,
 the function takes an argument found by instance search. Likewise,
 for the remaining variations.

 Let us now turn to an example of a function operating on the above many, and all, variations of such packages.
 This example may appear contrived, yet the power of this form of polymorphism
 appears at the end of this subsection where one programs towards a /particular/
 interface and has the result /generalised/ to other variations
 ---a prime use case is to code against a typeclass representation and use the
 same methods on bundled records.
 {{{code(â€œTimes Loopâ€: Iterate an action $n$ times. )}}}
 #+begin_src haskell
-- Suppose I have the following syntactic construction.
repeat : TermData â†’ â„• â†’ TermData
repeat t Zero      =  Var 0
repeat t (Succ n)  =  Add t (repeat t n)

-- Here is its semantic counterpart.
run : (Ï„ : TermRecord) â†’ TermRecord.Carrier Ï„ â†’ â„• â†’ TermRecord.Carrier Ï„
run Ï„ t Zero      =  TermRecord.Var Ï„ 0
run Ï„ t (Succ n)  =  TermRecord.Add Ï„ t (run Ï„ t n)

-- Which is merely multiplication for the naturals.
_Ã—_ : â„• â†’ â„• â†’ â„•
t Ã— Zero     = Zero
t Ã— (Succ n) = t + (t Ã— n)
 #+end_src

 The first two are instances of a package former, and it is not diffcult to construe the naturals as the carrier of a package former.
 After which, we should be able to write one generic function, by writing according to the pacakge former as the interface.
 {{{code(â€œTimes Loopâ€: Iterate an action $n$ times. )}}}
 #+begin_src haskell
instance
  â„•Terms : TermOn â„•
  â„•Terms = record {Var = Î» n â†’ 0; Add = _+_}

{- IsConsumer is defined below; ignore for now. -}
exp : âˆ€{v} {{_ : IsConsumer v}}  â†’  do Ï„ â† TermP v; Ï„ â†’ â„• â†’ Ï„
exp t Zero     = Var 0
exp t (Succ n) = Add t (exp t n)
 #+end_src
 For example, we immediately obtain an instance for strings.
 {{{code(â€œTimes Loopâ€: Iterate an action $n$ times. )}}}
 #+begin_src haskell
instance
  STerms : TermOn (List Char)
  STerms = record {Var = Î» n â†’ []; Add = _++_}

repeat-s = exp {v = typeclass}
{- Yields a whole family, which includes:

   repeat-s0 : {{TermOn (List Char)}} â†’ List Char â†’ â„• â†’ List Char
   repeat-s0 c Zero = []
   repeat-s0 c (Succ n) = c ++ repeat c n
-}
 #+end_src

 Now that's re-use! One function for many semantically distinct types.
 Notice that invoking ~exp~ on ~ListBop~ or ~TermFunctionsSumOn~ values is ill-typed
 since the mechanically verifiable constraint ~IsConsumer~ fails for those variations.
 Indeed, we may utilise a number of constraints on our package variations, such as
 the following.
 {{{code(Under the hood constraints)}}}
 #+begin_src haskell
data IsConsumer : Variation â†’ Set where
  Prod    : IsConsumer tuples
  DepProd : IsConsumer Î£
  Data    : IsConsumer datatype
  Rec     : IsConsumer record
 #+end_src
 When a user defines a variation, they can signal whether it is a consumer or not.
 Likewise, one can indicate whether a variation should have ~Set~-valued operations
 on not. Note that a default mechanism could be implemented, but the user should
 continue to have the ability to enforce a particular discipline
 ---c.f., how ~C#~ allows the user to enforce the subtyping variance of a type former.
 {{{code(Under the hood constraints)}}}
 #+begin_src haskell
data HasConstructiveRelations : Variation â†’ Set where
  Prod    : HasConstructiveRelations tuples
  DepProd : HasConstructiveRelations Î£
  Rec     : HasConstructiveRelations record
 #+end_src
 For example, ~data~ declarations cannot contain proofs of an arbitrary, but fixed, constructive relation
 without declaring it as a parameter to the type. Nonetheless, a user may want to be
 able to express syntactic statements about such proof terms
 ---say for proof automation--- and they should have the ability to toggle such
 a feature.

 A more important concern is the type of ~exp~: The phrase ~do Ï„ â† TermP v; Ï„ â†’ â„• â†’ Ï„~
 elaborates to different types according to the value of ~v~, whence to define ~exp~
 it seems necessary to actually pattern match on it to obtain a concrete type, which,
 for example, may contain more arguments. Case analysis on the possible packaging variations
 is far from ideal ---one might as well re-implement the definition only on the cases they
 want rather than all cases. The aim ---to be pursued further in the full thesis effort---
 is to invert the process: /Avoid case analysis in favour of a particularly convenient view./

 This is clarified best by referring to the current prototype language: Lisp.
 Since all data and methods in a lisp are essentially lists, when one prescribes
 how to project a value from a possibly nested datatype, then the same prescription
 essentially directs how to get to the location of that value and so we obtain
 /generic setters/. The following tiny example demonstrates this idea.
 {{{code(Generic Setters in Lisp)}}}
 #+begin_src emacs-lisp
(setq xs '("a" nil (x y z) 12))  ;; Heterogenous list of 4 items.
(cadar (cdaddr xs))              ;; â‡’ y
(setf (cadar (cdaddr xs)) 'woah) ;; xs â‡’ '("a" nil (x woah z) 12))
 #+end_src
 It is this flexibility that we aim to provide to users.
 They code not against a generic variation, but rather along one that
 is the most appropriate task at hand. We would hope that it would not
 be unrealistic to then mechanically derive the other forms from it.
 For example, suppose we wish to define retracts on magmas; rather than
 define the concept for each possible view, we define it once and obtain it
 for other views.
 {{{code(Example Algebra)}}}
 #+begin_src haskell
PackageFormer MagmaP (v : Variation) : Set where
  _â¨¾_ : MagmaP v â†’ MagmaP v â†’ MagmaP v

MagmaOn = MagmaP typeclass
AMagma  = MagmaP record
 #+end_src

 The ubiquity of magmas ---literally everywhere--- lends itself to recall that
 working with structure, possibly needless structure, may usurp the goals of
 proof cite:purposes_of_proof: No mathematician would naturally say
 /let M be an algebra on set C/ when it suffices to say /let M be an algebra/;
 yet it may be /convenient/ to phrase problems more elegantly when the carrier
 set is mentioned explicitly cite:packaging_mathematical_structures.
 On the other hand,
 having the carrier explicit for the sake of typeclass resolution
 relies on decidable type (non)equality; which may be resonable for a simplly
 typed language but for a DTL type normalisation generally requires non-trivial,
 non-constant, computation.
 Anyhow, as mentioned earlier, bundling data
 is akin to currying or nesting quantifiers, yet is vastly more expensive
 since library designers generally commit early to one form or another;
 in this case {{{newline}}} ~AMagma â‰… Î£ C : Set â€¢ MagmaOn C~
 and {{{newline}}}
 ~MagmaOn C â‰… Î£ M : AMagma â€¢ M.Carrier â‰¡ C~.
 {{{code(Example Operation)}}}
 #+begin_src haskell
retract : âˆ€{S T} â†’ (f : S â†’ T) â†’ MagmaOn T â†’ MagmaOn S
retract f Tgt = record {_â¨¾_ = Î» x y â†’ f x â¨¾ f y} where open MagmaOn Tgt
 #+end_src
 Since ~MagmaOn = MagmaP v~ where ~v = typeclass~, we would ideally be able
 to derive the generic form ---possibly via case analysis.
 {{{code(Variation Generalisation)}}}
 #+begin_src haskell
retract-v : âˆ€{v}
      â†’ âˆ€ {S T} (f : S â†’ T)
      â†’  do   tgt â† MagmaP v; tgt â‰¡ T  -- Intentionally no parens.
      â†’ (do-Î£ src â† MagmaP v; src â‰¡ S)
retract-v = â‹¯ -- Unclear at this stage.
 #+end_src
 #  {{_ : HasCarrier v}}
 The record case could, semi-algorithmically, yield:
 {{{code(Verbose Record Case)}}}
 #+begin_src haskell
retract-v {record}  :  âˆ€ {S T} (f : S â†’ T)
            â†’  âˆ€ (Tgt : AMagma) â†’ AMagma.Carrier Tgt â‰¡ T
            â†’  Î£ (Src : AMagma) â€¢ AMagma.Carrier Src â‰¡ S
retract-v {record} {S} {T} f Tgt refl =  record { Carrier = S
                        ;  _â¨¾_ = Î» x y â†’ f x â¨¾ f y }
                       , refl
                       where open AMagma Tgt
 #+end_src
 From a usability perspective the trivial proofs should not be present
 and so we need to algorithmically rewrite the above type to omit them, as follows.
 We would like to preserve the argument syntax, ~retract f Tgt~, that was originally declared.
 Unfortunately, for the record case, the type of ~f~ must refer to the types of the other magamas
 if we eliminate the trivial equalities. One possible workaround, as follows, is thus to simply provide
 a omit the tedious equality proofs since they can be found by instance search.
 {{{code(Usable Record Case)}}}
 #+begin_src haskell
retract-v {record}  :  âˆ€ {S T} (f : S â†’ T)
            â†’  âˆ€ (Tgt : AMagma) â¦ƒ_ : AMagma.Carrier Tgt â‰¡ T â¦„
            â†’  projâ‚ (â¦ƒÎ£â¦„ Src : AMagma â€¢ AMagma.Carrier Src â‰¡ S)
retract-v {record} f Tgt  = â‹¯

-- â€œâ¦ƒÎ£â¦„ (x : A) â€¢ B xâ€ consists of a pair
-- where the second is found by instance search.
 #+end_src
 Notice that we also project at the end since we do not care about the tedious proof;
 nor should its existence be forced upon the user.

 Before we move on, there is particular reason we have deviated from our ~TermP~ example
 to the ~MagmaP~ concept. The ~datatype~ variation for ~MagmaP~ does not provide a way
 to speak of variables of the data type ---indeed ~MagmaP datatype~ has no closed terms,
 whence no terms at all. It is thus appropriate to now introduce a variation for
 syntactic terms /over/ some variable set which is then utilised by a mechanically
 derivable semantic function that is freely homomorphic.

 {{{code(From Syntax to Semantics)}}}
 #+begin_src haskell
MagmaTermsOn = MagmaP term-typeclass
{-
â‰… data MagmaTermsOn (Vars : Set) : Set where
    Var : Vars â†’ MagmaTermsOn Vars
    _â¨¾_  : MagmaTermsOn Vars â†’ MagmaTermsOn Vars â†’ MagmaTermsOn Vars

MagmaTermsOn-sem : âˆ€ {v} {A}  â†’  do Ï„ â† MagmaP v;
                 (f : A â†’ Ï„) â†’ MagmaTermsOn A â†’ Ï„
MagmaTermsOn-sem {record} S f (Var x) = f x
MagmaTermsOn-sem {record} S f (l â¨¾ r)  = ll sâ¨¾ rr
  where _â¨¾s_ = AMagma._â¨¾_ S
    ll = MagmaTermsOn-sem {record} S f l
    rr = MagmaTermsOn-sem {record} S f r
â‹¯
-}
 #+end_src

 We will return to homomorphisms later on, for now it is important to notice
 that some variations may be useless ---as in the empty datatypes.
 There is also the opportunity to explore co-inductive datatypes.
***** Common Operations on Package Formers
 It is rather common in the record variation to have multiple instances being
 mentioned and it is desirable to refer to them with syntactically distinct yet appealing
 names ---such as using subscripts, primes, or other decoration. Moreover, a notion of
 homomorphism, structure-preservation, can usually be automatically inferred.

 Here we show what such declarations looks like, later we show that such things
 could be /user defined/.

 {{{code(An example package former)}}}
 #+begin_src haskell
PackageFormer TermRelP (v : Variation) : Set where
   Var : Int â†’ TermRelP v
   Add : TermRelP v â†’ TermRelP v â†’ TermRelP v
   Rel : TermRelP v â†’ TermRelP v â†’ Set  -- This time we have a relation as well.
 #+end_src
 {{{code(A prime-decorated package former)}}}
 #+begin_src haskell
Declare PackageFormer TermRelP (v : Variation) decorated (Î» x â†’ x ++ "â€²")
{-
â‰… PackageFormer TermRelPâ€² (v : Variation) : Set where
   Varâ€² : Int â†’ TermRelPâ€² v
   Addâ€² : TermRelPâ€² v â†’ TermRelPâ€² v â†’ TermRelPâ€² v
   Relâ€² : TermRelPâ€² v â†’ TermRelPâ€² v â†’ Set

-- Coherence Meta-property: âˆ€ v, d  â€¢  TermRelP v decorated d  â‰…  TermRelP v
-}
 #+end_src
 {{{code(Structure preserving operations)}}}
 #+begin_src haskell
Declare Homomorphism TermRelP (v : Variation)
{-
â‰… PackageFormer TermRelP-Homomorphism (v : Variation) : Set where

    Src : TermRelP v   decorated  (Î» x â†’ x ++ "â‚")
    Tgt : TermRelP v   decorated  (Î» x â†’ x ++ "â‚‚")

    map : Src â†’ Tgt
    -- Elaborates to â€œCarrier Src â†’ Carrier Tgtâ€ in â€œrecordâ€ variation.

    var_preservation : âˆ€ n   â†’ map (Varâ‚ n) â‰¡ Varâ‚‚ n
    add_preservation : âˆ€ x y â†’ map (Addâ‚ x y) â‰¡ Addâ‚‚ (map x) (map y)
    rel_preservation : âˆ€ x y â†’ Relâ‚ x y â†’ Relâ‚‚ (map x) (map y)

NB: The â€œdecoratedâ€ annotations are local to the package.
-}
 #+end_src

***** Inheritance & Defaults for Package Formers

 Things get a bit more interesting with multiple packaging,
 fields making use of dependent types, and of (multiple) default implementations.
 Besides defaults, a desirable feature of our envisioned system is the ability to lift definitional extensions
 into fields of the package, say for more efficient implementations.

 {{{code(Recall our example package former)}}}
 #+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
   Var : Int â†’ TermP v
   Add : TermP v â†’ TermP v â†’ TermP v
 #+end_src

 {{{code(All the pieces of \texttt{TermP} but now with additionall new pieces)}}}
 #+begin_src haskell
PackageFormer PreOrderedTermP (v : Variation) : Set  inherits-from (TermP v) where
   Ord   : OrderedTermP v â†’ OrderedTermP v â†’ Set
   Refl  : âˆ€ x â†’ Ord x x
   Trans : âˆ€ x y z â†’ Ord x y â†’ Ord y z â†’ Ord x z

   -- Two default â€˜implementationsâ€™

   defaultâ‚ Ord x y                =  x â‰¡ y
   defaultâ‚ Refl  x                =  refl
   defaultâ‚ Trans _ _ _ refl refl  =  refl

   defaultâ‚‚ Ord x y                =  âŠ¤
   defaultâ‚‚ Refl  x                =  tt
   defaultâ‚‚ Trans _ _ _ _ _        =  tt
 #+end_src

 Notice how â€œfree typeâ€ formation incorporates this new open-ended
 construct, ~Ord~, as a two-value holder. An alternative interpretation would
 be to eliminate it altogether from the elaborated data declaration.
 Anyhow, since we elaborate a relation as a pair former, proofs for
 such a relation cannot be included ---otherwise it's not a â€œfreeâ€ type!
 {{{code(Derivied ADT from a package former with constructive relations)}}}
 #+begin_src haskell
PreOrderedTermData = PreOrderedTermP data
{-
â‰…  data PreOrderedTermData : Set where
     Var : Int â†’ OrderedTermData
     Add : PreOrderedTermData â†’ PreOrderedTermData â†’ PreOrderedTermData
     Ord : PreOrderedTermData â†’ PreOrderedTermData â†’ PreOrderedTermData

     -- No reflexitivity axiom on â€˜Ordâ€™, nor transitivity!
-}
 #+end_src
 {{{code(Using a ~default~ implementation)}}}
 #+begin_src haskell
PreOrderedTermData = PreOrderedTermP data with-defaultâ‚
{-
â‰…  data PreOrderedTermData : Set where
     Var : Int â†’ OrderedTermData
     Add : PreOrderedTermData â†’ PreOrderedTermData â†’ PreOrderedTermData

     -- No â€˜Ordâ€™ construction, but instead a constructive relation and properties:

     Ord : PreOrderedTermData â†’ PreOrderedTermData â†’ Set
     Ord x y  =  x â‰¡ y

     Refl  : âˆ€ x â†’ Ord x x
     Refl  x  =  refl

     Trans : âˆ€ x y z â†’ Ord x y â†’ Ord y z â†’ Ord x z
     Trans _ _ _ refl refl  =  refl
-}
 #+end_src
 The naming ~Ord, Refl, Trans~ could have been altered to refer to the newly declared data
 type, for simplicity we have avoided such a transformation.
 Moreover, we could reserve ~with-defaultâ‚€~ to simply omit constructive relations from
 being reified as data constructors.

 {{{code(Keeping the axioms by using a record)}}}
 #+begin_src haskell
PreOrderedTermRecord = PreOrderedTermP record
{-
â‰…   record PreOrderedTermRecord : Set where
      field
    Carrier : Set
    Var     : Int â†’ Carrier
    Add     : Carrier â†’ Carrier â†’ Carrier
    Ord     : Carrier â†’ Carrier â†’ Set
    Refl    : âˆ€ x â†’ Ord x x
    Trans   : âˆ€ x y z â†’ Ord x y â†’ Ord y z â†’ Ord x z

     -- Notice that the reflexitivity & transitivity axioms are kept!
-}
 #+end_src
 Moreover, the default implementations means we also have the following
 declaration, where distinctions are made by the occurenace, or absence, of fields.
 {{{code(Defaults yield additional elaborations)}}}
 #+begin_src haskell
{-
    record PreOrderedTermRecord : Set where
      field
    Carrier : Set
    Var     : Int â†’ Carrier
    Add     : Carrier â†’ Carrier â†’ Carrier

      Ord     : Carrier â†’ Carrier â†’ Set
      Ord x y =  x â‰¡ y

      Refl    : âˆ€ x â†’ Ord x x
      Refl _ = refl

      Trans   : âˆ€ x y z â†’ Ord x y â†’ Ord y z â†’ Ord x z
      Trans _ _ _ refl refl = refl
-}
 #+end_src
 Here is our first observation of a uniform presentation of packaging,
 where the â€œintended useâ€ differs: Whether we want axioms or not?

 Not only is the use amicable, but utilities written for the first elaboration
 effortlessly apply to instances of the second elaboration. Unfortunately,
 the relationship is not symmetric
 ---e.g., using the additional information provided by the default implementations,
  ~âˆ€ x y â†’ Ord x y â†’ Add x y â‰¡ Add y x~ is provable for the latter but
 not the former. As such, there is need to be able to mark results applying
 to a subtype of a package former, or to eliminate such a desirable feature
 that reduces needless distinctions when applying utilties of the former to the
 latter. The thesis will provide a solution with a discussion of the alternatives
 and why they were not adopted.

***** Package Formers Dispense with The Diamond Problem

 Let's consider combining multiple containers.
 {{{code(A package former for unital magmas)}}}
 #+begin_src haskell
Package UnitalTermP (v : Variation) : Set inherits-from (TermP v) where
   unit : UnitalTermP v
   lid  : âˆ€ x â†’ Add unit x â‰¡ x
   rid  : âˆ€ x â†’ Add x unit â‰¡ x
 #+end_src
 # -- NB: Using â€œMaybeâ€, every â€œTermP recordâ€ can be converted into a â€œUnitalTermP recordâ€.
 {{{code(Inheriting from multiple pacakage formers)}}}
 #+begin_src haskell
Package PreOrderedMonoid (v : Variation) : Set
      inherits-from (UnitalTermP v; PreOrderedTermP v)
  where
   associative : âˆ€ x y z â†’ (Add x y) z â‰¡ Add x (Add y z)
   monotone    : âˆ€ x x' y y' â†’ Ord x x' â†’ Ord y y' â†’ Ord (Add x y) (Add x' y')
 #+end_src
 This package ought to be indistinguishable from the following, whence allowing tremendously flexible
 declarations and uses. In particular, there is no longer a need to distinguish between a hierarchical
 and a flattened perspective, since they are considered identical.
 {{{code(Equivalent backend representation)}}}
 #+begin_src haskell
Package PreOrderedMonoid (v : Variation) : Set where

   unitaltermp : UnitalTermP v
   preorderedtermp : PreOrderedTermP v

   associative : âˆ€ x y z â†’ (Add x y) z â‰¡ Add x (Add y z)
   monotone    : âˆ€ x x' y y' â†’ Ord x x' â†’ Ord y y' â†’ Ord (Add x y) (Add x' y')

   -- From which sub-structure does the above â€œAddâ€ arise?
   --
   -- The â€œrecordâ€ and â€œtypeclassâ€ variations elaborate with axioms declaring
   -- that identical names are indeed identical operations:
   carrier_coherence : unitaltermp.Carrier â‰¡ preorderedtermp.Carrier
   var_coherence     : unitaltermp.Var     â‰¡ preorderedtermp.Var
   add_coherence     : unitaltermp.Add     â‰¡ preorderedtermp.Add
   --
   -- They also elaborate with default tedious implementations:
   carrier_coherence = refl; var_coherence = refl; add_coherence = refl

   -- Moreover, we can continue the â€˜defaultâ€™ implementation.
   defaultâ‚ monotone _ _ _ _ refl refl = refl
   defaultâ‚‚ monotone _ _ _ _ _ _       = tt
 #+end_src

***** Package Formers & Representational Shifts

 Let us close this section by demonstrating how this genericity can aid in
 ubiquitous representational shifts that appear rather often in dependently typed programming.
 In pedestrian languages, there are usually less ways to accomplish a task in
 dependently typed languages and so programming style is not of great concern.
 In contrast, in a DTL, a user could, for example, work over an abstract data type
 where a particular argument is fixed or where it is allowed to vary.
 The two approaches are a matter of style, but can lead to awkward situations.
 # The downside of the former is that we cannot vary, whereas in the latter

 # context shifting; Î»-introduction; â‡’-theorem.
 #
 More concretely, we consider the bread and buffer of coding: Graphs.
 Without dependent types we can only speak about graphs /over/ a given vertex type,
 with dependent types we can speak about /a/ graph, irrespective of vertex type.
 The former is tantamount to the context ~Vertex âˆ¶ Type âŠ¢ Edges âˆ¶ Vertex â†’ Vertex  â†’ Type~,
 and an empty assumption context ~âŠ¢ Vertex âˆ¶ Set, Edges âˆ¶ Vertex â†’ Vertex â†’ Type~
 for the latter.
 However, the latter form sometimes leads us into contexts where we have two
 graphs ~G~ and ~H~ for which we make the tedious constraint {{{newline}}} ~Vertex G â‰¡ Vertex H~.
 It would be less clumsy to explicitly declare the two graphs to be /over/ the
 same vertex type.

 The previous paragraph mentioned a terse dependently-typed presentation of graphs,
 let us use the classic presentation as it may be more familiar to readers.
 {{{code(Graph package former)}}}
 #+begin_src haskell
PackageFormer GraphP (v : Variation) : Set where
  Vertex, Edges : Set
  src, tgt      : Edges â†’ Vertex

  -- The dependently typed notion of edges.
  derivied
    _âŸ¶_ : Vertex â†’ Vertex â†’ Set
    x âŸ¶ y  =  Î£ e : Edges  â€¢  src e â‰¡ x  âˆ§  tgt e â‰¡ y
 #+end_src

 {{{code(Graphs as records)}}}
 #+begin_src haskell
AGraph = GraphP record renaming (Carrier to â€œVertexâ€)
{-
â‰…   record AGraph : Set where
      field
    Vertex Edges : Set
    src    tgt   : Edges â†’ Vertex
-}

-- NB. The implicitly generated name â€œCarrierâ€ has been identified with
-- the *declared* name â€œVertexâ€. This is acceptable since they have the same type.
-- Without the identification, the record elaboration would have provided a
-- third type field named â€œCarrierâ€.
 #+end_src
 {{{code(Parameterised graphs as typeclasses)}}}
 #+begin_src haskell
GraphOver = TermP typeclass renaming (Carrier to â€œVertexâ€)
{-
â‰…   record GraphOver (Vertex : Set) : Set where
       field
      Edges   : Set
      src tgt : Edges â†’ Vertex
-}
 #+end_src
 With these in hand, our goal is to replace the following first line with the second.
 However, since both types ~GraphOver~ and ~AGraph~ are declared as one liners,
 such a transition is a cheap as possible.
 #+begin_src haskell
(G H : AGraph) â†’ Vertex G â‰¡ Vertex H â†’ â‹¯

(V : Set) â†’ (G H : GraphOver V) â†’ â‹¯
 #+end_src
 In order to /replace a semantic constraint with a syntactic constraint/
 the user simply need to use a /variant/ on packaging. Furthermore, we
 are ensured {{{newline}}} ~AGraph â‰… Î£ V âˆ¶ Set â€¢ GraphOver V~.

 Dependently-typed graphs are an curious structure. With a bit of renaming, and adding a few laws,
 we obtain a â€˜setoidâ€™ --i.e., an undirected graph where every node has a self-loop, and paths
 correspond are essentially edges.
 {{{code(Setoid package former)}}}
 #+begin_src haskell
PackageFormer SetoidP (v : Variation) : Set where
  -- Graph structure
  Carrier : Set
  _â‰ˆ_     : Carrier â†’ Carrier â†’ Set
  -- Properties
  refl  : âˆ€{e}     â†’ e â‰ˆ e
  sym   : âˆ€{d e}   â†’ e â‰ˆ d â†’ d â‰ˆ e
  trans : âˆ€{c d e} â†’ c â‰ˆ d â†’ d â‰ˆ e â†’ c â‰ˆ d
 #+end_src
 A non-dependently-typed â€˜signatureâ€™ of a structure is generally obtained by discarding the relational operators
 and all properties. For ~SetoidP~ one would immediately think the signature consists of just ~Carrier~.
 However, if we view it instead as undirected graphs with self-loops at each node and edge-transitivity, then
 one would say the signature is the vertices ~Carrier~ and the edges ~_â‰ˆ_~. It is thus not clear when an item,
 ~_â‰ˆ_~ or ~_âŸ¶_~, forms constructive proofs or provides a type family. As such, signature extraction thus requires
 a parameter identifying which elements constitute â€˜proof matterâ€™ ---then one simply filters a pacakge-former
 against this criterion to obtain the associated signature. More generally, this allows us to take an ~X~ structure
 and obtain may of its the associated views about where knowledge is consolidated cite:realms, including:
 #+BEGIN_SRC haskell
X         = âŸ¨ Carrier; Operations; Properties âŸ©     -- C.f., SetoidP
XOver C   = âŸ¨ Operations; Properties âŸ©
IsX C Ops = âŸ¨ Properties âŸ©
XSig      = âŸ¨ Carrier; OperationsâŸ©                  -- C.f., GraphP
 #+END_SRC
 Having the signature in hand, one can easily and mechanically generate many derivied concepts.
 For example, a â€˜homomorphismâ€™ is a family of functions of the underlying sorts such that
 the given operations are preserved. Likewise, equality of homomorphisms is extensional equality of
 the underlying maps. One can then generate closed and open terms and their interpretation functions.
 With this approach to signature extraction, we can use the same algorithms
 for the production of, say homomorphisms or other constructs, on completely
 different algebraic structures, whether they be monoids or graphs.
 Moreover, this implies that concepts generally not considered for a class
 of algebras can easily be derived and experimented with; likewise for exploring
 new algebraic theories.
 These matters are an application, rather than a goal, of our envisioned system.

 :Neat_but_irrelevant:
 Sometimes constraints on an item can be derived, leaked by a signature.

 E.g., the signature of sets, on a carrier, leaks that the carrier necessary
 has decidable equality.
 :End:

 The curiosity of graphs is that they are one of the simplest /two-sorted/ structures
 and one of the most common in computing. Counter to intuition, existing packaging
 systems, namely canonical structures and typeclasses, are oriented toward having
 a distinct parameter: They cannot work well with multi-parameters; like classical
 single-sorted algebra. However, the both /aim to solve a usability problem:/
 /Having to spell out everything is too tedious./ Typeclasses are essentially dictionary look-up,
 having unicity as an issue. Whereas canonical structures require familiarity with how unifer works
 --we provide enough information to the unifer to find the desired structure-- but, in general,
 canonical structures do not scale. It is one of the thesis efforts to ensure the the unionised
 approach scales by a complex example with clear avenues of extension.

 It should be clear from these examples that package formers provide
 expectant generality, including the common uses one is mostly interested in.
 What about unexpected uses? What if a user wishes to utilise a representation
 we did not conceive of? They should be able to use the existing language to
 form it.
**** Second Observation: Computing Similarity for Containers

 By necessity of the first corollary, we are forced to utilise a uniform language
 between the varying notions of packaging thereby relegating their treatment
 to be a normal aspect of a language's core vernacular, rather than an extra-linguistic feature.
 The previous examples hint at possible issues regarding well-definedness of certain constructs.
 Moreover, we only elaborated on a few compositional operations,
 ~inherits-from, renaming, decorated~, yet users
 may well wish to utilise their own compositional schemes and so it is imperative that we allow
 them such a flexibility.
 Consequently, users ought to be able to define their own compositional mechanisms, thereby
 necessitating that they be able to manipulate package declarations themselves
 which in-turn forces the language to be somewhat homoiconic. Moreover, to avoid a hierarchy
 of languages, the facility for manipulating package declarations must itself be a part of
 the core language, rather than an extra-linguistic feature ---c.f., Coq's Ltac.

 In our envisioned setup, every ~PackageFormer~ declaration adds a clause to a special
 function,
 {{{code(Under the hood)}}}
 #+begin_src haskell
packageInfo : PackageFormer â†’ PackageInfo
packageInfo = âŸªcompiler definedâŸ«
 #+end_src
 Where a ~PackageInfo~ consists of ~Name~, which is a list of parameter names and types, along with the name of the package former;
 and ~Declarations~, a list of name-type pairs whose last element is the target type.
 {{{code(PackageInfo: Just another package ---for â€œsignaturesâ€)}}}
 #+begin_src haskell
{- Draft: Lots of string manipulation, not ideal. -}
record PackageInfo : Set where
  field
    Name         : List (String Ã— String) Ã— String
    Declarations : List (String Ã— List String)
--
-- This is just another package,
-- it incidentally happens to be the representation of packages!
 #+end_src

 It is to be noted that there is no commitment to a string-based representation.
 It is only a prototype and the thesis will likely move to a better typed
 representation ---otherwise, we may run into too many problems of ill-formed
 package formers.

 {{{code(Recall our example package former)}}}
 #+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
  Var : Int â†’ TermP v
  Add : TermP v â†’ TermP v â†’ TermP v
 #+end_src
 The above declaration provides, under the hood, the following clause to ~packageInfo~.
 {{{code(Under the hood)}}}
 #+begin_src haskell
packageInfo TermP = record { Name         = ["v", Variation] , "TermP"
               ; Declarations = [ ("Var", ["Int", "TermP v"])
                        , ("Add", ["TermP v", "TermP v", "TermP v"])
                        ]
               }
 #+end_src
 # Note the â€˜vâ€™, whence String not Set in the defn of PackageInfo.

 We are now in a position to provide the semantics for the keyword ~Declare~,
 from the previous section. It takes a ~PackageInfo~ and declares a ~PackageFormer~.
 There should be a compile-time warning if such declarations are meaningless, ill-formed.

 For example, the previous {{{newline}}} ~Declare PackageFormer TermRelP (v âˆ¶ Variation) decorated (Î» x â†’ x ++ "â€²")~
 can thus be obtained by a user by defining ~decorated~ as an operation on packages!
 {{{code(User-defined composition scheme)}}}
 #+begin_src haskell
_decorated_ : PackageInfo â†’ (String â†’ String) â†’ PackageInfo
pk decorated f = record { Name         = bimap id f pk.Name
            ; Declarations = fmap (bimap f id) pk.Declarations
            }
 #+end_src

 To rectify the seemingly wild mixfix notions, we request from the compiler
 the following suitably general syntactic sugar.
 An operation, call it, ~altered-by~ of the type ~PackageInfo â†’ List PackageInfo â†’ List X â†’ PackageInfo~
 automatically obtains the syntactic sugar ~p altered-by (q0; â€¦; qk) with (f0; ...; fN)~ ---c.f., the ~inherits-from~ syntax above.

 # Woah! Look at how easy that was, no need to build it in!

 With such terse functional programs for forming composition schemes,
 there is no need to build much into the compiler.

 Users can define other similar operations, such as ~decorated-rounded~
 which replaces the first two binary relations' names with ~âŠ†~ and ~âŠ‚~;
 or ~decorated-square~ to make the renamings ~âŠ‘~ and ~âŠ~.
 Additionally, such renames would propagate into any axioms or derived laws.
 Moreover, the flexibility to invoke such operations in complex ways allows for
 intricate renamings to be generated at tremendous scale without worry that
 future renames would need to be made if the orginal packages included new items.
 Numerous examples of such renaming transpire manually in the impressive
 RATH cite:RATH development, as well as in Agda's standard library.

 When working with multiple values of the same record type, for example,
 one encounters a usability problem: Refereeing to the constituents without being verbose.
 The simplest solution is to qualify each invocation, as in ~instance.field~, however this
 is rather cumbersome, inelegant, and is awkward for mixfix names. An alternative is to
 locally rename the fields according to a scheme reflecting their use. For example, in
 a produce construction of 5 items, the field names would be renamed to have a subscript number.
 In a setting of two instances, a user may instead prefer a primed and an undecorated version
 of field names. Thus far, by hand we have created these tedious subscript and primed renamings,
 with our envisioned systems, we need no longer worry about such boilerplate.

 In nearly the same fashion, a user could have defined the ~inherits-from~ compositional scheme.
 Such a scheme may assume that all identically named items have the same types, and crash otherwise.
 A user could define a better scheme that takes a renaming function, or another function to handle
 the crash, or simply omitt conflicting names altogether.
 The examples suggest that many commonly occurring compositional mechanisms cite:tpc
 can be directly provided by a library, rather than by a particular compiler
 ---this includes the ability to hide fragments, expose the largest well-defined fragment,
 and to combine packages along a given substructure.

 Rather than select what we think is best, we can simply provide the general mechanism to the
 library designer and allow them the freedom to provide their own schemes.

**** Next Steps

 Our brief examples demonstrate that the less design decisions about packaging
 made by language designers, the more general, applicable, and, most importantly, increased homogeneity
 in the resulting datatype language without becoming unityped but rather thanks to being dependently-typed.
 As mentioned in the previous section on existing approaches, one formalism for
 packages is that of theories and theory combinators; below we thus draw on some problems from theory combinators
 rendered toward packaging systems.

 We have mentioned that the ~record~ and ~typeclass~ perspectives solve the common requirement of
 structures sharing an identical field. Other than that, we have essentially only
 outlined a general mechanism for declaring packages and compositional schemes, but have not
 discussed which are the most common and most useful packaging combinators.
 It is also desirable to discuss the formal properties of such combinators
 ---if anything, to ensure they are sensible and behave as expected.
 Moreover, which combinators act as a basis for all packaging combinators?
 Whence their use ensures the resulting composition is well-formed
 and they could be targeted for optimisations.
 #  Soundness & Completeness proofs?

 To make our approach accessible, the generic package operations are brought to the user
 rather than baked into the compiler ---too great a distance for most users.
 The ~Declare~ syntax reifies ~PackageInfo~'s into package declarations, but we have not mentioned
 under what constraints it can actually provide compiler-time, or typechecking-time,
 errors of ill-formedness. Moreover, how (in)efficient is this process?
 Could it be extended to work on variable, runtime provided, declarations
 for refying packages? Perhaps there is a constraint that suffices for the most common cases?
 Moreover, having observable ~PackageInfo~'s being automatically generated for every package declaration
 renders representation hiding nearly moot.

 The proposed approach boarders on meta-programming.
 Can type erasure and other compiler-specific optimisations be brought into
 the homoiconic-like setting being pursued here?
 We have mentioned a few â€˜built inâ€™ variations for packaging; can such a feature
 be liberated from the compiler and be bent to the users' will?
 We would need the ability to explain how a package elaborates.

 Tremendous flexibility is demanded from the back-end so as to ignore needless distinctions
 at the users' level. Whereas the practicality is promising, the feasibility of an
 implementation for such ambiguous parsing cite:ambiguous_parsing is unclear.
 It is also unclear what effects identifying syntactically distinct items
 has on, say, normalisation and propositional equality.

 The numerous claims and associaited bookkeeping of details pushes us into using a proof assistant, Agda.

 Our examples have been â€˜variationâ€™ polymorphic;
 we have been even more generic by defining ~decorated~.
 What are the limits of programming genericity provided by our scheme?
 It would unsurprising if this approach yields
 the next 700 module systems.

** Approach and Timeline
   :PROPERTIES:
   :CUSTOM_ID: approach_and_timeline
   :END:


 Packages, modules, classes, (dependent) records, (named) contexts, telescopes, theories, specifications
 ---whatever you wish to call them are essential structuring principles that
 enable modularity, encapsulation, inheritance, and reuse in formal libraries and programs.
 Moreover, as we have demonstrated, with the exception of use-cases,
 there are no significant differences between them in a dependently-typed setting, as cite:theories_as_types present a type theoretic calculus
 of a variant of record types that corresponds to theories.

*** Implementation Matter

 We will realise our proposal in an existing compiler
 and so working with it necessitates our implementations to be more than
 just â€˜research qualityâ€™ but actually ready for a broad audience.

 Which compiler and for which language?

 Since our attention is focused on dependently typed languages within the
 realm of @@latex: Martin-L\"{o}f's@@ Type Theory
 cite:lof_constructive_math}, Agda \parencite{agda_web is a natural
 candidate.

 Agda is currently one of the most used tools for proof and program experimentation
 involving dependent types. With its support for mixfix Unicode lexemes, it has
 become a strong competitor to Coq cite:coq_website,coq_inductive_coc, coq_coc} for both proof construction \parencite{agda_fixpoints, agda_quantifier_elim, agda_nondeterministic, agda_mergesort, agda_type_Safety, agda_aop
 and general program construction cite:agda_web, agda_trains, agda_bitcoin, agda_hardware
 ---Agda's lack of /syntactic/ distinction between
 programs and propositions, along with its pattern matching utilities in-place of
 â€˜tactic sledgehammersâ€™ cite:tactics, it has also become an attractive
 language for introducing dependent types and functional programming
 cite:agda_iowa_book, agda_plf, agda_teaching. With its syntactic similarity to Haskell, many Agda users treat
 their Agda code as if it were lazy with the ~let~ and ~where~ clauses preserving sharing
 ---which is not the case, since such clauses rewrite to top-level functions
 cite:agda_docs.
 Instead, Agda's evaluation strategy is normal order: Function definitions
 are invoked before arguments are evaluated, but computations of arguments
 are /not/ shared. This is a prime location for efficiency issues since type-checking
 in a dependently typed language tends to involve evaluation of terms.
 Surprisingly this has not stopped users from producing large-scale software
 developments cite:RATH, agda_trains, agda_web.

 # for agda's evluation strategy, see also
 # https://stackoverflow.com/questions/21210569/is-the-evaluation-strategy-of-agda-specified-anywhere

 Needless to say,
 a poor choice of elaboration strategy can lead to a loss of sharing
 ---not that Agda has sharing to begin with---,
 contain too many undesirable side-effects, hinder efficiency, or forgo compile-time optimisations.
 For example,
 Agda, as currently implemented using the Glasgow Haskell Compiler (GHC), is a realisation
 of @@latex: Martin-L\"{o}f's@@ Type Theory (MLTT) that is heralded as
 both a programming language and proof assistant.
 Unfortunately MLTT, as many other dependent logics
 ---such as the Calculus of Constructions with inductive types, which underlies both
 the Coq and Lean proof assistants---
 does not account for modules, thereby leaving these as consistency-preserving hacks thrown onto the implementation.
 As mentioned earlier, Agda simply rewrites modules into top
 level functions with module parameters realised as parameters to the resulting functions.
 This is an implementation detail and has little impact on theory construction,
 however, code reuse becomes unreasonably slow
 due to the loss of sharing that happens when module arguments need to be
 re-normalised in each function-counterpart.
 Consequently, only a minor subset of the Agda community actually /executes/ their
 programs. The rest of the community is generally content with type checking only;
 which does not hinder the reliability of proof.

 It is important to note that we employ Agda only as a proof-of-concept for
 our proposed exploration of first-class structuring-mechanisms in dependently typed languages.
 Admittedly Agda's support for Unicode mixfix lexemes makes it a pleasure to work
 in, with mechanised proofs being little work more than their LaTeX renditions.

*** Next Steps

 The approach we intend to follow consists of the following steps.
 Notice that feedback loop of practice into theory.

 :Weakness:
 1. Really study the other mechanisms that already exist.

    *Exhibiting such a weakness may suggest insufficient preparatory work!*
    *Possibly resulting in a fail!*

    - Survey module systems in theory, in existing DTLs, *and* in non-DTLs.

    - As far as we can tell, besides the MTT cite{mmt_main_paper, mmt_api}
      group, no one else is working on actually implementing
      solutions to the flaws we have identified, such as combination over
      structures.

    - This is promising in terms of novelty, if anything.

    - Analyse why there are not multiple implementations of such seemingly
      immensely useful concepts.

 :End:

 1. Distill the /true/ requirements for a solution;
    ensure good /fit for purpose/ criteria exists.

    - Understand the requirements of `modularity mechanisms' for DTLs.
    - Narrow down a design by choosing a set of requirements.
    - Identify necessary, and practical, trade-offs.
      Conflicting feature sets? Usability?
    - Ideally we want our implementations to avoid too much overhead,
      such as creating an entire new language; this may necessitate the
      weakening of other functionality.

 2. Deepen understanding of the opportunities given by DTL.

    - Understand the relationships between
       modules, records, contexts, telescopes, and signatures.
      * Do they have differing `types'?
      * As types themselves, do they have differing `values'?
      * In the setting of DTLs, are they essentially isomorphic?
      * What are the intended uses? What intentions do particular choices communicate?
        - E.g., â€œ$x = y$â€ communicates an equality and nothing more, whereas
      â€œ$x\! \iff\! y$â€ communicates a Boolean equality: A redundant, particularised, equality
      symbol serves to succinctly and elegantly communicate more information.

 3. Formulate basic, draft, semantics for a small set of DTL module primitives.

    - What is the type of a package former?
    - How does it fit into Agda's existing type hierarchy?
    - What are the types of the primitives themselves?
      + We wish to avoid metaprogramming
        after all, and so wish to remain within the language rather than
        in a metalanguage.

 4. Prototype some mechanisms; a combination of old, adapted, and novel ones
    to demonstrate the power of the system.

    + Implement the structuring mechanism combinators discussed earlier
      ---such as combination over common-substructures.

      + Possibly begin with reifying first class grouping mechanisms by
        representing contexts ---i..e, sequences of declarations with optional definitions---
        as records in Agda with the undefined declarations being fields and the rest being
        derived or definitional.

 5. Evaluate the mechanisms ---using fit-for-criteria.

    + Since the realisation would be in Agda, we would keep in touch with the community
      to ensure that the additions contribute to program design.

    + Evaluate the strength of the resulting additions in terms
      of practical use for library designers as well as in terms of program speed.

 6. Make sure to have a denotational semantics for the mechanisms.

    + Ensure that the additions are minimal, orthogonal, and construct a sound
      type theory around them.

 7. Refine 2-6 until elegance, or deadline, is reached, whichever comes first.

 # More importantly, as our results will likely need to be re-proven for definitional adjustment,
 # we intend to /mechanise/ all of our proofs in Agda as well ---when possible.
 # Therefore, Agda plays multiple roles: A dependently-typed language to experiment
 # with, as well as a proof checker for our results.

 Our timeline will discuss how we will carry out this approach in multiple
 passes and will discuss the conditions of a successful pass.

*** Timeline

 We shall iterate through the `approach phase' three times,
 utilising a feedback loop of practice into theory.
 The phases are discussed below.

 As our results will likely need to be re-proven for definitional adjustment,
 we intend to /mechanise/ all of our proofs in Agda as well ---when possible.
 Therefore, Agda plays multiple roles: A dependently-typed language to experiment
 with, as well as a proof checker for our results.

**** The First Pass: May-October 2019
 This stage concludes successfully provided the following checkpoints are achieved.

 + A thorough understanding of what is being done by others, and how
   our approach differs, is obtained /and/ documented.

 + Understand the Agda compilation ecosystem, provide a report on how to make
   alterations to it, and actually implement at least one structuring mechanism
   and provide use cases as well as preliminary efficiency analysis.

 + A publication covering existing mechanisms, their features and flaws,
   and possibly an explanation of why there is theoretical work on these issues
   but little to no implementation on them
   ---with a focus on practical uses and possible hurdles to use.

   - A side-effect of this is to produce an evaluation strategy for the mechanisms.
   - Moreover, this necessitates looking into the associated semantics,
     evaluating them, and proposing semantics for the mechanism we have designed.

 + Thesis writing should have begun and nearing completion are sections
   on introduction and background.

**** The Middle Pass: November 2019 - February 2020
 This stage concluded successfully provided the following checkpoints are achieved.

 + The success of the previous stage ensures an understanding of the Agda compilation
   ecosystem, as such it should take less time to implement the more mechanisms,
   theory combinators. The goal is to have the remaining mechanisms implemented,
   with a focus on the combination-over-a-structure mechanism.

   - With each implementation, reach-out to the Agda community to solicit
     feedback regarding improvements and possible use cases.

 + Extending the semantics for the newly implemented mechanisms.

   - Evaluating which mechanisms are more primitive, which are derived, and
     which can be used to /allow users to make their own *using* the concrete language itself/!

 + A publication of case studies utilising these combinators, as well as
   a comparison of how these are an improvement over traditional methods.

   - Analysing the interactions between features; does the addition of one
     hinder another.

   - Empirical tests for efficiency and utility.

 + Thesis writing should have progressed with sections on
   use cases, semantics, and feature design,
   having substantial matter if not nearing completion.

**** The Final Pass: March - April 2020
 This stage concluded successfully provided the following checkpoints are achieved.

 + Ensure that our implementations are meeting our requirements for a solution.

 + Begin mechanisation of proofs authenticating that the denotational
   semantics has desired, expected, properties; such as soundness and safeness.

**** Concluding Phase
 Wrap up all proof matters and finish the thesis.

 Suffice to say life tends to be more hectic than a schedule may permit
 and as such some times may deviate from the above intentions.
 Regardless, the goal will be to complete the thesis within 2 years time;
 in particular before September 2020.
** Conclusion
   :PROPERTIES:
   :CUSTOM_ID: conclusion
   :END:

 As already discussed,
 more often than not a module system is an afterthought secondary citizen
 whose primary purpose is to act as a namespace delimiter
 ---e.g., C#'s ~namespace~ construct---
 while relatively more effort is given to their abstraction encapsulation
 counterpart, e.g., C#'s ~class~'es.
 Some languages' module systems blend both namespace management and
 implementation hiding, e.g., as in the Haskell programming language.
 Other languages such as OCaml take modules even further: Not only are modules
 used for namespace organisation and datatype abstraction, but they can also be
 passed around as values for manipulation as if they were nothing special, thereby
 collapsing the distinction between record constructs and organisational constructs.

 The proposed research is to build upon the existing state of module
 systems and develop an extension to a compiler to substantiate our claims,
 and to ultimately discover new semantical relationships between programming
 language constructs in a dependently typed setting with modules as first-class
 citizens. This involves redesigning and enhancing existing module systems
 to take into account dependent types as well as producing rewrite theorems
 to ensure acceptable performance times.

 Intended outcomes include:
   1. A clean module system for DTLs
      + Dependent types blur many distinctions therefore rendering certain
        traditional programming constructs as inter-derivable and so only
        a minimal amount need be supported directly, while the rest can be
        defined within the extended type theory we will be creating.
        Since modules are records, which are
        one-field algebraic data types, and we can form sums of modules, it
        would not be surprising if first-class modules suffice for arbitrary data type
        definitions.

        # syntactic sugar â‰ˆ pre-processing

   2. /Utility Objectives/: A variety of use-cases contrasting the resulting system with previous
      approaches. In particular, the system should:

      + Reduce amount of â€˜noiseâ€™ necessary for working with grouping mechanisms in a number of ways.
      + It should be easy and elegant to use and, possibly, to extend.
   3. A module system that enables rather than inhibits (or worse) efficiency.
      + Currently Agda modules, for example, are sugar for extra functional parameters
        and so all implicit sharing in modules is lost at compilation time.
      + Deeply nested, deeply tagged, operations could be costly and so being apply
        to /soundly/ flatten modules and /soundly/ extract operations and results
        is a necessity when speed is concerned ---moreover, this needs to be mechanical and succinct if it is to be useful.
   4. Demonstrate that module features usually requiring meta-programming can be brought
      to the data-value level.
      + Names and types, for example, in a module should be accessible
        and alterable. For example, we can obtain a rig by combining two instances
        of a monoid module where we would rename the fields of one, or both, of them.
      + Thereby relegating abstract syntax tree and programs-as-strings manipulations
        to the edges of the computing environment.

 Most importantly, we intend to implement our theory to obtain
 validation that it â€œworksâ€!

 # It goes without saying, these are preliminary goals, as the outcomes are likely to
 # change and evolve multiple times as the research is carried out.

** COMMENT footer                                                    :ignore:

 Local Variables:
 eval: (progn (org-babel-goto-named-src-block "make-reports-class") (org-babel-execute-src-block) (outline-hide-sublevels 1))
 compile-command: (progn (org-babel-tangle) (org-latex-export-to-pdf) (async-shell-command "open thesis-proposal.pdf"))
 End:
* COMMENT Leftovers

** Let us conclude by attempting to justify the title of this thesis.

 Landin's /The Next 700 Programming Languages/ cite:seven_hundred_langs inspired a
 number of works, including
 cite:seven_hundred_tt_models,seven_hundred_provers,seven_hundred_hoas,seven_hundred_libraries,seven_hundred_data
 and more. The intended aim of the thesis is a requirements driven approach to
 coherent modularisation constructs in DTLs. In particular, we wish to extend
 Agda to be powerful enough to implement the module system features, in the core
 language, that people actually want and currently mimic by-hand or using
 third-party preprocessors. An eager fix would be to provide metaprogramming
 features, but unless one is altering the syntax or producing efficient code,
 this is glorified pre-processing ---it is a means to fake missing abstraction
 features. Moreover, metaprogramming would be a hammer too big for the nail we
 are interested in; so big that its introduction might ruin the soundness of the
 DTLs ---e.g., two terms may be ill-typed and ill-formed, such as ~x +~ and ~5 = 3~,
 but are meaningful when joined together, as in ~x + 5 = 3~. Our aim is to provide
 just the right level of abstraction so that, if anything, users can write a type
 of container or method upon it then derive â€˜700â€™ simple alternate views of the
 same container and method.

 To be clear, consider a semi-ring ---or any simple record of 17 different kinds
 of data. A semi-ring consists of two monoids ---each consisting of a total of 7
 items of data and proof matter--- where one of them is commutative and there are
 two distributivity axioms. Hence, a semi-ring consists of 17 items. If we wanted
 to expose, say, 3 such items ---for example, the shared carrier and the
 identities of each monoid--- then there are a total of $\binom{17}{3} = 680$
 ways, and if we jump to 4 items we have $\binom{17}{4} = 2380$ possible forms.
 Of course these numbers are only upper bounds when record fields depend on
 earlier items. In section 3, we provide explicit examples of different
 structural presentations of packages.

 Usually, library designers provide one or two views, along with conversion functions,
 and commit to those; instead we want to liberate them to choose whatever presentation
 is convenient for the tasks at hand and to work comfortably with the guarantee that
 all the presentations are isomorphic. Humans should be left to tackle difficult and
 interesting problems; machines should derive the tedious and uninteresting
 ---even if it's simple, it saves time, is less error-prone, and clearly communicates
 the underlying principle.

 If anything, our aim is practical ---to save developers from ad hoc copy-paste
 preprocessing hacks.

** COMMENT Introduction to diy modules

    A fundamental argument for the use of module systems in the design of large
  programs is that the structure of the program is partitioned into coherent
  semantical units that are furnished with an interface belying the complexity of
  their implementations. A well-established example is the use of the humble
  record to â€˜bundleâ€™ up the extensional properties of an object; here one works
  with objects as if they were atomic, rather than considering the
  collection of their identifying properties.  Users of dependently-typed
  languages like Agda and Coq will argue strongly that the effective use of
  module systems is extremely important for subsequent program development, and
  even users of dynamically typed languages like Javascript will admit that, for
  example, namespace violations are an area of concern.  A fundamental aspect of
  =PackageFormer= is that the relationship between a grouping mechanism and its
  constituent structuring sub-grouping mechanisms is made explicit: One extracts
  grouping mechanisms from declarations involving existing grouping mechanisms.
  In contrast to type theory wherein a type is specified by characterising how
  its elements may be formed, our approach allows both the building-up of
  grouping mechanisms from their parts and, also, the â€˜tearing downâ€™ of parts of
  existing grouping mechanisms ---as is the case of dropping a property from a
  record type to obtain another record type, or of transforming a record type
  into an algebraic data type.  Depending on their nature, grouping
  specifications may either allow the automatic derivation of â€˜introduction
  rulesâ€™ wherein the teared-down grouping is transformed into the new grouping,
  or allow â€˜elimination rulesâ€™ wherein the individual groupings that built-up the
  new grouping can be identified.  The semantics of a grouping specification
  is essentially the â€˜flatteningâ€™ of properties that extensionally constitute it.
  Our work describes the necessary primitives that allow grouping declarations.

  The intention is not to provide a fixed set of general-purpose grouping
  combinators that are sufficient to encompass all the future needs of all
  programmers but to provide a small kerneal of â€˜meta-primitivesâ€™ whereby
  programmers may invent their own grouping mechanisms peculiar to their own
  problem domain.

* Bib                                                                :ignore:
# LaTeX: \addcontentsline{toc}{section}{References}
#+LaTeX: \addcontentsline{toc}{part}{References}
#+LaTeX: \printbibliography
